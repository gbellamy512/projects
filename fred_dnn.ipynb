{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# set seed for reproducibility\n",
    "random_seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP</th>\n",
       "      <th>GDPC1</th>\n",
       "      <th>GDPPOT</th>\n",
       "      <th>CPIAUCSL</th>\n",
       "      <th>CPILFESL</th>\n",
       "      <th>GDPDEF</th>\n",
       "      <th>M1V</th>\n",
       "      <th>M2V</th>\n",
       "      <th>DFF</th>\n",
       "      <th>UNRATE</th>\n",
       "      <th>...</th>\n",
       "      <th>MANEMP</th>\n",
       "      <th>DSPIC96</th>\n",
       "      <th>PCE</th>\n",
       "      <th>PCEDG</th>\n",
       "      <th>PSAVERT</th>\n",
       "      <th>DSPI</th>\n",
       "      <th>INDPRO</th>\n",
       "      <th>HOUST</th>\n",
       "      <th>GPDI</th>\n",
       "      <th>MSPUS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1963-01-01</th>\n",
       "      <td>621.672</td>\n",
       "      <td>3628.306</td>\n",
       "      <td>3662.738125</td>\n",
       "      <td>30.44</td>\n",
       "      <td>31.5</td>\n",
       "      <td>17.134</td>\n",
       "      <td>4.178</td>\n",
       "      <td>1.690</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.7</td>\n",
       "      <td>...</td>\n",
       "      <td>15545.0</td>\n",
       "      <td>2541.1</td>\n",
       "      <td>374.4</td>\n",
       "      <td>53.1</td>\n",
       "      <td>10.9</td>\n",
       "      <td>430.0</td>\n",
       "      <td>26.0448</td>\n",
       "      <td>1244.0</td>\n",
       "      <td>99.689</td>\n",
       "      <td>17800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963-04-01</th>\n",
       "      <td>629.752</td>\n",
       "      <td>3669.020</td>\n",
       "      <td>3701.698767</td>\n",
       "      <td>30.48</td>\n",
       "      <td>31.7</td>\n",
       "      <td>17.164</td>\n",
       "      <td>4.194</td>\n",
       "      <td>1.675</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.7</td>\n",
       "      <td>...</td>\n",
       "      <td>15602.0</td>\n",
       "      <td>2547.1</td>\n",
       "      <td>376.4</td>\n",
       "      <td>53.2</td>\n",
       "      <td>10.7</td>\n",
       "      <td>431.1</td>\n",
       "      <td>26.7473</td>\n",
       "      <td>1689.0</td>\n",
       "      <td>101.650</td>\n",
       "      <td>18000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963-07-01</th>\n",
       "      <td>644.444</td>\n",
       "      <td>3749.681</td>\n",
       "      <td>3741.388301</td>\n",
       "      <td>30.69</td>\n",
       "      <td>31.8</td>\n",
       "      <td>17.187</td>\n",
       "      <td>4.248</td>\n",
       "      <td>1.680</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.6</td>\n",
       "      <td>...</td>\n",
       "      <td>15646.0</td>\n",
       "      <td>2572.6</td>\n",
       "      <td>384.4</td>\n",
       "      <td>55.5</td>\n",
       "      <td>10.1</td>\n",
       "      <td>438.0</td>\n",
       "      <td>27.0445</td>\n",
       "      <td>1614.0</td>\n",
       "      <td>104.612</td>\n",
       "      <td>17900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963-10-01</th>\n",
       "      <td>653.938</td>\n",
       "      <td>3774.264</td>\n",
       "      <td>3781.880559</td>\n",
       "      <td>30.75</td>\n",
       "      <td>32.0</td>\n",
       "      <td>17.326</td>\n",
       "      <td>4.269</td>\n",
       "      <td>1.672</td>\n",
       "      <td>3.50</td>\n",
       "      <td>5.5</td>\n",
       "      <td>...</td>\n",
       "      <td>15714.0</td>\n",
       "      <td>2617.3</td>\n",
       "      <td>386.0</td>\n",
       "      <td>54.2</td>\n",
       "      <td>11.5</td>\n",
       "      <td>447.0</td>\n",
       "      <td>27.5578</td>\n",
       "      <td>1779.0</td>\n",
       "      <td>107.189</td>\n",
       "      <td>18500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964-01-01</th>\n",
       "      <td>669.822</td>\n",
       "      <td>3853.835</td>\n",
       "      <td>3822.450115</td>\n",
       "      <td>30.94</td>\n",
       "      <td>32.2</td>\n",
       "      <td>17.381</td>\n",
       "      <td>4.345</td>\n",
       "      <td>1.685</td>\n",
       "      <td>3.25</td>\n",
       "      <td>5.6</td>\n",
       "      <td>...</td>\n",
       "      <td>15715.0</td>\n",
       "      <td>2652.8</td>\n",
       "      <td>396.8</td>\n",
       "      <td>57.9</td>\n",
       "      <td>10.7</td>\n",
       "      <td>455.3</td>\n",
       "      <td>27.8820</td>\n",
       "      <td>1603.0</td>\n",
       "      <td>110.474</td>\n",
       "      <td>18500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                GDP     GDPC1       GDPPOT  CPIAUCSL  CPILFESL  GDPDEF    M1V  \\\n",
       "Date                                                                            \n",
       "1963-01-01  621.672  3628.306  3662.738125     30.44      31.5  17.134  4.178   \n",
       "1963-04-01  629.752  3669.020  3701.698767     30.48      31.7  17.164  4.194   \n",
       "1963-07-01  644.444  3749.681  3741.388301     30.69      31.8  17.187  4.248   \n",
       "1963-10-01  653.938  3774.264  3781.880559     30.75      32.0  17.326  4.269   \n",
       "1964-01-01  669.822  3853.835  3822.450115     30.94      32.2  17.381  4.345   \n",
       "\n",
       "              M2V   DFF  UNRATE  ...   MANEMP  DSPIC96    PCE  PCEDG  PSAVERT  \\\n",
       "Date                             ...                                            \n",
       "1963-01-01  1.690  3.00     5.7  ...  15545.0   2541.1  374.4   53.1     10.9   \n",
       "1963-04-01  1.675  3.00     5.7  ...  15602.0   2547.1  376.4   53.2     10.7   \n",
       "1963-07-01  1.680  3.00     5.6  ...  15646.0   2572.6  384.4   55.5     10.1   \n",
       "1963-10-01  1.672  3.50     5.5  ...  15714.0   2617.3  386.0   54.2     11.5   \n",
       "1964-01-01  1.685  3.25     5.6  ...  15715.0   2652.8  396.8   57.9     10.7   \n",
       "\n",
       "             DSPI   INDPRO   HOUST     GPDI    MSPUS  \n",
       "Date                                                  \n",
       "1963-01-01  430.0  26.0448  1244.0   99.689  17800.0  \n",
       "1963-04-01  431.1  26.7473  1689.0  101.650  18000.0  \n",
       "1963-07-01  438.0  27.0445  1614.0  104.612  17900.0  \n",
       "1963-10-01  447.0  27.5578  1779.0  107.189  18500.0  \n",
       "1964-01-01  455.3  27.8820  1603.0  110.474  18500.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('fred_230718.csv', index_col='Date', parse_dates=True)\n",
    "df = df.asfreq('QS')\n",
    "earliest_date = '1963-01-01'\n",
    "latest_date = '2021-10-01'\n",
    "# # filter df index to be between earliest_date and latest_date\n",
    "df = df.loc[(df.index >= earliest_date) & (df.index <= latest_date)]\n",
    "df.dropna(axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set target and create, train, validate, and test datasets and then scale and transform them so they will work better with the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'MSPUS'\n",
    "y = df[target]\n",
    "X = df.drop(columns=[target]).shift(1).dropna()\n",
    "y = y.loc[X.index] # Make sure y and X have the same rows after dropna\n",
    "\n",
    "# https://datascience.stackexchange.com/questions/15135/train-test-validation-set-splitting-in-sklearn\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size=0.25, random_state=random_seed)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)  # validation data should also be scaled\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Log-transform the target variable\n",
    "y_train_log = np.log1p(y_train)\n",
    "y_valid_log = np.log1p(y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's create functions to train and evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, \n",
    "                X_valid, y_valid,\n",
    "                layer_sizes=[100, 100], \n",
    "                activation=\"relu\", \n",
    "                kernel_initializer=\"he_normal\", \n",
    "                learning_rate=0.001, \n",
    "                epochs=100,\n",
    "                batch_norm=False,\n",
    "                l1_l2=False,\n",
    "                l1=.01,\n",
    "                l2=.01):\n",
    "\n",
    "    # Create a sequential model\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # Add batch normalization and dense layers according to the layer_sizes\n",
    "    for size in layer_sizes:\n",
    "        if batch_norm:\n",
    "            model.add(tf.keras.layers.BatchNormalization())\n",
    "        if l1_l2:\n",
    "            model.add(tf.keras.layers.Dense(size, activation=activation, kernel_initializer=kernel_initializer\n",
    "                                            , kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "        else:\n",
    "            model.add(tf.keras.layers.Dense(size, activation=activation, kernel_initializer=kernel_initializer))\n",
    "\n",
    "    # Add a final Dense layer with no activation\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "    # Create the optimizer with the custom learning rate\n",
    "    sgd = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=\"mse\", optimizer=sgd)\n",
    "\n",
    "    # Train the model using the scaled data\n",
    "    model.fit(X_train, y_train, epochs=epochs, validation_data=(X_valid, y_valid))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, log_target=False):\n",
    "    # When predicting, transform the predictions back\n",
    "    y_pred = model.predict(X_test)\n",
    "    if log_target:\n",
    "        y_pred = np.expm1(y_pred).flatten()  # inverse of np.log1p(), make it 1D\n",
    "\n",
    "\n",
    "    # compute the RMSE on the original scale\n",
    "    mse = np.mean(tf.keras.losses.MSE(y_test, y_pred))\n",
    "    print('Test set MSE:', mse)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print('Test set RMSE:', rmse)\n",
    "    rmspe = (np.sqrt(np.mean(np.square((y_test - y_pred) / y_test)))) * 100\n",
    "    print('Test set RMSPE (%):', rmspe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll test some different architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no regularization\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 1s 44ms/step - loss: 84.1387 - val_loss: 31.2523\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 22.6037 - val_loss: 14.2730\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 12.1391 - val_loss: 10.9895\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 8.6289 - val_loss: 9.2844\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 6.6809 - val_loss: 8.4116\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 5.4317 - val_loss: 7.4204\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5749 - val_loss: 7.0579\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.9673 - val_loss: 6.6243\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.5756 - val_loss: 6.6934\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.2403 - val_loss: 6.1534\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 2.9438 - val_loss: 6.0129\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 2.6888 - val_loss: 5.4369\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2.4834 - val_loss: 5.2246\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2.3206 - val_loss: 5.0139\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2.1431 - val_loss: 5.1144\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.9937 - val_loss: 4.9957\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.8505 - val_loss: 4.7287\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.7408 - val_loss: 4.5198\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.6303 - val_loss: 4.4258\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.5303 - val_loss: 4.2392\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.4426 - val_loss: 4.1709\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.3619 - val_loss: 4.0208\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.2786 - val_loss: 3.8859\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.2107 - val_loss: 3.7808\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.1705 - val_loss: 3.7099\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0936 - val_loss: 3.6325\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0256 - val_loss: 3.6806\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.9731 - val_loss: 3.5988\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9133 - val_loss: 3.3915\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8689 - val_loss: 3.3064\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8313 - val_loss: 3.3912\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7961 - val_loss: 3.1731\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7616 - val_loss: 3.2209\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7330 - val_loss: 3.1363\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7025 - val_loss: 3.2202\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6686 - val_loss: 3.1519\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6444 - val_loss: 3.1101\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6174 - val_loss: 3.1009\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6019 - val_loss: 2.9630\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5822 - val_loss: 2.9564\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5577 - val_loss: 3.0867\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5344 - val_loss: 2.8826\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5237 - val_loss: 2.9572\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5032 - val_loss: 2.8847\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4890 - val_loss: 2.8718\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4722 - val_loss: 2.8327\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4574 - val_loss: 2.8248\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4480 - val_loss: 2.6926\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4367 - val_loss: 2.7970\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4272 - val_loss: 2.6470\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4164 - val_loss: 2.5305\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4067 - val_loss: 2.6085\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3958 - val_loss: 2.5978\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3891 - val_loss: 2.6943\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3740 - val_loss: 2.7034\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3666 - val_loss: 2.5763\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3608 - val_loss: 2.5867\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3568 - val_loss: 2.5762\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3451 - val_loss: 2.6352\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3425 - val_loss: 2.5604\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3440 - val_loss: 2.5030\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3265 - val_loss: 2.5683\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3203 - val_loss: 2.4648\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3192 - val_loss: 2.5321\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3089 - val_loss: 2.6313\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3095 - val_loss: 2.4553\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3011 - val_loss: 2.6000\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2956 - val_loss: 2.4882\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2922 - val_loss: 2.5165\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2865 - val_loss: 2.5917\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2848 - val_loss: 2.5542\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2763 - val_loss: 2.4925\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2754 - val_loss: 2.4718\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2730 - val_loss: 2.4947\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2673 - val_loss: 2.5465\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2633 - val_loss: 2.4860\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2589 - val_loss: 2.4646\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2555 - val_loss: 2.4748\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2528 - val_loss: 2.4424\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2533 - val_loss: 2.4524\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2452 - val_loss: 2.4906\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2424 - val_loss: 2.4028\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2419 - val_loss: 2.4043\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2384 - val_loss: 2.4713\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2353 - val_loss: 2.4617\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2318 - val_loss: 2.4133\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2304 - val_loss: 2.4469\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2278 - val_loss: 2.4446\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2246 - val_loss: 2.3984\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2236 - val_loss: 2.3483\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2216 - val_loss: 2.2911\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2227 - val_loss: 2.3023\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2177 - val_loss: 2.4285\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2141 - val_loss: 2.4060\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2142 - val_loss: 2.3527\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2102 - val_loss: 2.3595\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2068 - val_loss: 2.3665\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2067 - val_loss: 2.3219\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2069 - val_loss: 2.3327\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2037 - val_loss: 2.3591\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Test set MSE: 28440980000.0\n",
      "Test set RMSE: 168644.53\n",
      "Test set RMSPE (%): 65.77751547532992\n"
     ]
    }
   ],
   "source": [
    "print('no regularization')\n",
    "model = train_model(X_train=X_train_scaled, y_train=y_train_log, X_valid=X_test_scaled, y_valid=y_valid_log)\n",
    "evaluate_model(model, X_test_scaled, y_test, log_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch norm regularization\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 1s 39ms/step - loss: 91.8188 - val_loss: 57.3372\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 38.0203 - val_loss: 34.5477\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 14.1495 - val_loss: 25.6259\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 6.3922 - val_loss: 22.6237\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.9500 - val_loss: 21.3117\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.1586 - val_loss: 20.4079\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.1177 - val_loss: 20.1138\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0903 - val_loss: 19.7233\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.2863 - val_loss: 19.1145\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7014 - val_loss: 19.0018\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7565 - val_loss: 17.7536\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.9281 - val_loss: 16.5958\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4514 - val_loss: 16.1266\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9804 - val_loss: 16.0479\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6638 - val_loss: 15.2424\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.2714 - val_loss: 15.3255\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.6960 - val_loss: 14.1684\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.3379 - val_loss: 13.3682\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.4418 - val_loss: 14.1497\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2348 - val_loss: 12.9688\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0129 - val_loss: 12.5002\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0617 - val_loss: 11.6722\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0789 - val_loss: 11.3135\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2587 - val_loss: 11.2939\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9299 - val_loss: 10.4022\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2805 - val_loss: 9.9382\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5465 - val_loss: 9.6220\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1779 - val_loss: 9.9250\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.5973 - val_loss: 9.6099\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.9676 - val_loss: 8.2305\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2633 - val_loss: 8.4839\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2422 - val_loss: 8.8224\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0973 - val_loss: 8.1670\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7003 - val_loss: 7.7944\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.8515 - val_loss: 6.6699\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5965 - val_loss: 6.6674\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7238 - val_loss: 6.5833\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1678 - val_loss: 5.5723\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6201 - val_loss: 5.3426\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7373 - val_loss: 5.3668\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0294 - val_loss: 5.1947\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.9472 - val_loss: 5.8185\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6561 - val_loss: 5.8544\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7090 - val_loss: 5.2062\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7183 - val_loss: 5.0130\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6740 - val_loss: 4.4919\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.3898 - val_loss: 3.7681\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8771 - val_loss: 3.9828\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5428 - val_loss: 4.0204\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6255 - val_loss: 3.8779\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8624 - val_loss: 3.7299\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4449 - val_loss: 4.1300\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8569 - val_loss: 3.9818\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4940 - val_loss: 3.2486\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4879 - val_loss: 3.1311\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.9131 - val_loss: 3.8373\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7524 - val_loss: 3.2277\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.9234 - val_loss: 3.1631\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.9780 - val_loss: 3.0711\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.5959 - val_loss: 3.2975\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8928 - val_loss: 3.5656\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6076 - val_loss: 3.1617\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7103 - val_loss: 3.3330\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7086 - val_loss: 2.7920\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3641 - val_loss: 2.8549\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6279 - val_loss: 2.5697\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5537 - val_loss: 2.5708\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3170 - val_loss: 3.0279\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4225 - val_loss: 3.2404\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4597 - val_loss: 2.4977\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8859 - val_loss: 2.4699\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6140 - val_loss: 2.3898\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6080 - val_loss: 2.5735\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6124 - val_loss: 2.7059\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4658 - val_loss: 2.6057\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3835 - val_loss: 2.6072\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5043 - val_loss: 2.7754\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4156 - val_loss: 3.2439\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0222 - val_loss: 3.7144\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5356 - val_loss: 2.6829\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5429 - val_loss: 2.3757\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2867 - val_loss: 2.3535\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4508 - val_loss: 2.3155\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3341 - val_loss: 2.5134\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3164 - val_loss: 2.7004\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4364 - val_loss: 2.7663\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.9430 - val_loss: 2.7820\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6754 - val_loss: 2.8940\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.9974 - val_loss: 3.0648\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4450 - val_loss: 2.5530\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.9503 - val_loss: 2.0361\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6294 - val_loss: 2.7300\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3485 - val_loss: 2.3755\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4778 - val_loss: 2.5076\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3589 - val_loss: 2.6639\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0387 - val_loss: 3.1658\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5570 - val_loss: 3.1656\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3072 - val_loss: 2.8233\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3980 - val_loss: 2.2514\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2686 - val_loss: 2.3357\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Test set MSE: 129609730000.0\n",
      "Test set RMSE: 360013.5\n",
      "Test set RMSPE (%): 94.96954515089185\n"
     ]
    }
   ],
   "source": [
    "print('batch norm regularization')\n",
    "model = train_model(X_train=X_train_scaled, y_train=y_train_log, X_valid=X_test_scaled, y_valid=y_valid_log, batch_norm=True)\n",
    "evaluate_model(model, X_test_scaled, y_test, log_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1/L2 regularization\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 90.8356 - val_loss: 42.2560\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 36.6848 - val_loss: 37.0332\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.7529 - val_loss: 34.2125\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 30.6885 - val_loss: 33.1004\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 29.2681 - val_loss: 32.2815\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.2062 - val_loss: 31.1652\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 27.3883 - val_loss: 30.8277\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 26.7194 - val_loss: 30.5851\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 26.2135 - val_loss: 29.9900\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 25.8057 - val_loss: 29.0863\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 25.5490 - val_loss: 29.3981\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 25.1950 - val_loss: 29.0523\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 24.9105 - val_loss: 28.7978\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 24.7003 - val_loss: 28.9816\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 24.5240 - val_loss: 28.2874\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 24.2869 - val_loss: 27.9902\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 24.0882 - val_loss: 27.7826\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 23.8980 - val_loss: 27.4962\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 23.7421 - val_loss: 27.1108\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 23.6391 - val_loss: 27.2626\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 23.5092 - val_loss: 26.7261\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 23.3473 - val_loss: 27.0104\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 23.2501 - val_loss: 27.0474\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 23.1443 - val_loss: 26.4490\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 23.0333 - val_loss: 26.3792\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 22.9731 - val_loss: 26.2347\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.8544 - val_loss: 26.2793\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 22.8041 - val_loss: 26.0528\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 22.7142 - val_loss: 25.9441\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 22.6584 - val_loss: 25.9239\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 22.5863 - val_loss: 25.6981\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 22.5300 - val_loss: 25.7988\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 22.4674 - val_loss: 25.4637\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 22.4370 - val_loss: 25.3590\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 22.3645 - val_loss: 25.4168\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 22.3088 - val_loss: 25.0801\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.2726 - val_loss: 25.1416\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 22.2205 - val_loss: 25.2049\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 22.1847 - val_loss: 25.0287\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 22.1513 - val_loss: 25.1696\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 22.1242 - val_loss: 25.0594\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 22.0911 - val_loss: 24.7056\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 22.0528 - val_loss: 24.8447\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 22.0170 - val_loss: 24.7106\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.9861 - val_loss: 24.9174\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.9618 - val_loss: 24.7857\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.9414 - val_loss: 24.4325\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.9124 - val_loss: 24.4166\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.8800 - val_loss: 24.4602\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.8539 - val_loss: 24.4606\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.8425 - val_loss: 24.4115\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.8108 - val_loss: 24.3654\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.7930 - val_loss: 24.5278\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.7725 - val_loss: 24.3819\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.7402 - val_loss: 24.4540\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.7266 - val_loss: 24.4115\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.7075 - val_loss: 24.1284\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.6843 - val_loss: 24.1536\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.6636 - val_loss: 24.2130\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.6537 - val_loss: 24.1927\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.6261 - val_loss: 24.0361\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.6108 - val_loss: 24.0766\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.5966 - val_loss: 24.2572\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.5743 - val_loss: 24.1233\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.5624 - val_loss: 24.0584\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.5450 - val_loss: 24.1153\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.5245 - val_loss: 24.0335\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.5077 - val_loss: 23.8021\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.4935 - val_loss: 24.1432\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.4743 - val_loss: 23.9843\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.4592 - val_loss: 23.8671\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.4522 - val_loss: 24.0266\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.4286 - val_loss: 23.8276\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.4219 - val_loss: 24.0266\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.4074 - val_loss: 23.8368\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.3843 - val_loss: 23.7477\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.3721 - val_loss: 23.8472\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.3578 - val_loss: 23.8015\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.3431 - val_loss: 23.6605\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.3245 - val_loss: 23.8869\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.3116 - val_loss: 23.7719\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.2955 - val_loss: 23.6964\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.2841 - val_loss: 23.6645\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.2671 - val_loss: 23.7034\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.2558 - val_loss: 23.7920\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.2422 - val_loss: 23.6161\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.2354 - val_loss: 23.6684\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.2169 - val_loss: 23.6472\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.2001 - val_loss: 23.5492\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.1891 - val_loss: 23.5831\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.1762 - val_loss: 23.4975\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.1606 - val_loss: 23.3048\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.1515 - val_loss: 23.5076\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.1391 - val_loss: 23.4879\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.1238 - val_loss: 23.5211\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.1147 - val_loss: 23.5901\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.1014 - val_loss: 23.3567\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.0874 - val_loss: 23.3241\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.0750 - val_loss: 23.4031\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.0646 - val_loss: 23.3195\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Test set MSE: 43762373000.0\n",
      "Test set RMSE: 209194.58\n",
      "Test set RMSPE (%): 70.47389417915272\n"
     ]
    }
   ],
   "source": [
    "print('L1/L2 regularization')\n",
    "model = train_model(X_train=X_train_scaled, y_train=y_train_log, X_valid=X_test_scaled, y_valid=y_valid_log, l1_l2=True)\n",
    "evaluate_model(model, X_test_scaled, y_test, log_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch norm & L1/L2 regularization\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 1s 41ms/step - loss: 94.9053 - val_loss: 61.2724\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 53.3000 - val_loss: 46.9972\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 36.9144 - val_loss: 42.4953\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.2727 - val_loss: 40.0248\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 26.9551 - val_loss: 38.3869\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 26.2159 - val_loss: 38.9920\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 23.7855 - val_loss: 38.2659\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 23.8341 - val_loss: 38.1982\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 23.5903 - val_loss: 37.5987\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 23.1434 - val_loss: 37.6078\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 23.7072 - val_loss: 37.2197\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.9005 - val_loss: 37.1732\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 23.1811 - val_loss: 36.5969\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.6954 - val_loss: 35.8050\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 23.1800 - val_loss: 35.3764\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 22.8800 - val_loss: 34.8171\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 23.3273 - val_loss: 35.0816\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.8171 - val_loss: 34.3521\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 23.1715 - val_loss: 34.3336\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 22.3506 - val_loss: 33.2638\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.6213 - val_loss: 32.8810\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.9410 - val_loss: 32.4376\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.1161 - val_loss: 32.2423\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.2265 - val_loss: 31.3461\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.7694 - val_loss: 31.5189\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 23.1103 - val_loss: 31.2951\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.3002 - val_loss: 30.4730\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.8133 - val_loss: 29.4994\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.2935 - val_loss: 29.3870\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 22.2612 - val_loss: 29.2084\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 22.4112 - val_loss: 28.8410\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.0116 - val_loss: 28.5104\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.6388 - val_loss: 27.9281\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 21.9230 - val_loss: 28.0143\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.1917 - val_loss: 28.5606\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.5671 - val_loss: 28.0618\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21.9574 - val_loss: 27.5367\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 21.9376 - val_loss: 26.9729\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 22.0605 - val_loss: 27.0353\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.1221 - val_loss: 26.4127\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.0765 - val_loss: 26.6228\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 21.8390 - val_loss: 26.2379\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 21.6370 - val_loss: 25.9179\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 22.3242 - val_loss: 25.6475\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.0908 - val_loss: 25.4773\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 22.0145 - val_loss: 25.6737\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 21.7842 - val_loss: 25.8942\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.0463 - val_loss: 25.2923\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 21.7918 - val_loss: 25.1874\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.0164 - val_loss: 24.8014\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.3062 - val_loss: 24.5303\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.1245 - val_loss: 24.6566\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.7504 - val_loss: 24.7842\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.1152 - val_loss: 24.6289\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 21.5302 - val_loss: 24.4304\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.7300 - val_loss: 24.2481\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 21.9873 - val_loss: 24.4820\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 22.1159 - val_loss: 24.6932\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 22.3344 - val_loss: 24.2690\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 21.7625 - val_loss: 24.2554\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.7933 - val_loss: 24.3309\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.8691 - val_loss: 24.2364\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.9120 - val_loss: 24.1498\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.5599 - val_loss: 24.3457\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 22.2243 - val_loss: 24.3031\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.1106 - val_loss: 23.5059\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.5099 - val_loss: 23.6081\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 21.4156 - val_loss: 23.6204\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 21.4755 - val_loss: 23.9718\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 21.7111 - val_loss: 23.9481\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.4480 - val_loss: 23.8755\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 21.5537 - val_loss: 23.7339\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 21.3534 - val_loss: 23.7661\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 21.7022 - val_loss: 23.4354\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 21.3347 - val_loss: 23.3493\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.2397 - val_loss: 23.2615\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 21.4700 - val_loss: 23.1466\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.1885 - val_loss: 23.4545\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.2448 - val_loss: 23.3298\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.2208 - val_loss: 23.3392\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 21.3633 - val_loss: 23.2921\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 21.5986 - val_loss: 23.5652\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 21.1991 - val_loss: 23.6958\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 21.2833 - val_loss: 23.1163\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 21.6615 - val_loss: 22.8130\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 21.4380 - val_loss: 22.9205\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 21.6438 - val_loss: 22.8870\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 21.0935 - val_loss: 23.1749\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.3892 - val_loss: 23.6564\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.1535 - val_loss: 23.2041\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.0106 - val_loss: 23.0377\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.5864 - val_loss: 24.0256\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.5765 - val_loss: 24.2419\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.3000 - val_loss: 23.1173\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 21.0091 - val_loss: 23.2709\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 21.1692 - val_loss: 23.0734\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.1041 - val_loss: 22.9856\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 20.9920 - val_loss: 22.9356\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.2356 - val_loss: 22.9210\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 21.0364 - val_loss: 22.8129\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Test set MSE: 10554828000.0\n",
      "Test set RMSE: 102736.695\n",
      "Test set RMSPE (%): 46.46354060932141\n"
     ]
    }
   ],
   "source": [
    "print('batch norm & L1/L2 regularization')\n",
    "model = train_model(X_train=X_train_scaled, y_train=y_train_log, X_valid=X_test_scaled, y_valid=y_valid_log, batch_norm=True, l1_l2=True)\n",
    "evaluate_model(model, X_test_scaled, y_test, log_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "5/5 [==============================] - 1s 49ms/step - loss: 120.6202 - val_loss: 88.1180\n",
      "Epoch 2/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 70.2123 - val_loss: 70.0089\n",
      "Epoch 3/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 50.3130 - val_loss: 65.0032\n",
      "Epoch 4/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 42.3309 - val_loss: 62.9935\n",
      "Epoch 5/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 39.7752 - val_loss: 62.9605\n",
      "Epoch 6/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 37.6366 - val_loss: 63.2563\n",
      "Epoch 7/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 37.2086 - val_loss: 63.5868\n",
      "Epoch 8/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37.1155 - val_loss: 63.1984\n",
      "Epoch 9/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 36.3437 - val_loss: 63.9916\n",
      "Epoch 10/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 36.8389 - val_loss: 63.2158\n",
      "Epoch 11/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 36.1989 - val_loss: 62.5856\n",
      "Epoch 12/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 36.1506 - val_loss: 61.6798\n",
      "Epoch 13/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 36.4598 - val_loss: 61.4949\n",
      "Epoch 14/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 36.5597 - val_loss: 60.8042\n",
      "Epoch 15/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 35.8675 - val_loss: 60.4433\n",
      "Epoch 16/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 35.8209 - val_loss: 59.6046\n",
      "Epoch 17/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 36.3569 - val_loss: 58.5497\n",
      "Epoch 18/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 36.2912 - val_loss: 57.6884\n",
      "Epoch 19/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 35.5898 - val_loss: 57.0022\n",
      "Epoch 20/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 35.7428 - val_loss: 56.4149\n",
      "Epoch 21/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 35.5378 - val_loss: 55.5925\n",
      "Epoch 22/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 35.7161 - val_loss: 54.5705\n",
      "Epoch 23/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 35.6200 - val_loss: 53.8358\n",
      "Epoch 24/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 35.7422 - val_loss: 52.6532\n",
      "Epoch 25/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 35.7991 - val_loss: 51.9889\n",
      "Epoch 26/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 35.9899 - val_loss: 50.8008\n",
      "Epoch 27/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.3138 - val_loss: 50.5282\n",
      "Epoch 28/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 35.6092 - val_loss: 49.6170\n",
      "Epoch 29/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 35.9454 - val_loss: 49.0245\n",
      "Epoch 30/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 35.4442 - val_loss: 48.1542\n",
      "Epoch 31/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 35.7883 - val_loss: 47.3871\n",
      "Epoch 32/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 35.3516 - val_loss: 46.6716\n",
      "Epoch 33/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 35.7383 - val_loss: 46.3216\n",
      "Epoch 34/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 35.4129 - val_loss: 45.8772\n",
      "Epoch 35/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 35.6298 - val_loss: 45.1398\n",
      "Epoch 36/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 35.7044 - val_loss: 45.1328\n",
      "Epoch 37/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.3241 - val_loss: 44.6891\n",
      "Epoch 38/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 35.3815 - val_loss: 44.4039\n",
      "Epoch 39/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 35.2205 - val_loss: 43.3943\n",
      "Epoch 40/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.0312 - val_loss: 42.6865\n",
      "Epoch 41/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 35.2389 - val_loss: 43.0839\n",
      "Epoch 42/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 35.3224 - val_loss: 42.5523\n",
      "Epoch 43/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.3839 - val_loss: 42.1978\n",
      "Epoch 44/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.9128 - val_loss: 41.8159\n",
      "Epoch 45/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.0239 - val_loss: 41.4709\n",
      "Epoch 46/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.1888 - val_loss: 40.6427\n",
      "Epoch 47/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 34.9029 - val_loss: 40.9426\n",
      "Epoch 48/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 34.8854 - val_loss: 40.9188\n",
      "Epoch 49/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34.7802 - val_loss: 40.7943\n",
      "Epoch 50/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 34.8509 - val_loss: 39.7339\n",
      "Epoch 51/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 35.0686 - val_loss: 40.0326\n",
      "Epoch 52/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 34.8646 - val_loss: 39.3658\n",
      "Epoch 53/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 34.7671 - val_loss: 39.1594\n",
      "Epoch 54/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.6812 - val_loss: 39.3267\n",
      "Epoch 55/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 35.1009 - val_loss: 39.4022\n",
      "Epoch 56/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 34.8232 - val_loss: 38.9673\n",
      "Epoch 57/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 34.7427 - val_loss: 38.5134\n",
      "Epoch 58/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 34.8455 - val_loss: 39.0282\n",
      "Epoch 59/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 34.8878 - val_loss: 38.2418\n",
      "Epoch 60/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.6793 - val_loss: 38.3451\n",
      "Epoch 61/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 34.5773 - val_loss: 38.3232\n",
      "Epoch 62/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 34.8660 - val_loss: 38.2198\n",
      "Epoch 63/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.6165 - val_loss: 38.0552\n",
      "Epoch 64/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.7381 - val_loss: 37.4713\n",
      "Epoch 65/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.5176 - val_loss: 37.6001\n",
      "Epoch 66/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 34.4181 - val_loss: 37.5555\n",
      "Epoch 67/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 34.6109 - val_loss: 37.8474\n",
      "Epoch 68/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.4799 - val_loss: 37.4532\n",
      "Epoch 69/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.5014 - val_loss: 37.3020\n",
      "Epoch 70/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 34.6103 - val_loss: 37.3293\n",
      "Epoch 71/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 34.3530 - val_loss: 37.5357\n",
      "Epoch 72/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 34.5284 - val_loss: 37.7213\n",
      "Epoch 73/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 34.3774 - val_loss: 37.1573\n",
      "Epoch 74/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 34.6592 - val_loss: 37.1335\n",
      "Epoch 75/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 34.2393 - val_loss: 37.2832\n",
      "Epoch 76/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.3226 - val_loss: 36.7104\n",
      "Epoch 77/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 34.4292 - val_loss: 37.2643\n",
      "Epoch 78/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.4018 - val_loss: 37.4492\n",
      "Epoch 79/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 34.3651 - val_loss: 37.5460\n",
      "Epoch 80/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 34.3614 - val_loss: 37.3468\n",
      "Epoch 81/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 34.3805 - val_loss: 36.5249\n",
      "Epoch 82/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.2852 - val_loss: 36.3814\n",
      "Epoch 83/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 34.1916 - val_loss: 36.7553\n",
      "Epoch 84/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.3373 - val_loss: 36.5889\n",
      "Epoch 85/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 34.0846 - val_loss: 36.4863\n",
      "Epoch 86/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 34.0827 - val_loss: 36.5486\n",
      "Epoch 87/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 34.1350 - val_loss: 36.9452\n",
      "Epoch 88/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 34.0229 - val_loss: 37.1700\n",
      "Epoch 89/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 34.1356 - val_loss: 36.9219\n",
      "Epoch 90/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 34.1234 - val_loss: 36.7029\n",
      "Epoch 91/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 33.9811 - val_loss: 36.8953\n",
      "Epoch 92/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 34.0276 - val_loss: 36.4137\n",
      "Epoch 93/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 34.1691 - val_loss: 36.6939\n",
      "Epoch 94/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.9836 - val_loss: 36.3071\n",
      "Epoch 95/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.9667 - val_loss: 36.2265\n",
      "Epoch 96/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.8283 - val_loss: 35.9113\n",
      "Epoch 97/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33.9821 - val_loss: 36.0297\n",
      "Epoch 98/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.8642 - val_loss: 36.5818\n",
      "Epoch 99/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.8752 - val_loss: 36.3052\n",
      "Epoch 100/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.8960 - val_loss: 35.7091\n",
      "Epoch 101/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.9508 - val_loss: 36.0537\n",
      "Epoch 102/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.8946 - val_loss: 36.4252\n",
      "Epoch 103/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.7412 - val_loss: 36.0459\n",
      "Epoch 104/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.8492 - val_loss: 36.4704\n",
      "Epoch 105/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.7100 - val_loss: 36.1688\n",
      "Epoch 106/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.8255 - val_loss: 36.5698\n",
      "Epoch 107/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.7581 - val_loss: 35.6912\n",
      "Epoch 108/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 33.6207 - val_loss: 35.7044\n",
      "Epoch 109/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.7708 - val_loss: 35.5031\n",
      "Epoch 110/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.6566 - val_loss: 35.5263\n",
      "Epoch 111/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.5659 - val_loss: 35.8507\n",
      "Epoch 112/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.7251 - val_loss: 35.4625\n",
      "Epoch 113/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.4945 - val_loss: 35.6501\n",
      "Epoch 114/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.7763 - val_loss: 35.3611\n",
      "Epoch 115/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.5527 - val_loss: 35.7770\n",
      "Epoch 116/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.5738 - val_loss: 35.5719\n",
      "Epoch 117/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 33.6602 - val_loss: 35.5711\n",
      "Epoch 118/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33.5914 - val_loss: 35.2745\n",
      "Epoch 119/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33.7042 - val_loss: 35.7576\n",
      "Epoch 120/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 33.4984 - val_loss: 35.7712\n",
      "Epoch 121/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33.3639 - val_loss: 35.5665\n",
      "Epoch 122/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33.3526 - val_loss: 35.4494\n",
      "Epoch 123/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 33.3486 - val_loss: 35.3988\n",
      "Epoch 124/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33.3957 - val_loss: 35.6163\n",
      "Epoch 125/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.3851 - val_loss: 35.5472\n",
      "Epoch 126/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.4838 - val_loss: 35.5510\n",
      "Epoch 127/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.3911 - val_loss: 35.6541\n",
      "Epoch 128/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 33.2533 - val_loss: 35.4488\n",
      "Epoch 129/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.3933 - val_loss: 35.4599\n",
      "Epoch 130/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.2582 - val_loss: 35.4862\n",
      "Epoch 131/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.2944 - val_loss: 35.2961\n",
      "Epoch 132/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 33.2005 - val_loss: 35.3104\n",
      "Epoch 133/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 33.1582 - val_loss: 35.5359\n",
      "Epoch 134/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.2342 - val_loss: 34.9688\n",
      "Epoch 135/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.2371 - val_loss: 35.2133\n",
      "Epoch 136/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 33.1002 - val_loss: 35.2241\n",
      "Epoch 137/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.1170 - val_loss: 34.9478\n",
      "Epoch 138/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.1460 - val_loss: 35.4354\n",
      "Epoch 139/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.0687 - val_loss: 35.1936\n",
      "Epoch 140/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 32.9757 - val_loss: 35.1919\n",
      "Epoch 141/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.0939 - val_loss: 35.1918\n",
      "Epoch 142/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.0529 - val_loss: 35.0748\n",
      "Epoch 143/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.1239 - val_loss: 35.1579\n",
      "Epoch 144/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 32.9948 - val_loss: 35.0043\n",
      "Epoch 145/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 32.9665 - val_loss: 34.6203\n",
      "Epoch 146/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 32.9752 - val_loss: 34.8081\n",
      "Epoch 147/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 33.0179 - val_loss: 35.4530\n",
      "Epoch 148/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 33.0277 - val_loss: 34.5188\n",
      "Epoch 149/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.9660 - val_loss: 34.6280\n",
      "Epoch 150/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32.9134 - val_loss: 34.9841\n",
      "Epoch 151/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32.8902 - val_loss: 34.8352\n",
      "Epoch 152/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 32.8011 - val_loss: 34.4998\n",
      "Epoch 153/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 32.7678 - val_loss: 34.9524\n",
      "Epoch 154/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 32.8463 - val_loss: 35.2516\n",
      "Epoch 155/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 32.8758 - val_loss: 34.8504\n",
      "Epoch 156/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 32.7065 - val_loss: 34.8623\n",
      "Epoch 157/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 32.7671 - val_loss: 34.9892\n",
      "Epoch 158/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.8009 - val_loss: 35.2405\n",
      "Epoch 159/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 32.7974 - val_loss: 34.8500\n",
      "Epoch 160/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 32.7584 - val_loss: 34.6869\n",
      "Epoch 161/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 32.7014 - val_loss: 34.6117\n",
      "Epoch 162/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 32.7142 - val_loss: 34.6679\n",
      "Epoch 163/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 32.6690 - val_loss: 34.6333\n",
      "Epoch 164/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 32.6032 - val_loss: 35.0227\n",
      "Epoch 165/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 32.7725 - val_loss: 34.5856\n",
      "Epoch 166/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 32.6409 - val_loss: 34.4912\n",
      "Epoch 167/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 32.6475 - val_loss: 34.3931\n",
      "Epoch 168/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 32.6421 - val_loss: 34.2846\n",
      "Epoch 169/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 32.5705 - val_loss: 34.4953\n",
      "Epoch 170/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 32.5263 - val_loss: 34.2741\n",
      "Epoch 171/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 32.5929 - val_loss: 34.5099\n",
      "Epoch 172/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 32.4740 - val_loss: 34.3970\n",
      "Epoch 173/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 32.4631 - val_loss: 34.8750\n",
      "Epoch 174/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 32.5145 - val_loss: 35.1365\n",
      "Epoch 175/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 32.5144 - val_loss: 34.2458\n",
      "Epoch 176/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 32.3751 - val_loss: 34.3347\n",
      "Epoch 177/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 32.4379 - val_loss: 34.4573\n",
      "Epoch 178/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32.4153 - val_loss: 34.4444\n",
      "Epoch 179/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 32.4494 - val_loss: 34.0965\n",
      "Epoch 180/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 32.5528 - val_loss: 34.4276\n",
      "Epoch 181/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32.2987 - val_loss: 34.3847\n",
      "Epoch 182/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32.3287 - val_loss: 34.3661\n",
      "Epoch 183/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.2528 - val_loss: 34.4245\n",
      "Epoch 184/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.3570 - val_loss: 34.1055\n",
      "Epoch 185/500\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 32.3157 - val_loss: 34.7115\n",
      "Epoch 186/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 32.2660 - val_loss: 34.2264\n",
      "Epoch 187/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 32.1964 - val_loss: 34.1169\n",
      "Epoch 188/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 32.1963 - val_loss: 34.3134\n",
      "Epoch 189/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 32.5650 - val_loss: 34.2842\n",
      "Epoch 190/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32.1525 - val_loss: 34.2347\n",
      "Epoch 191/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32.1739 - val_loss: 34.2391\n",
      "Epoch 192/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32.1853 - val_loss: 34.3804\n",
      "Epoch 193/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32.1749 - val_loss: 34.3256\n",
      "Epoch 194/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.1141 - val_loss: 34.3294\n",
      "Epoch 195/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32.1088 - val_loss: 34.2409\n",
      "Epoch 196/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32.1382 - val_loss: 34.0134\n",
      "Epoch 197/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 32.0303 - val_loss: 33.9926\n",
      "Epoch 198/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 32.0051 - val_loss: 33.9199\n",
      "Epoch 199/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 32.0836 - val_loss: 34.3144\n",
      "Epoch 200/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31.9953 - val_loss: 34.1047\n",
      "Epoch 201/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.0102 - val_loss: 33.9152\n",
      "Epoch 202/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.9303 - val_loss: 34.1266\n",
      "Epoch 203/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.9308 - val_loss: 34.2067\n",
      "Epoch 204/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.9361 - val_loss: 34.1870\n",
      "Epoch 205/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31.9234 - val_loss: 34.0519\n",
      "Epoch 206/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 31.9569 - val_loss: 33.5917\n",
      "Epoch 207/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.8735 - val_loss: 33.8947\n",
      "Epoch 208/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31.8675 - val_loss: 33.9692\n",
      "Epoch 209/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.8414 - val_loss: 33.7733\n",
      "Epoch 210/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.9033 - val_loss: 33.6430\n",
      "Epoch 211/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31.8645 - val_loss: 33.9927\n",
      "Epoch 212/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.7903 - val_loss: 33.4157\n",
      "Epoch 213/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31.7746 - val_loss: 33.4858\n",
      "Epoch 214/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31.7638 - val_loss: 34.0565\n",
      "Epoch 215/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.7767 - val_loss: 33.4783\n",
      "Epoch 216/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31.8218 - val_loss: 33.9123\n",
      "Epoch 217/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.7357 - val_loss: 33.7534\n",
      "Epoch 218/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.7407 - val_loss: 34.0035\n",
      "Epoch 219/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.6688 - val_loss: 33.9506\n",
      "Epoch 220/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 31.6318 - val_loss: 33.8877\n",
      "Epoch 221/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.6440 - val_loss: 33.7114\n",
      "Epoch 222/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.6197 - val_loss: 33.7271\n",
      "Epoch 223/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.6051 - val_loss: 33.4478\n",
      "Epoch 224/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31.5907 - val_loss: 33.5288\n",
      "Epoch 225/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31.5644 - val_loss: 33.6954\n",
      "Epoch 226/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.5873 - val_loss: 33.2296\n",
      "Epoch 227/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31.5071 - val_loss: 33.4459\n",
      "Epoch 228/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.7300 - val_loss: 33.7314\n",
      "Epoch 229/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.5217 - val_loss: 33.3032\n",
      "Epoch 230/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31.4853 - val_loss: 33.4478\n",
      "Epoch 231/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.3995 - val_loss: 33.3564\n",
      "Epoch 232/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.4058 - val_loss: 33.2178\n",
      "Epoch 233/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.3905 - val_loss: 33.2229\n",
      "Epoch 234/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31.4661 - val_loss: 33.7732\n",
      "Epoch 235/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31.4676 - val_loss: 33.1505\n",
      "Epoch 236/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.3216 - val_loss: 33.1202\n",
      "Epoch 237/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31.3432 - val_loss: 33.0225\n",
      "Epoch 238/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31.2914 - val_loss: 33.0731\n",
      "Epoch 239/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31.3719 - val_loss: 33.0835\n",
      "Epoch 240/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31.3516 - val_loss: 33.3042\n",
      "Epoch 241/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31.2234 - val_loss: 33.0042\n",
      "Epoch 242/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.2469 - val_loss: 33.0563\n",
      "Epoch 243/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.2775 - val_loss: 33.2803\n",
      "Epoch 244/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31.2488 - val_loss: 33.2478\n",
      "Epoch 245/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31.2970 - val_loss: 32.9445\n",
      "Epoch 246/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.2030 - val_loss: 33.0578\n",
      "Epoch 247/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31.2370 - val_loss: 33.2463\n",
      "Epoch 248/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 31.2760 - val_loss: 33.0434\n",
      "Epoch 249/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.1444 - val_loss: 33.4521\n",
      "Epoch 250/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.1664 - val_loss: 33.1116\n",
      "Epoch 251/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31.1057 - val_loss: 32.9555\n",
      "Epoch 252/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31.1139 - val_loss: 32.9687\n",
      "Epoch 253/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.0526 - val_loss: 32.9794\n",
      "Epoch 254/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 31.1293 - val_loss: 33.0143\n",
      "Epoch 255/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.0687 - val_loss: 33.0600\n",
      "Epoch 256/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.0339 - val_loss: 32.9903\n",
      "Epoch 257/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.0336 - val_loss: 32.8153\n",
      "Epoch 258/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.0281 - val_loss: 32.5473\n",
      "Epoch 259/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.0064 - val_loss: 32.8508\n",
      "Epoch 260/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 30.9842 - val_loss: 32.9003\n",
      "Epoch 261/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30.9494 - val_loss: 32.8922\n",
      "Epoch 262/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 30.9350 - val_loss: 32.7552\n",
      "Epoch 263/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.9093 - val_loss: 32.5339\n",
      "Epoch 264/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.8675 - val_loss: 32.8182\n",
      "Epoch 265/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.9196 - val_loss: 33.1282\n",
      "Epoch 266/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 30.8327 - val_loss: 32.6434\n",
      "Epoch 267/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.7958 - val_loss: 32.6831\n",
      "Epoch 268/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30.8406 - val_loss: 33.0842\n",
      "Epoch 269/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 30.7983 - val_loss: 32.8047\n",
      "Epoch 270/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.7924 - val_loss: 32.5840\n",
      "Epoch 271/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.7722 - val_loss: 32.4165\n",
      "Epoch 272/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.7675 - val_loss: 33.0045\n",
      "Epoch 273/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.7086 - val_loss: 32.6171\n",
      "Epoch 274/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.7697 - val_loss: 32.2623\n",
      "Epoch 275/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 30.7663 - val_loss: 32.5926\n",
      "Epoch 276/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.6371 - val_loss: 32.5177\n",
      "Epoch 277/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.6910 - val_loss: 32.6732\n",
      "Epoch 278/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 30.6776 - val_loss: 32.7576\n",
      "Epoch 279/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30.8726 - val_loss: 33.2333\n",
      "Epoch 280/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 30.6805 - val_loss: 32.6410\n",
      "Epoch 281/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.6455 - val_loss: 32.3166\n",
      "Epoch 282/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.6558 - val_loss: 32.1992\n",
      "Epoch 283/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30.6109 - val_loss: 32.4120\n",
      "Epoch 284/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30.5936 - val_loss: 32.5563\n",
      "Epoch 285/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.5753 - val_loss: 32.7974\n",
      "Epoch 286/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.5726 - val_loss: 32.6670\n",
      "Epoch 287/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.5041 - val_loss: 32.3478\n",
      "Epoch 288/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 30.4948 - val_loss: 32.1769\n",
      "Epoch 289/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.5065 - val_loss: 32.6434\n",
      "Epoch 290/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.4638 - val_loss: 32.7402\n",
      "Epoch 291/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30.4533 - val_loss: 32.2319\n",
      "Epoch 292/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 30.4404 - val_loss: 32.3578\n",
      "Epoch 293/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 30.4350 - val_loss: 32.3129\n",
      "Epoch 294/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 30.4484 - val_loss: 32.2999\n",
      "Epoch 295/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 30.4014 - val_loss: 32.0610\n",
      "Epoch 296/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.3460 - val_loss: 31.9592\n",
      "Epoch 297/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.3637 - val_loss: 32.3515\n",
      "Epoch 298/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 30.3514 - val_loss: 32.1864\n",
      "Epoch 299/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 30.2719 - val_loss: 32.0060\n",
      "Epoch 300/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.3077 - val_loss: 32.1885\n",
      "Epoch 301/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 30.2757 - val_loss: 31.9820\n",
      "Epoch 302/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 30.3141 - val_loss: 32.4335\n",
      "Epoch 303/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.3422 - val_loss: 32.3368\n",
      "Epoch 304/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 30.2442 - val_loss: 32.2452\n",
      "Epoch 305/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 30.2088 - val_loss: 32.1604\n",
      "Epoch 306/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30.2042 - val_loss: 32.0519\n",
      "Epoch 307/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 30.1953 - val_loss: 32.4202\n",
      "Epoch 308/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.2157 - val_loss: 32.0169\n",
      "Epoch 309/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.1318 - val_loss: 32.2164\n",
      "Epoch 310/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 30.1190 - val_loss: 32.1367\n",
      "Epoch 311/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.1069 - val_loss: 32.1593\n",
      "Epoch 312/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.0619 - val_loss: 32.0947\n",
      "Epoch 313/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.1405 - val_loss: 32.1490\n",
      "Epoch 314/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.0900 - val_loss: 32.0678\n",
      "Epoch 315/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 30.0094 - val_loss: 31.6471\n",
      "Epoch 316/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.0211 - val_loss: 31.9822\n",
      "Epoch 317/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.0164 - val_loss: 31.8104\n",
      "Epoch 318/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 29.9804 - val_loss: 31.8196\n",
      "Epoch 319/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 29.9954 - val_loss: 31.8200\n",
      "Epoch 320/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 29.9801 - val_loss: 32.0159\n",
      "Epoch 321/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29.9206 - val_loss: 31.8853\n",
      "Epoch 322/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.9870 - val_loss: 31.5529\n",
      "Epoch 323/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.9454 - val_loss: 31.4744\n",
      "Epoch 324/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29.8703 - val_loss: 31.6555\n",
      "Epoch 325/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 30.0754 - val_loss: 31.7711\n",
      "Epoch 326/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29.8852 - val_loss: 31.7261\n",
      "Epoch 327/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29.8614 - val_loss: 31.7618\n",
      "Epoch 328/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29.8696 - val_loss: 31.2696\n",
      "Epoch 329/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29.7949 - val_loss: 31.4505\n",
      "Epoch 330/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 29.8039 - val_loss: 31.7115\n",
      "Epoch 331/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.7623 - val_loss: 31.5282\n",
      "Epoch 332/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 29.8005 - val_loss: 31.7797\n",
      "Epoch 333/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.8461 - val_loss: 31.5052\n",
      "Epoch 334/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29.7805 - val_loss: 31.4142\n",
      "Epoch 335/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.7320 - val_loss: 31.3444\n",
      "Epoch 336/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 29.6778 - val_loss: 31.4495\n",
      "Epoch 337/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.6986 - val_loss: 31.4640\n",
      "Epoch 338/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.6377 - val_loss: 31.4810\n",
      "Epoch 339/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.7310 - val_loss: 31.6243\n",
      "Epoch 340/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 29.7193 - val_loss: 32.1148\n",
      "Epoch 341/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 29.6163 - val_loss: 31.4512\n",
      "Epoch 342/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.6121 - val_loss: 31.4229\n",
      "Epoch 343/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.5908 - val_loss: 31.4215\n",
      "Epoch 344/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29.6630 - val_loss: 31.3643\n",
      "Epoch 345/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.5802 - val_loss: 31.2796\n",
      "Epoch 346/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29.5154 - val_loss: 31.4536\n",
      "Epoch 347/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.6494 - val_loss: 31.8584\n",
      "Epoch 348/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 29.5440 - val_loss: 31.6947\n",
      "Epoch 349/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 29.5236 - val_loss: 31.5537\n",
      "Epoch 350/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.4936 - val_loss: 31.3789\n",
      "Epoch 351/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.4421 - val_loss: 31.6089\n",
      "Epoch 352/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 29.3712 - val_loss: 31.5316\n",
      "Epoch 353/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 29.4903 - val_loss: 31.8182\n",
      "Epoch 354/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.4077 - val_loss: 31.3776\n",
      "Epoch 355/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29.4195 - val_loss: 30.8337\n",
      "Epoch 356/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.4543 - val_loss: 31.6034\n",
      "Epoch 357/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29.3884 - val_loss: 31.1670\n",
      "Epoch 358/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.3403 - val_loss: 31.2789\n",
      "Epoch 359/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.3127 - val_loss: 31.2235\n",
      "Epoch 360/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.3366 - val_loss: 31.0991\n",
      "Epoch 361/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.3153 - val_loss: 31.0651\n",
      "Epoch 362/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 29.3229 - val_loss: 31.3633\n",
      "Epoch 363/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 29.2247 - val_loss: 31.3591\n",
      "Epoch 364/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 29.2475 - val_loss: 31.3172\n",
      "Epoch 365/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.1904 - val_loss: 31.1163\n",
      "Epoch 366/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29.2317 - val_loss: 31.1225\n",
      "Epoch 367/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29.2276 - val_loss: 31.2199\n",
      "Epoch 368/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.1678 - val_loss: 31.1725\n",
      "Epoch 369/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.1073 - val_loss: 31.0550\n",
      "Epoch 370/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.1439 - val_loss: 31.0423\n",
      "Epoch 371/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.1394 - val_loss: 31.0207\n",
      "Epoch 372/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 29.1054 - val_loss: 30.9320\n",
      "Epoch 373/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.0871 - val_loss: 31.0117\n",
      "Epoch 374/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.0931 - val_loss: 31.3372\n",
      "Epoch 375/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29.1075 - val_loss: 31.2080\n",
      "Epoch 376/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.0635 - val_loss: 31.1641\n",
      "Epoch 377/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.0112 - val_loss: 31.0490\n",
      "Epoch 378/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.0047 - val_loss: 30.9441\n",
      "Epoch 379/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.9943 - val_loss: 30.9097\n",
      "Epoch 380/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.9853 - val_loss: 31.2781\n",
      "Epoch 381/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.9667 - val_loss: 31.1425\n",
      "Epoch 382/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.9698 - val_loss: 30.8397\n",
      "Epoch 383/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.9149 - val_loss: 30.6998\n",
      "Epoch 384/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.9141 - val_loss: 30.8658\n",
      "Epoch 385/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.9085 - val_loss: 30.8614\n",
      "Epoch 386/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.8782 - val_loss: 30.9253\n",
      "Epoch 387/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.9255 - val_loss: 30.6600\n",
      "Epoch 388/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.8166 - val_loss: 30.5607\n",
      "Epoch 389/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.8724 - val_loss: 31.0890\n",
      "Epoch 390/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.8039 - val_loss: 30.7833\n",
      "Epoch 391/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.7905 - val_loss: 30.7033\n",
      "Epoch 392/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.7888 - val_loss: 31.0478\n",
      "Epoch 393/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.7741 - val_loss: 30.6227\n",
      "Epoch 394/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.7094 - val_loss: 30.5315\n",
      "Epoch 395/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.7838 - val_loss: 30.8188\n",
      "Epoch 396/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.7287 - val_loss: 30.6857\n",
      "Epoch 397/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.7464 - val_loss: 30.9375\n",
      "Epoch 398/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.6739 - val_loss: 30.7917\n",
      "Epoch 399/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.6779 - val_loss: 30.5589\n",
      "Epoch 400/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.6679 - val_loss: 30.6371\n",
      "Epoch 401/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28.6982 - val_loss: 30.8641\n",
      "Epoch 402/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28.7010 - val_loss: 30.7683\n",
      "Epoch 403/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.6418 - val_loss: 30.1768\n",
      "Epoch 404/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.6160 - val_loss: 30.5033\n",
      "Epoch 405/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.5840 - val_loss: 30.6211\n",
      "Epoch 406/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.5878 - val_loss: 30.4458\n",
      "Epoch 407/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.5996 - val_loss: 30.4018\n",
      "Epoch 408/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 28.4997 - val_loss: 30.4792\n",
      "Epoch 409/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.5259 - val_loss: 30.4899\n",
      "Epoch 410/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 28.4947 - val_loss: 30.3958\n",
      "Epoch 411/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.4858 - val_loss: 30.3210\n",
      "Epoch 412/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.4226 - val_loss: 30.1962\n",
      "Epoch 413/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.4298 - val_loss: 29.9894\n",
      "Epoch 414/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.5573 - val_loss: 30.1273\n",
      "Epoch 415/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.3990 - val_loss: 30.4672\n",
      "Epoch 416/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.3934 - val_loss: 30.4257\n",
      "Epoch 417/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.4138 - val_loss: 30.4802\n",
      "Epoch 418/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.3518 - val_loss: 29.9199\n",
      "Epoch 419/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.4535 - val_loss: 30.2630\n",
      "Epoch 420/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.3584 - val_loss: 30.3740\n",
      "Epoch 421/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.3296 - val_loss: 30.1546\n",
      "Epoch 422/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28.2823 - val_loss: 30.2118\n",
      "Epoch 423/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.3028 - val_loss: 30.1577\n",
      "Epoch 424/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.3350 - val_loss: 30.2872\n",
      "Epoch 425/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.3443 - val_loss: 30.4422\n",
      "Epoch 426/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.3105 - val_loss: 30.3850\n",
      "Epoch 427/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.2846 - val_loss: 29.9902\n",
      "Epoch 428/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.2860 - val_loss: 29.9353\n",
      "Epoch 429/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.2125 - val_loss: 30.1901\n",
      "Epoch 430/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.2088 - val_loss: 29.8004\n",
      "Epoch 431/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.1790 - val_loss: 30.2210\n",
      "Epoch 432/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.1312 - val_loss: 30.2204\n",
      "Epoch 433/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28.1480 - val_loss: 29.6316\n",
      "Epoch 434/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28.1705 - val_loss: 30.3021\n",
      "Epoch 435/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28.1067 - val_loss: 29.7846\n",
      "Epoch 436/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.0976 - val_loss: 29.6931\n",
      "Epoch 437/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.0743 - val_loss: 30.2293\n",
      "Epoch 438/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.0932 - val_loss: 30.0033\n",
      "Epoch 439/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.0465 - val_loss: 29.7796\n",
      "Epoch 440/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 28.0299 - val_loss: 30.1699\n",
      "Epoch 441/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.0004 - val_loss: 30.0629\n",
      "Epoch 442/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.9939 - val_loss: 29.7284\n",
      "Epoch 443/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.9507 - val_loss: 29.6401\n",
      "Epoch 444/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.9491 - val_loss: 29.8296\n",
      "Epoch 445/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.9647 - val_loss: 29.7009\n",
      "Epoch 446/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.9212 - val_loss: 29.6079\n",
      "Epoch 447/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27.8673 - val_loss: 29.7292\n",
      "Epoch 448/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27.8782 - val_loss: 29.8422\n",
      "Epoch 449/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.8794 - val_loss: 30.2142\n",
      "Epoch 450/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 27.9515 - val_loss: 30.1015\n",
      "Epoch 451/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.8696 - val_loss: 29.6651\n",
      "Epoch 452/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.8530 - val_loss: 29.5272\n",
      "Epoch 453/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.8358 - val_loss: 29.6185\n",
      "Epoch 454/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.8330 - val_loss: 29.7491\n",
      "Epoch 455/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.8436 - val_loss: 29.4258\n",
      "Epoch 456/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.8338 - val_loss: 29.9630\n",
      "Epoch 457/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.7744 - val_loss: 29.6954\n",
      "Epoch 458/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.7568 - val_loss: 29.4772\n",
      "Epoch 459/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27.7813 - val_loss: 29.7275\n",
      "Epoch 460/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.7449 - val_loss: 29.8269\n",
      "Epoch 461/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.6834 - val_loss: 29.8140\n",
      "Epoch 462/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.6753 - val_loss: 29.6142\n",
      "Epoch 463/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.6961 - val_loss: 29.4413\n",
      "Epoch 464/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27.6618 - val_loss: 29.5761\n",
      "Epoch 465/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.6751 - val_loss: 29.8269\n",
      "Epoch 466/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27.6609 - val_loss: 29.4126\n",
      "Epoch 467/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.5676 - val_loss: 29.2819\n",
      "Epoch 468/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.5988 - val_loss: 29.2983\n",
      "Epoch 469/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27.5860 - val_loss: 29.4234\n",
      "Epoch 470/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27.5926 - val_loss: 29.4686\n",
      "Epoch 471/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.5542 - val_loss: 29.4733\n",
      "Epoch 472/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27.5184 - val_loss: 29.5441\n",
      "Epoch 473/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 27.5430 - val_loss: 29.6616\n",
      "Epoch 474/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27.5223 - val_loss: 29.7674\n",
      "Epoch 475/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27.4853 - val_loss: 29.1316\n",
      "Epoch 476/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27.6145 - val_loss: 29.4524\n",
      "Epoch 477/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27.4506 - val_loss: 29.2283\n",
      "Epoch 478/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 27.4189 - val_loss: 29.3752\n",
      "Epoch 479/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27.4117 - val_loss: 29.4575\n",
      "Epoch 480/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27.3819 - val_loss: 29.0940\n",
      "Epoch 481/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.4097 - val_loss: 29.4182\n",
      "Epoch 482/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.3680 - val_loss: 29.2641\n",
      "Epoch 483/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.3699 - val_loss: 29.3576\n",
      "Epoch 484/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27.3460 - val_loss: 29.2017\n",
      "Epoch 485/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.3617 - val_loss: 29.1795\n",
      "Epoch 486/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.3175 - val_loss: 29.0596\n",
      "Epoch 487/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.2998 - val_loss: 29.1114\n",
      "Epoch 488/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.3359 - val_loss: 28.9745\n",
      "Epoch 489/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.2994 - val_loss: 29.4588\n",
      "Epoch 490/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 27.2698 - val_loss: 28.9487\n",
      "Epoch 491/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.2369 - val_loss: 29.1133\n",
      "Epoch 492/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.2934 - val_loss: 29.1655\n",
      "Epoch 493/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.2376 - val_loss: 29.4949\n",
      "Epoch 494/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.1905 - val_loss: 28.8616\n",
      "Epoch 495/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.1788 - val_loss: 29.1489\n",
      "Epoch 496/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.1543 - val_loss: 29.1240\n",
      "Epoch 497/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27.1353 - val_loss: 28.9930\n",
      "Epoch 498/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27.2170 - val_loss: 29.5839\n",
      "Epoch 499/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.1810 - val_loss: 29.0652\n",
      "Epoch 500/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27.0773 - val_loss: 29.1039\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001EAD34C4310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Test set MSE: 1838292500.0\n",
      "Test set RMSE: 42875.312\n",
      "Test set RMSPE (%): 23.965706532472502\n"
     ]
    }
   ],
   "source": [
    "model = train_model(epochs=500, layer_sizes=[100, 100, 100], X_train=X_train_scaled, y_train=y_train_log, X_valid=X_test_scaled, y_valid=y_valid_log, batch_norm=True, l1_l2=True)\n",
    "evaluate_model(model, X_test_scaled, y_test, log_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "5/5 [==============================] - 1s 59ms/step - loss: 130.8261 - val_loss: 127.5651\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 78.6194 - val_loss: 103.2864\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 60.6630 - val_loss: 95.1316\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 53.3632 - val_loss: 92.4517\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 51.3319 - val_loss: 90.8049\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 50.6987 - val_loss: 88.9517\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 49.6738 - val_loss: 89.5176\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 49.9208 - val_loss: 88.3966\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 49.8291 - val_loss: 87.0021\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 49.6946 - val_loss: 85.9262\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 49.4304 - val_loss: 85.1124\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 49.8511 - val_loss: 84.0827\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 49.4291 - val_loss: 82.3513\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 49.5827 - val_loss: 80.9875\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 49.1691 - val_loss: 79.5379\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 49.2015 - val_loss: 77.7914\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 49.2094 - val_loss: 76.3805\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 49.0326 - val_loss: 74.8217\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 48.9781 - val_loss: 74.0464\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 49.0168 - val_loss: 72.8684\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 48.7405 - val_loss: 71.8333\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 48.8751 - val_loss: 70.7011\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 48.7406 - val_loss: 69.4200\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 48.5113 - val_loss: 68.8402\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 48.9357 - val_loss: 67.8595\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 48.5480 - val_loss: 66.8411\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 48.4696 - val_loss: 64.4892\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 49.0473 - val_loss: 64.2489\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 48.4993 - val_loss: 62.4727\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 48.5128 - val_loss: 62.0565\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 48.6060 - val_loss: 61.5513\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 48.2332 - val_loss: 60.8882\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 48.4473 - val_loss: 60.5266\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 48.3446 - val_loss: 59.6166\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 48.0272 - val_loss: 58.6113\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 48.3515 - val_loss: 58.0812\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 48.1301 - val_loss: 57.6600\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 48.1450 - val_loss: 56.4592\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 48.1616 - val_loss: 56.1120\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 48.1725 - val_loss: 55.6444\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 48.0769 - val_loss: 54.7971\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 48.0281 - val_loss: 54.7350\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 47.9212 - val_loss: 54.3837\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 47.9595 - val_loss: 54.2056\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 47.9213 - val_loss: 53.4814\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 47.9602 - val_loss: 53.0970\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 48.0167 - val_loss: 52.4930\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 47.9170 - val_loss: 52.7886\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 47.9002 - val_loss: 52.5135\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 47.9010 - val_loss: 52.2322\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 47.7721 - val_loss: 52.0533\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 47.7075 - val_loss: 51.8472\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 47.9049 - val_loss: 51.2343\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 47.7323 - val_loss: 51.0913\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 47.5097 - val_loss: 51.3622\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 47.6396 - val_loss: 51.1043\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 47.7300 - val_loss: 50.7249\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 47.8719 - val_loss: 50.3833\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 47.5300 - val_loss: 50.6696\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 47.5413 - val_loss: 50.6026\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 47.4659 - val_loss: 50.2461\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 47.3964 - val_loss: 50.1613\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 47.5611 - val_loss: 49.9511\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 47.3822 - val_loss: 50.1097\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 47.3573 - val_loss: 50.4023\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 47.2358 - val_loss: 49.8515\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 47.2163 - val_loss: 49.8169\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 47.4638 - val_loss: 50.0803\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 47.1316 - val_loss: 50.0226\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 47.1956 - val_loss: 49.4287\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 47.1461 - val_loss: 49.3459\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 47.2094 - val_loss: 49.2126\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 47.4267 - val_loss: 49.2893\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 47.1102 - val_loss: 49.1795\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 47.1548 - val_loss: 49.2566\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 47.0345 - val_loss: 49.4264\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 47.0450 - val_loss: 49.2483\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 47.3056 - val_loss: 48.9263\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 46.9964 - val_loss: 48.9000\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 46.8781 - val_loss: 49.2251\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 47.0998 - val_loss: 48.8740\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 46.8373 - val_loss: 48.6184\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46.8508 - val_loss: 48.7991\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46.8748 - val_loss: 48.7723\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46.8266 - val_loss: 48.6297\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46.7397 - val_loss: 48.7394\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46.6474 - val_loss: 48.5337\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46.7196 - val_loss: 48.4477\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46.6516 - val_loss: 48.3540\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46.6525 - val_loss: 48.3459\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 46.5830 - val_loss: 48.6641\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46.5806 - val_loss: 48.2293\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 46.5279 - val_loss: 48.3024\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 46.5128 - val_loss: 48.4938\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46.5999 - val_loss: 48.0459\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 46.5164 - val_loss: 48.0967\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 46.4654 - val_loss: 48.3919\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46.4504 - val_loss: 48.0332\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46.4493 - val_loss: 48.1574\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 46.3760 - val_loss: 47.9053\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46.3706 - val_loss: 48.2648\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46.4862 - val_loss: 48.2364\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46.3013 - val_loss: 48.0336\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 46.3376 - val_loss: 48.1347\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46.3063 - val_loss: 47.8564\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46.2436 - val_loss: 48.0866\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 46.1418 - val_loss: 48.1280\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46.2139 - val_loss: 48.0625\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 46.3989 - val_loss: 47.9017\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46.3386 - val_loss: 47.5551\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 46.1093 - val_loss: 47.6803\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 45.9755 - val_loss: 47.7480\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46.0886 - val_loss: 47.8341\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46.0977 - val_loss: 47.6758\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 46.0925 - val_loss: 48.4130\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 46.0784 - val_loss: 48.0692\n",
      "Epoch 117/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 45.9506 - val_loss: 48.0023\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 45.9531 - val_loss: 47.6931\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 45.8537 - val_loss: 47.5809\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 45.8681 - val_loss: 47.7020\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 45.8655 - val_loss: 47.7430\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 45.8016 - val_loss: 47.5441\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 45.7893 - val_loss: 47.5345\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 45.7321 - val_loss: 47.7989\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 45.6502 - val_loss: 47.6372\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 45.7008 - val_loss: 47.6116\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 45.7311 - val_loss: 47.2618\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 45.8447 - val_loss: 47.3362\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 45.7174 - val_loss: 47.4324\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 45.6762 - val_loss: 47.3352\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 45.6345 - val_loss: 47.7974\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 45.6364 - val_loss: 47.4812\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 45.5408 - val_loss: 47.1739\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 45.5602 - val_loss: 47.1458\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 45.5109 - val_loss: 47.6110\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 45.5082 - val_loss: 47.5667\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 45.4866 - val_loss: 47.2780\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 45.3863 - val_loss: 47.2785\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 45.4228 - val_loss: 46.9333\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 45.4250 - val_loss: 47.0427\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 45.3683 - val_loss: 47.3372\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 45.3455 - val_loss: 47.0630\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 45.3991 - val_loss: 46.9580\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 45.2905 - val_loss: 46.6960\n",
      "Epoch 145/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 45.2439 - val_loss: 46.8540\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 45.2485 - val_loss: 46.6936\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 45.1781 - val_loss: 46.9328\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 45.3295 - val_loss: 47.2497\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 45.2624 - val_loss: 47.0979\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 45.2266 - val_loss: 47.2349\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 45.1243 - val_loss: 46.9769\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 45.0872 - val_loss: 46.6945\n",
      "Epoch 153/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 45.0282 - val_loss: 46.7354\n",
      "Epoch 154/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 45.0547 - val_loss: 46.5615\n",
      "Epoch 155/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 45.0196 - val_loss: 46.6318\n",
      "Epoch 156/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 44.9878 - val_loss: 46.6039\n",
      "Epoch 157/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 44.9732 - val_loss: 46.5191\n",
      "Epoch 158/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 44.9045 - val_loss: 46.7873\n",
      "Epoch 159/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 44.8819 - val_loss: 46.6716\n",
      "Epoch 160/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 44.8306 - val_loss: 46.5591\n",
      "Epoch 161/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 44.7469 - val_loss: 46.4617\n",
      "Epoch 162/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 44.7578 - val_loss: 46.3963\n",
      "Epoch 163/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 44.7158 - val_loss: 46.6183\n",
      "Epoch 164/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 44.7034 - val_loss: 46.5218\n",
      "Epoch 165/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 44.7191 - val_loss: 46.3581\n",
      "Epoch 166/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.6005 - val_loss: 46.3758\n",
      "Epoch 167/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.7224 - val_loss: 46.2365\n",
      "Epoch 168/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 44.6837 - val_loss: 46.4660\n",
      "Epoch 169/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 44.6262 - val_loss: 46.3477\n",
      "Epoch 170/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 44.5520 - val_loss: 46.5243\n",
      "Epoch 171/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 44.6396 - val_loss: 46.4273\n",
      "Epoch 172/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 44.5506 - val_loss: 46.4190\n",
      "Epoch 173/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 44.6115 - val_loss: 46.7983\n",
      "Epoch 174/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 44.4822 - val_loss: 46.6550\n",
      "Epoch 175/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 44.5287 - val_loss: 46.4301\n",
      "Epoch 176/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.4547 - val_loss: 46.4356\n",
      "Epoch 177/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 44.4065 - val_loss: 46.2707\n",
      "Epoch 178/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 44.4209 - val_loss: 46.2404\n",
      "Epoch 179/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 44.4156 - val_loss: 46.1970\n",
      "Epoch 180/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 44.3379 - val_loss: 46.3014\n",
      "Epoch 181/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 44.3437 - val_loss: 46.2483\n",
      "Epoch 182/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 44.3351 - val_loss: 45.9680\n",
      "Epoch 183/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 44.2743 - val_loss: 46.0182\n",
      "Epoch 184/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 44.2523 - val_loss: 46.0832\n",
      "Epoch 185/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 44.1868 - val_loss: 46.0488\n",
      "Epoch 186/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 44.1601 - val_loss: 45.8297\n",
      "Epoch 187/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 44.1814 - val_loss: 45.9361\n",
      "Epoch 188/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 44.1764 - val_loss: 46.0115\n",
      "Epoch 189/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 44.1000 - val_loss: 45.8704\n",
      "Epoch 190/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 44.0744 - val_loss: 45.6564\n",
      "Epoch 191/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 44.1383 - val_loss: 45.5537\n",
      "Epoch 192/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 44.1481 - val_loss: 45.5897\n",
      "Epoch 193/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.1265 - val_loss: 46.1467\n",
      "Epoch 194/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 44.0518 - val_loss: 46.0667\n",
      "Epoch 195/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 43.9875 - val_loss: 46.0579\n",
      "Epoch 196/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 43.9271 - val_loss: 45.8225\n",
      "Epoch 197/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 43.9095 - val_loss: 45.6790\n",
      "Epoch 198/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 43.9412 - val_loss: 45.7524\n",
      "Epoch 199/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43.9393 - val_loss: 45.7176\n",
      "Epoch 200/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 43.8794 - val_loss: 45.5831\n",
      "Epoch 201/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43.8531 - val_loss: 45.4260\n",
      "Epoch 202/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 43.7617 - val_loss: 45.5161\n",
      "Epoch 203/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 43.7663 - val_loss: 45.5637\n",
      "Epoch 204/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 43.6923 - val_loss: 45.6815\n",
      "Epoch 205/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43.7667 - val_loss: 45.3346\n",
      "Epoch 206/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43.7283 - val_loss: 45.2419\n",
      "Epoch 207/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43.7083 - val_loss: 45.2549\n",
      "Epoch 208/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 43.6686 - val_loss: 45.3177\n",
      "Epoch 209/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43.6547 - val_loss: 45.3256\n",
      "Epoch 210/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 43.5987 - val_loss: 45.2911\n",
      "Epoch 211/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 43.6895 - val_loss: 45.4309\n",
      "Epoch 212/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 43.6641 - val_loss: 45.2890\n",
      "Epoch 213/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 43.4866 - val_loss: 45.2511\n",
      "Epoch 214/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43.4996 - val_loss: 45.3543\n",
      "Epoch 215/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 43.4619 - val_loss: 45.3792\n",
      "Epoch 216/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 43.4606 - val_loss: 45.3327\n",
      "Epoch 217/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 43.3980 - val_loss: 45.3437\n",
      "Epoch 218/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43.4921 - val_loss: 44.9442\n",
      "Epoch 219/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43.3849 - val_loss: 45.4115\n",
      "Epoch 220/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43.3437 - val_loss: 45.0511\n",
      "Epoch 221/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 43.3713 - val_loss: 45.0826\n",
      "Epoch 222/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 43.3360 - val_loss: 45.0408\n",
      "Epoch 223/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 43.2959 - val_loss: 45.1163\n",
      "Epoch 224/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43.3412 - val_loss: 44.9926\n",
      "Epoch 225/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 43.1760 - val_loss: 45.0861\n",
      "Epoch 226/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 43.2042 - val_loss: 45.1650\n",
      "Epoch 227/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43.1382 - val_loss: 45.1640\n",
      "Epoch 228/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 43.1238 - val_loss: 44.9558\n",
      "Epoch 229/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43.1604 - val_loss: 44.8253\n",
      "Epoch 230/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 43.1018 - val_loss: 44.9221\n",
      "Epoch 231/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 43.0665 - val_loss: 44.8272\n",
      "Epoch 232/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43.0789 - val_loss: 44.6013\n",
      "Epoch 233/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 43.0409 - val_loss: 44.6633\n",
      "Epoch 234/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 43.0126 - val_loss: 44.6179\n",
      "Epoch 235/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42.9866 - val_loss: 44.8007\n",
      "Epoch 236/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 42.9935 - val_loss: 44.9881\n",
      "Epoch 237/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42.9450 - val_loss: 44.9226\n",
      "Epoch 238/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 42.9550 - val_loss: 44.5948\n",
      "Epoch 239/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 42.8653 - val_loss: 44.6374\n",
      "Epoch 240/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 43.0333 - val_loss: 44.8801\n",
      "Epoch 241/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 42.8619 - val_loss: 44.7581\n",
      "Epoch 242/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42.8835 - val_loss: 44.7380\n",
      "Epoch 243/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 42.8825 - val_loss: 44.4320\n",
      "Epoch 244/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 42.7782 - val_loss: 44.5507\n",
      "Epoch 245/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 42.7316 - val_loss: 44.5011\n",
      "Epoch 246/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 42.7247 - val_loss: 44.5999\n",
      "Epoch 247/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42.7138 - val_loss: 44.5512\n",
      "Epoch 248/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 42.6883 - val_loss: 44.6198\n",
      "Epoch 249/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42.6823 - val_loss: 44.4152\n",
      "Epoch 250/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42.6366 - val_loss: 44.3351\n",
      "Epoch 251/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42.6003 - val_loss: 44.3716\n",
      "Epoch 252/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42.5688 - val_loss: 44.3823\n",
      "Epoch 253/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42.5863 - val_loss: 44.3072\n",
      "Epoch 254/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42.5236 - val_loss: 44.2763\n",
      "Epoch 255/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 42.4889 - val_loss: 44.3774\n",
      "Epoch 256/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 42.4594 - val_loss: 44.4890\n",
      "Epoch 257/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 42.4743 - val_loss: 44.3707\n",
      "Epoch 258/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 42.4662 - val_loss: 44.1111\n",
      "Epoch 259/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42.3975 - val_loss: 44.1225\n",
      "Epoch 260/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42.4145 - val_loss: 44.1006\n",
      "Epoch 261/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42.4081 - val_loss: 44.0872\n",
      "Epoch 262/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 42.3353 - val_loss: 44.0104\n",
      "Epoch 263/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 42.2967 - val_loss: 44.0963\n",
      "Epoch 264/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 42.2796 - val_loss: 44.0414\n",
      "Epoch 265/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 42.2240 - val_loss: 44.0663\n",
      "Epoch 266/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 42.2794 - val_loss: 44.1072\n",
      "Epoch 267/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 42.2218 - val_loss: 44.0704\n",
      "Epoch 268/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42.3010 - val_loss: 43.9912\n",
      "Epoch 269/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 42.1691 - val_loss: 43.9347\n",
      "Epoch 270/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 42.1234 - val_loss: 43.7982\n",
      "Epoch 271/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 42.1311 - val_loss: 43.9807\n",
      "Epoch 272/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 42.1125 - val_loss: 43.8977\n",
      "Epoch 273/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 42.1248 - val_loss: 44.1243\n",
      "Epoch 274/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 42.0547 - val_loss: 44.0058\n",
      "Epoch 275/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42.0740 - val_loss: 43.7868\n",
      "Epoch 276/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41.9928 - val_loss: 43.9827\n",
      "Epoch 277/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41.9435 - val_loss: 43.7773\n",
      "Epoch 278/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41.9756 - val_loss: 43.6773\n",
      "Epoch 279/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 41.9050 - val_loss: 43.5981\n",
      "Epoch 280/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 41.9381 - val_loss: 43.7748\n",
      "Epoch 281/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41.9777 - val_loss: 43.5919\n",
      "Epoch 282/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41.8945 - val_loss: 43.6488\n",
      "Epoch 283/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41.8561 - val_loss: 43.7942\n",
      "Epoch 284/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41.8362 - val_loss: 43.5492\n",
      "Epoch 285/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41.8159 - val_loss: 43.5628\n",
      "Epoch 286/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41.7402 - val_loss: 43.5961\n",
      "Epoch 287/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41.7637 - val_loss: 43.5395\n",
      "Epoch 288/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41.7480 - val_loss: 43.3564\n",
      "Epoch 289/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41.6682 - val_loss: 43.4519\n",
      "Epoch 290/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41.7369 - val_loss: 43.2650\n",
      "Epoch 291/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41.6824 - val_loss: 43.1566\n",
      "Epoch 292/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41.6850 - val_loss: 43.0764\n",
      "Epoch 293/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41.6233 - val_loss: 43.2459\n",
      "Epoch 294/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41.6568 - val_loss: 43.1905\n",
      "Epoch 295/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41.6264 - val_loss: 43.4809\n",
      "Epoch 296/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41.5448 - val_loss: 43.2088\n",
      "Epoch 297/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41.5239 - val_loss: 43.4346\n",
      "Epoch 298/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 41.5287 - val_loss: 43.1514\n",
      "Epoch 299/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41.4446 - val_loss: 43.2442\n",
      "Epoch 300/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41.4536 - val_loss: 43.3250\n",
      "Epoch 301/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41.4048 - val_loss: 43.1131\n",
      "Epoch 302/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41.4439 - val_loss: 43.1216\n",
      "Epoch 303/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41.3538 - val_loss: 43.1487\n",
      "Epoch 304/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41.3564 - val_loss: 43.2753\n",
      "Epoch 305/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41.3463 - val_loss: 43.0583\n",
      "Epoch 306/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41.3629 - val_loss: 43.1051\n",
      "Epoch 307/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41.2819 - val_loss: 43.2431\n",
      "Epoch 308/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41.2858 - val_loss: 43.3376\n",
      "Epoch 309/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 41.3264 - val_loss: 43.0828\n",
      "Epoch 310/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41.2019 - val_loss: 43.0720\n",
      "Epoch 311/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41.2071 - val_loss: 43.0063\n",
      "Epoch 312/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41.1058 - val_loss: 43.0217\n",
      "Epoch 313/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41.1397 - val_loss: 42.8720\n",
      "Epoch 314/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41.1819 - val_loss: 43.0761\n",
      "Epoch 315/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41.0732 - val_loss: 42.8284\n",
      "Epoch 316/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41.0814 - val_loss: 42.9474\n",
      "Epoch 317/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 41.0799 - val_loss: 42.9546\n",
      "Epoch 318/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 41.0153 - val_loss: 42.8200\n",
      "Epoch 319/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 41.0079 - val_loss: 42.9077\n",
      "Epoch 320/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41.0040 - val_loss: 43.0695\n",
      "Epoch 321/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 41.0247 - val_loss: 42.6544\n",
      "Epoch 322/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 40.8966 - val_loss: 42.6868\n",
      "Epoch 323/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40.9336 - val_loss: 42.6539\n",
      "Epoch 324/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 40.8829 - val_loss: 42.6047\n",
      "Epoch 325/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 40.9051 - val_loss: 42.5455\n",
      "Epoch 326/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 40.9307 - val_loss: 42.8275\n",
      "Epoch 327/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 40.8542 - val_loss: 42.9599\n",
      "Epoch 328/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40.8175 - val_loss: 42.6893\n",
      "Epoch 329/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 40.7720 - val_loss: 42.5631\n",
      "Epoch 330/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 40.7577 - val_loss: 42.4891\n",
      "Epoch 331/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 40.7162 - val_loss: 42.5497\n",
      "Epoch 332/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40.7294 - val_loss: 42.5946\n",
      "Epoch 333/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 40.7091 - val_loss: 42.3250\n",
      "Epoch 334/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40.6734 - val_loss: 42.5081\n",
      "Epoch 335/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40.6505 - val_loss: 42.4822\n",
      "Epoch 336/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 40.6136 - val_loss: 42.5954\n",
      "Epoch 337/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 40.6077 - val_loss: 42.4530\n",
      "Epoch 338/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40.5783 - val_loss: 42.5115\n",
      "Epoch 339/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40.5477 - val_loss: 42.4891\n",
      "Epoch 340/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40.5495 - val_loss: 42.7070\n",
      "Epoch 341/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40.5035 - val_loss: 42.4861\n",
      "Epoch 342/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 40.5993 - val_loss: 42.4010\n",
      "Epoch 343/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 40.4999 - val_loss: 42.0891\n",
      "Epoch 344/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40.4872 - val_loss: 41.9639\n",
      "Epoch 345/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 40.4332 - val_loss: 42.1066\n",
      "Epoch 346/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40.3748 - val_loss: 42.2794\n",
      "Epoch 347/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 40.3582 - val_loss: 42.4298\n",
      "Epoch 348/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 40.3533 - val_loss: 42.2839\n",
      "Epoch 349/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 40.2841 - val_loss: 42.1916\n",
      "Epoch 350/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 40.2795 - val_loss: 42.2213\n",
      "Epoch 351/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40.3683 - val_loss: 42.4431\n",
      "Epoch 352/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40.2338 - val_loss: 42.1525\n",
      "Epoch 353/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 40.2826 - val_loss: 42.0703\n",
      "Epoch 354/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 40.3779 - val_loss: 42.3277\n",
      "Epoch 355/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40.2358 - val_loss: 41.9344\n",
      "Epoch 356/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40.1594 - val_loss: 41.9070\n",
      "Epoch 357/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 40.1018 - val_loss: 41.9413\n",
      "Epoch 358/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 40.0970 - val_loss: 41.8865\n",
      "Epoch 359/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 40.1111 - val_loss: 41.8393\n",
      "Epoch 360/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 40.1394 - val_loss: 42.0169\n",
      "Epoch 361/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 40.0560 - val_loss: 41.9028\n",
      "Epoch 362/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39.9715 - val_loss: 41.8320\n",
      "Epoch 363/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39.9762 - val_loss: 41.9388\n",
      "Epoch 364/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39.9603 - val_loss: 41.9856\n",
      "Epoch 365/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 39.9657 - val_loss: 41.8484\n",
      "Epoch 366/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 40.0051 - val_loss: 41.9026\n",
      "Epoch 367/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39.8625 - val_loss: 41.7249\n",
      "Epoch 368/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39.8819 - val_loss: 41.6583\n",
      "Epoch 369/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 39.8186 - val_loss: 41.8148\n",
      "Epoch 370/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39.8233 - val_loss: 41.6543\n",
      "Epoch 371/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39.8487 - val_loss: 41.8571\n",
      "Epoch 372/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39.8156 - val_loss: 41.9568\n",
      "Epoch 373/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39.7952 - val_loss: 41.3733\n",
      "Epoch 374/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39.7416 - val_loss: 41.5092\n",
      "Epoch 375/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39.8132 - val_loss: 41.6465\n",
      "Epoch 376/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 39.6514 - val_loss: 41.5667\n",
      "Epoch 377/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39.6459 - val_loss: 41.4295\n",
      "Epoch 378/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39.6861 - val_loss: 41.4291\n",
      "Epoch 379/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39.6664 - val_loss: 41.5730\n",
      "Epoch 380/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 39.5906 - val_loss: 41.5471\n",
      "Epoch 381/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 39.5653 - val_loss: 41.5932\n",
      "Epoch 382/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 39.5312 - val_loss: 41.5788\n",
      "Epoch 383/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39.5458 - val_loss: 41.4308\n",
      "Epoch 384/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39.4859 - val_loss: 41.3781\n",
      "Epoch 385/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39.4684 - val_loss: 41.2609\n",
      "Epoch 386/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 39.5473 - val_loss: 41.7466\n",
      "Epoch 387/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39.4896 - val_loss: 41.7827\n",
      "Epoch 388/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39.4479 - val_loss: 41.2191\n",
      "Epoch 389/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39.4066 - val_loss: 41.3164\n",
      "Epoch 390/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39.3588 - val_loss: 41.4435\n",
      "Epoch 391/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39.3495 - val_loss: 41.3027\n",
      "Epoch 392/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39.3232 - val_loss: 41.1345\n",
      "Epoch 393/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 39.3209 - val_loss: 41.2381\n",
      "Epoch 394/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 39.3063 - val_loss: 41.2331\n",
      "Epoch 395/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 39.2543 - val_loss: 41.3375\n",
      "Epoch 396/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39.2641 - val_loss: 41.3391\n",
      "Epoch 397/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 39.1889 - val_loss: 41.0590\n",
      "Epoch 398/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39.1686 - val_loss: 41.1557\n",
      "Epoch 399/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 39.1777 - val_loss: 41.0424\n",
      "Epoch 400/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39.1525 - val_loss: 41.1780\n",
      "Epoch 401/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39.1305 - val_loss: 41.0241\n",
      "Epoch 402/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39.0833 - val_loss: 40.9000\n",
      "Epoch 403/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39.0696 - val_loss: 40.9418\n",
      "Epoch 404/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39.0445 - val_loss: 40.9978\n",
      "Epoch 405/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39.0738 - val_loss: 40.7481\n",
      "Epoch 406/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39.0503 - val_loss: 40.8451\n",
      "Epoch 407/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 38.9959 - val_loss: 40.7940\n",
      "Epoch 408/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 38.9443 - val_loss: 40.9474\n",
      "Epoch 409/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 38.9370 - val_loss: 40.9301\n",
      "Epoch 410/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 38.9279 - val_loss: 40.7730\n",
      "Epoch 411/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 38.8900 - val_loss: 40.7525\n",
      "Epoch 412/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 38.8621 - val_loss: 40.8198\n",
      "Epoch 413/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 38.8623 - val_loss: 40.7358\n",
      "Epoch 414/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 38.8509 - val_loss: 40.6204\n",
      "Epoch 415/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 38.8048 - val_loss: 40.5175\n",
      "Epoch 416/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 38.8813 - val_loss: 40.8379\n",
      "Epoch 417/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 38.7694 - val_loss: 40.7604\n",
      "Epoch 418/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 38.7456 - val_loss: 40.7907\n",
      "Epoch 419/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 38.7425 - val_loss: 40.6838\n",
      "Epoch 420/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38.7161 - val_loss: 40.4970\n",
      "Epoch 421/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 38.6914 - val_loss: 40.4382\n",
      "Epoch 422/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 38.6764 - val_loss: 40.5755\n",
      "Epoch 423/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 38.6575 - val_loss: 40.5408\n",
      "Epoch 424/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38.5866 - val_loss: 40.4148\n",
      "Epoch 425/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38.5705 - val_loss: 40.4453\n",
      "Epoch 426/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 38.5965 - val_loss: 40.6432\n",
      "Epoch 427/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 38.5965 - val_loss: 40.4523\n",
      "Epoch 428/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.5185 - val_loss: 40.3435\n",
      "Epoch 429/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 38.5454 - val_loss: 40.1373\n",
      "Epoch 430/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 38.4771 - val_loss: 40.2444\n",
      "Epoch 431/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38.4304 - val_loss: 40.3195\n",
      "Epoch 432/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 38.4239 - val_loss: 40.2206\n",
      "Epoch 433/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 38.4489 - val_loss: 40.4877\n",
      "Epoch 434/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38.3871 - val_loss: 40.2794\n",
      "Epoch 435/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 38.3373 - val_loss: 40.2065\n",
      "Epoch 436/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 38.4250 - val_loss: 40.3007\n",
      "Epoch 437/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 38.3350 - val_loss: 40.1572\n",
      "Epoch 438/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 38.2782 - val_loss: 40.1528\n",
      "Epoch 439/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 38.3267 - val_loss: 40.1001\n",
      "Epoch 440/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38.2543 - val_loss: 40.0993\n",
      "Epoch 441/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 38.3404 - val_loss: 40.2410\n",
      "Epoch 442/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 38.2824 - val_loss: 40.1173\n",
      "Epoch 443/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38.1997 - val_loss: 40.1597\n",
      "Epoch 444/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 38.1745 - val_loss: 39.8968\n",
      "Epoch 445/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 38.1621 - val_loss: 39.8619\n",
      "Epoch 446/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 38.1869 - val_loss: 40.1895\n",
      "Epoch 447/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 38.0892 - val_loss: 40.0029\n",
      "Epoch 448/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 38.1773 - val_loss: 40.1970\n",
      "Epoch 449/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 38.0829 - val_loss: 40.1331\n",
      "Epoch 450/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 38.0402 - val_loss: 39.9182\n",
      "Epoch 451/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 38.0010 - val_loss: 39.8760\n",
      "Epoch 452/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 37.9928 - val_loss: 39.8951\n",
      "Epoch 453/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38.0141 - val_loss: 39.7671\n",
      "Epoch 454/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 37.9670 - val_loss: 39.6540\n",
      "Epoch 455/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 37.9464 - val_loss: 39.7039\n",
      "Epoch 456/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 37.9912 - val_loss: 39.7845\n",
      "Epoch 457/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 37.9001 - val_loss: 39.7812\n",
      "Epoch 458/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 37.8334 - val_loss: 39.6869\n",
      "Epoch 459/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 37.8889 - val_loss: 39.7718\n",
      "Epoch 460/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37.8360 - val_loss: 39.6800\n",
      "Epoch 461/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 37.7893 - val_loss: 39.6693\n",
      "Epoch 462/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 37.7591 - val_loss: 39.5973\n",
      "Epoch 463/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37.7631 - val_loss: 39.5610\n",
      "Epoch 464/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37.7458 - val_loss: 39.8595\n",
      "Epoch 465/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 37.7152 - val_loss: 39.6547\n",
      "Epoch 466/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 37.6601 - val_loss: 39.6248\n",
      "Epoch 467/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 37.6910 - val_loss: 39.5296\n",
      "Epoch 468/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37.6874 - val_loss: 39.5606\n",
      "Epoch 469/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37.6598 - val_loss: 39.5891\n",
      "Epoch 470/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 37.5959 - val_loss: 39.4602\n",
      "Epoch 471/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37.5789 - val_loss: 39.5331\n",
      "Epoch 472/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37.5840 - val_loss: 39.7147\n",
      "Epoch 473/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37.5210 - val_loss: 39.4377\n",
      "Epoch 474/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 37.5711 - val_loss: 39.2478\n",
      "Epoch 475/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 37.5169 - val_loss: 39.1670\n",
      "Epoch 476/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 37.4648 - val_loss: 39.2357\n",
      "Epoch 477/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 37.4262 - val_loss: 39.2082\n",
      "Epoch 478/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 37.4250 - val_loss: 39.1444\n",
      "Epoch 479/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 37.4165 - val_loss: 39.2596\n",
      "Epoch 480/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37.3749 - val_loss: 39.1034\n",
      "Epoch 481/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 37.3470 - val_loss: 39.1052\n",
      "Epoch 482/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 37.3657 - val_loss: 39.2324\n",
      "Epoch 483/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 37.2774 - val_loss: 39.1806\n",
      "Epoch 484/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 37.2674 - val_loss: 39.1764\n",
      "Epoch 485/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 37.2927 - val_loss: 39.2343\n",
      "Epoch 486/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 37.2551 - val_loss: 39.3033\n",
      "Epoch 487/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 37.2420 - val_loss: 39.0848\n",
      "Epoch 488/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37.1872 - val_loss: 39.0301\n",
      "Epoch 489/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 37.1974 - val_loss: 38.9565\n",
      "Epoch 490/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 37.1789 - val_loss: 39.0548\n",
      "Epoch 491/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37.1477 - val_loss: 38.9465\n",
      "Epoch 492/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37.1079 - val_loss: 39.0309\n",
      "Epoch 493/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 37.0859 - val_loss: 39.0919\n",
      "Epoch 494/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 37.0757 - val_loss: 39.1147\n",
      "Epoch 495/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37.0820 - val_loss: 39.0093\n",
      "Epoch 496/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37.0067 - val_loss: 38.8786\n",
      "Epoch 497/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36.9884 - val_loss: 38.9156\n",
      "Epoch 498/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36.9825 - val_loss: 38.9535\n",
      "Epoch 499/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36.9673 - val_loss: 39.0158\n",
      "Epoch 500/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36.9740 - val_loss: 38.7730\n",
      "Epoch 501/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36.9190 - val_loss: 38.9545\n",
      "Epoch 502/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36.9011 - val_loss: 38.9787\n",
      "Epoch 503/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36.8571 - val_loss: 38.7560\n",
      "Epoch 504/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36.9133 - val_loss: 38.6383\n",
      "Epoch 505/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36.8255 - val_loss: 38.6959\n",
      "Epoch 506/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36.8095 - val_loss: 38.9034\n",
      "Epoch 507/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 36.8297 - val_loss: 38.5759\n",
      "Epoch 508/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36.8048 - val_loss: 38.8853\n",
      "Epoch 509/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36.7921 - val_loss: 38.9150\n",
      "Epoch 510/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 36.7083 - val_loss: 38.8574\n",
      "Epoch 511/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36.7040 - val_loss: 38.5790\n",
      "Epoch 512/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36.7417 - val_loss: 38.6121\n",
      "Epoch 513/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 36.6675 - val_loss: 38.6298\n",
      "Epoch 514/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36.6441 - val_loss: 38.7847\n",
      "Epoch 515/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 36.6465 - val_loss: 38.4353\n",
      "Epoch 516/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 36.6203 - val_loss: 38.3552\n",
      "Epoch 517/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36.5818 - val_loss: 38.5041\n",
      "Epoch 518/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 36.6631 - val_loss: 38.5109\n",
      "Epoch 519/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 36.5414 - val_loss: 38.3962\n",
      "Epoch 520/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 36.4944 - val_loss: 38.4153\n",
      "Epoch 521/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 36.4628 - val_loss: 38.3677\n",
      "Epoch 522/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 36.4569 - val_loss: 38.4465\n",
      "Epoch 523/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 36.5140 - val_loss: 38.4776\n",
      "Epoch 524/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 36.4502 - val_loss: 38.2939\n",
      "Epoch 525/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 36.4085 - val_loss: 38.3200\n",
      "Epoch 526/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 36.3713 - val_loss: 38.3753\n",
      "Epoch 527/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 36.3483 - val_loss: 38.3080\n",
      "Epoch 528/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 36.3467 - val_loss: 38.1408\n",
      "Epoch 529/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 36.3713 - val_loss: 38.1474\n",
      "Epoch 530/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 36.2720 - val_loss: 38.2621\n",
      "Epoch 531/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 36.2824 - val_loss: 38.0863\n",
      "Epoch 532/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 36.2961 - val_loss: 38.4743\n",
      "Epoch 533/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 36.2133 - val_loss: 38.1886\n",
      "Epoch 534/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 36.2192 - val_loss: 38.2434\n",
      "Epoch 535/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 36.1651 - val_loss: 38.2145\n",
      "Epoch 536/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 36.1767 - val_loss: 37.9305\n",
      "Epoch 537/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 36.1452 - val_loss: 38.0260\n",
      "Epoch 538/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 36.1236 - val_loss: 38.1229\n",
      "Epoch 539/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 36.1308 - val_loss: 37.8517\n",
      "Epoch 540/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36.0895 - val_loss: 37.8610\n",
      "Epoch 541/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 36.1001 - val_loss: 37.9293\n",
      "Epoch 542/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 36.0434 - val_loss: 38.0196\n",
      "Epoch 543/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 36.0537 - val_loss: 37.8008\n",
      "Epoch 544/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 36.0471 - val_loss: 38.0176\n",
      "Epoch 545/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 35.9635 - val_loss: 37.9338\n",
      "Epoch 546/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 36.0874 - val_loss: 38.2910\n",
      "Epoch 547/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 35.9374 - val_loss: 37.9130\n",
      "Epoch 548/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 35.9330 - val_loss: 37.9103\n",
      "Epoch 549/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 35.9083 - val_loss: 37.8020\n",
      "Epoch 550/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 35.9005 - val_loss: 37.9903\n",
      "Epoch 551/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 35.8885 - val_loss: 37.7309\n",
      "Epoch 552/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 35.8990 - val_loss: 37.9010\n",
      "Epoch 553/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 35.8849 - val_loss: 37.7008\n",
      "Epoch 554/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 35.8021 - val_loss: 37.6408\n",
      "Epoch 555/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 35.7560 - val_loss: 37.7042\n",
      "Epoch 556/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 35.7698 - val_loss: 37.6638\n",
      "Epoch 557/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 35.7184 - val_loss: 37.6199\n",
      "Epoch 558/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 35.7247 - val_loss: 37.5923\n",
      "Epoch 559/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 35.6967 - val_loss: 37.7702\n",
      "Epoch 560/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 35.6425 - val_loss: 37.6539\n",
      "Epoch 561/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 35.6660 - val_loss: 37.4894\n",
      "Epoch 562/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 35.6114 - val_loss: 37.5571\n",
      "Epoch 563/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 35.6216 - val_loss: 37.4567\n",
      "Epoch 564/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 35.5423 - val_loss: 37.5190\n",
      "Epoch 565/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 35.5789 - val_loss: 37.4203\n",
      "Epoch 566/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 35.5076 - val_loss: 37.4960\n",
      "Epoch 567/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 35.5160 - val_loss: 37.4986\n",
      "Epoch 568/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 35.4877 - val_loss: 37.5467\n",
      "Epoch 569/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 35.4644 - val_loss: 37.4421\n",
      "Epoch 570/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 35.4546 - val_loss: 37.3369\n",
      "Epoch 571/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 35.4274 - val_loss: 37.3764\n",
      "Epoch 572/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 35.3860 - val_loss: 37.3365\n",
      "Epoch 573/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.3892 - val_loss: 37.3401\n",
      "Epoch 574/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 35.3941 - val_loss: 37.3216\n",
      "Epoch 575/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 35.4035 - val_loss: 37.6013\n",
      "Epoch 576/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.3787 - val_loss: 37.1572\n",
      "Epoch 577/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 35.3090 - val_loss: 37.3213\n",
      "Epoch 578/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 35.2914 - val_loss: 37.3526\n",
      "Epoch 579/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 35.2566 - val_loss: 37.2064\n",
      "Epoch 580/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 35.2347 - val_loss: 37.3190\n",
      "Epoch 581/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 35.2337 - val_loss: 37.3986\n",
      "Epoch 582/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 35.2206 - val_loss: 37.3338\n",
      "Epoch 583/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 35.1975 - val_loss: 37.1362\n",
      "Epoch 584/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 35.1502 - val_loss: 37.1951\n",
      "Epoch 585/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 35.1385 - val_loss: 37.0850\n",
      "Epoch 586/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 35.1147 - val_loss: 37.2405\n",
      "Epoch 587/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 35.1017 - val_loss: 37.0367\n",
      "Epoch 588/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 35.1349 - val_loss: 36.8831\n",
      "Epoch 589/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 35.0803 - val_loss: 36.8606\n",
      "Epoch 590/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 35.0671 - val_loss: 37.1468\n",
      "Epoch 591/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 35.0232 - val_loss: 36.9174\n",
      "Epoch 592/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 35.0494 - val_loss: 37.1658\n",
      "Epoch 593/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 35.0058 - val_loss: 36.9987\n",
      "Epoch 594/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 35.1003 - val_loss: 37.4979\n",
      "Epoch 595/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 35.0260 - val_loss: 37.1122\n",
      "Epoch 596/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.9316 - val_loss: 36.8305\n",
      "Epoch 597/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34.9017 - val_loss: 36.8693\n",
      "Epoch 598/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 34.9908 - val_loss: 36.6714\n",
      "Epoch 599/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34.8670 - val_loss: 36.9034\n",
      "Epoch 600/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 34.9110 - val_loss: 36.7400\n",
      "Epoch 601/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 34.8588 - val_loss: 36.7195\n",
      "Epoch 602/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 34.8033 - val_loss: 36.7161\n",
      "Epoch 603/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34.8153 - val_loss: 36.6009\n",
      "Epoch 604/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 34.7558 - val_loss: 36.7422\n",
      "Epoch 605/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 34.7276 - val_loss: 36.8868\n",
      "Epoch 606/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 34.7441 - val_loss: 36.8018\n",
      "Epoch 607/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.6963 - val_loss: 36.6097\n",
      "Epoch 608/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34.7191 - val_loss: 37.0043\n",
      "Epoch 609/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.7207 - val_loss: 36.7180\n",
      "Epoch 610/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 34.6110 - val_loss: 36.6756\n",
      "Epoch 611/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 34.6116 - val_loss: 36.8210\n",
      "Epoch 612/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 34.5768 - val_loss: 36.5772\n",
      "Epoch 613/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 34.5788 - val_loss: 36.6015\n",
      "Epoch 614/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 34.5112 - val_loss: 36.5173\n",
      "Epoch 615/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34.5242 - val_loss: 36.5878\n",
      "Epoch 616/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 34.5490 - val_loss: 36.6272\n",
      "Epoch 617/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.5093 - val_loss: 36.4402\n",
      "Epoch 618/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 34.4803 - val_loss: 36.5443\n",
      "Epoch 619/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34.4275 - val_loss: 36.4777\n",
      "Epoch 620/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 34.4003 - val_loss: 36.3916\n",
      "Epoch 621/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 34.4191 - val_loss: 36.3588\n",
      "Epoch 622/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 34.3881 - val_loss: 36.4069\n",
      "Epoch 623/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 34.3301 - val_loss: 36.2219\n",
      "Epoch 624/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 34.3402 - val_loss: 36.3059\n",
      "Epoch 625/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 34.3672 - val_loss: 36.1787\n",
      "Epoch 626/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 34.2724 - val_loss: 36.1380\n",
      "Epoch 627/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 34.2506 - val_loss: 36.2647\n",
      "Epoch 628/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34.2504 - val_loss: 36.1638\n",
      "Epoch 629/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 34.2851 - val_loss: 36.0018\n",
      "Epoch 630/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 34.2133 - val_loss: 36.2046\n",
      "Epoch 631/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 34.1901 - val_loss: 36.0669\n",
      "Epoch 632/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 34.1954 - val_loss: 36.2681\n",
      "Epoch 633/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 34.1351 - val_loss: 36.2900\n",
      "Epoch 634/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 34.1483 - val_loss: 36.0099\n",
      "Epoch 635/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 34.1046 - val_loss: 36.0385\n",
      "Epoch 636/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 34.1065 - val_loss: 36.0738\n",
      "Epoch 637/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 34.0923 - val_loss: 36.1236\n",
      "Epoch 638/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 34.0221 - val_loss: 36.0284\n",
      "Epoch 639/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34.0210 - val_loss: 35.9233\n",
      "Epoch 640/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33.9919 - val_loss: 36.0071\n",
      "Epoch 641/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 33.9921 - val_loss: 35.8858\n",
      "Epoch 642/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 34.0014 - val_loss: 35.8027\n",
      "Epoch 643/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33.9223 - val_loss: 35.8831\n",
      "Epoch 644/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 33.9537 - val_loss: 35.9954\n",
      "Epoch 645/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33.9362 - val_loss: 35.8549\n",
      "Epoch 646/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 33.8975 - val_loss: 35.7143\n",
      "Epoch 647/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 33.8642 - val_loss: 35.6767\n",
      "Epoch 648/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 33.8597 - val_loss: 35.8081\n",
      "Epoch 649/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33.8608 - val_loss: 35.7426\n",
      "Epoch 650/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33.8588 - val_loss: 35.7184\n",
      "Epoch 651/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33.8064 - val_loss: 36.0905\n",
      "Epoch 652/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33.7995 - val_loss: 35.7727\n",
      "Epoch 653/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 33.7811 - val_loss: 35.6644\n",
      "Epoch 654/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33.7463 - val_loss: 35.6724\n",
      "Epoch 655/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 33.7041 - val_loss: 35.7151\n",
      "Epoch 656/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33.6787 - val_loss: 35.7548\n",
      "Epoch 657/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33.6627 - val_loss: 35.6782\n",
      "Epoch 658/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33.6332 - val_loss: 35.5962\n",
      "Epoch 659/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 33.6134 - val_loss: 35.5025\n",
      "Epoch 660/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 33.6321 - val_loss: 35.8204\n",
      "Epoch 661/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33.5979 - val_loss: 35.8831\n",
      "Epoch 662/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33.5490 - val_loss: 35.5027\n",
      "Epoch 663/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 33.5557 - val_loss: 35.5543\n",
      "Epoch 664/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 33.5126 - val_loss: 35.5484\n",
      "Epoch 665/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33.4991 - val_loss: 35.4138\n",
      "Epoch 666/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 33.5017 - val_loss: 35.4914\n",
      "Epoch 667/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 33.4654 - val_loss: 35.3961\n",
      "Epoch 668/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 33.4762 - val_loss: 35.4190\n",
      "Epoch 669/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 33.4979 - val_loss: 35.7013\n",
      "Epoch 670/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 33.4047 - val_loss: 35.4209\n",
      "Epoch 671/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 33.3909 - val_loss: 35.2605\n",
      "Epoch 672/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 33.3657 - val_loss: 35.2567\n",
      "Epoch 673/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 33.3106 - val_loss: 35.2324\n",
      "Epoch 674/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 33.3123 - val_loss: 35.3762\n",
      "Epoch 675/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 33.3242 - val_loss: 35.4351\n",
      "Epoch 676/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 33.3087 - val_loss: 35.4399\n",
      "Epoch 677/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 33.2426 - val_loss: 35.2941\n",
      "Epoch 678/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 33.2694 - val_loss: 35.2895\n",
      "Epoch 679/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33.2410 - val_loss: 35.3598\n",
      "Epoch 680/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 33.2277 - val_loss: 35.1178\n",
      "Epoch 681/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 33.1832 - val_loss: 35.1655\n",
      "Epoch 682/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 33.1731 - val_loss: 35.1505\n",
      "Epoch 683/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33.1613 - val_loss: 35.0637\n",
      "Epoch 684/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 33.2088 - val_loss: 35.3123\n",
      "Epoch 685/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 33.1017 - val_loss: 35.1984\n",
      "Epoch 686/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 33.1284 - val_loss: 34.9291\n",
      "Epoch 687/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 33.0889 - val_loss: 34.8451\n",
      "Epoch 688/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 33.0902 - val_loss: 34.9629\n",
      "Epoch 689/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 33.0332 - val_loss: 35.0825\n",
      "Epoch 690/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 33.0224 - val_loss: 35.0885\n",
      "Epoch 691/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 32.9953 - val_loss: 35.1170\n",
      "Epoch 692/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 32.9756 - val_loss: 35.1755\n",
      "Epoch 693/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 32.9238 - val_loss: 35.0496\n",
      "Epoch 694/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.9071 - val_loss: 34.9356\n",
      "Epoch 695/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.9578 - val_loss: 34.8844\n",
      "Epoch 696/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.8868 - val_loss: 34.9168\n",
      "Epoch 697/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 32.8443 - val_loss: 34.8491\n",
      "Epoch 698/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 32.8305 - val_loss: 34.8095\n",
      "Epoch 699/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 32.8063 - val_loss: 34.8907\n",
      "Epoch 700/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 32.8416 - val_loss: 34.7187\n",
      "Epoch 701/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 32.7858 - val_loss: 34.9084\n",
      "Epoch 702/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.7717 - val_loss: 34.8840\n",
      "Epoch 703/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.7924 - val_loss: 34.5898\n",
      "Epoch 704/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.7683 - val_loss: 34.8433\n",
      "Epoch 705/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.7087 - val_loss: 34.8631\n",
      "Epoch 706/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.7138 - val_loss: 34.7411\n",
      "Epoch 707/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.6704 - val_loss: 34.7382\n",
      "Epoch 708/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.6462 - val_loss: 34.6827\n",
      "Epoch 709/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.6110 - val_loss: 34.7237\n",
      "Epoch 710/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.5994 - val_loss: 34.5788\n",
      "Epoch 711/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.6209 - val_loss: 34.6786\n",
      "Epoch 712/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 32.5945 - val_loss: 34.5782\n",
      "Epoch 713/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.5608 - val_loss: 34.6205\n",
      "Epoch 714/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.5648 - val_loss: 34.3651\n",
      "Epoch 715/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.5294 - val_loss: 34.3148\n",
      "Epoch 716/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.4808 - val_loss: 34.2388\n",
      "Epoch 717/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.4762 - val_loss: 34.3264\n",
      "Epoch 718/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.4435 - val_loss: 34.3883\n",
      "Epoch 719/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.4063 - val_loss: 34.3114\n",
      "Epoch 720/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.4237 - val_loss: 34.2547\n",
      "Epoch 721/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.3794 - val_loss: 34.3979\n",
      "Epoch 722/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.4370 - val_loss: 34.5897\n",
      "Epoch 723/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.4382 - val_loss: 34.3633\n",
      "Epoch 724/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.3506 - val_loss: 34.3676\n",
      "Epoch 725/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.3500 - val_loss: 34.4129\n",
      "Epoch 726/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.3019 - val_loss: 34.1861\n",
      "Epoch 727/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.3177 - val_loss: 34.5222\n",
      "Epoch 728/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.2675 - val_loss: 34.3360\n",
      "Epoch 729/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.1952 - val_loss: 34.1890\n",
      "Epoch 730/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.2388 - val_loss: 34.2301\n",
      "Epoch 731/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 32.2155 - val_loss: 34.3816\n",
      "Epoch 732/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.2167 - val_loss: 34.2501\n",
      "Epoch 733/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.1358 - val_loss: 34.1691\n",
      "Epoch 734/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.1335 - val_loss: 34.2119\n",
      "Epoch 735/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.0980 - val_loss: 34.0934\n",
      "Epoch 736/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.1349 - val_loss: 33.9305\n",
      "Epoch 737/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.0903 - val_loss: 34.1298\n",
      "Epoch 738/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.0572 - val_loss: 33.9117\n",
      "Epoch 739/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.0197 - val_loss: 33.9589\n",
      "Epoch 740/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.0156 - val_loss: 34.2246\n",
      "Epoch 741/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31.9909 - val_loss: 33.9853\n",
      "Epoch 742/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.0013 - val_loss: 33.7359\n",
      "Epoch 743/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31.9544 - val_loss: 33.8233\n",
      "Epoch 744/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31.9679 - val_loss: 33.8736\n",
      "Epoch 745/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 31.9100 - val_loss: 34.0372\n",
      "Epoch 746/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31.9106 - val_loss: 33.8142\n",
      "Epoch 747/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31.9027 - val_loss: 33.7074\n",
      "Epoch 748/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31.8749 - val_loss: 33.9258\n",
      "Epoch 749/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 31.8799 - val_loss: 33.9068\n",
      "Epoch 750/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31.8126 - val_loss: 33.8564\n",
      "Epoch 751/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31.8013 - val_loss: 33.9764\n",
      "Epoch 752/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31.8128 - val_loss: 33.7612\n",
      "Epoch 753/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31.8241 - val_loss: 33.6389\n",
      "Epoch 754/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31.7404 - val_loss: 33.6123\n",
      "Epoch 755/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31.7175 - val_loss: 33.6989\n",
      "Epoch 756/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31.7261 - val_loss: 33.7640\n",
      "Epoch 757/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 31.6793 - val_loss: 33.6996\n",
      "Epoch 758/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31.6571 - val_loss: 33.7938\n",
      "Epoch 759/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31.6238 - val_loss: 33.6384\n",
      "Epoch 760/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31.6477 - val_loss: 33.6194\n",
      "Epoch 761/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31.6100 - val_loss: 33.5938\n",
      "Epoch 762/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31.5819 - val_loss: 33.6490\n",
      "Epoch 763/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 31.5516 - val_loss: 33.6618\n",
      "Epoch 764/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31.5699 - val_loss: 33.5646\n",
      "Epoch 765/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31.5288 - val_loss: 33.3818\n",
      "Epoch 766/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 31.4855 - val_loss: 33.5273\n",
      "Epoch 767/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31.4772 - val_loss: 33.4527\n",
      "Epoch 768/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31.4765 - val_loss: 33.3042\n",
      "Epoch 769/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31.4495 - val_loss: 33.5286\n",
      "Epoch 770/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31.4369 - val_loss: 33.6139\n",
      "Epoch 771/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31.5384 - val_loss: 33.8812\n",
      "Epoch 772/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31.4123 - val_loss: 33.5723\n",
      "Epoch 773/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31.3918 - val_loss: 33.4277\n",
      "Epoch 774/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31.3575 - val_loss: 33.4270\n",
      "Epoch 775/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31.3508 - val_loss: 33.5225\n",
      "Epoch 776/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31.3390 - val_loss: 33.3221\n",
      "Epoch 777/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31.3071 - val_loss: 33.2735\n",
      "Epoch 778/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 31.2734 - val_loss: 33.3200\n",
      "Epoch 779/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 31.2620 - val_loss: 33.2045\n",
      "Epoch 780/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31.2637 - val_loss: 33.3240\n",
      "Epoch 781/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31.2642 - val_loss: 33.0718\n",
      "Epoch 782/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31.2002 - val_loss: 33.2769\n",
      "Epoch 783/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31.1664 - val_loss: 33.1253\n",
      "Epoch 784/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31.1700 - val_loss: 33.0002\n",
      "Epoch 785/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31.1470 - val_loss: 33.0187\n",
      "Epoch 786/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31.1118 - val_loss: 33.1219\n",
      "Epoch 787/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 31.0815 - val_loss: 33.1984\n",
      "Epoch 788/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31.1016 - val_loss: 33.0991\n",
      "Epoch 789/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31.0744 - val_loss: 33.0964\n",
      "Epoch 790/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 31.0350 - val_loss: 33.1546\n",
      "Epoch 791/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31.0766 - val_loss: 33.0826\n",
      "Epoch 792/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 31.0526 - val_loss: 33.2239\n",
      "Epoch 793/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 31.0142 - val_loss: 33.0152\n",
      "Epoch 794/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 31.0123 - val_loss: 33.0715\n",
      "Epoch 795/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30.9242 - val_loss: 32.9642\n",
      "Epoch 796/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30.9231 - val_loss: 32.8772\n",
      "Epoch 797/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 30.9324 - val_loss: 33.0889\n",
      "Epoch 798/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30.9128 - val_loss: 32.9675\n",
      "Epoch 799/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30.8552 - val_loss: 32.8676\n",
      "Epoch 800/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 30.8981 - val_loss: 32.6276\n",
      "Epoch 801/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30.8488 - val_loss: 32.8479\n",
      "Epoch 802/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 30.8146 - val_loss: 32.7327\n",
      "Epoch 803/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 30.8191 - val_loss: 32.6894\n",
      "Epoch 804/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 30.7866 - val_loss: 32.8112\n",
      "Epoch 805/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30.7806 - val_loss: 32.7067\n",
      "Epoch 806/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30.7736 - val_loss: 32.9724\n",
      "Epoch 807/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30.7420 - val_loss: 32.7217\n",
      "Epoch 808/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30.6946 - val_loss: 32.7383\n",
      "Epoch 809/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 30.6761 - val_loss: 32.5450\n",
      "Epoch 810/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 30.6809 - val_loss: 32.5524\n",
      "Epoch 811/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30.6408 - val_loss: 32.6316\n",
      "Epoch 812/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 30.6328 - val_loss: 32.6505\n",
      "Epoch 813/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30.6143 - val_loss: 32.5613\n",
      "Epoch 814/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30.5848 - val_loss: 32.5960\n",
      "Epoch 815/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30.5699 - val_loss: 32.5569\n",
      "Epoch 816/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30.5808 - val_loss: 32.4657\n",
      "Epoch 817/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30.5380 - val_loss: 32.6080\n",
      "Epoch 818/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 30.5049 - val_loss: 32.4374\n",
      "Epoch 819/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30.4841 - val_loss: 32.6025\n",
      "Epoch 820/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 30.4746 - val_loss: 32.4839\n",
      "Epoch 821/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30.4593 - val_loss: 32.5489\n",
      "Epoch 822/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30.4806 - val_loss: 32.8507\n",
      "Epoch 823/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30.4327 - val_loss: 32.5007\n",
      "Epoch 824/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 30.4051 - val_loss: 32.3868\n",
      "Epoch 825/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 30.4060 - val_loss: 32.3571\n",
      "Epoch 826/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30.4492 - val_loss: 32.8335\n",
      "Epoch 827/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 30.3821 - val_loss: 32.3730\n",
      "Epoch 828/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 30.3550 - val_loss: 32.2590\n",
      "Epoch 829/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 30.3105 - val_loss: 32.3965\n",
      "Epoch 830/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 30.2946 - val_loss: 32.4267\n",
      "Epoch 831/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30.2771 - val_loss: 32.2339\n",
      "Epoch 832/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 30.2484 - val_loss: 32.2678\n",
      "Epoch 833/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30.2342 - val_loss: 32.3334\n",
      "Epoch 834/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30.2067 - val_loss: 32.2758\n",
      "Epoch 835/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 30.2111 - val_loss: 32.1178\n",
      "Epoch 836/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30.1832 - val_loss: 32.1076\n",
      "Epoch 837/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30.1640 - val_loss: 32.2810\n",
      "Epoch 838/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30.1236 - val_loss: 32.2478\n",
      "Epoch 839/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30.1092 - val_loss: 32.1465\n",
      "Epoch 840/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 30.0978 - val_loss: 32.0368\n",
      "Epoch 841/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 30.0882 - val_loss: 32.1344\n",
      "Epoch 842/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30.0657 - val_loss: 32.0928\n",
      "Epoch 843/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30.0505 - val_loss: 32.0480\n",
      "Epoch 844/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30.0347 - val_loss: 32.3256\n",
      "Epoch 845/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.9991 - val_loss: 32.0491\n",
      "Epoch 846/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29.9962 - val_loss: 32.0965\n",
      "Epoch 847/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29.9897 - val_loss: 31.8762\n",
      "Epoch 848/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29.9782 - val_loss: 31.8725\n",
      "Epoch 849/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29.9310 - val_loss: 31.8343\n",
      "Epoch 850/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.9293 - val_loss: 32.0019\n",
      "Epoch 851/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.9101 - val_loss: 31.8814\n",
      "Epoch 852/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29.8872 - val_loss: 31.9556\n",
      "Epoch 853/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 29.8486 - val_loss: 31.8776\n",
      "Epoch 854/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.8436 - val_loss: 31.8882\n",
      "Epoch 855/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.8096 - val_loss: 31.8037\n",
      "Epoch 856/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29.8196 - val_loss: 31.7141\n",
      "Epoch 857/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.7784 - val_loss: 31.7154\n",
      "Epoch 858/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 29.7866 - val_loss: 31.8734\n",
      "Epoch 859/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 29.7207 - val_loss: 31.7892\n",
      "Epoch 860/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29.7499 - val_loss: 31.6151\n",
      "Epoch 861/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29.6971 - val_loss: 31.7532\n",
      "Epoch 862/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29.6957 - val_loss: 31.7457\n",
      "Epoch 863/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29.6755 - val_loss: 31.9820\n",
      "Epoch 864/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29.6756 - val_loss: 31.8244\n",
      "Epoch 865/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.6585 - val_loss: 31.5468\n",
      "Epoch 866/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29.6104 - val_loss: 31.6348\n",
      "Epoch 867/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29.6636 - val_loss: 31.6737\n",
      "Epoch 868/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 29.5678 - val_loss: 31.5482\n",
      "Epoch 869/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.5821 - val_loss: 31.4583\n",
      "Epoch 870/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29.5661 - val_loss: 31.6976\n",
      "Epoch 871/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.5368 - val_loss: 31.6159\n",
      "Epoch 872/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.5089 - val_loss: 31.6845\n",
      "Epoch 873/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29.4590 - val_loss: 31.7277\n",
      "Epoch 874/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 29.4702 - val_loss: 31.5014\n",
      "Epoch 875/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.4619 - val_loss: 31.4161\n",
      "Epoch 876/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.4449 - val_loss: 31.3820\n",
      "Epoch 877/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 29.4532 - val_loss: 31.4745\n",
      "Epoch 878/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.4335 - val_loss: 31.4941\n",
      "Epoch 879/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 29.3918 - val_loss: 31.3691\n",
      "Epoch 880/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 29.3720 - val_loss: 31.4801\n",
      "Epoch 881/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.3340 - val_loss: 31.5583\n",
      "Epoch 882/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 29.3648 - val_loss: 31.2846\n",
      "Epoch 883/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 29.3403 - val_loss: 31.3545\n",
      "Epoch 884/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 29.3052 - val_loss: 31.3126\n",
      "Epoch 885/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 29.3447 - val_loss: 31.6759\n",
      "Epoch 886/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.3005 - val_loss: 31.5932\n",
      "Epoch 887/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.2234 - val_loss: 31.2736\n",
      "Epoch 888/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29.2110 - val_loss: 31.3206\n",
      "Epoch 889/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.1930 - val_loss: 31.3842\n",
      "Epoch 890/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.2164 - val_loss: 31.1062\n",
      "Epoch 891/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.2411 - val_loss: 30.9889\n",
      "Epoch 892/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.1639 - val_loss: 31.0305\n",
      "Epoch 893/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29.1323 - val_loss: 31.1276\n",
      "Epoch 894/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.1050 - val_loss: 31.1447\n",
      "Epoch 895/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.1342 - val_loss: 31.0878\n",
      "Epoch 896/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.0685 - val_loss: 31.1272\n",
      "Epoch 897/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 29.0870 - val_loss: 31.3223\n",
      "Epoch 898/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 29.0412 - val_loss: 31.1857\n",
      "Epoch 899/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.0159 - val_loss: 31.0841\n",
      "Epoch 900/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.9869 - val_loss: 31.1196\n",
      "Epoch 901/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.9768 - val_loss: 31.0545\n",
      "Epoch 902/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.9746 - val_loss: 31.0041\n",
      "Epoch 903/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.9576 - val_loss: 30.9589\n",
      "Epoch 904/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28.9676 - val_loss: 30.9841\n",
      "Epoch 905/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.9010 - val_loss: 31.2214\n",
      "Epoch 906/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.8866 - val_loss: 30.9221\n",
      "Epoch 907/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.9022 - val_loss: 30.9586\n",
      "Epoch 908/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.8666 - val_loss: 31.1129\n",
      "Epoch 909/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.8327 - val_loss: 30.8989\n",
      "Epoch 910/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.8678 - val_loss: 31.0350\n",
      "Epoch 911/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.8062 - val_loss: 30.8491\n",
      "Epoch 912/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28.8183 - val_loss: 30.7991\n",
      "Epoch 913/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.7448 - val_loss: 30.7473\n",
      "Epoch 914/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 28.7625 - val_loss: 30.7056\n",
      "Epoch 915/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 28.7380 - val_loss: 30.9472\n",
      "Epoch 916/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 28.6894 - val_loss: 30.7673\n",
      "Epoch 917/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.6821 - val_loss: 30.8160\n",
      "Epoch 918/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.6794 - val_loss: 30.8291\n",
      "Epoch 919/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.6248 - val_loss: 30.6924\n",
      "Epoch 920/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.6641 - val_loss: 30.8497\n",
      "Epoch 921/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.6467 - val_loss: 30.7003\n",
      "Epoch 922/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.6026 - val_loss: 30.6330\n",
      "Epoch 923/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.5884 - val_loss: 30.4557\n",
      "Epoch 924/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.5708 - val_loss: 30.5733\n",
      "Epoch 925/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.5460 - val_loss: 30.5611\n",
      "Epoch 926/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.5284 - val_loss: 30.6550\n",
      "Epoch 927/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.4958 - val_loss: 30.5505\n",
      "Epoch 928/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.4822 - val_loss: 30.4927\n",
      "Epoch 929/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.4903 - val_loss: 30.6955\n",
      "Epoch 930/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.4657 - val_loss: 30.5242\n",
      "Epoch 931/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.4266 - val_loss: 30.5728\n",
      "Epoch 932/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.4760 - val_loss: 30.8186\n",
      "Epoch 933/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.4234 - val_loss: 30.6609\n",
      "Epoch 934/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.4159 - val_loss: 30.3359\n",
      "Epoch 935/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.3876 - val_loss: 30.3468\n",
      "Epoch 936/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.3477 - val_loss: 30.2025\n",
      "Epoch 937/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.3687 - val_loss: 30.1184\n",
      "Epoch 938/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.3135 - val_loss: 30.3352\n",
      "Epoch 939/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.2700 - val_loss: 30.3368\n",
      "Epoch 940/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.2856 - val_loss: 30.3036\n",
      "Epoch 941/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.2491 - val_loss: 30.4545\n",
      "Epoch 942/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.2824 - val_loss: 30.3237\n",
      "Epoch 943/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.2191 - val_loss: 30.1347\n",
      "Epoch 944/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.1936 - val_loss: 30.3704\n",
      "Epoch 945/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.1832 - val_loss: 30.1218\n",
      "Epoch 946/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.1709 - val_loss: 30.1855\n",
      "Epoch 947/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.1581 - val_loss: 30.4244\n",
      "Epoch 948/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.1267 - val_loss: 30.2141\n",
      "Epoch 949/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.1204 - val_loss: 30.1365\n",
      "Epoch 950/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.1182 - val_loss: 30.3208\n",
      "Epoch 951/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28.0810 - val_loss: 30.0726\n",
      "Epoch 952/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28.0661 - val_loss: 29.9741\n",
      "Epoch 953/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.0447 - val_loss: 29.9899\n",
      "Epoch 954/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.0379 - val_loss: 29.8962\n",
      "Epoch 955/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.0091 - val_loss: 29.7802\n",
      "Epoch 956/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.9766 - val_loss: 29.8980\n",
      "Epoch 957/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.0422 - val_loss: 29.9581\n",
      "Epoch 958/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.9637 - val_loss: 30.0979\n",
      "Epoch 959/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.9796 - val_loss: 29.9278\n",
      "Epoch 960/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.9279 - val_loss: 30.0159\n",
      "Epoch 961/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.9451 - val_loss: 29.8697\n",
      "Epoch 962/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.8670 - val_loss: 29.8678\n",
      "Epoch 963/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.8500 - val_loss: 29.8457\n",
      "Epoch 964/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27.8385 - val_loss: 29.8998\n",
      "Epoch 965/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.8414 - val_loss: 30.0929\n",
      "Epoch 966/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27.8817 - val_loss: 29.8286\n",
      "Epoch 967/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.7880 - val_loss: 29.9168\n",
      "Epoch 968/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.7953 - val_loss: 29.7135\n",
      "Epoch 969/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.7938 - val_loss: 29.9468\n",
      "Epoch 970/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.7541 - val_loss: 29.7523\n",
      "Epoch 971/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.7279 - val_loss: 29.9036\n",
      "Epoch 972/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.7175 - val_loss: 29.7941\n",
      "Epoch 973/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.7121 - val_loss: 29.9727\n",
      "Epoch 974/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.6978 - val_loss: 29.7146\n",
      "Epoch 975/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.6512 - val_loss: 29.6164\n",
      "Epoch 976/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.6355 - val_loss: 29.7634\n",
      "Epoch 977/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.6188 - val_loss: 29.6538\n",
      "Epoch 978/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.6531 - val_loss: 29.6465\n",
      "Epoch 979/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.5747 - val_loss: 29.6825\n",
      "Epoch 980/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.5595 - val_loss: 29.6482\n",
      "Epoch 981/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.5519 - val_loss: 29.8667\n",
      "Epoch 982/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27.5593 - val_loss: 29.7506\n",
      "Epoch 983/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.5286 - val_loss: 29.6345\n",
      "Epoch 984/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.4859 - val_loss: 29.5581\n",
      "Epoch 985/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.4770 - val_loss: 29.4642\n",
      "Epoch 986/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.5058 - val_loss: 29.6791\n",
      "Epoch 987/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.4467 - val_loss: 29.5398\n",
      "Epoch 988/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.4160 - val_loss: 29.4147\n",
      "Epoch 989/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.4461 - val_loss: 29.7171\n",
      "Epoch 990/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.4352 - val_loss: 29.4820\n",
      "Epoch 991/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.3755 - val_loss: 29.3211\n",
      "Epoch 992/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.3920 - val_loss: 29.6934\n",
      "Epoch 993/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.4855 - val_loss: 29.0132\n",
      "Epoch 994/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.3195 - val_loss: 29.2064\n",
      "Epoch 995/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.3165 - val_loss: 29.2250\n",
      "Epoch 996/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27.3291 - val_loss: 29.2423\n",
      "Epoch 997/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27.3028 - val_loss: 29.4645\n",
      "Epoch 998/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.2492 - val_loss: 29.3697\n",
      "Epoch 999/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.2923 - val_loss: 29.8331\n",
      "Epoch 1000/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.2410 - val_loss: 29.2499\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001EA07085940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Test set MSE: 3721102300.0\n",
      "Test set RMSE: 61000.84\n",
      "Test set RMSPE (%): 25.967039840698636\n"
     ]
    }
   ],
   "source": [
    "model = train_model(epochs=1_000, layer_sizes=[100, 100, 100, 100], X_train=X_train_scaled, y_train=y_train_log, X_valid=X_test_scaled, y_valid=y_valid_log, batch_norm=True, l1_l2=True)\n",
    "evaluate_model(model, X_test_scaled, y_test, log_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Load MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Create a more complex DNN model\n",
    "def create_model():\n",
    "    return tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    # # this one was actually slower on GPU, batch size wasn't specified either\n",
    "    # return tf.keras.models.Sequential([\n",
    "    #     tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    #     tf.keras.layers.Dense(128, activation='relu'),\n",
    "    #     tf.keras.layers.Dropout(0.2),\n",
    "    #     tf.keras.layers.Dense(10)\n",
    "    # ])\n",
    "\n",
    "# Train and evaluate the model, returning the time taken\n",
    "def train_and_evaluate(model, x_train, y_train, x_test, y_test):\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # model.fit(x_train, y_train, epochs=5)\n",
    "    model.fit(x_train, y_train, epochs=5, batch_size=512)\n",
    "    end_time = time.time()\n",
    "\n",
    "    model.evaluate(x_test, y_test, verbose=2)\n",
    "    \n",
    "    return end_time - start_time\n",
    "\n",
    "# Check if a GPU is available\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available\")\n",
    "    with tf.device('/GPU:0'):  # train with GPU\n",
    "        model = create_model()\n",
    "        gpu_time = train_and_evaluate(model, x_train, y_train, x_test, y_test)\n",
    "        print(\"Time taken to train with GPU: {:.2f} seconds\".format(gpu_time))\n",
    "        \n",
    "    with tf.device('/CPU:0'):  # train with CPU\n",
    "        model = create_model()\n",
    "        cpu_time = train_and_evaluate(model, x_train, y_train, x_test, y_test)\n",
    "        print(\"Time taken to train with CPU: {:.2f} seconds\".format(cpu_time))\n",
    "        \n",
    "    speed_increase = (cpu_time - gpu_time) / cpu_time * 100\n",
    "    print(\"GPU is {:.2f}% faster than CPU\".format(speed_increase))\n",
    "else:\n",
    "    print(\"GPU not available, training with CPU only\")\n",
    "    model = create_model()\n",
    "    cpu_time = train_and_evaluate(model, x_train, y_train, x_test, y_test)\n",
    "    print(\"Time taken to train with CPU: {:.2f} seconds\".format(cpu_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
