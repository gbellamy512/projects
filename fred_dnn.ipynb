{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "# from functools import partial\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# set seed for reproducibility\n",
    "random_seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP</th>\n",
       "      <th>GDPC1</th>\n",
       "      <th>GDPPOT</th>\n",
       "      <th>CPIAUCSL</th>\n",
       "      <th>CPILFESL</th>\n",
       "      <th>GDPDEF</th>\n",
       "      <th>M1V</th>\n",
       "      <th>M2V</th>\n",
       "      <th>DFF</th>\n",
       "      <th>UNRATE</th>\n",
       "      <th>...</th>\n",
       "      <th>MANEMP</th>\n",
       "      <th>DSPIC96</th>\n",
       "      <th>PCE</th>\n",
       "      <th>PCEDG</th>\n",
       "      <th>PSAVERT</th>\n",
       "      <th>DSPI</th>\n",
       "      <th>INDPRO</th>\n",
       "      <th>HOUST</th>\n",
       "      <th>GPDI</th>\n",
       "      <th>MSPUS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1963-01-01</th>\n",
       "      <td>621.672</td>\n",
       "      <td>3628.306</td>\n",
       "      <td>3662.738125</td>\n",
       "      <td>30.44</td>\n",
       "      <td>31.5</td>\n",
       "      <td>17.134</td>\n",
       "      <td>4.178</td>\n",
       "      <td>1.690</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.7</td>\n",
       "      <td>...</td>\n",
       "      <td>15545.0</td>\n",
       "      <td>2541.1</td>\n",
       "      <td>374.4</td>\n",
       "      <td>53.1</td>\n",
       "      <td>10.9</td>\n",
       "      <td>430.0</td>\n",
       "      <td>26.0448</td>\n",
       "      <td>1244.0</td>\n",
       "      <td>99.689</td>\n",
       "      <td>17800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963-04-01</th>\n",
       "      <td>629.752</td>\n",
       "      <td>3669.020</td>\n",
       "      <td>3701.698767</td>\n",
       "      <td>30.48</td>\n",
       "      <td>31.7</td>\n",
       "      <td>17.164</td>\n",
       "      <td>4.194</td>\n",
       "      <td>1.675</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.7</td>\n",
       "      <td>...</td>\n",
       "      <td>15602.0</td>\n",
       "      <td>2547.1</td>\n",
       "      <td>376.4</td>\n",
       "      <td>53.2</td>\n",
       "      <td>10.7</td>\n",
       "      <td>431.1</td>\n",
       "      <td>26.7473</td>\n",
       "      <td>1689.0</td>\n",
       "      <td>101.650</td>\n",
       "      <td>18000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963-07-01</th>\n",
       "      <td>644.444</td>\n",
       "      <td>3749.681</td>\n",
       "      <td>3741.388301</td>\n",
       "      <td>30.69</td>\n",
       "      <td>31.8</td>\n",
       "      <td>17.187</td>\n",
       "      <td>4.248</td>\n",
       "      <td>1.680</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.6</td>\n",
       "      <td>...</td>\n",
       "      <td>15646.0</td>\n",
       "      <td>2572.6</td>\n",
       "      <td>384.4</td>\n",
       "      <td>55.5</td>\n",
       "      <td>10.1</td>\n",
       "      <td>438.0</td>\n",
       "      <td>27.0445</td>\n",
       "      <td>1614.0</td>\n",
       "      <td>104.612</td>\n",
       "      <td>17900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963-10-01</th>\n",
       "      <td>653.938</td>\n",
       "      <td>3774.264</td>\n",
       "      <td>3781.880559</td>\n",
       "      <td>30.75</td>\n",
       "      <td>32.0</td>\n",
       "      <td>17.326</td>\n",
       "      <td>4.269</td>\n",
       "      <td>1.672</td>\n",
       "      <td>3.50</td>\n",
       "      <td>5.5</td>\n",
       "      <td>...</td>\n",
       "      <td>15714.0</td>\n",
       "      <td>2617.3</td>\n",
       "      <td>386.0</td>\n",
       "      <td>54.2</td>\n",
       "      <td>11.5</td>\n",
       "      <td>447.0</td>\n",
       "      <td>27.5578</td>\n",
       "      <td>1779.0</td>\n",
       "      <td>107.189</td>\n",
       "      <td>18500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964-01-01</th>\n",
       "      <td>669.822</td>\n",
       "      <td>3853.835</td>\n",
       "      <td>3822.450115</td>\n",
       "      <td>30.94</td>\n",
       "      <td>32.2</td>\n",
       "      <td>17.381</td>\n",
       "      <td>4.345</td>\n",
       "      <td>1.685</td>\n",
       "      <td>3.25</td>\n",
       "      <td>5.6</td>\n",
       "      <td>...</td>\n",
       "      <td>15715.0</td>\n",
       "      <td>2652.8</td>\n",
       "      <td>396.8</td>\n",
       "      <td>57.9</td>\n",
       "      <td>10.7</td>\n",
       "      <td>455.3</td>\n",
       "      <td>27.8820</td>\n",
       "      <td>1603.0</td>\n",
       "      <td>110.474</td>\n",
       "      <td>18500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                GDP     GDPC1       GDPPOT  CPIAUCSL  CPILFESL  GDPDEF    M1V  \\\n",
       "Date                                                                            \n",
       "1963-01-01  621.672  3628.306  3662.738125     30.44      31.5  17.134  4.178   \n",
       "1963-04-01  629.752  3669.020  3701.698767     30.48      31.7  17.164  4.194   \n",
       "1963-07-01  644.444  3749.681  3741.388301     30.69      31.8  17.187  4.248   \n",
       "1963-10-01  653.938  3774.264  3781.880559     30.75      32.0  17.326  4.269   \n",
       "1964-01-01  669.822  3853.835  3822.450115     30.94      32.2  17.381  4.345   \n",
       "\n",
       "              M2V   DFF  UNRATE  ...   MANEMP  DSPIC96    PCE  PCEDG  PSAVERT  \\\n",
       "Date                             ...                                            \n",
       "1963-01-01  1.690  3.00     5.7  ...  15545.0   2541.1  374.4   53.1     10.9   \n",
       "1963-04-01  1.675  3.00     5.7  ...  15602.0   2547.1  376.4   53.2     10.7   \n",
       "1963-07-01  1.680  3.00     5.6  ...  15646.0   2572.6  384.4   55.5     10.1   \n",
       "1963-10-01  1.672  3.50     5.5  ...  15714.0   2617.3  386.0   54.2     11.5   \n",
       "1964-01-01  1.685  3.25     5.6  ...  15715.0   2652.8  396.8   57.9     10.7   \n",
       "\n",
       "             DSPI   INDPRO   HOUST     GPDI    MSPUS  \n",
       "Date                                                  \n",
       "1963-01-01  430.0  26.0448  1244.0   99.689  17800.0  \n",
       "1963-04-01  431.1  26.7473  1689.0  101.650  18000.0  \n",
       "1963-07-01  438.0  27.0445  1614.0  104.612  17900.0  \n",
       "1963-10-01  447.0  27.5578  1779.0  107.189  18500.0  \n",
       "1964-01-01  455.3  27.8820  1603.0  110.474  18500.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('fred_230718.csv', index_col='Date', parse_dates=True)\n",
    "df = df.asfreq('QS')\n",
    "earliest_date = '1963-01-01'\n",
    "latest_date = '2021-10-01'\n",
    "# # filter df index to be between earliest_date and latest_date\n",
    "df = df.loc[(df.index >= earliest_date) & (df.index <= latest_date)]\n",
    "df.dropna(axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set target and create, train, validate, and test datasets and then scale and transform them so they will work better with the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'MSPUS'\n",
    "y = df[target]\n",
    "X = df.drop(columns=[target]).shift(1).dropna()\n",
    "y = y.loc[X.index] # Make sure y and X have the same rows after dropna\n",
    "\n",
    "# https://datascience.stackexchange.com/questions/15135/train-test-validation-set-splitting-in-sklearn\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size=0.25, random_state=random_seed)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)  # validation data should also be scaled\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Log-transform the target variable\n",
    "y_train_log = np.log1p(y_train)\n",
    "y_valid_log = np.log1p(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of X_train: <class 'numpy.ndarray'>\n",
      "Shape of X_train: (141, 25)\n",
      "Type of y_train: <class 'pandas.core.series.Series'>\n",
      "Shape of y_train: (141,)\n",
      "Min of y_train: 17900.0\n",
      "Max of y_train: 369800.0\n",
      "                  GDP      GDPC1        GDPPOT  CPIAUCSL  CPILFESL   GDPDEF  \\\n",
      "Date                                                                          \n",
      "1970-04-01   1051.200   4939.759   4942.234479    37.900    39.600   21.280   \n",
      "2010-01-01  14651.248  15379.155  16122.163920   216.509   220.501   95.267   \n",
      "1975-04-01   1616.116   5551.713   5821.185285    52.300    52.300   29.110   \n",
      "1984-10-01   4084.250   7690.985   7828.967378   104.100   105.000   53.104   \n",
      "2002-07-01  10887.460  13477.356  13739.879490   179.300   189.700   80.783   \n",
      "...               ...        ...           ...       ...       ...      ...   \n",
      "1983-04-01   3473.413   6896.561   7442.965382    97.900    97.600   50.364   \n",
      "1974-01-01   1476.289   5731.632   5579.493499    45.600    46.300   25.757   \n",
      "2001-01-01  10435.744  13262.250  13134.756980   173.900   182.600   78.688   \n",
      "2013-07-01  16699.551  16464.402  17034.097600   231.797   232.832  101.428   \n",
      "1984-04-01   3908.054   7488.167   7691.232895   102.100   102.500   52.190   \n",
      "\n",
      "              M1V    M2V    DFF  UNRATE  ...    PAYEMS   MANEMP  DSPIC96  \\\n",
      "Date                                     ...                               \n",
      "1970-04-01  5.112  1.789   5.00     3.9  ...   71176.0  18424.0   3571.8   \n",
      "2010-01-01  8.698  1.726   0.11    10.0  ...  130045.0  11538.0  11538.1   \n",
      "1975-04-01  5.875  1.766   3.87     8.1  ...   77293.0  17344.0   4175.7   \n",
      "1984-10-01  7.540  1.829  10.85     7.5  ...   94789.0  18013.0   5697.4   \n",
      "2002-07-01  9.150  1.972   1.88     5.9  ...  130623.0  15392.0  10007.2   \n",
      "...           ...    ...    ...     ...  ...       ...      ...      ...   \n",
      "1983-04-01  7.176  1.745  11.20    10.4  ...   88990.0  16705.0   5217.2   \n",
      "1974-01-01  5.657  1.739  10.90     4.6  ...   77607.0  18702.0   4298.1   \n",
      "2001-01-01  9.546  2.134   6.60     3.9  ...  132351.0  17217.0   9627.4   \n",
      "2013-07-01  6.611  1.570   0.16     7.6  ...  135871.0  12000.0  12299.0   \n",
      "1984-04-01  7.402  1.812   9.92     8.0  ...   92673.0  17630.0   5535.1   \n",
      "\n",
      "                PCE   PCEDG  PSAVERT     DSPI   INDPRO   HOUST      GPDI  \n",
      "Date                                                                      \n",
      "1970-04-01    628.7    89.3     11.8    732.1  38.1217  1085.0   168.113  \n",
      "2010-01-01   9976.7  1003.6      5.2  10943.4  87.6595   534.0  1998.710  \n",
      "1975-04-01    975.6   129.5     13.2   1154.2  41.5880  1032.0   244.306  \n",
      "1984-10-01   2494.6   341.5     11.6   2925.6  54.6658  1732.0   838.852  \n",
      "2002-07-01   7312.5  1001.5      5.5   8053.4  89.7933  1592.0  1933.282  \n",
      "...             ...     ...      ...      ...      ...     ...       ...  \n",
      "1983-04-01   2174.0   268.3     11.1   2533.1  47.9518  1586.0   565.520  \n",
      "1974-01-01    868.2   129.3     14.4   1042.3  45.9627  1677.0   280.858  \n",
      "2001-01-01   6893.8   920.6      4.8   7571.7  93.0019  1549.0  2067.227  \n",
      "2013-07-01  11259.3  1182.3      6.2  12414.9  98.9927   835.0  2775.276  \n",
      "1984-04-01   2419.4   336.8     10.0   2784.7  53.2371  1897.0   790.872  \n",
      "\n",
      "[141 rows x 25 columns]\n",
      "[[-1.04555936 -1.13581712 -1.13213378 ... -1.19451188 -0.89741945\n",
      "  -1.0748169 ]\n",
      " [ 1.10832922  1.11345807  1.22022509 ...  0.83882138 -2.34470251\n",
      "   0.59574233]\n",
      " [-0.95609158 -1.00396534 -0.94719453 ... -1.0522338  -1.03663179\n",
      "  -1.00528498]\n",
      " ...\n",
      " [ 0.44070467  0.65734912  0.59164749 ...  1.05810604  0.32134524\n",
      "   0.65826931]\n",
      " [ 1.43272634  1.34728569  1.41210423 ...  1.30400498 -1.55408145\n",
      "   1.30441796]\n",
      " [-0.5931091  -0.58673641 -0.5537195  ... -0.57408373  1.23541875\n",
      "  -0.50650186]]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # assuming X_train and X_test are your training and test datasets\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_valid = scaler.transform(X_valid)  # validation data should also be scaled\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # Check the type and shape of X_train\n",
    "# print(\"Type of X_train:\", type(X_train))\n",
    "# print(\"Shape of X_train:\", X_train.shape)\n",
    "\n",
    "# # Check the type and shape of y_train\n",
    "# print(\"Type of y_train:\", type(y_train))\n",
    "# print(\"Shape of y_train:\", y_train.shape)\n",
    "\n",
    "# # Check the range of y_train values\n",
    "# print(\"Min of y_train:\", y_train.min())\n",
    "# print(\"Max of y_train:\", y_train.max())\n",
    "\n",
    "# # If you're using pandas, you can get a statistical summary of your data\n",
    "# if isinstance(X_train, pd.DataFrame):\n",
    "#     print(X_train.describe())\n",
    "    \n",
    "# print(X_train)\n",
    "# print(X_train)\n",
    "\n",
    "# # Log-transform the target variable\n",
    "# y_train = np.log1p(y_train)\n",
    "# y_valid = np.log1p(y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's create functions to train and evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, \n",
    "                X_valid, y_valid,\n",
    "                layer_sizes=[100, 100], \n",
    "                activation=\"relu\", \n",
    "                kernel_initializer=\"he_normal\", \n",
    "                learning_rate=0.001, \n",
    "                epochs=100,\n",
    "                batch_norm=False,\n",
    "                l1_l2=False,\n",
    "                l1=.01,\n",
    "                l2=.01):\n",
    "\n",
    "    # Create a sequential model\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # Add batch normalization and dense layers according to the layer_sizes\n",
    "    for size in layer_sizes:\n",
    "        if batch_norm:\n",
    "            model.add(tf.keras.layers.BatchNormalization())\n",
    "        if l1_l2:\n",
    "            model.add(tf.keras.layers.Dense(size, activation=activation, kernel_initializer=kernel_initializer\n",
    "                                            , kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "        else:\n",
    "            model.add(tf.keras.layers.Dense(size, activation=activation, kernel_initializer=kernel_initializer))\n",
    "\n",
    "    # Add a final Dense layer with no activation\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "    # Create the optimizer with the custom learning rate\n",
    "    sgd = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=\"mse\", optimizer=sgd)\n",
    "\n",
    "    # Train the model using the scaled data\n",
    "    model.fit(X_train, y_train, epochs=epochs, validation_data=(X_valid, y_valid))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, log_target=False):\n",
    "    # When predicting, transform the predictions back\n",
    "    y_pred = model.predict(X_test)\n",
    "    if log_target:\n",
    "        y_pred = np.expm1(y_pred).flatten()  # inverse of np.log1p(), make it 1D\n",
    "\n",
    "\n",
    "    # compute the RMSE on the original scale\n",
    "    mse = np.mean(tf.keras.losses.MSE(y_test, y_pred))\n",
    "    print('Test set MSE:', mse)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print('Test set RMSE:', rmse)\n",
    "    rmspe = (np.sqrt(np.mean(np.square((y_test - y_pred) / y_test)))) * 100\n",
    "    print('Test set RMSPE (%):', rmspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_model(X_train, y_train, \n",
    "#                 X_valid, y_valid,\n",
    "#                 layer_sizes=[100, 100], \n",
    "#                 activation=\"relu\", \n",
    "#                 kernel_initializer=\"he_normal\", \n",
    "#                 learning_rate=0.001, \n",
    "#                 epochs=100,\n",
    "#                 batch_norm=False,\n",
    "#                 l1_l2=False,\n",
    "#                 l1=.01,\n",
    "#                 l2=.01):\n",
    "\n",
    "#     # Create a sequential model\n",
    "#     model = tf.keras.Sequential()\n",
    "\n",
    "#     # Add batch normalization and dense layers according to the layer_sizes\n",
    "#     for size in layer_sizes:\n",
    "#         if batch_norm:\n",
    "#             model.add(tf.keras.layers.BatchNormalization())\n",
    "#         if l1_l2:\n",
    "#             model.add(tf.keras.layers.Dense(size, activation=activation, kernel_initializer=kernel_initializer\n",
    "#                                             , kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "#         else:\n",
    "#             model.add(tf.keras.layers.Dense(size, activation=activation, kernel_initializer=kernel_initializer))\n",
    "\n",
    "#     # Add a final Dense layer with no activation\n",
    "#     model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "#     # Create the optimizer with the custom learning rate\n",
    "#     sgd = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "#     # Compile the model\n",
    "#     model.compile(loss=\"mse\", optimizer=sgd)\n",
    "\n",
    "#     # Train the model using the scaled data\n",
    "#     model.fit(X_train, y_train, epochs=epochs, validation_data=(X_valid, y_valid))\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll test some different architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no regularization\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 70.5498 - val_loss: 18.2292\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 13.0595 - val_loss: 9.4761\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 7.7773 - val_loss: 7.1266\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 5.4752 - val_loss: 6.2495\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.0522 - val_loss: 5.7089\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.2820 - val_loss: 5.4086\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 2.7394 - val_loss: 5.0812\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 2.4031 - val_loss: 4.7386\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 2.1108 - val_loss: 4.6396\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.8883 - val_loss: 4.4839\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.7394 - val_loss: 4.3385\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.5724 - val_loss: 4.2330\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.4626 - val_loss: 4.1048\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.3495 - val_loss: 3.8788\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.2583 - val_loss: 3.9504\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1761 - val_loss: 4.0555\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.1163 - val_loss: 3.8726\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0578 - val_loss: 3.7350\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0172 - val_loss: 3.7594\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9572 - val_loss: 3.6240\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9046 - val_loss: 3.3956\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8600 - val_loss: 3.4996\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8211 - val_loss: 3.5167\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8127 - val_loss: 3.4727\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7621 - val_loss: 3.2895\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7289 - val_loss: 3.3578\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6987 - val_loss: 3.2078\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6821 - val_loss: 3.2423\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6438 - val_loss: 3.2181\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6244 - val_loss: 3.2576\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5987 - val_loss: 3.3157\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5824 - val_loss: 3.2823\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5609 - val_loss: 3.2413\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5443 - val_loss: 3.2442\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5234 - val_loss: 3.1413\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5149 - val_loss: 3.1779\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4985 - val_loss: 3.0202\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4816 - val_loss: 2.9824\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4706 - val_loss: 2.9653\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4548 - val_loss: 3.0948\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4469 - val_loss: 2.9472\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4342 - val_loss: 3.0628\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4235 - val_loss: 2.9561\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4155 - val_loss: 2.9744\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4019 - val_loss: 3.0665\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4011 - val_loss: 3.0341\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3898 - val_loss: 2.9266\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3865 - val_loss: 2.8369\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3719 - val_loss: 2.7863\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3681 - val_loss: 2.8440\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3576 - val_loss: 2.7732\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3549 - val_loss: 2.9353\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3442 - val_loss: 2.9460\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3357 - val_loss: 2.7466\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3257 - val_loss: 2.7741\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3208 - val_loss: 2.6657\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3147 - val_loss: 2.6521\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3126 - val_loss: 2.6104\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3066 - val_loss: 2.6550\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2978 - val_loss: 2.6661\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2944 - val_loss: 2.7290\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2940 - val_loss: 2.7431\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2902 - val_loss: 2.6159\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2841 - val_loss: 2.6801\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2791 - val_loss: 2.5628\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2770 - val_loss: 2.8325\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2729 - val_loss: 2.6474\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2685 - val_loss: 2.6051\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2639 - val_loss: 2.5532\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2651 - val_loss: 2.5937\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2589 - val_loss: 2.4838\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2582 - val_loss: 2.5227\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2519 - val_loss: 2.5072\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2566 - val_loss: 2.5583\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2472 - val_loss: 2.5322\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2444 - val_loss: 2.6142\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2422 - val_loss: 2.5928\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2388 - val_loss: 2.4719\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2352 - val_loss: 2.5824\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2367 - val_loss: 2.5289\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2304 - val_loss: 2.5656\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2271 - val_loss: 2.3860\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2264 - val_loss: 2.5167\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2209 - val_loss: 2.4900\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2190 - val_loss: 2.4777\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2210 - val_loss: 2.4868\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2161 - val_loss: 2.5437\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2124 - val_loss: 2.5451\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2108 - val_loss: 2.4599\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2121 - val_loss: 2.4143\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2044 - val_loss: 2.4945\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2046 - val_loss: 2.4982\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2013 - val_loss: 2.4595\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2000 - val_loss: 2.4987\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1993 - val_loss: 2.3846\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2018 - val_loss: 2.5049\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1984 - val_loss: 2.4376\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1982 - val_loss: 2.5873\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1956 - val_loss: 2.5132\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1901 - val_loss: 2.4843\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Test set MSE: 18223825000.0\n",
      "Test set RMSE: 134995.64\n",
      "Test set RMSPE (%): 69.62159273843127\n"
     ]
    }
   ],
   "source": [
    "print('no regularization')\n",
    "model = train_model(X_train=X_train_scaled, y_train=y_train_log, X_valid=X_test_scaled, y_valid=y_valid_log)\n",
    "evaluate_model(model, X_test_scaled, y_test, log_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch norm regularization\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 1s 34ms/step - loss: 84.8679 - val_loss: 49.5498\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 33.2674 - val_loss: 28.4453\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 13.9458 - val_loss: 20.3044\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.3257 - val_loss: 16.5661\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.0580 - val_loss: 15.1796\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.0581 - val_loss: 13.7792\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.1410 - val_loss: 14.1509\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8369 - val_loss: 13.6924\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.1171 - val_loss: 13.6655\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.8299 - val_loss: 13.1738\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.3699 - val_loss: 12.5914\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.7382 - val_loss: 12.5623\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7193 - val_loss: 12.0142\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.2155 - val_loss: 11.8847\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 2.2103 - val_loss: 11.4367\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9310 - val_loss: 11.4871\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.2525 - val_loss: 11.5787\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7915 - val_loss: 10.9270\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2.1387 - val_loss: 10.3628\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.3660 - val_loss: 10.0241\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.8603 - val_loss: 9.6603\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.9894 - val_loss: 9.7616\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2.1444 - val_loss: 9.6861\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8952 - val_loss: 8.9242\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7761 - val_loss: 8.4278\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.9037 - val_loss: 7.7680\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6108 - val_loss: 7.7325\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1273 - val_loss: 7.7397\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.0252 - val_loss: 7.0400\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.0578 - val_loss: 6.5184\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.4164 - val_loss: 6.9942\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.3656 - val_loss: 6.6130\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.9330 - val_loss: 6.2354\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.9938 - val_loss: 5.8063\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.9684 - val_loss: 5.5918\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0141 - val_loss: 5.5173\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8358 - val_loss: 5.3401\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.5727 - val_loss: 5.1006\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.1892 - val_loss: 5.3691\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.4308 - val_loss: 4.7484\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.4963 - val_loss: 5.4131\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5665 - val_loss: 4.3491\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9024 - val_loss: 4.6100\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8713 - val_loss: 4.6567\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7503 - val_loss: 4.8234\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4429 - val_loss: 4.4278\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8122 - val_loss: 3.9396\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0116 - val_loss: 4.4326\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7233 - val_loss: 4.1196\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.1624 - val_loss: 3.7816\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5978 - val_loss: 3.4029\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6403 - val_loss: 3.0484\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0637 - val_loss: 3.0571\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7030 - val_loss: 3.1880\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.1540 - val_loss: 3.0722\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4526 - val_loss: 3.2943\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7274 - val_loss: 2.8606\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3757 - val_loss: 2.5808\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7024 - val_loss: 3.0851\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3369 - val_loss: 3.0952\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.0054 - val_loss: 2.3498\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.2154 - val_loss: 2.8133\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.2933 - val_loss: 2.6170\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.1761 - val_loss: 3.1197\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6309 - val_loss: 3.1454\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5093 - val_loss: 3.0945\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4265 - val_loss: 3.0791\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7789 - val_loss: 2.7123\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5190 - val_loss: 3.0602\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4952 - val_loss: 2.8710\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.9719 - val_loss: 2.3746\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4506 - val_loss: 2.6510\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4599 - val_loss: 2.6880\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5254 - val_loss: 2.5680\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4470 - val_loss: 2.6854\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.8068 - val_loss: 2.3678\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.0309 - val_loss: 2.4606\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5787 - val_loss: 2.0273\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5059 - val_loss: 2.1152\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6256 - val_loss: 2.7306\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6930 - val_loss: 2.3734\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3492 - val_loss: 2.5245\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3262 - val_loss: 2.5248\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4388 - val_loss: 2.0245\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5029 - val_loss: 2.1097\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5715 - val_loss: 2.3999\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5606 - val_loss: 2.7752\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4593 - val_loss: 2.7956\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7328 - val_loss: 1.9765\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5371 - val_loss: 2.6713\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3203 - val_loss: 2.3711\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2889 - val_loss: 2.2809\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3842 - val_loss: 2.0543\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6966 - val_loss: 2.5102\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7637 - val_loss: 2.6689\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4916 - val_loss: 2.9789\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3778 - val_loss: 2.9445\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3490 - val_loss: 2.1691\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6169 - val_loss: 2.7460\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5915 - val_loss: 2.3377\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Test set MSE: 52698223000.0\n",
      "Test set RMSE: 229560.94\n",
      "Test set RMSPE (%): 66.42761362442018\n"
     ]
    }
   ],
   "source": [
    "print('batch norm regularization')\n",
    "model = train_model(X_train=X_train_scaled, y_train=y_train_log, X_valid=X_test_scaled, y_valid=y_valid_log, batch_norm=True)\n",
    "evaluate_model(model, X_test_scaled, y_test, log_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1/L2 regularization\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 120.7640 - val_loss: 42.7649\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 35.6855 - val_loss: 31.3888\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 29.0362 - val_loss: 29.2702\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 26.8305 - val_loss: 27.5348\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 25.5189 - val_loss: 26.9305\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 24.7070 - val_loss: 26.4374\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 24.1821 - val_loss: 26.0597\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 23.8158 - val_loss: 25.5782\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 23.4779 - val_loss: 25.3300\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 23.2357 - val_loss: 25.2998\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 23.0364 - val_loss: 25.4193\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 22.8880 - val_loss: 24.9449\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 22.7470 - val_loss: 24.8152\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 22.6220 - val_loss: 24.7440\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 22.5114 - val_loss: 24.5649\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 22.4250 - val_loss: 24.7209\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 22.3576 - val_loss: 24.3768\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 22.2847 - val_loss: 24.4676\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 22.2131 - val_loss: 24.4022\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 22.1555 - val_loss: 24.2511\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 22.1019 - val_loss: 24.1219\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 22.0468 - val_loss: 24.1636\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.9991 - val_loss: 24.2040\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.9590 - val_loss: 24.0359\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.9193 - val_loss: 24.0349\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.8829 - val_loss: 23.9947\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.8546 - val_loss: 23.9901\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.8260 - val_loss: 23.8291\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.7924 - val_loss: 23.9274\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.7676 - val_loss: 23.8599\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.7312 - val_loss: 23.7898\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.7029 - val_loss: 23.8253\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.6837 - val_loss: 23.9488\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.6601 - val_loss: 23.7349\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.6313 - val_loss: 23.7332\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.6155 - val_loss: 23.6410\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.5887 - val_loss: 23.6838\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 21.5678 - val_loss: 23.6506\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.5490 - val_loss: 23.5971\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.5300 - val_loss: 23.5188\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.5112 - val_loss: 23.6274\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 21.5036 - val_loss: 23.5277\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.4782 - val_loss: 23.4819\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.4590 - val_loss: 23.4546\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.4429 - val_loss: 23.4084\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 21.4259 - val_loss: 23.4216\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.4043 - val_loss: 23.4571\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.3929 - val_loss: 23.4515\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 21.3681 - val_loss: 23.4854\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.3534 - val_loss: 23.4328\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.3392 - val_loss: 23.4698\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 21.3264 - val_loss: 23.3773\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.3041 - val_loss: 23.2613\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.2928 - val_loss: 23.2784\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.2778 - val_loss: 23.4310\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 21.2617 - val_loss: 23.2882\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.2517 - val_loss: 23.3485\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.2333 - val_loss: 23.3290\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.2223 - val_loss: 23.2456\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.2071 - val_loss: 23.2154\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.1923 - val_loss: 23.2435\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.1842 - val_loss: 23.1369\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 21.1633 - val_loss: 23.1921\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.1531 - val_loss: 23.1868\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 21.1366 - val_loss: 23.1757\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.1243 - val_loss: 23.0707\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.1164 - val_loss: 23.0283\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.0990 - val_loss: 23.0872\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.0875 - val_loss: 23.0763\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.0723 - val_loss: 23.1491\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.0609 - val_loss: 23.1561\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.0472 - val_loss: 23.1668\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.0353 - val_loss: 23.1538\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.0226 - val_loss: 22.9880\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.0105 - val_loss: 22.9668\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 20.9968 - val_loss: 23.1774\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 20.9849 - val_loss: 22.9513\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 20.9722 - val_loss: 23.0474\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 20.9656 - val_loss: 23.0348\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 20.9484 - val_loss: 23.0632\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 20.9369 - val_loss: 23.0248\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 20.9240 - val_loss: 22.9106\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 20.9115 - val_loss: 23.0122\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 20.9025 - val_loss: 22.9077\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 20.8910 - val_loss: 22.8083\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 20.8756 - val_loss: 22.8940\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 20.8655 - val_loss: 22.8239\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 20.8520 - val_loss: 22.8587\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 20.8393 - val_loss: 22.8844\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 20.8285 - val_loss: 22.8199\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 20.8208 - val_loss: 22.9425\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 20.8077 - val_loss: 22.8577\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 20.7954 - val_loss: 22.7987\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 20.7823 - val_loss: 22.7330\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 20.7705 - val_loss: 22.7468\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 20.7597 - val_loss: 22.7848\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 20.7483 - val_loss: 22.7820\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 20.7362 - val_loss: 22.7384\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 20.7283 - val_loss: 22.6228\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 20.7157 - val_loss: 22.6729\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Test set MSE: 66462134000.0\n",
      "Test set RMSE: 257802.52\n",
      "Test set RMSPE (%): 77.11859056277274\n"
     ]
    }
   ],
   "source": [
    "print('L1/L2 regularization')\n",
    "model = train_model(X_train=X_train_scaled, y_train=y_train_log, X_valid=X_test_scaled, y_valid=y_valid_log, l1_l2=True)\n",
    "evaluate_model(model, X_test_scaled, y_test, log_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch norm & L1/L2 regularization\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 1s 40ms/step - loss: 132.4064 - val_loss: 99.2007\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 67.2103 - val_loss: 70.9417\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 40.0420 - val_loss: 57.1364\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.2002 - val_loss: 49.4219\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 25.4513 - val_loss: 44.9561\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 25.1547 - val_loss: 43.2461\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 24.4969 - val_loss: 41.6827\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 24.8143 - val_loss: 41.1456\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 23.8803 - val_loss: 40.4307\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 23.5445 - val_loss: 39.6514\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 23.3550 - val_loss: 38.3875\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 23.2575 - val_loss: 37.9077\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 22.9723 - val_loss: 37.7233\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 23.8034 - val_loss: 37.2370\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 22.8983 - val_loss: 36.8264\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 22.6014 - val_loss: 35.8397\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 22.2953 - val_loss: 35.1058\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 23.1029 - val_loss: 34.6923\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.5200 - val_loss: 34.1850\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 23.7588 - val_loss: 33.9654\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.1550 - val_loss: 33.4517\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 22.9979 - val_loss: 32.8234\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 22.8539 - val_loss: 32.6245\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 22.1374 - val_loss: 31.7903\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 23.0422 - val_loss: 31.6805\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.7315 - val_loss: 31.8376\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.5270 - val_loss: 30.6085\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 22.2992 - val_loss: 29.9562\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 22.3406 - val_loss: 29.8525\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.9996 - val_loss: 28.5844\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 22.6047 - val_loss: 28.0676\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 22.1681 - val_loss: 28.0591\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 22.1047 - val_loss: 27.9508\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 22.0861 - val_loss: 27.6667\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 22.8955 - val_loss: 28.2190\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 22.1822 - val_loss: 27.2800\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 22.0505 - val_loss: 26.9869\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.7731 - val_loss: 26.6562\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 22.0427 - val_loss: 26.3110\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 22.1566 - val_loss: 26.4647\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 22.0074 - val_loss: 26.8301\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 22.3376 - val_loss: 26.2457\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 22.5887 - val_loss: 26.1621\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 22.3354 - val_loss: 25.6311\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.9436 - val_loss: 25.6814\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.8841 - val_loss: 25.3734\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 22.4215 - val_loss: 25.1013\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.9796 - val_loss: 25.0251\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.5616 - val_loss: 24.8633\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 22.2278 - val_loss: 24.8768\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.9502 - val_loss: 24.4687\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 22.2471 - val_loss: 24.2642\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 22.0880 - val_loss: 23.9147\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.7051 - val_loss: 23.8852\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.7178 - val_loss: 23.7140\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.6229 - val_loss: 23.8451\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.2870 - val_loss: 23.9090\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.6646 - val_loss: 23.9555\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.3557 - val_loss: 23.9427\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.4162 - val_loss: 24.0245\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.4793 - val_loss: 24.1167\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.8524 - val_loss: 23.7552\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.4021 - val_loss: 23.6112\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.5248 - val_loss: 23.5876\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.4895 - val_loss: 23.5906\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.5879 - val_loss: 23.1453\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.3993 - val_loss: 23.0690\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.4955 - val_loss: 23.3395\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.2306 - val_loss: 23.5321\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.3761 - val_loss: 23.2714\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.7552 - val_loss: 23.3711\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.3191 - val_loss: 23.3616\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.8016 - val_loss: 23.0383\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.3707 - val_loss: 23.5707\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.5024 - val_loss: 22.9671\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.5981 - val_loss: 22.9928\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.6368 - val_loss: 23.3073\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.2368 - val_loss: 23.2476\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.4228 - val_loss: 23.7889\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.5274 - val_loss: 23.3193\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.5173 - val_loss: 22.9811\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.2574 - val_loss: 23.1900\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.8390 - val_loss: 23.1514\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.3516 - val_loss: 22.8903\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.3529 - val_loss: 23.2297\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.2976 - val_loss: 22.7522\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.3218 - val_loss: 22.5182\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.2053 - val_loss: 22.7069\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.0870 - val_loss: 22.8244\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.2185 - val_loss: 23.0574\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.1144 - val_loss: 23.1344\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.1385 - val_loss: 22.7081\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.1801 - val_loss: 22.8058\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.0330 - val_loss: 22.8771\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.1047 - val_loss: 22.8181\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 20.9499 - val_loss: 22.6418\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 20.9982 - val_loss: 22.8226\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.0410 - val_loss: 23.1143\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 20.9668 - val_loss: 22.7542\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.3044 - val_loss: 22.7837\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000025656A37B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Test set MSE: 109605930000.0\n",
      "Test set RMSE: 331067.88\n",
      "Test set RMSPE (%): 90.46298431013379\n"
     ]
    }
   ],
   "source": [
    "print('batch norm & L1/L2 regularization')\n",
    "model = train_model(X_train=X_train_scaled, y_train=y_train_log, X_valid=X_test_scaled, y_valid=y_valid_log, batch_norm=True, l1_l2=True)\n",
    "evaluate_model(model, X_test_scaled, y_test, log_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "5/5 [==============================] - 1s 48ms/step - loss: 130.8462 - val_loss: 117.1993\n",
      "Epoch 2/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 71.6521 - val_loss: 86.0730\n",
      "Epoch 3/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 46.7458 - val_loss: 72.6256\n",
      "Epoch 4/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 39.3288 - val_loss: 67.7948\n",
      "Epoch 5/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 37.0374 - val_loss: 65.6379\n",
      "Epoch 6/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 37.1516 - val_loss: 65.0785\n",
      "Epoch 7/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.8489 - val_loss: 64.7685\n",
      "Epoch 8/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.8235 - val_loss: 65.0353\n",
      "Epoch 9/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 36.1383 - val_loss: 63.8180\n",
      "Epoch 10/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.3750 - val_loss: 64.2071\n",
      "Epoch 11/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.5439 - val_loss: 63.2670\n",
      "Epoch 12/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.7048 - val_loss: 61.7644\n",
      "Epoch 13/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.0260 - val_loss: 61.4186\n",
      "Epoch 14/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.8417 - val_loss: 60.1837\n",
      "Epoch 15/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.8605 - val_loss: 59.4183\n",
      "Epoch 16/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 35.5394 - val_loss: 57.7259\n",
      "Epoch 17/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.2718 - val_loss: 57.1888\n",
      "Epoch 18/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.6304 - val_loss: 56.3048\n",
      "Epoch 19/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 35.5820 - val_loss: 55.5852\n",
      "Epoch 20/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.5867 - val_loss: 54.2486\n",
      "Epoch 21/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.3338 - val_loss: 53.8363\n",
      "Epoch 22/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.5764 - val_loss: 53.2128\n",
      "Epoch 23/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.4621 - val_loss: 51.8547\n",
      "Epoch 24/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.4175 - val_loss: 50.7900\n",
      "Epoch 25/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.9264 - val_loss: 49.6045\n",
      "Epoch 26/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.3541 - val_loss: 49.0521\n",
      "Epoch 27/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 35.5470 - val_loss: 48.3684\n",
      "Epoch 28/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.2453 - val_loss: 47.5334\n",
      "Epoch 29/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.8769 - val_loss: 47.0590\n",
      "Epoch 30/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 35.2399 - val_loss: 46.2940\n",
      "Epoch 31/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 35.0706 - val_loss: 45.9244\n",
      "Epoch 32/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 35.3983 - val_loss: 45.5741\n",
      "Epoch 33/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.0872 - val_loss: 44.5154\n",
      "Epoch 34/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.2160 - val_loss: 44.0942\n",
      "Epoch 35/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.0559 - val_loss: 43.6069\n",
      "Epoch 36/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 35.0914 - val_loss: 42.9430\n",
      "Epoch 37/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.8149 - val_loss: 42.6332\n",
      "Epoch 38/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 35.0581 - val_loss: 42.1240\n",
      "Epoch 39/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.9629 - val_loss: 41.4586\n",
      "Epoch 40/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.9297 - val_loss: 41.0042\n",
      "Epoch 41/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.8465 - val_loss: 40.4370\n",
      "Epoch 42/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.8318 - val_loss: 40.1101\n",
      "Epoch 43/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.9226 - val_loss: 39.9923\n",
      "Epoch 44/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 35.1334 - val_loss: 39.6320\n",
      "Epoch 45/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.8560 - val_loss: 39.4835\n",
      "Epoch 46/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.8724 - val_loss: 39.3693\n",
      "Epoch 47/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.8368 - val_loss: 39.0088\n",
      "Epoch 48/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.8822 - val_loss: 38.8879\n",
      "Epoch 49/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.6808 - val_loss: 38.4251\n",
      "Epoch 50/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.6889 - val_loss: 38.2992\n",
      "Epoch 51/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.8136 - val_loss: 38.1960\n",
      "Epoch 52/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 34.9096 - val_loss: 37.9878\n",
      "Epoch 53/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.8112 - val_loss: 38.2367\n",
      "Epoch 54/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.7938 - val_loss: 37.6074\n",
      "Epoch 55/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.6307 - val_loss: 37.8185\n",
      "Epoch 56/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.5528 - val_loss: 37.6780\n",
      "Epoch 57/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.6706 - val_loss: 37.6110\n",
      "Epoch 58/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 34.5766 - val_loss: 37.5017\n",
      "Epoch 59/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.6505 - val_loss: 37.2815\n",
      "Epoch 60/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.7820 - val_loss: 37.0685\n",
      "Epoch 61/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 34.4214 - val_loss: 37.0557\n",
      "Epoch 62/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.4310 - val_loss: 36.8859\n",
      "Epoch 63/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.6727 - val_loss: 36.7706\n",
      "Epoch 64/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.4475 - val_loss: 36.5307\n",
      "Epoch 65/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.4390 - val_loss: 36.8613\n",
      "Epoch 66/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.2965 - val_loss: 36.7655\n",
      "Epoch 67/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.5154 - val_loss: 36.8815\n",
      "Epoch 68/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.2964 - val_loss: 36.6375\n",
      "Epoch 69/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.2679 - val_loss: 36.5887\n",
      "Epoch 70/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.3185 - val_loss: 36.4564\n",
      "Epoch 71/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.2132 - val_loss: 36.4554\n",
      "Epoch 72/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.2573 - val_loss: 36.2190\n",
      "Epoch 73/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.1313 - val_loss: 36.2144\n",
      "Epoch 74/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.2441 - val_loss: 36.2405\n",
      "Epoch 75/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.1880 - val_loss: 35.9348\n",
      "Epoch 76/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.1803 - val_loss: 35.9940\n",
      "Epoch 77/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.1763 - val_loss: 36.1195\n",
      "Epoch 78/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.0702 - val_loss: 35.9286\n",
      "Epoch 79/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.1227 - val_loss: 35.8182\n",
      "Epoch 80/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 34.1624 - val_loss: 36.3817\n",
      "Epoch 81/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.0900 - val_loss: 36.0816\n",
      "Epoch 82/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.1193 - val_loss: 36.1326\n",
      "Epoch 83/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.2024 - val_loss: 35.9900\n",
      "Epoch 84/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.9997 - val_loss: 36.0769\n",
      "Epoch 85/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.9418 - val_loss: 35.7679\n",
      "Epoch 86/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 34.0413 - val_loss: 36.3126\n",
      "Epoch 87/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 34.1210 - val_loss: 35.8371\n",
      "Epoch 88/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 33.8793 - val_loss: 35.9944\n",
      "Epoch 89/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 33.9906 - val_loss: 35.9972\n",
      "Epoch 90/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.8657 - val_loss: 35.7851\n",
      "Epoch 91/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 33.8685 - val_loss: 35.8059\n",
      "Epoch 92/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 33.8915 - val_loss: 35.5269\n",
      "Epoch 93/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.8080 - val_loss: 35.5875\n",
      "Epoch 94/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.8010 - val_loss: 35.7397\n",
      "Epoch 95/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.7002 - val_loss: 35.8825\n",
      "Epoch 96/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.8621 - val_loss: 35.5470\n",
      "Epoch 97/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.8843 - val_loss: 35.9890\n",
      "Epoch 98/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 33.7294 - val_loss: 35.7892\n",
      "Epoch 99/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.7090 - val_loss: 35.7332\n",
      "Epoch 100/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.7425 - val_loss: 35.4174\n",
      "Epoch 101/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.6932 - val_loss: 35.8286\n",
      "Epoch 102/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 33.5795 - val_loss: 35.5219\n",
      "Epoch 103/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.8164 - val_loss: 35.2594\n",
      "Epoch 104/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.6257 - val_loss: 35.4358\n",
      "Epoch 105/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.6278 - val_loss: 35.9009\n",
      "Epoch 106/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.5319 - val_loss: 35.6675\n",
      "Epoch 107/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.6421 - val_loss: 35.7266\n",
      "Epoch 108/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 33.5484 - val_loss: 35.7580\n",
      "Epoch 109/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.6348 - val_loss: 35.5210\n",
      "Epoch 110/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 33.5468 - val_loss: 35.3759\n",
      "Epoch 111/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.4828 - val_loss: 35.4125\n",
      "Epoch 112/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.6056 - val_loss: 36.0985\n",
      "Epoch 113/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 33.5559 - val_loss: 35.3147\n",
      "Epoch 114/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 33.4726 - val_loss: 35.7096\n",
      "Epoch 115/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.3433 - val_loss: 35.2965\n",
      "Epoch 116/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.3157 - val_loss: 35.2830\n",
      "Epoch 117/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.3604 - val_loss: 35.1518\n",
      "Epoch 118/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.5594 - val_loss: 34.7705\n",
      "Epoch 119/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.3426 - val_loss: 35.1186\n",
      "Epoch 120/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.3608 - val_loss: 35.0645\n",
      "Epoch 121/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.3787 - val_loss: 35.2840\n",
      "Epoch 122/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.3067 - val_loss: 35.1672\n",
      "Epoch 123/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.2615 - val_loss: 34.9828\n",
      "Epoch 124/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.2090 - val_loss: 35.1484\n",
      "Epoch 125/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.2098 - val_loss: 35.1606\n",
      "Epoch 126/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 33.4344 - val_loss: 35.6499\n",
      "Epoch 127/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.1843 - val_loss: 35.0228\n",
      "Epoch 128/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 33.2868 - val_loss: 35.3389\n",
      "Epoch 129/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.1489 - val_loss: 34.8904\n",
      "Epoch 130/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.1279 - val_loss: 34.8683\n",
      "Epoch 131/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.0300 - val_loss: 34.8228\n",
      "Epoch 132/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.1263 - val_loss: 34.8388\n",
      "Epoch 133/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.1132 - val_loss: 34.9561\n",
      "Epoch 134/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.1631 - val_loss: 35.1213\n",
      "Epoch 135/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 33.1522 - val_loss: 34.6168\n",
      "Epoch 136/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.1239 - val_loss: 34.7083\n",
      "Epoch 137/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.2010 - val_loss: 34.9670\n",
      "Epoch 138/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 32.9602 - val_loss: 34.6097\n",
      "Epoch 139/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.9442 - val_loss: 34.7532\n",
      "Epoch 140/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 32.9601 - val_loss: 34.6680\n",
      "Epoch 141/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 32.9313 - val_loss: 34.5734\n",
      "Epoch 142/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.9266 - val_loss: 34.8492\n",
      "Epoch 143/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 32.9035 - val_loss: 34.4505\n",
      "Epoch 144/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.8654 - val_loss: 34.6857\n",
      "Epoch 145/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.8072 - val_loss: 34.9102\n",
      "Epoch 146/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.7811 - val_loss: 34.8199\n",
      "Epoch 147/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.7884 - val_loss: 34.4971\n",
      "Epoch 148/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 32.8086 - val_loss: 34.4775\n",
      "Epoch 149/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.7474 - val_loss: 34.4531\n",
      "Epoch 150/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.7883 - val_loss: 34.3146\n",
      "Epoch 151/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.7826 - val_loss: 34.4087\n",
      "Epoch 152/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.7373 - val_loss: 34.4444\n",
      "Epoch 153/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 32.6464 - val_loss: 34.3895\n",
      "Epoch 154/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.6847 - val_loss: 34.4014\n",
      "Epoch 155/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.6159 - val_loss: 34.4507\n",
      "Epoch 156/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.6798 - val_loss: 34.5791\n",
      "Epoch 157/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.6146 - val_loss: 34.5480\n",
      "Epoch 158/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 32.6000 - val_loss: 34.4710\n",
      "Epoch 159/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.5662 - val_loss: 34.5993\n",
      "Epoch 160/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.5519 - val_loss: 34.3885\n",
      "Epoch 161/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 32.5148 - val_loss: 34.5157\n",
      "Epoch 162/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 32.6389 - val_loss: 34.2216\n",
      "Epoch 163/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 32.5895 - val_loss: 34.2279\n",
      "Epoch 164/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 32.5632 - val_loss: 34.2185\n",
      "Epoch 165/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.5718 - val_loss: 34.5857\n",
      "Epoch 166/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.5121 - val_loss: 34.1855\n",
      "Epoch 167/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.5635 - val_loss: 34.3952\n",
      "Epoch 168/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.3690 - val_loss: 34.4461\n",
      "Epoch 169/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 32.4109 - val_loss: 34.6287\n",
      "Epoch 170/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.3776 - val_loss: 34.5239\n",
      "Epoch 171/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.3445 - val_loss: 34.1766\n",
      "Epoch 172/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.3355 - val_loss: 34.0018\n",
      "Epoch 173/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.3419 - val_loss: 34.3011\n",
      "Epoch 174/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.4035 - val_loss: 34.3324\n",
      "Epoch 175/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 32.3795 - val_loss: 34.2784\n",
      "Epoch 176/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 32.3873 - val_loss: 34.3254\n",
      "Epoch 177/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.3618 - val_loss: 34.7104\n",
      "Epoch 178/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.2836 - val_loss: 34.1916\n",
      "Epoch 179/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.3003 - val_loss: 33.9770\n",
      "Epoch 180/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.2253 - val_loss: 34.3289\n",
      "Epoch 181/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.1649 - val_loss: 34.0706\n",
      "Epoch 182/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.1552 - val_loss: 34.0623\n",
      "Epoch 183/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 32.1629 - val_loss: 34.1854\n",
      "Epoch 184/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.3151 - val_loss: 33.8604\n",
      "Epoch 185/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.1470 - val_loss: 34.1341\n",
      "Epoch 186/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.1409 - val_loss: 34.0392\n",
      "Epoch 187/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.0563 - val_loss: 33.8655\n",
      "Epoch 188/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 32.1319 - val_loss: 34.0687\n",
      "Epoch 189/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.0262 - val_loss: 34.0620\n",
      "Epoch 190/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 32.0305 - val_loss: 33.7717\n",
      "Epoch 191/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.0392 - val_loss: 33.9099\n",
      "Epoch 192/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.9772 - val_loss: 33.9206\n",
      "Epoch 193/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 32.0269 - val_loss: 34.0705\n",
      "Epoch 194/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.9490 - val_loss: 33.8913\n",
      "Epoch 195/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.9783 - val_loss: 33.6990\n",
      "Epoch 196/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.9325 - val_loss: 34.0011\n",
      "Epoch 197/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.8597 - val_loss: 33.9172\n",
      "Epoch 198/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.9704 - val_loss: 34.0254\n",
      "Epoch 199/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.8564 - val_loss: 33.7364\n",
      "Epoch 200/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.8191 - val_loss: 33.6338\n",
      "Epoch 201/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.8266 - val_loss: 33.7377\n",
      "Epoch 202/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.9235 - val_loss: 33.9257\n",
      "Epoch 203/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.8111 - val_loss: 33.7812\n",
      "Epoch 204/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.8641 - val_loss: 33.5058\n",
      "Epoch 205/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.7975 - val_loss: 33.7998\n",
      "Epoch 206/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.7371 - val_loss: 33.7622\n",
      "Epoch 207/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.7389 - val_loss: 33.8039\n",
      "Epoch 208/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.6940 - val_loss: 33.6742\n",
      "Epoch 209/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 31.7367 - val_loss: 33.8962\n",
      "Epoch 210/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.7800 - val_loss: 33.4712\n",
      "Epoch 211/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.7552 - val_loss: 33.8216\n",
      "Epoch 212/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.6543 - val_loss: 33.3989\n",
      "Epoch 213/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.5894 - val_loss: 33.5893\n",
      "Epoch 214/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.6067 - val_loss: 33.4108\n",
      "Epoch 215/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.6716 - val_loss: 33.4644\n",
      "Epoch 216/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.5477 - val_loss: 33.5269\n",
      "Epoch 217/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.6433 - val_loss: 33.6878\n",
      "Epoch 218/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.6143 - val_loss: 33.1879\n",
      "Epoch 219/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.5587 - val_loss: 33.1708\n",
      "Epoch 220/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.5030 - val_loss: 33.2768\n",
      "Epoch 221/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.4818 - val_loss: 33.1583\n",
      "Epoch 222/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.4523 - val_loss: 33.2700\n",
      "Epoch 223/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 31.4531 - val_loss: 33.2928\n",
      "Epoch 224/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.4685 - val_loss: 33.3455\n",
      "Epoch 225/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.5524 - val_loss: 33.4574\n",
      "Epoch 226/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.4228 - val_loss: 33.4769\n",
      "Epoch 227/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.3651 - val_loss: 33.3180\n",
      "Epoch 228/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.4457 - val_loss: 33.3215\n",
      "Epoch 229/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.3894 - val_loss: 33.2185\n",
      "Epoch 230/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.4008 - val_loss: 33.4102\n",
      "Epoch 231/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.3376 - val_loss: 33.2727\n",
      "Epoch 232/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.2889 - val_loss: 33.2523\n",
      "Epoch 233/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.3286 - val_loss: 33.2949\n",
      "Epoch 234/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.3042 - val_loss: 33.2722\n",
      "Epoch 235/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.3008 - val_loss: 33.2872\n",
      "Epoch 236/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.2578 - val_loss: 33.0393\n",
      "Epoch 237/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.2187 - val_loss: 33.1598\n",
      "Epoch 238/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.1693 - val_loss: 33.1177\n",
      "Epoch 239/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.2627 - val_loss: 32.9326\n",
      "Epoch 240/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.2242 - val_loss: 33.0166\n",
      "Epoch 241/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.1398 - val_loss: 32.9095\n",
      "Epoch 242/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.1884 - val_loss: 32.9776\n",
      "Epoch 243/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.1657 - val_loss: 32.9953\n",
      "Epoch 244/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.0934 - val_loss: 33.0040\n",
      "Epoch 245/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.0925 - val_loss: 32.9279\n",
      "Epoch 246/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.1069 - val_loss: 32.9025\n",
      "Epoch 247/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.0975 - val_loss: 32.9669\n",
      "Epoch 248/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.0452 - val_loss: 32.9308\n",
      "Epoch 249/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.0412 - val_loss: 32.8953\n",
      "Epoch 250/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.0620 - val_loss: 32.5340\n",
      "Epoch 251/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.0155 - val_loss: 32.8352\n",
      "Epoch 252/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.9312 - val_loss: 32.9578\n",
      "Epoch 253/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.9133 - val_loss: 32.8380\n",
      "Epoch 254/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.8790 - val_loss: 32.9280\n",
      "Epoch 255/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 30.9017 - val_loss: 32.8800\n",
      "Epoch 256/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 30.9098 - val_loss: 32.7897\n",
      "Epoch 257/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.8721 - val_loss: 32.6295\n",
      "Epoch 258/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.8952 - val_loss: 33.0579\n",
      "Epoch 259/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 30.8708 - val_loss: 32.8133\n",
      "Epoch 260/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 30.8150 - val_loss: 32.9942\n",
      "Epoch 261/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 30.8880 - val_loss: 32.7973\n",
      "Epoch 262/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 30.7679 - val_loss: 32.7744\n",
      "Epoch 263/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 30.7663 - val_loss: 32.6249\n",
      "Epoch 264/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.7577 - val_loss: 32.5741\n",
      "Epoch 265/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.7747 - val_loss: 32.7739\n",
      "Epoch 266/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.6906 - val_loss: 32.6698\n",
      "Epoch 267/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.7298 - val_loss: 32.5852\n",
      "Epoch 268/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.7554 - val_loss: 32.3932\n",
      "Epoch 269/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.6716 - val_loss: 32.4472\n",
      "Epoch 270/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 30.6166 - val_loss: 32.4718\n",
      "Epoch 271/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.7080 - val_loss: 32.7564\n",
      "Epoch 272/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.7075 - val_loss: 32.3690\n",
      "Epoch 273/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.6344 - val_loss: 32.5760\n",
      "Epoch 274/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 30.5440 - val_loss: 32.4864\n",
      "Epoch 275/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.5325 - val_loss: 32.5309\n",
      "Epoch 276/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 30.5775 - val_loss: 32.4150\n",
      "Epoch 277/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 30.6476 - val_loss: 32.4689\n",
      "Epoch 278/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 30.4853 - val_loss: 32.4425\n",
      "Epoch 279/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.5436 - val_loss: 32.3251\n",
      "Epoch 280/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.4840 - val_loss: 32.4013\n",
      "Epoch 281/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.5398 - val_loss: 32.1820\n",
      "Epoch 282/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.4312 - val_loss: 32.2207\n",
      "Epoch 283/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 30.4715 - val_loss: 32.4643\n",
      "Epoch 284/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.4429 - val_loss: 32.3193\n",
      "Epoch 285/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.4355 - val_loss: 32.4574\n",
      "Epoch 286/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.4607 - val_loss: 32.2733\n",
      "Epoch 287/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.3523 - val_loss: 32.4192\n",
      "Epoch 288/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.3488 - val_loss: 32.4449\n",
      "Epoch 289/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.3500 - val_loss: 32.1987\n",
      "Epoch 290/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 30.3552 - val_loss: 32.1446\n",
      "Epoch 291/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 30.3517 - val_loss: 32.4953\n",
      "Epoch 292/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 30.3061 - val_loss: 32.3901\n",
      "Epoch 293/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.2892 - val_loss: 32.1521\n",
      "Epoch 294/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 30.2298 - val_loss: 32.2136\n",
      "Epoch 295/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 30.2711 - val_loss: 32.1193\n",
      "Epoch 296/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.2394 - val_loss: 32.0745\n",
      "Epoch 297/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.1947 - val_loss: 32.2317\n",
      "Epoch 298/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 30.2243 - val_loss: 32.0343\n",
      "Epoch 299/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 30.1405 - val_loss: 32.0448\n",
      "Epoch 300/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 30.1460 - val_loss: 32.0480\n",
      "Epoch 301/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 30.2241 - val_loss: 32.1664\n",
      "Epoch 302/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.1267 - val_loss: 32.0357\n",
      "Epoch 303/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.0928 - val_loss: 32.2753\n",
      "Epoch 304/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.1136 - val_loss: 31.7941\n",
      "Epoch 305/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.0677 - val_loss: 31.8150\n",
      "Epoch 306/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 30.0281 - val_loss: 31.6554\n",
      "Epoch 307/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 30.0400 - val_loss: 31.8251\n",
      "Epoch 308/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 30.0414 - val_loss: 31.8543\n",
      "Epoch 309/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.0009 - val_loss: 31.5911\n",
      "Epoch 310/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 30.0038 - val_loss: 31.9252\n",
      "Epoch 311/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 30.0062 - val_loss: 32.0253\n",
      "Epoch 312/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 29.9816 - val_loss: 31.7966\n",
      "Epoch 313/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 29.9235 - val_loss: 31.8314\n",
      "Epoch 314/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 29.9298 - val_loss: 31.9235\n",
      "Epoch 315/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.8710 - val_loss: 32.0110\n",
      "Epoch 316/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.9559 - val_loss: 31.9764\n",
      "Epoch 317/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.8708 - val_loss: 31.7850\n",
      "Epoch 318/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 29.9258 - val_loss: 31.4665\n",
      "Epoch 319/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 29.8775 - val_loss: 31.6838\n",
      "Epoch 320/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 29.8252 - val_loss: 31.8014\n",
      "Epoch 321/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.8581 - val_loss: 31.7055\n",
      "Epoch 322/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 29.8452 - val_loss: 31.4782\n",
      "Epoch 323/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.8879 - val_loss: 31.7131\n",
      "Epoch 324/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.7610 - val_loss: 31.5076\n",
      "Epoch 325/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 29.7454 - val_loss: 31.5189\n",
      "Epoch 326/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.7146 - val_loss: 31.4428\n",
      "Epoch 327/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 29.7448 - val_loss: 31.4273\n",
      "Epoch 328/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.7689 - val_loss: 31.5586\n",
      "Epoch 329/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.7325 - val_loss: 31.3511\n",
      "Epoch 330/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 29.6765 - val_loss: 31.4703\n",
      "Epoch 331/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 29.6524 - val_loss: 31.3631\n",
      "Epoch 332/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 29.6690 - val_loss: 31.6532\n",
      "Epoch 333/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.6873 - val_loss: 31.6870\n",
      "Epoch 334/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 29.5666 - val_loss: 31.6574\n",
      "Epoch 335/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 29.5875 - val_loss: 31.6279\n",
      "Epoch 336/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 29.6531 - val_loss: 31.7353\n",
      "Epoch 337/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.6092 - val_loss: 31.4861\n",
      "Epoch 338/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.5359 - val_loss: 31.6352\n",
      "Epoch 339/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.4842 - val_loss: 31.3814\n",
      "Epoch 340/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 29.6617 - val_loss: 31.6452\n",
      "Epoch 341/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 29.5080 - val_loss: 31.2372\n",
      "Epoch 342/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.4727 - val_loss: 31.4899\n",
      "Epoch 343/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.4374 - val_loss: 31.2309\n",
      "Epoch 344/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.4265 - val_loss: 31.4405\n",
      "Epoch 345/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.4218 - val_loss: 31.3538\n",
      "Epoch 346/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 29.4476 - val_loss: 31.4085\n",
      "Epoch 347/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 29.3729 - val_loss: 31.4222\n",
      "Epoch 348/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.4081 - val_loss: 31.5081\n",
      "Epoch 349/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.3041 - val_loss: 31.3135\n",
      "Epoch 350/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 29.3064 - val_loss: 31.2113\n",
      "Epoch 351/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 29.2831 - val_loss: 31.1676\n",
      "Epoch 352/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 29.2775 - val_loss: 31.1306\n",
      "Epoch 353/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 29.3004 - val_loss: 31.3067\n",
      "Epoch 354/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.2437 - val_loss: 31.1236\n",
      "Epoch 355/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.2385 - val_loss: 31.3678\n",
      "Epoch 356/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.2306 - val_loss: 31.2523\n",
      "Epoch 357/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.2021 - val_loss: 31.0216\n",
      "Epoch 358/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.2167 - val_loss: 31.2849\n",
      "Epoch 359/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.1984 - val_loss: 31.1425\n",
      "Epoch 360/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 29.2855 - val_loss: 31.3961\n",
      "Epoch 361/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 29.2265 - val_loss: 31.2531\n",
      "Epoch 362/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 29.2719 - val_loss: 30.8198\n",
      "Epoch 363/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.1138 - val_loss: 31.0783\n",
      "Epoch 364/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.0883 - val_loss: 30.8724\n",
      "Epoch 365/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.1521 - val_loss: 30.8569\n",
      "Epoch 366/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.0807 - val_loss: 31.0759\n",
      "Epoch 367/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.0772 - val_loss: 31.0203\n",
      "Epoch 368/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.0699 - val_loss: 31.1470\n",
      "Epoch 369/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.9998 - val_loss: 30.9296\n",
      "Epoch 370/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 29.0594 - val_loss: 30.8398\n",
      "Epoch 371/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.9777 - val_loss: 30.8974\n",
      "Epoch 372/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.9650 - val_loss: 30.8622\n",
      "Epoch 373/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.9508 - val_loss: 30.9336\n",
      "Epoch 374/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.9751 - val_loss: 30.7643\n",
      "Epoch 375/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.8920 - val_loss: 30.9863\n",
      "Epoch 376/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.9895 - val_loss: 30.7867\n",
      "Epoch 377/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.9180 - val_loss: 30.6347\n",
      "Epoch 378/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.8896 - val_loss: 30.6149\n",
      "Epoch 379/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.8610 - val_loss: 30.8408\n",
      "Epoch 380/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.8239 - val_loss: 30.7881\n",
      "Epoch 381/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.8309 - val_loss: 31.0835\n",
      "Epoch 382/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.8596 - val_loss: 30.8417\n",
      "Epoch 383/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.8298 - val_loss: 30.8006\n",
      "Epoch 384/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.8259 - val_loss: 30.8069\n",
      "Epoch 385/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.8112 - val_loss: 30.3996\n",
      "Epoch 386/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.7696 - val_loss: 30.5388\n",
      "Epoch 387/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.7545 - val_loss: 30.5949\n",
      "Epoch 388/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.7599 - val_loss: 30.8235\n",
      "Epoch 389/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.7099 - val_loss: 30.8517\n",
      "Epoch 390/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.7126 - val_loss: 30.6063\n",
      "Epoch 391/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.6711 - val_loss: 30.5835\n",
      "Epoch 392/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.6678 - val_loss: 30.3690\n",
      "Epoch 393/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.6451 - val_loss: 30.4531\n",
      "Epoch 394/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.6447 - val_loss: 30.5068\n",
      "Epoch 395/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.6249 - val_loss: 30.4890\n",
      "Epoch 396/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.6028 - val_loss: 30.7537\n",
      "Epoch 397/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.5762 - val_loss: 30.5655\n",
      "Epoch 398/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.5046 - val_loss: 30.4736\n",
      "Epoch 399/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.5758 - val_loss: 30.5208\n",
      "Epoch 400/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.5597 - val_loss: 30.4985\n",
      "Epoch 401/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.5818 - val_loss: 30.4833\n",
      "Epoch 402/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.4786 - val_loss: 30.4715\n",
      "Epoch 403/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.4633 - val_loss: 30.2519\n",
      "Epoch 404/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.4225 - val_loss: 30.3575\n",
      "Epoch 405/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.4631 - val_loss: 30.3822\n",
      "Epoch 406/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.4438 - val_loss: 30.5133\n",
      "Epoch 407/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.3863 - val_loss: 30.3204\n",
      "Epoch 408/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.4023 - val_loss: 30.1122\n",
      "Epoch 409/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.4951 - val_loss: 30.2128\n",
      "Epoch 410/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.3649 - val_loss: 30.5024\n",
      "Epoch 411/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.3793 - val_loss: 30.1950\n",
      "Epoch 412/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.3492 - val_loss: 30.0184\n",
      "Epoch 413/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.3220 - val_loss: 30.1249\n",
      "Epoch 414/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.2992 - val_loss: 30.0861\n",
      "Epoch 415/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.2904 - val_loss: 30.0999\n",
      "Epoch 416/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.3273 - val_loss: 30.2039\n",
      "Epoch 417/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.2491 - val_loss: 30.1260\n",
      "Epoch 418/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.3567 - val_loss: 29.9943\n",
      "Epoch 419/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.2516 - val_loss: 30.0564\n",
      "Epoch 420/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.2451 - val_loss: 30.0918\n",
      "Epoch 421/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.1809 - val_loss: 30.1531\n",
      "Epoch 422/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.1621 - val_loss: 30.2741\n",
      "Epoch 423/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.1695 - val_loss: 30.1728\n",
      "Epoch 424/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.1853 - val_loss: 30.0188\n",
      "Epoch 425/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.1226 - val_loss: 29.9836\n",
      "Epoch 426/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.0661 - val_loss: 29.9272\n",
      "Epoch 427/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.1422 - val_loss: 29.8631\n",
      "Epoch 428/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.1148 - val_loss: 29.9658\n",
      "Epoch 429/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.0527 - val_loss: 30.0660\n",
      "Epoch 430/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.0530 - val_loss: 29.9362\n",
      "Epoch 431/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.0499 - val_loss: 30.0145\n",
      "Epoch 432/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.0563 - val_loss: 30.1063\n",
      "Epoch 433/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.0600 - val_loss: 29.7353\n",
      "Epoch 434/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.9846 - val_loss: 29.9666\n",
      "Epoch 435/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.0043 - val_loss: 29.8158\n",
      "Epoch 436/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.9550 - val_loss: 29.8072\n",
      "Epoch 437/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 27.9018 - val_loss: 29.8224\n",
      "Epoch 438/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 27.8936 - val_loss: 29.8277\n",
      "Epoch 439/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 27.9431 - val_loss: 29.9377\n",
      "Epoch 440/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.9274 - val_loss: 29.8755\n",
      "Epoch 441/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 27.9204 - val_loss: 29.7117\n",
      "Epoch 442/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.8871 - val_loss: 29.5906\n",
      "Epoch 443/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.8662 - val_loss: 29.7459\n",
      "Epoch 444/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.8370 - val_loss: 29.5407\n",
      "Epoch 445/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.8006 - val_loss: 29.5568\n",
      "Epoch 446/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.8366 - val_loss: 29.7304\n",
      "Epoch 447/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.7727 - val_loss: 29.6207\n",
      "Epoch 448/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.7918 - val_loss: 29.8597\n",
      "Epoch 449/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.8078 - val_loss: 29.6137\n",
      "Epoch 450/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27.8197 - val_loss: 29.3284\n",
      "Epoch 451/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 27.7241 - val_loss: 29.4492\n",
      "Epoch 452/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.7739 - val_loss: 29.7610\n",
      "Epoch 453/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.7256 - val_loss: 29.4735\n",
      "Epoch 454/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 27.6809 - val_loss: 29.6497\n",
      "Epoch 455/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.6478 - val_loss: 29.6021\n",
      "Epoch 456/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.6772 - val_loss: 29.2640\n",
      "Epoch 457/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.6518 - val_loss: 29.4629\n",
      "Epoch 458/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.6007 - val_loss: 29.3440\n",
      "Epoch 459/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.6438 - val_loss: 29.2105\n",
      "Epoch 460/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 27.5954 - val_loss: 29.6707\n",
      "Epoch 461/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.6142 - val_loss: 29.1225\n",
      "Epoch 462/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.5262 - val_loss: 29.4052\n",
      "Epoch 463/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.5692 - val_loss: 29.1806\n",
      "Epoch 464/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.5008 - val_loss: 29.2966\n",
      "Epoch 465/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 27.5063 - val_loss: 29.5012\n",
      "Epoch 466/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.5067 - val_loss: 29.3555\n",
      "Epoch 467/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.5583 - val_loss: 29.7603\n",
      "Epoch 468/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 27.4881 - val_loss: 29.3767\n",
      "Epoch 469/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.4920 - val_loss: 29.3309\n",
      "Epoch 470/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.4831 - val_loss: 29.1623\n",
      "Epoch 471/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.4514 - val_loss: 29.2425\n",
      "Epoch 472/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.4008 - val_loss: 29.2464\n",
      "Epoch 473/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.3812 - val_loss: 29.3542\n",
      "Epoch 474/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 27.3603 - val_loss: 29.4875\n",
      "Epoch 475/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 27.3634 - val_loss: 29.2730\n",
      "Epoch 476/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.3376 - val_loss: 29.2430\n",
      "Epoch 477/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 27.4555 - val_loss: 29.3344\n",
      "Epoch 478/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 27.3259 - val_loss: 29.3591\n",
      "Epoch 479/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.3805 - val_loss: 29.1858\n",
      "Epoch 480/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.3094 - val_loss: 29.3302\n",
      "Epoch 481/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.2486 - val_loss: 29.3891\n",
      "Epoch 482/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 27.2985 - val_loss: 29.0567\n",
      "Epoch 483/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.2319 - val_loss: 29.0020\n",
      "Epoch 484/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.2491 - val_loss: 28.9297\n",
      "Epoch 485/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 27.2284 - val_loss: 29.1908\n",
      "Epoch 486/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 27.2002 - val_loss: 29.0873\n",
      "Epoch 487/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.2642 - val_loss: 29.1463\n",
      "Epoch 488/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.1550 - val_loss: 28.9349\n",
      "Epoch 489/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.1598 - val_loss: 29.0874\n",
      "Epoch 490/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 27.0964 - val_loss: 29.0237\n",
      "Epoch 491/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.1455 - val_loss: 28.8448\n",
      "Epoch 492/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 27.1434 - val_loss: 29.1264\n",
      "Epoch 493/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 27.0895 - val_loss: 28.8975\n",
      "Epoch 494/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 27.0655 - val_loss: 28.9720\n",
      "Epoch 495/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.0660 - val_loss: 28.9150\n",
      "Epoch 496/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.0379 - val_loss: 28.9151\n",
      "Epoch 497/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.0060 - val_loss: 28.8729\n",
      "Epoch 498/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.0126 - val_loss: 29.3081\n",
      "Epoch 499/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 26.9753 - val_loss: 28.9728\n",
      "Epoch 500/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 26.9487 - val_loss: 29.1467\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002565BCD8A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Test set MSE: 2249251800.0\n",
      "Test set RMSE: 47426.277\n",
      "Test set RMSPE (%): 25.028128463869397\n"
     ]
    }
   ],
   "source": [
    "model = train_model(epochs=500, layer_sizes=[100, 100, 100], X_train=X_train_scaled, y_train=y_train_log, X_valid=X_test_scaled, y_valid=y_valid_log, batch_norm=True, l1_l2=True)\n",
    "evaluate_model(model, X_test_scaled, y_test, log_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "5/5 [==============================] - 1s 55ms/step - loss: 135.8632 - val_loss: 121.4666\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 83.6910 - val_loss: 103.3548\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 62.7004 - val_loss: 95.3329\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 55.4414 - val_loss: 91.9281\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 52.5846 - val_loss: 90.4432\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 52.3933 - val_loss: 89.6609\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 51.3995 - val_loss: 89.5967\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 50.0060 - val_loss: 88.9638\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 49.7933 - val_loss: 87.6125\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 49.7284 - val_loss: 87.1628\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 49.7812 - val_loss: 86.0580\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 49.4415 - val_loss: 85.2724\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 49.4859 - val_loss: 83.7042\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 49.6062 - val_loss: 82.7420\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 50.1043 - val_loss: 81.0508\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 49.1892 - val_loss: 80.3894\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 49.7334 - val_loss: 78.9067\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 49.3575 - val_loss: 77.8664\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 49.0711 - val_loss: 76.6342\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 49.3261 - val_loss: 75.5918\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 49.2043 - val_loss: 74.5329\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 49.3301 - val_loss: 72.6165\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 49.4760 - val_loss: 71.5486\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 48.8116 - val_loss: 70.0604\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 48.9390 - val_loss: 68.9255\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 48.9006 - val_loss: 67.6626\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 49.0531 - val_loss: 66.8079\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 48.8063 - val_loss: 65.5020\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 48.6673 - val_loss: 64.6514\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 48.9886 - val_loss: 64.2405\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 48.8203 - val_loss: 63.2465\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 48.5352 - val_loss: 62.0762\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 48.7081 - val_loss: 61.6048\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 48.6054 - val_loss: 61.1268\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 48.8530 - val_loss: 60.0906\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 48.5877 - val_loss: 59.4145\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 48.5680 - val_loss: 59.1618\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 48.6769 - val_loss: 57.8367\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 48.3339 - val_loss: 57.6365\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 48.3898 - val_loss: 57.3505\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 48.5620 - val_loss: 56.8602\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 48.2484 - val_loss: 56.2632\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 48.2801 - val_loss: 55.6327\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 48.1948 - val_loss: 55.4917\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 48.3779 - val_loss: 54.9056\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 48.1838 - val_loss: 54.5428\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 48.2677 - val_loss: 54.4047\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 48.2477 - val_loss: 53.9172\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 48.1840 - val_loss: 53.9100\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 48.0303 - val_loss: 53.6742\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 48.2833 - val_loss: 53.5356\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 47.9669 - val_loss: 53.6438\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 47.9137 - val_loss: 52.8699\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 47.9224 - val_loss: 52.9419\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 47.8744 - val_loss: 53.0393\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 47.9157 - val_loss: 52.4386\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 47.9611 - val_loss: 52.3861\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 47.8810 - val_loss: 51.7412\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 47.7643 - val_loss: 51.4849\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 47.9398 - val_loss: 51.1492\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 47.7821 - val_loss: 51.7435\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 47.7732 - val_loss: 52.0783\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 47.9475 - val_loss: 51.5320\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 47.8414 - val_loss: 51.9767\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 47.7046 - val_loss: 51.8108\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 47.4868 - val_loss: 51.4237\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 47.7132 - val_loss: 51.1856\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 47.6323 - val_loss: 51.2413\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 47.4104 - val_loss: 50.7777\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 47.4891 - val_loss: 50.6367\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 47.6177 - val_loss: 51.1165\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 47.4834 - val_loss: 50.6733\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 47.3084 - val_loss: 50.8172\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 47.3645 - val_loss: 50.5449\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 47.3192 - val_loss: 50.4149\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 47.3754 - val_loss: 50.1495\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 47.2806 - val_loss: 50.5242\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 47.1852 - val_loss: 50.6478\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 47.3211 - val_loss: 50.7392\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 47.2425 - val_loss: 50.3750\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 47.1459 - val_loss: 50.4555\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 47.2922 - val_loss: 50.3310\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 47.1407 - val_loss: 50.1136\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 47.0865 - val_loss: 50.4180\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 47.1205 - val_loss: 50.1356\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 47.1777 - val_loss: 49.7367\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 46.9771 - val_loss: 50.2779\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 47.0219 - val_loss: 49.9033\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 47.0876 - val_loss: 49.6459\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 46.9296 - val_loss: 49.8783\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 46.9838 - val_loss: 49.2718\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 46.8098 - val_loss: 49.4064\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 46.7952 - val_loss: 49.6245\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 46.9357 - val_loss: 49.8603\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 46.9664 - val_loss: 49.8373\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 46.8024 - val_loss: 49.8923\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 46.7528 - val_loss: 49.5747\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 46.6710 - val_loss: 49.6701\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 46.7021 - val_loss: 49.1374\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 46.6784 - val_loss: 49.0789\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 46.7198 - val_loss: 49.5349\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 46.6119 - val_loss: 49.4878\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46.5249 - val_loss: 49.5690\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 46.5240 - val_loss: 49.8152\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 46.5167 - val_loss: 49.5875\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 46.4997 - val_loss: 48.9671\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 46.4443 - val_loss: 49.2061\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 46.4174 - val_loss: 49.3027\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 46.4268 - val_loss: 48.9496\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 46.4082 - val_loss: 49.4707\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46.5514 - val_loss: 49.4566\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 46.3326 - val_loss: 49.1819\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 46.4673 - val_loss: 49.2848\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 46.3183 - val_loss: 49.2396\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 46.2074 - val_loss: 49.2151\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 46.2108 - val_loss: 49.1200\n",
      "Epoch 117/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 46.2845 - val_loss: 48.8736\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 46.3163 - val_loss: 48.4770\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 46.2409 - val_loss: 48.3964\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 46.2410 - val_loss: 49.0811\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 46.2735 - val_loss: 48.8717\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 46.0786 - val_loss: 49.3391\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 46.1183 - val_loss: 48.7872\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 46.0211 - val_loss: 48.6239\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 46.0113 - val_loss: 48.8211\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 45.9054 - val_loss: 48.5699\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 45.9861 - val_loss: 48.8600\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 45.9447 - val_loss: 48.3731\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 45.8696 - val_loss: 48.4926\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 45.9733 - val_loss: 48.6373\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 45.7973 - val_loss: 48.6127\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 45.7754 - val_loss: 48.3667\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 45.7342 - val_loss: 48.2810\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 45.7745 - val_loss: 48.4365\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 45.7344 - val_loss: 48.3922\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 45.6356 - val_loss: 48.5679\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 45.6919 - val_loss: 48.1699\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 45.6588 - val_loss: 48.4384\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 45.6572 - val_loss: 48.1193\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 45.7360 - val_loss: 48.4437\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 45.6370 - val_loss: 48.2296\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 45.5360 - val_loss: 48.1446\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 45.5241 - val_loss: 48.4383\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 45.4275 - val_loss: 48.1848\n",
      "Epoch 145/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 45.4942 - val_loss: 48.1031\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 45.4647 - val_loss: 47.8617\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 45.4092 - val_loss: 47.8525\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 45.3644 - val_loss: 47.9587\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 45.3535 - val_loss: 48.3714\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 45.3576 - val_loss: 48.1697\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 45.2762 - val_loss: 48.1183\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 45.2912 - val_loss: 48.3954\n",
      "Epoch 153/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 45.4185 - val_loss: 48.2012\n",
      "Epoch 154/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 45.3320 - val_loss: 48.1803\n",
      "Epoch 155/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 45.2295 - val_loss: 47.8758\n",
      "Epoch 156/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 45.2248 - val_loss: 47.8408\n",
      "Epoch 157/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 45.3450 - val_loss: 47.7016\n",
      "Epoch 158/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 45.2129 - val_loss: 47.6761\n",
      "Epoch 159/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 45.1244 - val_loss: 47.9100\n",
      "Epoch 160/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 45.1970 - val_loss: 48.2223\n",
      "Epoch 161/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 45.0834 - val_loss: 47.9345\n",
      "Epoch 162/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 45.0561 - val_loss: 47.6153\n",
      "Epoch 163/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 45.0077 - val_loss: 47.5864\n",
      "Epoch 164/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.9560 - val_loss: 47.4812\n",
      "Epoch 165/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.9626 - val_loss: 47.5849\n",
      "Epoch 166/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 44.9680 - val_loss: 47.4574\n",
      "Epoch 167/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.8492 - val_loss: 47.7663\n",
      "Epoch 168/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 44.9738 - val_loss: 47.4367\n",
      "Epoch 169/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.9493 - val_loss: 47.7256\n",
      "Epoch 170/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.8123 - val_loss: 47.4444\n",
      "Epoch 171/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.8288 - val_loss: 47.4374\n",
      "Epoch 172/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.7419 - val_loss: 47.3201\n",
      "Epoch 173/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.8368 - val_loss: 47.1231\n",
      "Epoch 174/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 44.6963 - val_loss: 47.1227\n",
      "Epoch 175/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.7405 - val_loss: 47.4632\n",
      "Epoch 176/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 44.6703 - val_loss: 47.6045\n",
      "Epoch 177/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 44.6739 - val_loss: 47.5317\n",
      "Epoch 178/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.7630 - val_loss: 47.3279\n",
      "Epoch 179/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 44.6334 - val_loss: 47.1169\n",
      "Epoch 180/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.5813 - val_loss: 46.9650\n",
      "Epoch 181/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.5788 - val_loss: 46.7907\n",
      "Epoch 182/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.5276 - val_loss: 46.8882\n",
      "Epoch 183/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.5341 - val_loss: 47.1189\n",
      "Epoch 184/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 44.5695 - val_loss: 46.7789\n",
      "Epoch 185/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.4639 - val_loss: 46.8824\n",
      "Epoch 186/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 44.4463 - val_loss: 46.8498\n",
      "Epoch 187/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 44.3709 - val_loss: 46.8970\n",
      "Epoch 188/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.5311 - val_loss: 46.6645\n",
      "Epoch 189/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.3544 - val_loss: 46.8136\n",
      "Epoch 190/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 44.3313 - val_loss: 46.9305\n",
      "Epoch 191/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 44.3579 - val_loss: 46.7507\n",
      "Epoch 192/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.2170 - val_loss: 46.6674\n",
      "Epoch 193/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.2640 - val_loss: 46.2245\n",
      "Epoch 194/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 44.2293 - val_loss: 46.3798\n",
      "Epoch 195/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.2247 - val_loss: 46.5619\n",
      "Epoch 196/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.2622 - val_loss: 46.8268\n",
      "Epoch 197/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 44.1555 - val_loss: 46.6677\n",
      "Epoch 198/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 44.1054 - val_loss: 46.4444\n",
      "Epoch 199/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.1011 - val_loss: 46.5156\n",
      "Epoch 200/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.1479 - val_loss: 46.6526\n",
      "Epoch 201/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.1332 - val_loss: 46.6668\n",
      "Epoch 202/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.1126 - val_loss: 46.7226\n",
      "Epoch 203/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.1579 - val_loss: 46.2990\n",
      "Epoch 204/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 44.0918 - val_loss: 46.4675\n",
      "Epoch 205/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 43.9076 - val_loss: 46.5099\n",
      "Epoch 206/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 43.9138 - val_loss: 46.4102\n",
      "Epoch 207/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 43.9350 - val_loss: 46.6281\n",
      "Epoch 208/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 43.8861 - val_loss: 46.6617\n",
      "Epoch 209/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 43.9756 - val_loss: 46.1824\n",
      "Epoch 210/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 43.9226 - val_loss: 46.2041\n",
      "Epoch 211/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 43.8391 - val_loss: 46.3619\n",
      "Epoch 212/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 43.7757 - val_loss: 46.0434\n",
      "Epoch 213/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 43.7649 - val_loss: 46.2010\n",
      "Epoch 214/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 43.7777 - val_loss: 46.0516\n",
      "Epoch 215/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 43.6916 - val_loss: 45.8474\n",
      "Epoch 216/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 43.6944 - val_loss: 46.0601\n",
      "Epoch 217/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 43.6256 - val_loss: 46.0598\n",
      "Epoch 218/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 43.5974 - val_loss: 46.0478\n",
      "Epoch 219/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 43.5935 - val_loss: 46.1571\n",
      "Epoch 220/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 43.6187 - val_loss: 46.2264\n",
      "Epoch 221/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 43.5795 - val_loss: 46.1367\n",
      "Epoch 222/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 43.5448 - val_loss: 45.8766\n",
      "Epoch 223/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 43.4979 - val_loss: 46.0810\n",
      "Epoch 224/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 43.5886 - val_loss: 46.5039\n",
      "Epoch 225/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 43.4569 - val_loss: 45.9934\n",
      "Epoch 226/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 43.5387 - val_loss: 46.0689\n",
      "Epoch 227/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 43.3446 - val_loss: 45.7999\n",
      "Epoch 228/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 43.3840 - val_loss: 45.9145\n",
      "Epoch 229/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 43.3764 - val_loss: 45.9662\n",
      "Epoch 230/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 43.3965 - val_loss: 45.8474\n",
      "Epoch 231/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 43.3109 - val_loss: 45.4775\n",
      "Epoch 232/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 43.3522 - val_loss: 45.5175\n",
      "Epoch 233/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 43.2561 - val_loss: 45.6251\n",
      "Epoch 234/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 43.2141 - val_loss: 45.6844\n",
      "Epoch 235/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 43.2317 - val_loss: 45.5610\n",
      "Epoch 236/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 43.1446 - val_loss: 45.3954\n",
      "Epoch 237/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 43.2018 - val_loss: 45.8555\n",
      "Epoch 238/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 43.2037 - val_loss: 45.5947\n",
      "Epoch 239/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 43.1675 - val_loss: 45.4389\n",
      "Epoch 240/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 43.1361 - val_loss: 45.6372\n",
      "Epoch 241/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 43.1135 - val_loss: 45.5726\n",
      "Epoch 242/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 43.0302 - val_loss: 45.4756\n",
      "Epoch 243/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 43.0677 - val_loss: 45.5498\n",
      "Epoch 244/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 43.0462 - val_loss: 45.6452\n",
      "Epoch 245/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 43.0243 - val_loss: 45.4329\n",
      "Epoch 246/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 42.8901 - val_loss: 45.3300\n",
      "Epoch 247/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 42.9042 - val_loss: 45.3138\n",
      "Epoch 248/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 42.9380 - val_loss: 45.2782\n",
      "Epoch 249/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 42.8639 - val_loss: 45.2866\n",
      "Epoch 250/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 42.9166 - val_loss: 45.1912\n",
      "Epoch 251/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 42.8141 - val_loss: 45.3124\n",
      "Epoch 252/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 42.7728 - val_loss: 45.4051\n",
      "Epoch 253/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 42.8551 - val_loss: 45.5270\n",
      "Epoch 254/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 42.7632 - val_loss: 45.3907\n",
      "Epoch 255/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 42.7775 - val_loss: 45.3824\n",
      "Epoch 256/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 42.7220 - val_loss: 45.0257\n",
      "Epoch 257/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 42.6718 - val_loss: 45.0202\n",
      "Epoch 258/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 42.6677 - val_loss: 44.9333\n",
      "Epoch 259/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 42.6071 - val_loss: 45.1112\n",
      "Epoch 260/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 42.6033 - val_loss: 44.9938\n",
      "Epoch 261/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 42.6184 - val_loss: 44.9812\n",
      "Epoch 262/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42.5636 - val_loss: 45.2007\n",
      "Epoch 263/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 42.5721 - val_loss: 45.0593\n",
      "Epoch 264/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 42.5789 - val_loss: 44.9347\n",
      "Epoch 265/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 42.4688 - val_loss: 44.7515\n",
      "Epoch 266/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 42.5192 - val_loss: 44.4981\n",
      "Epoch 267/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 42.4735 - val_loss: 44.7406\n",
      "Epoch 268/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 42.5191 - val_loss: 44.9824\n",
      "Epoch 269/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 42.4703 - val_loss: 44.7120\n",
      "Epoch 270/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 42.4207 - val_loss: 45.0219\n",
      "Epoch 271/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 42.3315 - val_loss: 44.6245\n",
      "Epoch 272/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 42.3829 - val_loss: 44.5402\n",
      "Epoch 273/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 42.3272 - val_loss: 44.5914\n",
      "Epoch 274/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 42.3290 - val_loss: 44.3322\n",
      "Epoch 275/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 42.2696 - val_loss: 44.3802\n",
      "Epoch 276/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 42.2050 - val_loss: 44.6045\n",
      "Epoch 277/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 42.2187 - val_loss: 44.4497\n",
      "Epoch 278/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 42.2039 - val_loss: 44.5435\n",
      "Epoch 279/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 42.1774 - val_loss: 44.5654\n",
      "Epoch 280/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 42.1989 - val_loss: 44.4689\n",
      "Epoch 281/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 42.1573 - val_loss: 44.3795\n",
      "Epoch 282/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 42.1233 - val_loss: 44.5069\n",
      "Epoch 283/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 42.0663 - val_loss: 44.2767\n",
      "Epoch 284/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 42.0393 - val_loss: 44.3259\n",
      "Epoch 285/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 42.1580 - val_loss: 44.1628\n",
      "Epoch 286/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 42.1062 - val_loss: 43.8521\n",
      "Epoch 287/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 42.0219 - val_loss: 43.9359\n",
      "Epoch 288/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 41.9510 - val_loss: 44.1453\n",
      "Epoch 289/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 41.9591 - val_loss: 44.0948\n",
      "Epoch 290/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 41.8813 - val_loss: 44.2001\n",
      "Epoch 291/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 41.8783 - val_loss: 44.0351\n",
      "Epoch 292/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 41.9791 - val_loss: 44.1550\n",
      "Epoch 293/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 41.8217 - val_loss: 44.1293\n",
      "Epoch 294/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 41.8161 - val_loss: 44.0974\n",
      "Epoch 295/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 41.8318 - val_loss: 44.1395\n",
      "Epoch 296/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 41.7623 - val_loss: 44.0704\n",
      "Epoch 297/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 41.6879 - val_loss: 43.9440\n",
      "Epoch 298/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 41.7037 - val_loss: 44.1308\n",
      "Epoch 299/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 41.7364 - val_loss: 44.0447\n",
      "Epoch 300/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41.6726 - val_loss: 43.8702\n",
      "Epoch 301/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 41.6230 - val_loss: 43.8214\n",
      "Epoch 302/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 41.6217 - val_loss: 43.8366\n",
      "Epoch 303/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 41.6328 - val_loss: 43.8312\n",
      "Epoch 304/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 41.5634 - val_loss: 43.8751\n",
      "Epoch 305/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 41.6077 - val_loss: 44.0344\n",
      "Epoch 306/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 41.5441 - val_loss: 43.6974\n",
      "Epoch 307/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 41.5312 - val_loss: 43.7048\n",
      "Epoch 308/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 41.6053 - val_loss: 43.6323\n",
      "Epoch 309/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 41.4877 - val_loss: 43.7104\n",
      "Epoch 310/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 41.5600 - val_loss: 43.8453\n",
      "Epoch 311/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 41.4366 - val_loss: 43.7528\n",
      "Epoch 312/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 41.4527 - val_loss: 43.9475\n",
      "Epoch 313/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 41.4205 - val_loss: 43.7745\n",
      "Epoch 314/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 41.4500 - val_loss: 43.7792\n",
      "Epoch 315/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 41.3255 - val_loss: 43.8092\n",
      "Epoch 316/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 41.4006 - val_loss: 43.5707\n",
      "Epoch 317/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 41.2555 - val_loss: 43.6581\n",
      "Epoch 318/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 41.2734 - val_loss: 43.7919\n",
      "Epoch 319/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 41.2462 - val_loss: 43.6612\n",
      "Epoch 320/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 41.1822 - val_loss: 43.6064\n",
      "Epoch 321/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 41.2076 - val_loss: 43.5139\n",
      "Epoch 322/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 41.1288 - val_loss: 43.5072\n",
      "Epoch 323/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 41.1016 - val_loss: 43.3704\n",
      "Epoch 324/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41.1241 - val_loss: 43.3746\n",
      "Epoch 325/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 41.0886 - val_loss: 43.4537\n",
      "Epoch 326/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 41.1141 - val_loss: 43.1309\n",
      "Epoch 327/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 41.0349 - val_loss: 43.2646\n",
      "Epoch 328/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 40.9931 - val_loss: 43.3870\n",
      "Epoch 329/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 40.9855 - val_loss: 43.1398\n",
      "Epoch 330/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 40.9314 - val_loss: 43.1700\n",
      "Epoch 331/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 40.9665 - val_loss: 43.0731\n",
      "Epoch 332/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 40.8969 - val_loss: 43.3129\n",
      "Epoch 333/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 40.8972 - val_loss: 43.3973\n",
      "Epoch 334/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 40.8697 - val_loss: 43.1818\n",
      "Epoch 335/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 40.8736 - val_loss: 43.2220\n",
      "Epoch 336/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 40.8618 - val_loss: 43.1658\n",
      "Epoch 337/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 40.8273 - val_loss: 43.0968\n",
      "Epoch 338/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 40.8020 - val_loss: 42.9190\n",
      "Epoch 339/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 40.7317 - val_loss: 42.8255\n",
      "Epoch 340/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 40.7187 - val_loss: 42.7894\n",
      "Epoch 341/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 40.7626 - val_loss: 42.9304\n",
      "Epoch 342/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 40.7023 - val_loss: 43.0616\n",
      "Epoch 343/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 40.7101 - val_loss: 43.1502\n",
      "Epoch 344/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 40.6626 - val_loss: 42.8157\n",
      "Epoch 345/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 40.6140 - val_loss: 43.1204\n",
      "Epoch 346/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 40.6283 - val_loss: 42.9482\n",
      "Epoch 347/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 40.5883 - val_loss: 42.8191\n",
      "Epoch 348/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 40.6023 - val_loss: 42.8492\n",
      "Epoch 349/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 40.5389 - val_loss: 42.7007\n",
      "Epoch 350/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 40.5040 - val_loss: 42.8120\n",
      "Epoch 351/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 40.4877 - val_loss: 42.8476\n",
      "Epoch 352/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 40.5354 - val_loss: 43.1366\n",
      "Epoch 353/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 40.4660 - val_loss: 42.9692\n",
      "Epoch 354/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 40.4045 - val_loss: 42.6031\n",
      "Epoch 355/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 40.3789 - val_loss: 42.5187\n",
      "Epoch 356/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 40.3897 - val_loss: 42.5768\n",
      "Epoch 357/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 40.3220 - val_loss: 42.6594\n",
      "Epoch 358/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 40.3675 - val_loss: 42.5394\n",
      "Epoch 359/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 40.2742 - val_loss: 42.6300\n",
      "Epoch 360/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 40.3206 - val_loss: 42.5026\n",
      "Epoch 361/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 40.2516 - val_loss: 42.3799\n",
      "Epoch 362/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 40.2193 - val_loss: 42.3643\n",
      "Epoch 363/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 40.2115 - val_loss: 42.4090\n",
      "Epoch 364/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 40.1925 - val_loss: 42.3427\n",
      "Epoch 365/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 40.1463 - val_loss: 42.6205\n",
      "Epoch 366/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40.1709 - val_loss: 42.5935\n",
      "Epoch 367/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 40.0702 - val_loss: 42.3927\n",
      "Epoch 368/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 40.1000 - val_loss: 42.2090\n",
      "Epoch 369/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 40.1132 - val_loss: 42.5889\n",
      "Epoch 370/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 40.0283 - val_loss: 42.4444\n",
      "Epoch 371/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 40.0655 - val_loss: 42.3590\n",
      "Epoch 372/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 39.9692 - val_loss: 42.1884\n",
      "Epoch 373/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 39.9812 - val_loss: 42.1404\n",
      "Epoch 374/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 39.9312 - val_loss: 42.0724\n",
      "Epoch 375/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 39.9134 - val_loss: 42.2291\n",
      "Epoch 376/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 39.8879 - val_loss: 42.1687\n",
      "Epoch 377/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 39.9011 - val_loss: 42.1689\n",
      "Epoch 378/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 39.9576 - val_loss: 42.2197\n",
      "Epoch 379/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 39.8275 - val_loss: 42.0604\n",
      "Epoch 380/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 39.8193 - val_loss: 41.9805\n",
      "Epoch 381/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 39.8262 - val_loss: 41.9438\n",
      "Epoch 382/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 39.9005 - val_loss: 41.7898\n",
      "Epoch 383/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 39.7678 - val_loss: 42.0832\n",
      "Epoch 384/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 39.7473 - val_loss: 42.1066\n",
      "Epoch 385/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 39.7288 - val_loss: 41.6256\n",
      "Epoch 386/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 39.7259 - val_loss: 41.9146\n",
      "Epoch 387/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 39.7237 - val_loss: 41.9933\n",
      "Epoch 388/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 39.6390 - val_loss: 41.9103\n",
      "Epoch 389/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39.6720 - val_loss: 41.9453\n",
      "Epoch 390/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 39.5970 - val_loss: 41.9536\n",
      "Epoch 391/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 39.6103 - val_loss: 41.8610\n",
      "Epoch 392/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 39.5248 - val_loss: 41.8313\n",
      "Epoch 393/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 39.5513 - val_loss: 41.9164\n",
      "Epoch 394/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 39.4808 - val_loss: 41.8206\n",
      "Epoch 395/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 39.4404 - val_loss: 41.7212\n",
      "Epoch 396/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 39.4328 - val_loss: 41.5529\n",
      "Epoch 397/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39.4461 - val_loss: 41.6069\n",
      "Epoch 398/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 39.3894 - val_loss: 41.8663\n",
      "Epoch 399/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 39.3550 - val_loss: 41.5183\n",
      "Epoch 400/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 39.3492 - val_loss: 41.6967\n",
      "Epoch 401/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 39.3371 - val_loss: 41.5994\n",
      "Epoch 402/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 39.3002 - val_loss: 41.6247\n",
      "Epoch 403/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 39.2770 - val_loss: 41.4939\n",
      "Epoch 404/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 39.3385 - val_loss: 41.4856\n",
      "Epoch 405/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 39.2410 - val_loss: 41.7711\n",
      "Epoch 406/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 39.2337 - val_loss: 41.4011\n",
      "Epoch 407/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 39.2829 - val_loss: 41.0874\n",
      "Epoch 408/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 39.1922 - val_loss: 41.3078\n",
      "Epoch 409/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 39.1129 - val_loss: 41.2943\n",
      "Epoch 410/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 39.1183 - val_loss: 41.2700\n",
      "Epoch 411/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 39.1179 - val_loss: 41.2492\n",
      "Epoch 412/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 39.0644 - val_loss: 41.2994\n",
      "Epoch 413/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 39.0720 - val_loss: 41.3653\n",
      "Epoch 414/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 39.0180 - val_loss: 41.2022\n",
      "Epoch 415/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 39.0210 - val_loss: 41.0138\n",
      "Epoch 416/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 38.9924 - val_loss: 41.1507\n",
      "Epoch 417/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 38.9813 - val_loss: 41.2305\n",
      "Epoch 418/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 38.9707 - val_loss: 40.9162\n",
      "Epoch 419/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 38.9041 - val_loss: 41.2073\n",
      "Epoch 420/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 38.8830 - val_loss: 41.1509\n",
      "Epoch 421/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 38.8678 - val_loss: 41.0299\n",
      "Epoch 422/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 38.8503 - val_loss: 41.0907\n",
      "Epoch 423/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 38.8711 - val_loss: 40.9815\n",
      "Epoch 424/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 38.9717 - val_loss: 41.1172\n",
      "Epoch 425/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 38.8075 - val_loss: 40.8951\n",
      "Epoch 426/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 38.8427 - val_loss: 40.8082\n",
      "Epoch 427/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 38.7849 - val_loss: 40.7160\n",
      "Epoch 428/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 38.7294 - val_loss: 40.7888\n",
      "Epoch 429/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 38.6930 - val_loss: 40.9119\n",
      "Epoch 430/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 38.8908 - val_loss: 41.0104\n",
      "Epoch 431/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 38.6618 - val_loss: 40.7993\n",
      "Epoch 432/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 38.6126 - val_loss: 40.7700\n",
      "Epoch 433/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 38.6254 - val_loss: 40.7856\n",
      "Epoch 434/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 38.5908 - val_loss: 40.6239\n",
      "Epoch 435/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 38.7419 - val_loss: 40.6158\n",
      "Epoch 436/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 38.7036 - val_loss: 40.6800\n",
      "Epoch 437/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 38.5210 - val_loss: 40.7916\n",
      "Epoch 438/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 38.4937 - val_loss: 40.7182\n",
      "Epoch 439/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 38.5120 - val_loss: 40.7466\n",
      "Epoch 440/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 38.4545 - val_loss: 40.7541\n",
      "Epoch 441/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 38.4389 - val_loss: 40.7338\n",
      "Epoch 442/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 38.3936 - val_loss: 40.7732\n",
      "Epoch 443/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 38.4065 - val_loss: 40.4088\n",
      "Epoch 444/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 38.4305 - val_loss: 40.4300\n",
      "Epoch 445/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 38.3543 - val_loss: 40.6519\n",
      "Epoch 446/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 38.3317 - val_loss: 40.6540\n",
      "Epoch 447/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 38.3491 - val_loss: 40.5507\n",
      "Epoch 448/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 38.2920 - val_loss: 40.3019\n",
      "Epoch 449/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 38.2364 - val_loss: 40.4692\n",
      "Epoch 450/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 38.2148 - val_loss: 40.3124\n",
      "Epoch 451/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 38.2093 - val_loss: 40.4237\n",
      "Epoch 452/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 38.1881 - val_loss: 40.5142\n",
      "Epoch 453/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 38.1672 - val_loss: 40.5057\n",
      "Epoch 454/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 38.2388 - val_loss: 40.3926\n",
      "Epoch 455/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 38.1625 - val_loss: 40.3489\n",
      "Epoch 456/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 38.1784 - val_loss: 40.3780\n",
      "Epoch 457/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 38.1048 - val_loss: 40.5598\n",
      "Epoch 458/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 38.0723 - val_loss: 40.4529\n",
      "Epoch 459/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 38.0704 - val_loss: 40.2136\n",
      "Epoch 460/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 37.9968 - val_loss: 40.3548\n",
      "Epoch 461/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 38.0187 - val_loss: 40.1571\n",
      "Epoch 462/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 38.0391 - val_loss: 40.2445\n",
      "Epoch 463/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 37.9456 - val_loss: 40.0301\n",
      "Epoch 464/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 37.9659 - val_loss: 40.0012\n",
      "Epoch 465/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 37.9115 - val_loss: 40.1637\n",
      "Epoch 466/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 37.9086 - val_loss: 40.2303\n",
      "Epoch 467/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 37.8429 - val_loss: 40.1881\n",
      "Epoch 468/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 37.8528 - val_loss: 40.0739\n",
      "Epoch 469/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 37.8026 - val_loss: 39.8605\n",
      "Epoch 470/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 37.8346 - val_loss: 39.9291\n",
      "Epoch 471/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 37.8548 - val_loss: 39.6600\n",
      "Epoch 472/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 37.7711 - val_loss: 39.9044\n",
      "Epoch 473/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 37.7381 - val_loss: 39.9678\n",
      "Epoch 474/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 37.6966 - val_loss: 39.9580\n",
      "Epoch 475/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 37.6963 - val_loss: 39.9435\n",
      "Epoch 476/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 37.6776 - val_loss: 39.7467\n",
      "Epoch 477/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 37.7768 - val_loss: 39.7475\n",
      "Epoch 478/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 37.6442 - val_loss: 40.0430\n",
      "Epoch 479/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 37.6308 - val_loss: 39.7555\n",
      "Epoch 480/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 37.6299 - val_loss: 39.9115\n",
      "Epoch 481/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 37.5504 - val_loss: 39.7486\n",
      "Epoch 482/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 37.5688 - val_loss: 39.9735\n",
      "Epoch 483/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 37.5260 - val_loss: 40.1298\n",
      "Epoch 484/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 37.5527 - val_loss: 39.8123\n",
      "Epoch 485/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 37.4861 - val_loss: 39.7888\n",
      "Epoch 486/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 37.4295 - val_loss: 39.7797\n",
      "Epoch 487/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 37.4632 - val_loss: 39.9231\n",
      "Epoch 488/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 37.4100 - val_loss: 39.8118\n",
      "Epoch 489/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 37.4130 - val_loss: 39.8128\n",
      "Epoch 490/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 37.4286 - val_loss: 39.6772\n",
      "Epoch 491/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 37.4088 - val_loss: 39.6993\n",
      "Epoch 492/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 37.3280 - val_loss: 39.5671\n",
      "Epoch 493/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 37.2725 - val_loss: 39.6305\n",
      "Epoch 494/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 37.2707 - val_loss: 39.3005\n",
      "Epoch 495/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 37.2556 - val_loss: 39.3958\n",
      "Epoch 496/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 37.2204 - val_loss: 39.4191\n",
      "Epoch 497/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 37.2200 - val_loss: 39.4146\n",
      "Epoch 498/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 37.1854 - val_loss: 39.3131\n",
      "Epoch 499/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 37.2105 - val_loss: 39.5719\n",
      "Epoch 500/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 37.1476 - val_loss: 39.5429\n",
      "Epoch 501/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 37.1425 - val_loss: 39.3774\n",
      "Epoch 502/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 37.1050 - val_loss: 39.2428\n",
      "Epoch 503/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 37.1144 - val_loss: 39.3619\n",
      "Epoch 504/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 37.0471 - val_loss: 39.2155\n",
      "Epoch 505/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 37.0348 - val_loss: 39.2652\n",
      "Epoch 506/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 37.0052 - val_loss: 39.2922\n",
      "Epoch 507/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 37.0067 - val_loss: 39.2093\n",
      "Epoch 508/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36.9577 - val_loss: 39.2451\n",
      "Epoch 509/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 36.9738 - val_loss: 39.0644\n",
      "Epoch 510/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.9314 - val_loss: 39.1587\n",
      "Epoch 511/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 36.9218 - val_loss: 39.1371\n",
      "Epoch 512/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 36.8924 - val_loss: 39.1300\n",
      "Epoch 513/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.9559 - val_loss: 39.0355\n",
      "Epoch 514/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 36.8651 - val_loss: 39.0930\n",
      "Epoch 515/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.8556 - val_loss: 39.0707\n",
      "Epoch 516/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.8268 - val_loss: 38.9015\n",
      "Epoch 517/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 36.7956 - val_loss: 38.9648\n",
      "Epoch 518/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.7935 - val_loss: 38.9203\n",
      "Epoch 519/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.7519 - val_loss: 38.9284\n",
      "Epoch 520/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.7007 - val_loss: 38.9553\n",
      "Epoch 521/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.6994 - val_loss: 38.8609\n",
      "Epoch 522/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.7131 - val_loss: 38.7953\n",
      "Epoch 523/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.6493 - val_loss: 38.8351\n",
      "Epoch 524/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 36.6491 - val_loss: 38.9092\n",
      "Epoch 525/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.6423 - val_loss: 38.8522\n",
      "Epoch 526/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 36.6558 - val_loss: 38.6245\n",
      "Epoch 527/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.6144 - val_loss: 38.8172\n",
      "Epoch 528/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 36.5369 - val_loss: 38.8368\n",
      "Epoch 529/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 36.5492 - val_loss: 38.9383\n",
      "Epoch 530/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.5064 - val_loss: 38.6760\n",
      "Epoch 531/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.6215 - val_loss: 38.7910\n",
      "Epoch 532/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.4836 - val_loss: 38.6594\n",
      "Epoch 533/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.4422 - val_loss: 38.6868\n",
      "Epoch 534/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.4653 - val_loss: 38.3862\n",
      "Epoch 535/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 36.4345 - val_loss: 38.6207\n",
      "Epoch 536/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 36.3968 - val_loss: 38.5208\n",
      "Epoch 537/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.3476 - val_loss: 38.5398\n",
      "Epoch 538/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.3424 - val_loss: 38.5834\n",
      "Epoch 539/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.3368 - val_loss: 38.5726\n",
      "Epoch 540/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.3213 - val_loss: 38.5236\n",
      "Epoch 541/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.2663 - val_loss: 38.4788\n",
      "Epoch 542/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 36.2325 - val_loss: 38.6062\n",
      "Epoch 543/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 36.2178 - val_loss: 38.5085\n",
      "Epoch 544/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.1970 - val_loss: 38.5165\n",
      "Epoch 545/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.1808 - val_loss: 38.3977\n",
      "Epoch 546/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 36.1678 - val_loss: 38.2968\n",
      "Epoch 547/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 36.1542 - val_loss: 38.3719\n",
      "Epoch 548/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.1035 - val_loss: 38.2527\n",
      "Epoch 549/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 36.1101 - val_loss: 38.3933\n",
      "Epoch 550/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.1118 - val_loss: 38.4988\n",
      "Epoch 551/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 36.0473 - val_loss: 38.2985\n",
      "Epoch 552/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 36.0264 - val_loss: 38.0698\n",
      "Epoch 553/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.0047 - val_loss: 38.1431\n",
      "Epoch 554/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.0064 - val_loss: 38.0944\n",
      "Epoch 555/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 35.9597 - val_loss: 38.1283\n",
      "Epoch 556/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.9592 - val_loss: 38.0803\n",
      "Epoch 557/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 35.9309 - val_loss: 38.0287\n",
      "Epoch 558/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.9243 - val_loss: 38.0165\n",
      "Epoch 559/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 35.8839 - val_loss: 38.0009\n",
      "Epoch 560/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 35.8740 - val_loss: 38.0430\n",
      "Epoch 561/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.8713 - val_loss: 38.1196\n",
      "Epoch 562/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 35.8386 - val_loss: 37.9712\n",
      "Epoch 563/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 35.7959 - val_loss: 38.0797\n",
      "Epoch 564/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.8024 - val_loss: 37.8271\n",
      "Epoch 565/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 35.7825 - val_loss: 38.1116\n",
      "Epoch 566/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 35.7226 - val_loss: 37.9738\n",
      "Epoch 567/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 35.7414 - val_loss: 37.7201\n",
      "Epoch 568/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.7216 - val_loss: 37.9162\n",
      "Epoch 569/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 35.6578 - val_loss: 37.8253\n",
      "Epoch 570/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.6242 - val_loss: 37.7643\n",
      "Epoch 571/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.6314 - val_loss: 37.8808\n",
      "Epoch 572/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.6245 - val_loss: 37.7872\n",
      "Epoch 573/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.6138 - val_loss: 37.8350\n",
      "Epoch 574/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.5641 - val_loss: 37.6194\n",
      "Epoch 575/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 35.5568 - val_loss: 37.6498\n",
      "Epoch 576/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 35.5426 - val_loss: 37.7541\n",
      "Epoch 577/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 35.5106 - val_loss: 37.6341\n",
      "Epoch 578/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 35.5280 - val_loss: 37.7382\n",
      "Epoch 579/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 35.4638 - val_loss: 37.4651\n",
      "Epoch 580/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 35.4458 - val_loss: 37.6395\n",
      "Epoch 581/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.4318 - val_loss: 37.6155\n",
      "Epoch 582/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.4187 - val_loss: 37.6091\n",
      "Epoch 583/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 35.3932 - val_loss: 37.4497\n",
      "Epoch 584/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.3447 - val_loss: 37.5997\n",
      "Epoch 585/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.3447 - val_loss: 37.6037\n",
      "Epoch 586/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.3108 - val_loss: 37.5058\n",
      "Epoch 587/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 35.3372 - val_loss: 37.6762\n",
      "Epoch 588/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.3120 - val_loss: 37.4037\n",
      "Epoch 589/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 35.2787 - val_loss: 37.3319\n",
      "Epoch 590/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 35.2517 - val_loss: 37.2981\n",
      "Epoch 591/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.2342 - val_loss: 37.3452\n",
      "Epoch 592/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 35.2098 - val_loss: 37.3923\n",
      "Epoch 593/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 35.1525 - val_loss: 37.4161\n",
      "Epoch 594/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.2446 - val_loss: 37.3133\n",
      "Epoch 595/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.1457 - val_loss: 37.3996\n",
      "Epoch 596/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 35.1480 - val_loss: 37.5762\n",
      "Epoch 597/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.0774 - val_loss: 37.2349\n",
      "Epoch 598/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.1476 - val_loss: 37.1624\n",
      "Epoch 599/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 35.0382 - val_loss: 37.0229\n",
      "Epoch 600/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.0587 - val_loss: 37.2348\n",
      "Epoch 601/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.9938 - val_loss: 37.1795\n",
      "Epoch 602/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.0283 - val_loss: 37.1469\n",
      "Epoch 603/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.9958 - val_loss: 37.1434\n",
      "Epoch 604/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.9575 - val_loss: 36.9503\n",
      "Epoch 605/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.9732 - val_loss: 36.8394\n",
      "Epoch 606/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.9078 - val_loss: 36.9729\n",
      "Epoch 607/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.8945 - val_loss: 37.1016\n",
      "Epoch 608/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.8885 - val_loss: 36.9483\n",
      "Epoch 609/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.8583 - val_loss: 36.8790\n",
      "Epoch 610/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 34.8819 - val_loss: 36.6702\n",
      "Epoch 611/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.8756 - val_loss: 37.0787\n",
      "Epoch 612/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.7698 - val_loss: 37.0327\n",
      "Epoch 613/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.7414 - val_loss: 36.9552\n",
      "Epoch 614/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.7829 - val_loss: 36.8701\n",
      "Epoch 615/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.7182 - val_loss: 36.8271\n",
      "Epoch 616/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.7221 - val_loss: 36.7664\n",
      "Epoch 617/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 34.6731 - val_loss: 36.8465\n",
      "Epoch 618/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 34.6444 - val_loss: 36.9875\n",
      "Epoch 619/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.6445 - val_loss: 36.9244\n",
      "Epoch 620/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.6185 - val_loss: 36.9369\n",
      "Epoch 621/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.5873 - val_loss: 36.9778\n",
      "Epoch 622/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.5407 - val_loss: 36.8663\n",
      "Epoch 623/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.5453 - val_loss: 36.7849\n",
      "Epoch 624/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.5242 - val_loss: 36.8130\n",
      "Epoch 625/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.5109 - val_loss: 36.7317\n",
      "Epoch 626/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.4983 - val_loss: 36.8802\n",
      "Epoch 627/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.4746 - val_loss: 36.6275\n",
      "Epoch 628/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.4387 - val_loss: 36.6241\n",
      "Epoch 629/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.4200 - val_loss: 36.4573\n",
      "Epoch 630/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.4807 - val_loss: 36.5165\n",
      "Epoch 631/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.3912 - val_loss: 36.7057\n",
      "Epoch 632/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.3980 - val_loss: 36.6870\n",
      "Epoch 633/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.3548 - val_loss: 36.5909\n",
      "Epoch 634/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.3296 - val_loss: 36.5334\n",
      "Epoch 635/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.3088 - val_loss: 36.5133\n",
      "Epoch 636/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.2790 - val_loss: 36.3753\n",
      "Epoch 637/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.2479 - val_loss: 36.4316\n",
      "Epoch 638/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.2494 - val_loss: 36.5593\n",
      "Epoch 639/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.1877 - val_loss: 36.3715\n",
      "Epoch 640/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 34.2038 - val_loss: 36.4062\n",
      "Epoch 641/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.2366 - val_loss: 36.3709\n",
      "Epoch 642/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.1791 - val_loss: 36.5079\n",
      "Epoch 643/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.1594 - val_loss: 36.2890\n",
      "Epoch 644/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.1861 - val_loss: 36.0676\n",
      "Epoch 645/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.0870 - val_loss: 36.3239\n",
      "Epoch 646/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.0932 - val_loss: 36.3208\n",
      "Epoch 647/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.0661 - val_loss: 36.2100\n",
      "Epoch 648/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.0740 - val_loss: 36.2897\n",
      "Epoch 649/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34.0826 - val_loss: 36.0088\n",
      "Epoch 650/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.0058 - val_loss: 36.2861\n",
      "Epoch 651/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.0076 - val_loss: 36.1517\n",
      "Epoch 652/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.9427 - val_loss: 36.1857\n",
      "Epoch 653/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.9925 - val_loss: 36.1640\n",
      "Epoch 654/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.9498 - val_loss: 36.2083\n",
      "Epoch 655/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.9279 - val_loss: 36.1130\n",
      "Epoch 656/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.8980 - val_loss: 36.1525\n",
      "Epoch 657/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.8760 - val_loss: 36.0225\n",
      "Epoch 658/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.8665 - val_loss: 36.0536\n",
      "Epoch 659/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.8196 - val_loss: 35.9605\n",
      "Epoch 660/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.8135 - val_loss: 36.0071\n",
      "Epoch 661/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.7793 - val_loss: 36.0048\n",
      "Epoch 662/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.7723 - val_loss: 36.0409\n",
      "Epoch 663/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.7541 - val_loss: 35.9467\n",
      "Epoch 664/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.6858 - val_loss: 35.9423\n",
      "Epoch 665/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.7038 - val_loss: 35.9647\n",
      "Epoch 666/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.6563 - val_loss: 35.9076\n",
      "Epoch 667/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.6315 - val_loss: 35.7062\n",
      "Epoch 668/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.6208 - val_loss: 35.6975\n",
      "Epoch 669/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.5976 - val_loss: 35.7150\n",
      "Epoch 670/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.6064 - val_loss: 35.7092\n",
      "Epoch 671/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.6004 - val_loss: 35.6556\n",
      "Epoch 672/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.5720 - val_loss: 35.9163\n",
      "Epoch 673/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.5367 - val_loss: 35.8803\n",
      "Epoch 674/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.5151 - val_loss: 35.6921\n",
      "Epoch 675/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.5070 - val_loss: 35.6592\n",
      "Epoch 676/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.4832 - val_loss: 35.8184\n",
      "Epoch 677/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.4350 - val_loss: 35.5789\n",
      "Epoch 678/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.4685 - val_loss: 35.6697\n",
      "Epoch 679/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.3980 - val_loss: 35.4818\n",
      "Epoch 680/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.4020 - val_loss: 35.4880\n",
      "Epoch 681/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.3601 - val_loss: 35.6095\n",
      "Epoch 682/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.3863 - val_loss: 35.7063\n",
      "Epoch 683/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 33.3169 - val_loss: 35.5992\n",
      "Epoch 684/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.3492 - val_loss: 35.5449\n",
      "Epoch 685/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.3126 - val_loss: 35.5211\n",
      "Epoch 686/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.2965 - val_loss: 35.4877\n",
      "Epoch 687/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.2793 - val_loss: 35.6603\n",
      "Epoch 688/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.2170 - val_loss: 35.3377\n",
      "Epoch 689/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.2119 - val_loss: 35.3507\n",
      "Epoch 690/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.2297 - val_loss: 35.5011\n",
      "Epoch 691/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.1822 - val_loss: 35.3112\n",
      "Epoch 692/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.1402 - val_loss: 35.3337\n",
      "Epoch 693/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.2049 - val_loss: 35.1690\n",
      "Epoch 694/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.1400 - val_loss: 35.2064\n",
      "Epoch 695/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.0890 - val_loss: 35.3688\n",
      "Epoch 696/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.0911 - val_loss: 35.4997\n",
      "Epoch 697/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.1003 - val_loss: 35.3047\n",
      "Epoch 698/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.0452 - val_loss: 35.3817\n",
      "Epoch 699/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.0019 - val_loss: 35.1218\n",
      "Epoch 700/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 33.0121 - val_loss: 35.0911\n",
      "Epoch 701/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.9775 - val_loss: 35.2584\n",
      "Epoch 702/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.9612 - val_loss: 35.3118\n",
      "Epoch 703/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.9848 - val_loss: 35.3964\n",
      "Epoch 704/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.9205 - val_loss: 35.1209\n",
      "Epoch 705/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 32.9054 - val_loss: 34.9992\n",
      "Epoch 706/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.8552 - val_loss: 35.0173\n",
      "Epoch 707/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.8608 - val_loss: 35.0460\n",
      "Epoch 708/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.8405 - val_loss: 34.9669\n",
      "Epoch 709/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.8380 - val_loss: 34.9264\n",
      "Epoch 710/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.8180 - val_loss: 35.1352\n",
      "Epoch 711/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 32.7635 - val_loss: 35.0031\n",
      "Epoch 712/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.7644 - val_loss: 35.0163\n",
      "Epoch 713/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.7362 - val_loss: 34.9012\n",
      "Epoch 714/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.7383 - val_loss: 34.9276\n",
      "Epoch 715/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 32.7226 - val_loss: 34.6860\n",
      "Epoch 716/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.6754 - val_loss: 34.8747\n",
      "Epoch 717/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.6578 - val_loss: 35.1323\n",
      "Epoch 718/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.6604 - val_loss: 34.7944\n",
      "Epoch 719/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.6048 - val_loss: 34.7727\n",
      "Epoch 720/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.6058 - val_loss: 34.7700\n",
      "Epoch 721/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.6006 - val_loss: 34.6794\n",
      "Epoch 722/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.5490 - val_loss: 34.6730\n",
      "Epoch 723/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.5833 - val_loss: 34.6242\n",
      "Epoch 724/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.5679 - val_loss: 34.7758\n",
      "Epoch 725/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.5220 - val_loss: 34.7305\n",
      "Epoch 726/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.5162 - val_loss: 34.8423\n",
      "Epoch 727/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 32.5070 - val_loss: 34.8530\n",
      "Epoch 728/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.4467 - val_loss: 34.5490\n",
      "Epoch 729/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.4502 - val_loss: 34.3965\n",
      "Epoch 730/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.4127 - val_loss: 34.5099\n",
      "Epoch 731/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.3932 - val_loss: 34.4122\n",
      "Epoch 732/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.3556 - val_loss: 34.4413\n",
      "Epoch 733/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.3592 - val_loss: 34.6473\n",
      "Epoch 734/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.3202 - val_loss: 34.4815\n",
      "Epoch 735/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.2976 - val_loss: 34.5982\n",
      "Epoch 736/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.2825 - val_loss: 34.4943\n",
      "Epoch 737/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.2743 - val_loss: 34.3758\n",
      "Epoch 738/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.2820 - val_loss: 34.3530\n",
      "Epoch 739/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.2275 - val_loss: 34.4422\n",
      "Epoch 740/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.2021 - val_loss: 34.5530\n",
      "Epoch 741/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.1851 - val_loss: 34.5098\n",
      "Epoch 742/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.1546 - val_loss: 34.5085\n",
      "Epoch 743/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.1692 - val_loss: 34.3146\n",
      "Epoch 744/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.1802 - val_loss: 34.2802\n",
      "Epoch 745/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 32.1020 - val_loss: 34.3814\n",
      "Epoch 746/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 32.0914 - val_loss: 34.3187\n",
      "Epoch 747/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.0615 - val_loss: 34.1053\n",
      "Epoch 748/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.0728 - val_loss: 34.3540\n",
      "Epoch 749/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.0372 - val_loss: 34.2373\n",
      "Epoch 750/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 31.9915 - val_loss: 34.1822\n",
      "Epoch 751/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 31.9952 - val_loss: 33.9993\n",
      "Epoch 752/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.9687 - val_loss: 34.0363\n",
      "Epoch 753/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.0024 - val_loss: 34.1008\n",
      "Epoch 754/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 31.9559 - val_loss: 34.2153\n",
      "Epoch 755/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.9528 - val_loss: 34.1160\n",
      "Epoch 756/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 31.9001 - val_loss: 33.9328\n",
      "Epoch 757/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.9115 - val_loss: 33.9509\n",
      "Epoch 758/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.8715 - val_loss: 33.7932\n",
      "Epoch 759/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.8080 - val_loss: 33.8516\n",
      "Epoch 760/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 31.8019 - val_loss: 33.9369\n",
      "Epoch 761/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.8558 - val_loss: 34.1742\n",
      "Epoch 762/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 31.7822 - val_loss: 33.8351\n",
      "Epoch 763/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.7683 - val_loss: 33.8551\n",
      "Epoch 764/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 31.8015 - val_loss: 34.1298\n",
      "Epoch 765/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.7146 - val_loss: 33.9632\n",
      "Epoch 766/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31.6807 - val_loss: 33.8235\n",
      "Epoch 767/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.7104 - val_loss: 33.9805\n",
      "Epoch 768/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.6473 - val_loss: 33.8838\n",
      "Epoch 769/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 31.7149 - val_loss: 34.0523\n",
      "Epoch 770/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.6321 - val_loss: 33.8020\n",
      "Epoch 771/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.5939 - val_loss: 33.7826\n",
      "Epoch 772/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.5726 - val_loss: 33.7242\n",
      "Epoch 773/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.5687 - val_loss: 33.6245\n",
      "Epoch 774/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.5500 - val_loss: 33.5162\n",
      "Epoch 775/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 31.5185 - val_loss: 33.5399\n",
      "Epoch 776/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.4856 - val_loss: 33.5222\n",
      "Epoch 777/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 31.4811 - val_loss: 33.6173\n",
      "Epoch 778/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.5011 - val_loss: 33.6135\n",
      "Epoch 779/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 31.4603 - val_loss: 33.4672\n",
      "Epoch 780/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.4351 - val_loss: 33.5492\n",
      "Epoch 781/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 31.3982 - val_loss: 33.5281\n",
      "Epoch 782/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.3758 - val_loss: 33.6162\n",
      "Epoch 783/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.3980 - val_loss: 33.3142\n",
      "Epoch 784/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.3627 - val_loss: 33.3987\n",
      "Epoch 785/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 31.3257 - val_loss: 33.5821\n",
      "Epoch 786/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 31.3438 - val_loss: 33.4966\n",
      "Epoch 787/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.2838 - val_loss: 33.3879\n",
      "Epoch 788/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.2788 - val_loss: 33.3959\n",
      "Epoch 789/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.2460 - val_loss: 33.2761\n",
      "Epoch 790/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 31.2137 - val_loss: 33.3691\n",
      "Epoch 791/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 31.1854 - val_loss: 33.4129\n",
      "Epoch 792/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.2161 - val_loss: 33.6393\n",
      "Epoch 793/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 31.2098 - val_loss: 33.3075\n",
      "Epoch 794/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.1932 - val_loss: 33.3438\n",
      "Epoch 795/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.1406 - val_loss: 33.1447\n",
      "Epoch 796/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 31.1225 - val_loss: 33.2327\n",
      "Epoch 797/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.0902 - val_loss: 33.1158\n",
      "Epoch 798/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 31.0702 - val_loss: 33.0735\n",
      "Epoch 799/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.0576 - val_loss: 33.2140\n",
      "Epoch 800/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.0867 - val_loss: 33.3685\n",
      "Epoch 801/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 31.0374 - val_loss: 33.3568\n",
      "Epoch 802/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 31.0226 - val_loss: 33.2789\n",
      "Epoch 803/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.0012 - val_loss: 33.1093\n",
      "Epoch 804/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.0167 - val_loss: 33.1160\n",
      "Epoch 805/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.9483 - val_loss: 32.8961\n",
      "Epoch 806/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.9338 - val_loss: 33.0053\n",
      "Epoch 807/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.9198 - val_loss: 32.9076\n",
      "Epoch 808/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.9241 - val_loss: 32.9624\n",
      "Epoch 809/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.8975 - val_loss: 32.8329\n",
      "Epoch 810/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.8482 - val_loss: 32.8678\n",
      "Epoch 811/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.8216 - val_loss: 33.0136\n",
      "Epoch 812/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.8200 - val_loss: 33.0474\n",
      "Epoch 813/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.7934 - val_loss: 32.8142\n",
      "Epoch 814/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.7619 - val_loss: 32.9322\n",
      "Epoch 815/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.7407 - val_loss: 32.9300\n",
      "Epoch 816/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.7626 - val_loss: 33.0281\n",
      "Epoch 817/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.7296 - val_loss: 32.9622\n",
      "Epoch 818/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.7158 - val_loss: 32.8710\n",
      "Epoch 819/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.6954 - val_loss: 32.6842\n",
      "Epoch 820/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.6527 - val_loss: 32.8295\n",
      "Epoch 821/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.6629 - val_loss: 32.5632\n",
      "Epoch 822/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.6038 - val_loss: 32.6188\n",
      "Epoch 823/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.5966 - val_loss: 32.5746\n",
      "Epoch 824/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 30.6016 - val_loss: 32.6897\n",
      "Epoch 825/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.5656 - val_loss: 32.7707\n",
      "Epoch 826/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.5312 - val_loss: 32.7676\n",
      "Epoch 827/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.5379 - val_loss: 32.7368\n",
      "Epoch 828/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.5120 - val_loss: 32.4678\n",
      "Epoch 829/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.4814 - val_loss: 32.6601\n",
      "Epoch 830/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.4705 - val_loss: 32.4710\n",
      "Epoch 831/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.4287 - val_loss: 32.5495\n",
      "Epoch 832/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.4221 - val_loss: 32.5219\n",
      "Epoch 833/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.4106 - val_loss: 32.5692\n",
      "Epoch 834/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.4209 - val_loss: 32.5806\n",
      "Epoch 835/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.3981 - val_loss: 32.5415\n",
      "Epoch 836/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.3755 - val_loss: 32.8397\n",
      "Epoch 837/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.3607 - val_loss: 32.5239\n",
      "Epoch 838/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.3499 - val_loss: 32.5527\n",
      "Epoch 839/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 30.3166 - val_loss: 32.2780\n",
      "Epoch 840/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.2737 - val_loss: 32.2941\n",
      "Epoch 841/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.2512 - val_loss: 32.2787\n",
      "Epoch 842/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.2330 - val_loss: 32.3966\n",
      "Epoch 843/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.2863 - val_loss: 32.1552\n",
      "Epoch 844/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.2266 - val_loss: 32.0761\n",
      "Epoch 845/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.2002 - val_loss: 32.4609\n",
      "Epoch 846/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.1678 - val_loss: 32.3764\n",
      "Epoch 847/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.1681 - val_loss: 31.9809\n",
      "Epoch 848/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.1450 - val_loss: 32.1492\n",
      "Epoch 849/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.1569 - val_loss: 32.2440\n",
      "Epoch 850/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.1380 - val_loss: 32.1586\n",
      "Epoch 851/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.0706 - val_loss: 32.2027\n",
      "Epoch 852/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.0969 - val_loss: 32.1595\n",
      "Epoch 853/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.0214 - val_loss: 32.1940\n",
      "Epoch 854/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.0210 - val_loss: 32.1187\n",
      "Epoch 855/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29.9897 - val_loss: 32.1769\n",
      "Epoch 856/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.0270 - val_loss: 32.1051\n",
      "Epoch 857/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.9541 - val_loss: 31.9811\n",
      "Epoch 858/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.9507 - val_loss: 32.0947\n",
      "Epoch 859/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.9107 - val_loss: 31.9275\n",
      "Epoch 860/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.8990 - val_loss: 32.1913\n",
      "Epoch 861/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.8751 - val_loss: 32.0103\n",
      "Epoch 862/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.8655 - val_loss: 31.9097\n",
      "Epoch 863/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.8689 - val_loss: 32.1660\n",
      "Epoch 864/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.8392 - val_loss: 31.9351\n",
      "Epoch 865/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.8228 - val_loss: 31.9376\n",
      "Epoch 866/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.8074 - val_loss: 31.9473\n",
      "Epoch 867/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 29.8118 - val_loss: 31.7238\n",
      "Epoch 868/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.7627 - val_loss: 31.8480\n",
      "Epoch 869/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29.8218 - val_loss: 32.0295\n",
      "Epoch 870/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.7289 - val_loss: 31.9382\n",
      "Epoch 871/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.7344 - val_loss: 31.8302\n",
      "Epoch 872/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.7533 - val_loss: 31.7480\n",
      "Epoch 873/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 29.7054 - val_loss: 32.0701\n",
      "Epoch 874/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 29.6551 - val_loss: 31.7914\n",
      "Epoch 875/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.6847 - val_loss: 31.9553\n",
      "Epoch 876/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.7010 - val_loss: 32.1022\n",
      "Epoch 877/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.6224 - val_loss: 31.9765\n",
      "Epoch 878/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.6119 - val_loss: 31.9467\n",
      "Epoch 879/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.5747 - val_loss: 31.7259\n",
      "Epoch 880/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.5481 - val_loss: 31.7514\n",
      "Epoch 881/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.5528 - val_loss: 31.4270\n",
      "Epoch 882/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.5046 - val_loss: 31.5586\n",
      "Epoch 883/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.4983 - val_loss: 31.5866\n",
      "Epoch 884/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.4645 - val_loss: 31.5388\n",
      "Epoch 885/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.5014 - val_loss: 31.8271\n",
      "Epoch 886/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 29.4215 - val_loss: 31.5866\n",
      "Epoch 887/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 29.4080 - val_loss: 31.5069\n",
      "Epoch 888/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.4001 - val_loss: 31.3703\n",
      "Epoch 889/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.3591 - val_loss: 31.4024\n",
      "Epoch 890/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.3543 - val_loss: 31.6101\n",
      "Epoch 891/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.3470 - val_loss: 31.4021\n",
      "Epoch 892/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.3186 - val_loss: 31.3694\n",
      "Epoch 893/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.2970 - val_loss: 31.3250\n",
      "Epoch 894/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.2810 - val_loss: 31.4187\n",
      "Epoch 895/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.2819 - val_loss: 31.4291\n",
      "Epoch 896/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.2392 - val_loss: 31.3431\n",
      "Epoch 897/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.2306 - val_loss: 31.3623\n",
      "Epoch 898/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.2176 - val_loss: 31.2944\n",
      "Epoch 899/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 29.1980 - val_loss: 31.1194\n",
      "Epoch 900/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.1790 - val_loss: 31.4305\n",
      "Epoch 901/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.1603 - val_loss: 31.3625\n",
      "Epoch 902/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.1376 - val_loss: 31.4431\n",
      "Epoch 903/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.1278 - val_loss: 31.4902\n",
      "Epoch 904/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29.1010 - val_loss: 31.2172\n",
      "Epoch 905/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.0783 - val_loss: 31.1380\n",
      "Epoch 906/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.0762 - val_loss: 31.1882\n",
      "Epoch 907/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.0658 - val_loss: 31.1283\n",
      "Epoch 908/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.0514 - val_loss: 31.0591\n",
      "Epoch 909/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.9849 - val_loss: 31.1247\n",
      "Epoch 910/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.0136 - val_loss: 31.2006\n",
      "Epoch 911/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.9778 - val_loss: 31.0680\n",
      "Epoch 912/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.9678 - val_loss: 30.9873\n",
      "Epoch 913/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.9322 - val_loss: 31.0488\n",
      "Epoch 914/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.9110 - val_loss: 30.9644\n",
      "Epoch 915/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.8969 - val_loss: 30.9308\n",
      "Epoch 916/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.8769 - val_loss: 30.8592\n",
      "Epoch 917/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.9793 - val_loss: 30.8755\n",
      "Epoch 918/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.8918 - val_loss: 31.0853\n",
      "Epoch 919/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.8357 - val_loss: 31.0429\n",
      "Epoch 920/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.8256 - val_loss: 31.1018\n",
      "Epoch 921/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.7942 - val_loss: 31.1428\n",
      "Epoch 922/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.7756 - val_loss: 31.0072\n",
      "Epoch 923/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.7584 - val_loss: 30.9495\n",
      "Epoch 924/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.7344 - val_loss: 30.9696\n",
      "Epoch 925/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.7102 - val_loss: 30.8416\n",
      "Epoch 926/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.7214 - val_loss: 30.9291\n",
      "Epoch 927/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.6761 - val_loss: 30.9902\n",
      "Epoch 928/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.6721 - val_loss: 30.8222\n",
      "Epoch 929/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.6307 - val_loss: 30.7575\n",
      "Epoch 930/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.6121 - val_loss: 30.6849\n",
      "Epoch 931/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.6237 - val_loss: 30.8627\n",
      "Epoch 932/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 28.5895 - val_loss: 30.7397\n",
      "Epoch 933/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.6222 - val_loss: 30.6113\n",
      "Epoch 934/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.5778 - val_loss: 30.8470\n",
      "Epoch 935/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.5322 - val_loss: 30.6354\n",
      "Epoch 936/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.5159 - val_loss: 30.7672\n",
      "Epoch 937/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.5058 - val_loss: 30.7963\n",
      "Epoch 938/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.4865 - val_loss: 30.6930\n",
      "Epoch 939/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.4698 - val_loss: 30.5461\n",
      "Epoch 940/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.4371 - val_loss: 30.4278\n",
      "Epoch 941/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.4479 - val_loss: 30.4247\n",
      "Epoch 942/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.4039 - val_loss: 30.5745\n",
      "Epoch 943/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.4028 - val_loss: 30.4167\n",
      "Epoch 944/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.3682 - val_loss: 30.2803\n",
      "Epoch 945/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.3363 - val_loss: 30.2591\n",
      "Epoch 946/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.3397 - val_loss: 30.2238\n",
      "Epoch 947/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.3051 - val_loss: 30.2893\n",
      "Epoch 948/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.2944 - val_loss: 30.2930\n",
      "Epoch 949/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.3001 - val_loss: 30.2864\n",
      "Epoch 950/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.2632 - val_loss: 30.2072\n",
      "Epoch 951/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.2701 - val_loss: 30.2466\n",
      "Epoch 952/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.2532 - val_loss: 30.2300\n",
      "Epoch 953/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.2190 - val_loss: 30.3218\n",
      "Epoch 954/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.1972 - val_loss: 30.1558\n",
      "Epoch 955/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.1645 - val_loss: 30.1302\n",
      "Epoch 956/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.1756 - val_loss: 30.5026\n",
      "Epoch 957/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.1565 - val_loss: 30.2155\n",
      "Epoch 958/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.1203 - val_loss: 30.1520\n",
      "Epoch 959/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.0968 - val_loss: 30.2091\n",
      "Epoch 960/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.1109 - val_loss: 30.2980\n",
      "Epoch 961/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.1226 - val_loss: 30.1503\n",
      "Epoch 962/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.0425 - val_loss: 30.0865\n",
      "Epoch 963/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.0552 - val_loss: 30.1287\n",
      "Epoch 964/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.0109 - val_loss: 30.1608\n",
      "Epoch 965/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27.9873 - val_loss: 29.9854\n",
      "Epoch 966/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.9927 - val_loss: 30.1821\n",
      "Epoch 967/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.9657 - val_loss: 30.2065\n",
      "Epoch 968/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 27.9562 - val_loss: 30.0589\n",
      "Epoch 969/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 27.9267 - val_loss: 30.0349\n",
      "Epoch 970/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 27.9075 - val_loss: 30.0227\n",
      "Epoch 971/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 27.9104 - val_loss: 29.9752\n",
      "Epoch 972/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.9988 - val_loss: 30.0697\n",
      "Epoch 973/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.8905 - val_loss: 30.0331\n",
      "Epoch 974/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.8467 - val_loss: 29.9881\n",
      "Epoch 975/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 27.8156 - val_loss: 29.8780\n",
      "Epoch 976/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 27.8290 - val_loss: 29.6772\n",
      "Epoch 977/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.8028 - val_loss: 29.5611\n",
      "Epoch 978/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 27.7852 - val_loss: 29.6070\n",
      "Epoch 979/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.7883 - val_loss: 29.7896\n",
      "Epoch 980/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27.7297 - val_loss: 29.8958\n",
      "Epoch 981/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 27.7458 - val_loss: 29.8428\n",
      "Epoch 982/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 27.6902 - val_loss: 29.8535\n",
      "Epoch 983/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.6906 - val_loss: 29.6828\n",
      "Epoch 984/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.6578 - val_loss: 29.7845\n",
      "Epoch 985/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.7086 - val_loss: 30.0148\n",
      "Epoch 986/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 27.6243 - val_loss: 29.7865\n",
      "Epoch 987/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 27.6128 - val_loss: 29.6473\n",
      "Epoch 988/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 27.6291 - val_loss: 29.6668\n",
      "Epoch 989/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.6017 - val_loss: 29.6046\n",
      "Epoch 990/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.5571 - val_loss: 29.5783\n",
      "Epoch 991/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.5336 - val_loss: 29.8010\n",
      "Epoch 992/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 27.5565 - val_loss: 29.6100\n",
      "Epoch 993/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.5017 - val_loss: 29.5246\n",
      "Epoch 994/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 27.5107 - val_loss: 29.5407\n",
      "Epoch 995/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.4646 - val_loss: 29.5404\n",
      "Epoch 996/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 27.4651 - val_loss: 29.4469\n",
      "Epoch 997/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 27.4340 - val_loss: 29.5548\n",
      "Epoch 998/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 27.4698 - val_loss: 29.5235\n",
      "Epoch 999/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 27.4214 - val_loss: 29.3753\n",
      "Epoch 1000/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 27.4170 - val_loss: 29.2996\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Test set MSE: 17178606000.0\n",
      "Test set RMSE: 131067.18\n",
      "Test set RMSPE (%): 39.3098284024135\n"
     ]
    }
   ],
   "source": [
    "model = train_model(epochs=1_000, layer_sizes=[100, 100, 100, 100], X_train=X_train_scaled, y_train=y_train_log, X_valid=X_test_scaled, y_valid=y_valid_log, batch_norm=True, l1_l2=True)\n",
    "evaluate_model(model, X_test_scaled, y_test, log_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Load MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Create a more complex DNN model\n",
    "def create_model():\n",
    "    return tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    # # this one was actually slower on GPU, batch size wasn't specified either\n",
    "    # return tf.keras.models.Sequential([\n",
    "    #     tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    #     tf.keras.layers.Dense(128, activation='relu'),\n",
    "    #     tf.keras.layers.Dropout(0.2),\n",
    "    #     tf.keras.layers.Dense(10)\n",
    "    # ])\n",
    "\n",
    "# Train and evaluate the model, returning the time taken\n",
    "def train_and_evaluate(model, x_train, y_train, x_test, y_test):\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # model.fit(x_train, y_train, epochs=5)\n",
    "    model.fit(x_train, y_train, epochs=5, batch_size=512)\n",
    "    end_time = time.time()\n",
    "\n",
    "    model.evaluate(x_test, y_test, verbose=2)\n",
    "    \n",
    "    return end_time - start_time\n",
    "\n",
    "# Check if a GPU is available\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available\")\n",
    "    with tf.device('/GPU:0'):  # train with GPU\n",
    "        model = create_model()\n",
    "        gpu_time = train_and_evaluate(model, x_train, y_train, x_test, y_test)\n",
    "        print(\"Time taken to train with GPU: {:.2f} seconds\".format(gpu_time))\n",
    "        \n",
    "    with tf.device('/CPU:0'):  # train with CPU\n",
    "        model = create_model()\n",
    "        cpu_time = train_and_evaluate(model, x_train, y_train, x_test, y_test)\n",
    "        print(\"Time taken to train with CPU: {:.2f} seconds\".format(cpu_time))\n",
    "        \n",
    "    speed_increase = (cpu_time - gpu_time) / cpu_time * 100\n",
    "    print(\"GPU is {:.2f}% faster than CPU\".format(speed_increase))\n",
    "else:\n",
    "    print(\"GPU not available, training with CPU only\")\n",
    "    model = create_model()\n",
    "    cpu_time = train_and_evaluate(model, x_train, y_train, x_test, y_test)\n",
    "    print(\"Time taken to train with CPU: {:.2f} seconds\".format(cpu_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
