{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgrantbell\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import wandb\n",
    "wandb.login()\n",
    "from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
    "\n",
    "# set seed for reproducibility\n",
    "random_seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP</th>\n",
       "      <th>GDPC1</th>\n",
       "      <th>GDPPOT</th>\n",
       "      <th>CPIAUCSL</th>\n",
       "      <th>CPILFESL</th>\n",
       "      <th>GDPDEF</th>\n",
       "      <th>M1V</th>\n",
       "      <th>M2V</th>\n",
       "      <th>DFF</th>\n",
       "      <th>UNRATE</th>\n",
       "      <th>...</th>\n",
       "      <th>MANEMP</th>\n",
       "      <th>DSPIC96</th>\n",
       "      <th>PCE</th>\n",
       "      <th>PCEDG</th>\n",
       "      <th>PSAVERT</th>\n",
       "      <th>DSPI</th>\n",
       "      <th>INDPRO</th>\n",
       "      <th>HOUST</th>\n",
       "      <th>GPDI</th>\n",
       "      <th>MSPUS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1963-01-01</th>\n",
       "      <td>621.672</td>\n",
       "      <td>3628.306</td>\n",
       "      <td>3662.738125</td>\n",
       "      <td>30.44</td>\n",
       "      <td>31.5</td>\n",
       "      <td>17.134</td>\n",
       "      <td>4.178</td>\n",
       "      <td>1.690</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.7</td>\n",
       "      <td>...</td>\n",
       "      <td>15545.0</td>\n",
       "      <td>2541.1</td>\n",
       "      <td>374.4</td>\n",
       "      <td>53.1</td>\n",
       "      <td>10.9</td>\n",
       "      <td>430.0</td>\n",
       "      <td>26.0448</td>\n",
       "      <td>1244.0</td>\n",
       "      <td>99.689</td>\n",
       "      <td>17800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963-04-01</th>\n",
       "      <td>629.752</td>\n",
       "      <td>3669.020</td>\n",
       "      <td>3701.698767</td>\n",
       "      <td>30.48</td>\n",
       "      <td>31.7</td>\n",
       "      <td>17.164</td>\n",
       "      <td>4.194</td>\n",
       "      <td>1.675</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.7</td>\n",
       "      <td>...</td>\n",
       "      <td>15602.0</td>\n",
       "      <td>2547.1</td>\n",
       "      <td>376.4</td>\n",
       "      <td>53.2</td>\n",
       "      <td>10.7</td>\n",
       "      <td>431.1</td>\n",
       "      <td>26.7473</td>\n",
       "      <td>1689.0</td>\n",
       "      <td>101.650</td>\n",
       "      <td>18000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963-07-01</th>\n",
       "      <td>644.444</td>\n",
       "      <td>3749.681</td>\n",
       "      <td>3741.388301</td>\n",
       "      <td>30.69</td>\n",
       "      <td>31.8</td>\n",
       "      <td>17.187</td>\n",
       "      <td>4.248</td>\n",
       "      <td>1.680</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.6</td>\n",
       "      <td>...</td>\n",
       "      <td>15646.0</td>\n",
       "      <td>2572.6</td>\n",
       "      <td>384.4</td>\n",
       "      <td>55.5</td>\n",
       "      <td>10.1</td>\n",
       "      <td>438.0</td>\n",
       "      <td>27.0445</td>\n",
       "      <td>1614.0</td>\n",
       "      <td>104.612</td>\n",
       "      <td>17900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963-10-01</th>\n",
       "      <td>653.938</td>\n",
       "      <td>3774.264</td>\n",
       "      <td>3781.880559</td>\n",
       "      <td>30.75</td>\n",
       "      <td>32.0</td>\n",
       "      <td>17.326</td>\n",
       "      <td>4.269</td>\n",
       "      <td>1.672</td>\n",
       "      <td>3.50</td>\n",
       "      <td>5.5</td>\n",
       "      <td>...</td>\n",
       "      <td>15714.0</td>\n",
       "      <td>2617.3</td>\n",
       "      <td>386.0</td>\n",
       "      <td>54.2</td>\n",
       "      <td>11.5</td>\n",
       "      <td>447.0</td>\n",
       "      <td>27.5578</td>\n",
       "      <td>1779.0</td>\n",
       "      <td>107.189</td>\n",
       "      <td>18500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964-01-01</th>\n",
       "      <td>669.822</td>\n",
       "      <td>3853.835</td>\n",
       "      <td>3822.450115</td>\n",
       "      <td>30.94</td>\n",
       "      <td>32.2</td>\n",
       "      <td>17.381</td>\n",
       "      <td>4.345</td>\n",
       "      <td>1.685</td>\n",
       "      <td>3.25</td>\n",
       "      <td>5.6</td>\n",
       "      <td>...</td>\n",
       "      <td>15715.0</td>\n",
       "      <td>2652.8</td>\n",
       "      <td>396.8</td>\n",
       "      <td>57.9</td>\n",
       "      <td>10.7</td>\n",
       "      <td>455.3</td>\n",
       "      <td>27.8820</td>\n",
       "      <td>1603.0</td>\n",
       "      <td>110.474</td>\n",
       "      <td>18500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                GDP     GDPC1       GDPPOT  CPIAUCSL  CPILFESL  GDPDEF    M1V  \\\n",
       "Date                                                                            \n",
       "1963-01-01  621.672  3628.306  3662.738125     30.44      31.5  17.134  4.178   \n",
       "1963-04-01  629.752  3669.020  3701.698767     30.48      31.7  17.164  4.194   \n",
       "1963-07-01  644.444  3749.681  3741.388301     30.69      31.8  17.187  4.248   \n",
       "1963-10-01  653.938  3774.264  3781.880559     30.75      32.0  17.326  4.269   \n",
       "1964-01-01  669.822  3853.835  3822.450115     30.94      32.2  17.381  4.345   \n",
       "\n",
       "              M2V   DFF  UNRATE  ...   MANEMP  DSPIC96    PCE  PCEDG  PSAVERT  \\\n",
       "Date                             ...                                            \n",
       "1963-01-01  1.690  3.00     5.7  ...  15545.0   2541.1  374.4   53.1     10.9   \n",
       "1963-04-01  1.675  3.00     5.7  ...  15602.0   2547.1  376.4   53.2     10.7   \n",
       "1963-07-01  1.680  3.00     5.6  ...  15646.0   2572.6  384.4   55.5     10.1   \n",
       "1963-10-01  1.672  3.50     5.5  ...  15714.0   2617.3  386.0   54.2     11.5   \n",
       "1964-01-01  1.685  3.25     5.6  ...  15715.0   2652.8  396.8   57.9     10.7   \n",
       "\n",
       "             DSPI   INDPRO   HOUST     GPDI    MSPUS  \n",
       "Date                                                  \n",
       "1963-01-01  430.0  26.0448  1244.0   99.689  17800.0  \n",
       "1963-04-01  431.1  26.7473  1689.0  101.650  18000.0  \n",
       "1963-07-01  438.0  27.0445  1614.0  104.612  17900.0  \n",
       "1963-10-01  447.0  27.5578  1779.0  107.189  18500.0  \n",
       "1964-01-01  455.3  27.8820  1603.0  110.474  18500.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('fred_230718.csv', index_col='Date', parse_dates=True)\n",
    "df = df.asfreq('QS')\n",
    "earliest_date = '1963-01-01'\n",
    "latest_date = '2021-10-01'\n",
    "# # filter df index to be between earliest_date and latest_date\n",
    "df = df.loc[(df.index >= earliest_date) & (df.index <= latest_date)]\n",
    "df.dropna(axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set target and create, train, validate, and test datasets and then scale and transform them so they will work better with the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'MSPUS'\n",
    "y = df[target]\n",
    "X = df.drop(columns=[target]).shift(1).dropna()\n",
    "y = y.loc[X.index] # Make sure y and X have the same rows after dropna\n",
    "\n",
    "# https://datascience.stackexchange.com/questions/15135/train-test-validation-set-splitting-in-sklearn\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size=0.25, random_state=random_seed)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)  # validation data should also be scaled\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Log-transform the target variable\n",
    "y_train_log = np.log1p(y_train)\n",
    "y_valid_log = np.log1p(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
    "\n",
    "def train_model(X_train, y_train, \n",
    "                X_valid, y_valid,\n",
    "                layer_sizes=[100, 100], \n",
    "                activation=\"relu\", \n",
    "                kernel_initializer=\"he_normal\", \n",
    "                loss='mse',\n",
    "                learning_rate=0.001, \n",
    "                epochs=100,\n",
    "                batch_norm=False,\n",
    "                l1_l2=False,\n",
    "                l1=.01,\n",
    "                l2=.01,\n",
    "                metrics=['mse']):\n",
    "\n",
    "    # Create a sequential model\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # Add batch normalization and dense layers according to the layer_sizes\n",
    "    for size in layer_sizes:\n",
    "        if batch_norm:\n",
    "            model.add(tf.keras.layers.BatchNormalization())\n",
    "        if l1_l2:\n",
    "            model.add(tf.keras.layers.Dense(size, activation=activation, kernel_initializer=kernel_initializer\n",
    "                                            , kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "        else:\n",
    "            model.add(tf.keras.layers.Dense(size, activation=activation, kernel_initializer=kernel_initializer))\n",
    "\n",
    "    # Add a final Dense layer with no activation\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "    # Create the optimizer with the custom learning rate\n",
    "    sgd = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=loss, optimizer=sgd, metrics=metrics)\n",
    "    \n",
    "    # Add WandbMetricsLogger to log metrics and WandbModelCheckpoint to log model checkpoints\n",
    "    wandb_callbacks = [\n",
    "        WandbMetricsLogger(),\n",
    "        # WandbModelCheckpoint(filepath=\"my_model_{epoch:02d}\"),\n",
    "        # WandbModelCheckpoint(filepath=\"my_model_best\", save_best_only=True, monitor='val_loss'),\n",
    "    ]\n",
    "\n",
    "    # Train the model using the scaled data\n",
    "    model.fit(X_train, y_train, epochs=epochs, validation_data=(X_valid, y_valid), callbacks=wandb_callbacks)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: texsheds\n",
      "Sweep URL: https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: avhlos0q with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 490\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_initializer: he_normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1: 0.26001267383913895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_l2: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2: 0.12403897658461828\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.009927344296418127\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: mse\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmetrics: mae\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\grant\\OneDrive\\Desktop\\vscode\\py_fin\\wandb\\run-20230719_171637-avhlos0q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/grantbell/fred_dnn_sweep/runs/avhlos0q' target=\"_blank\">dutiful-sweep-1</a></strong> to <a href='https://wandb.ai/grantbell/fred_dnn_sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/grantbell/fred_dnn_sweep' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/grantbell/fred_dnn_sweep/runs/avhlos0q' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/runs/avhlos0q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/490\n",
      "5/5 [==============================] - 1s 48ms/step - loss: 570.3391 - mae: 8.7908 - val_loss: 469.9981 - val_mae: 3.8360\n",
      "Epoch 2/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 442.3130 - mae: 2.5543 - val_loss: 407.1049 - val_mae: 2.2991\n",
      "Epoch 3/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 388.3901 - mae: 1.4074 - val_loss: 360.2989 - val_mae: 1.7185\n",
      "Epoch 4/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 343.6057 - mae: 1.0487 - val_loss: 320.3231 - val_mae: 1.5308\n",
      "Epoch 5/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 308.1617 - mae: 2.0513 - val_loss: 296.2966 - val_mae: 3.9805\n",
      "Epoch 6/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 275.4482 - mae: 2.6122 - val_loss: 252.0265 - val_mae: 1.7217\n",
      "Epoch 7/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 238.8707 - mae: 1.7510 - val_loss: 220.4049 - val_mae: 2.1397\n",
      "Epoch 8/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 208.5961 - mae: 1.6037 - val_loss: 197.1609 - val_mae: 2.0617\n",
      "Epoch 9/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 182.3044 - mae: 1.4910 - val_loss: 167.7803 - val_mae: 1.9885\n",
      "Epoch 10/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 158.6145 - mae: 1.5265 - val_loss: 156.3586 - val_mae: 2.5896\n",
      "Epoch 11/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 142.9926 - mae: 2.1576 - val_loss: 126.4168 - val_mae: 1.8393\n",
      "Epoch 12/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 118.0751 - mae: 1.1017 - val_loss: 109.1562 - val_mae: 1.3910\n",
      "Epoch 13/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 102.7551 - mae: 1.3761 - val_loss: 99.0053 - val_mae: 2.5120\n",
      "Epoch 14/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 88.1606 - mae: 1.1327 - val_loss: 80.6234 - val_mae: 1.0373\n",
      "Epoch 15/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 76.1563 - mae: 1.2643 - val_loss: 72.1403 - val_mae: 2.1160\n",
      "Epoch 16/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 66.8160 - mae: 1.4031 - val_loss: 60.4353 - val_mae: 1.4593\n",
      "Epoch 17/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 54.8286 - mae: 0.4284 - val_loss: 51.6501 - val_mae: 1.2872\n",
      "Epoch 18/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 47.0381 - mae: 0.3231 - val_loss: 44.5292 - val_mae: 1.2231\n",
      "Epoch 19/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 40.6232 - mae: 0.3229 - val_loss: 39.0991 - val_mae: 1.2147\n",
      "Epoch 20/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 36.0784 - mae: 0.7606 - val_loss: 35.7186 - val_mae: 1.6664\n",
      "Epoch 21/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 31.7990 - mae: 0.8674 - val_loss: 29.9643 - val_mae: 0.9699\n",
      "Epoch 22/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 27.4935 - mae: 0.5556 - val_loss: 27.2525 - val_mae: 1.3337\n",
      "Epoch 23/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 24.3300 - mae: 0.5482 - val_loss: 25.2128 - val_mae: 1.4150\n",
      "Epoch 24/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 21.9998 - mae: 0.6661 - val_loss: 21.7168 - val_mae: 1.2480\n",
      "Epoch 25/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 18.8789 - mae: 0.3101 - val_loss: 19.3863 - val_mae: 1.1740\n",
      "Epoch 26/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 16.6638 - mae: 0.2212 - val_loss: 17.3016 - val_mae: 1.1557\n",
      "Epoch 27/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 14.7329 - mae: 0.1812 - val_loss: 15.5893 - val_mae: 1.1412\n",
      "Epoch 28/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 13.0991 - mae: 0.1894 - val_loss: 14.3667 - val_mae: 1.2510\n",
      "Epoch 29/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 11.7473 - mae: 0.2745 - val_loss: 12.2998 - val_mae: 1.0232\n",
      "Epoch 30/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 10.3581 - mae: 0.1907 - val_loss: 11.1598 - val_mae: 1.0464\n",
      "Epoch 31/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 9.2016 - mae: 0.1886 - val_loss: 10.0517 - val_mae: 1.0144\n",
      "Epoch 32/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 8.2488 - mae: 0.2009 - val_loss: 9.2823 - val_mae: 1.0343\n",
      "Epoch 33/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.4581 - mae: 0.2038 - val_loss: 8.5357 - val_mae: 1.0204\n",
      "Epoch 34/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 6.8066 - mae: 0.2085 - val_loss: 8.0636 - val_mae: 1.0512\n",
      "Epoch 35/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.2844 - mae: 0.2062 - val_loss: 7.6543 - val_mae: 1.0493\n",
      "Epoch 36/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.8614 - mae: 0.2096 - val_loss: 7.0995 - val_mae: 1.0118\n",
      "Epoch 37/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.5106 - mae: 0.2133 - val_loss: 6.8071 - val_mae: 1.0004\n",
      "Epoch 38/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 5.2697 - mae: 0.2102 - val_loss: 6.4436 - val_mae: 0.9549\n",
      "Epoch 39/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 5.0934 - mae: 0.2047 - val_loss: 6.6511 - val_mae: 1.0463\n",
      "Epoch 40/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 5.0072 - mae: 0.2251 - val_loss: 6.2061 - val_mae: 0.9442\n",
      "Epoch 41/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.9148 - mae: 0.2187 - val_loss: 6.0439 - val_mae: 0.8907\n",
      "Epoch 42/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.8735 - mae: 0.2177 - val_loss: 6.0533 - val_mae: 0.9265\n",
      "Epoch 43/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.8320 - mae: 0.2219 - val_loss: 6.0232 - val_mae: 0.9054\n",
      "Epoch 44/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.8160 - mae: 0.2153 - val_loss: 6.1915 - val_mae: 0.9884\n",
      "Epoch 45/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.8029 - mae: 0.2256 - val_loss: 6.0775 - val_mae: 0.9347\n",
      "Epoch 46/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.7807 - mae: 0.2089 - val_loss: 6.0739 - val_mae: 0.9500\n",
      "Epoch 47/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.7717 - mae: 0.2216 - val_loss: 6.0501 - val_mae: 0.9491\n",
      "Epoch 48/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.7526 - mae: 0.2301 - val_loss: 6.0465 - val_mae: 0.9584\n",
      "Epoch 49/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.7350 - mae: 0.2237 - val_loss: 6.1465 - val_mae: 0.9840\n",
      "Epoch 50/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.7233 - mae: 0.2193 - val_loss: 5.9457 - val_mae: 0.9342\n",
      "Epoch 51/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.7088 - mae: 0.2183 - val_loss: 6.0385 - val_mae: 0.9580\n",
      "Epoch 52/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.7042 - mae: 0.2218 - val_loss: 6.0931 - val_mae: 0.9882\n",
      "Epoch 53/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.6870 - mae: 0.2177 - val_loss: 6.0531 - val_mae: 0.9697\n",
      "Epoch 54/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.6818 - mae: 0.2128 - val_loss: 6.1305 - val_mae: 1.0086\n",
      "Epoch 55/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.6662 - mae: 0.1974 - val_loss: 6.0194 - val_mae: 0.9658\n",
      "Epoch 56/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.6705 - mae: 0.2197 - val_loss: 5.9561 - val_mae: 0.9442\n",
      "Epoch 57/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.6622 - mae: 0.2082 - val_loss: 6.0315 - val_mae: 0.9745\n",
      "Epoch 58/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.6366 - mae: 0.1940 - val_loss: 5.9939 - val_mae: 0.9719\n",
      "Epoch 59/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.6236 - mae: 0.1968 - val_loss: 5.9602 - val_mae: 0.9506\n",
      "Epoch 60/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.6259 - mae: 0.1904 - val_loss: 5.9682 - val_mae: 0.9676\n",
      "Epoch 61/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.6119 - mae: 0.1962 - val_loss: 6.0477 - val_mae: 0.9834\n",
      "Epoch 62/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.6008 - mae: 0.1784 - val_loss: 5.9386 - val_mae: 0.9544\n",
      "Epoch 63/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5968 - mae: 0.1784 - val_loss: 6.0019 - val_mae: 0.9685\n",
      "Epoch 64/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5909 - mae: 0.1698 - val_loss: 5.9921 - val_mae: 0.9766\n",
      "Epoch 65/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5887 - mae: 0.1738 - val_loss: 6.1326 - val_mae: 1.0118\n",
      "Epoch 66/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5908 - mae: 0.1675 - val_loss: 5.9934 - val_mae: 0.9781\n",
      "Epoch 67/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5882 - mae: 0.1713 - val_loss: 5.9639 - val_mae: 0.9639\n",
      "Epoch 68/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5920 - mae: 0.1798 - val_loss: 6.0454 - val_mae: 0.9911\n",
      "Epoch 69/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5962 - mae: 0.1735 - val_loss: 5.9807 - val_mae: 0.9733\n",
      "Epoch 70/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5878 - mae: 0.1739 - val_loss: 5.9327 - val_mae: 0.9533\n",
      "Epoch 71/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5913 - mae: 0.1769 - val_loss: 6.0452 - val_mae: 0.9859\n",
      "Epoch 72/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5841 - mae: 0.1641 - val_loss: 6.0260 - val_mae: 0.9841\n",
      "Epoch 73/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5947 - mae: 0.1781 - val_loss: 6.0193 - val_mae: 0.9847\n",
      "Epoch 74/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5931 - mae: 0.1829 - val_loss: 6.1085 - val_mae: 1.0133\n",
      "Epoch 75/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.6075 - mae: 0.1947 - val_loss: 6.0333 - val_mae: 0.9856\n",
      "Epoch 76/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5840 - mae: 0.1710 - val_loss: 5.9947 - val_mae: 0.9728\n",
      "Epoch 77/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5894 - mae: 0.1730 - val_loss: 6.0601 - val_mae: 0.9951\n",
      "Epoch 78/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5810 - mae: 0.1674 - val_loss: 5.9565 - val_mae: 0.9575\n",
      "Epoch 79/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5779 - mae: 0.1573 - val_loss: 6.0377 - val_mae: 0.9862\n",
      "Epoch 80/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5782 - mae: 0.1587 - val_loss: 5.9276 - val_mae: 0.9530\n",
      "Epoch 81/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5793 - mae: 0.1589 - val_loss: 6.1600 - val_mae: 1.0235\n",
      "Epoch 82/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5810 - mae: 0.1626 - val_loss: 6.2024 - val_mae: 1.0380\n",
      "Epoch 83/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5753 - mae: 0.1545 - val_loss: 6.0867 - val_mae: 0.9988\n",
      "Epoch 84/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5789 - mae: 0.1549 - val_loss: 6.0177 - val_mae: 0.9840\n",
      "Epoch 85/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5817 - mae: 0.1723 - val_loss: 6.0349 - val_mae: 0.9793\n",
      "Epoch 86/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5739 - mae: 0.1530 - val_loss: 5.9705 - val_mae: 0.9608\n",
      "Epoch 87/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5747 - mae: 0.1536 - val_loss: 6.0641 - val_mae: 0.9915\n",
      "Epoch 88/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5719 - mae: 0.1535 - val_loss: 6.0725 - val_mae: 0.9985\n",
      "Epoch 89/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5733 - mae: 0.1507 - val_loss: 6.1665 - val_mae: 1.0232\n",
      "Epoch 90/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5735 - mae: 0.1499 - val_loss: 6.1525 - val_mae: 1.0222\n",
      "Epoch 91/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5849 - mae: 0.1750 - val_loss: 6.0707 - val_mae: 0.9936\n",
      "Epoch 92/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5733 - mae: 0.1548 - val_loss: 6.0050 - val_mae: 0.9739\n",
      "Epoch 93/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5703 - mae: 0.1496 - val_loss: 6.0399 - val_mae: 0.9860\n",
      "Epoch 94/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5685 - mae: 0.1481 - val_loss: 6.1401 - val_mae: 1.0192\n",
      "Epoch 95/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5707 - mae: 0.1547 - val_loss: 6.0427 - val_mae: 0.9871\n",
      "Epoch 96/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5753 - mae: 0.1507 - val_loss: 6.1112 - val_mae: 1.0128\n",
      "Epoch 97/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5673 - mae: 0.1527 - val_loss: 6.1142 - val_mae: 1.0093\n",
      "Epoch 98/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5683 - mae: 0.1473 - val_loss: 6.1488 - val_mae: 1.0222\n",
      "Epoch 99/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5667 - mae: 0.1436 - val_loss: 6.0670 - val_mae: 0.9987\n",
      "Epoch 100/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5672 - mae: 0.1504 - val_loss: 6.0712 - val_mae: 0.9967\n",
      "Epoch 101/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5671 - mae: 0.1470 - val_loss: 6.0811 - val_mae: 0.9975\n",
      "Epoch 102/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5654 - mae: 0.1494 - val_loss: 6.0073 - val_mae: 0.9786\n",
      "Epoch 103/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5686 - mae: 0.1509 - val_loss: 6.0667 - val_mae: 0.9913\n",
      "Epoch 104/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5716 - mae: 0.1541 - val_loss: 6.1689 - val_mae: 1.0265\n",
      "Epoch 105/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5674 - mae: 0.1444 - val_loss: 6.0086 - val_mae: 0.9787\n",
      "Epoch 106/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5730 - mae: 0.1633 - val_loss: 5.9656 - val_mae: 0.9674\n",
      "Epoch 107/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5626 - mae: 0.1473 - val_loss: 6.0476 - val_mae: 0.9845\n",
      "Epoch 108/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5666 - mae: 0.1509 - val_loss: 6.0538 - val_mae: 0.9960\n",
      "Epoch 109/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5622 - mae: 0.1454 - val_loss: 5.9785 - val_mae: 0.9617\n",
      "Epoch 110/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5629 - mae: 0.1453 - val_loss: 6.0879 - val_mae: 1.0061\n",
      "Epoch 111/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5619 - mae: 0.1471 - val_loss: 6.0656 - val_mae: 0.9900\n",
      "Epoch 112/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5660 - mae: 0.1479 - val_loss: 5.9892 - val_mae: 0.9730\n",
      "Epoch 113/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5632 - mae: 0.1468 - val_loss: 6.1871 - val_mae: 1.0277\n",
      "Epoch 114/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5780 - mae: 0.1714 - val_loss: 5.9417 - val_mae: 0.9555\n",
      "Epoch 115/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5747 - mae: 0.1566 - val_loss: 6.1510 - val_mae: 1.0176\n",
      "Epoch 116/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5675 - mae: 0.1553 - val_loss: 6.1347 - val_mae: 1.0244\n",
      "Epoch 117/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5609 - mae: 0.1378 - val_loss: 6.0909 - val_mae: 0.9974\n",
      "Epoch 118/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5609 - mae: 0.1417 - val_loss: 6.0147 - val_mae: 0.9856\n",
      "Epoch 119/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5646 - mae: 0.1553 - val_loss: 6.0876 - val_mae: 1.0028\n",
      "Epoch 120/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5676 - mae: 0.1572 - val_loss: 6.0063 - val_mae: 0.9884\n",
      "Epoch 121/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5683 - mae: 0.1609 - val_loss: 6.0588 - val_mae: 0.9905\n",
      "Epoch 122/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5636 - mae: 0.1508 - val_loss: 6.0987 - val_mae: 1.0116\n",
      "Epoch 123/490\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.5617 - mae: 0.1451 - val_loss: 5.9440 - val_mae: 0.9578\n",
      "Epoch 124/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5618 - mae: 0.1493 - val_loss: 5.9759 - val_mae: 0.9737\n",
      "Epoch 125/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5626 - mae: 0.1518 - val_loss: 6.1387 - val_mae: 1.0168\n",
      "Epoch 126/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5773 - mae: 0.1707 - val_loss: 6.0601 - val_mae: 0.9999\n",
      "Epoch 127/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5640 - mae: 0.1564 - val_loss: 6.0761 - val_mae: 0.9961\n",
      "Epoch 128/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5611 - mae: 0.1500 - val_loss: 6.1423 - val_mae: 1.0254\n",
      "Epoch 129/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5538 - mae: 0.1421 - val_loss: 6.0838 - val_mae: 0.9959\n",
      "Epoch 130/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5572 - mae: 0.1350 - val_loss: 6.0198 - val_mae: 0.9881\n",
      "Epoch 131/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5622 - mae: 0.1550 - val_loss: 6.0706 - val_mae: 0.9946\n",
      "Epoch 132/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5560 - mae: 0.1445 - val_loss: 6.2474 - val_mae: 1.0508\n",
      "Epoch 133/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5644 - mae: 0.1498 - val_loss: 6.0673 - val_mae: 0.9887\n",
      "Epoch 134/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5592 - mae: 0.1473 - val_loss: 6.0388 - val_mae: 0.9903\n",
      "Epoch 135/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5576 - mae: 0.1434 - val_loss: 6.0273 - val_mae: 0.9803\n",
      "Epoch 136/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5545 - mae: 0.1398 - val_loss: 6.0583 - val_mae: 1.0029\n",
      "Epoch 137/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5619 - mae: 0.1535 - val_loss: 6.0001 - val_mae: 0.9622\n",
      "Epoch 138/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5585 - mae: 0.1325 - val_loss: 5.9583 - val_mae: 0.9653\n",
      "Epoch 139/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5540 - mae: 0.1468 - val_loss: 6.1587 - val_mae: 1.0208\n",
      "Epoch 140/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5683 - mae: 0.1538 - val_loss: 6.0511 - val_mae: 1.0029\n",
      "Epoch 141/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5640 - mae: 0.1614 - val_loss: 5.9941 - val_mae: 0.9646\n",
      "Epoch 142/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5693 - mae: 0.1635 - val_loss: 6.1869 - val_mae: 1.0380\n",
      "Epoch 143/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5657 - mae: 0.1624 - val_loss: 6.1338 - val_mae: 1.0124\n",
      "Epoch 144/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5565 - mae: 0.1428 - val_loss: 6.0537 - val_mae: 0.9949\n",
      "Epoch 145/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5493 - mae: 0.1333 - val_loss: 6.0260 - val_mae: 0.9788\n",
      "Epoch 146/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5724 - mae: 0.1665 - val_loss: 6.0231 - val_mae: 0.9921\n",
      "Epoch 147/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5503 - mae: 0.1447 - val_loss: 6.0836 - val_mae: 0.9994\n",
      "Epoch 148/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5505 - mae: 0.1351 - val_loss: 6.0050 - val_mae: 0.9827\n",
      "Epoch 149/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5537 - mae: 0.1361 - val_loss: 6.1401 - val_mae: 1.0187\n",
      "Epoch 150/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5585 - mae: 0.1602 - val_loss: 6.1057 - val_mae: 1.0146\n",
      "Epoch 151/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5494 - mae: 0.1343 - val_loss: 6.0783 - val_mae: 0.9961\n",
      "Epoch 152/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5522 - mae: 0.1349 - val_loss: 6.0031 - val_mae: 0.9852\n",
      "Epoch 153/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5464 - mae: 0.1360 - val_loss: 6.1387 - val_mae: 1.0144\n",
      "Epoch 154/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5509 - mae: 0.1342 - val_loss: 6.0026 - val_mae: 0.9819\n",
      "Epoch 155/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5499 - mae: 0.1386 - val_loss: 6.1415 - val_mae: 1.0143\n",
      "Epoch 156/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5523 - mae: 0.1385 - val_loss: 6.2037 - val_mae: 1.0429\n",
      "Epoch 157/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5632 - mae: 0.1629 - val_loss: 6.0953 - val_mae: 0.9985\n",
      "Epoch 158/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5499 - mae: 0.1368 - val_loss: 6.0011 - val_mae: 0.9872\n",
      "Epoch 159/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5512 - mae: 0.1468 - val_loss: 6.1964 - val_mae: 1.0374\n",
      "Epoch 160/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5557 - mae: 0.1402 - val_loss: 6.0767 - val_mae: 1.0110\n",
      "Epoch 161/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5534 - mae: 0.1488 - val_loss: 6.0292 - val_mae: 0.9861\n",
      "Epoch 162/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5492 - mae: 0.1392 - val_loss: 6.0036 - val_mae: 0.9774\n",
      "Epoch 163/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5467 - mae: 0.1406 - val_loss: 6.1834 - val_mae: 1.0268\n",
      "Epoch 164/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5482 - mae: 0.1328 - val_loss: 6.0669 - val_mae: 1.0015\n",
      "Epoch 165/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5457 - mae: 0.1257 - val_loss: 6.1927 - val_mae: 1.0321\n",
      "Epoch 166/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5521 - mae: 0.1383 - val_loss: 5.9929 - val_mae: 0.9757\n",
      "Epoch 167/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5500 - mae: 0.1456 - val_loss: 6.0995 - val_mae: 1.0026\n",
      "Epoch 168/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5628 - mae: 0.1596 - val_loss: 6.0799 - val_mae: 1.0092\n",
      "Epoch 169/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5461 - mae: 0.1355 - val_loss: 6.1308 - val_mae: 1.0151\n",
      "Epoch 170/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5512 - mae: 0.1417 - val_loss: 6.1381 - val_mae: 1.0274\n",
      "Epoch 171/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5516 - mae: 0.1496 - val_loss: 6.0956 - val_mae: 1.0122\n",
      "Epoch 172/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5664 - mae: 0.1710 - val_loss: 6.1309 - val_mae: 1.0254\n",
      "Epoch 173/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5455 - mae: 0.1364 - val_loss: 6.1623 - val_mae: 1.0228\n",
      "Epoch 174/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5459 - mae: 0.1335 - val_loss: 6.1947 - val_mae: 1.0422\n",
      "Epoch 175/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5542 - mae: 0.1529 - val_loss: 6.1374 - val_mae: 1.0155\n",
      "Epoch 176/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5590 - mae: 0.1490 - val_loss: 6.0051 - val_mae: 0.9882\n",
      "Epoch 177/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5413 - mae: 0.1323 - val_loss: 6.1757 - val_mae: 1.0234\n",
      "Epoch 178/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5456 - mae: 0.1293 - val_loss: 5.9313 - val_mae: 0.9587\n",
      "Epoch 179/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5452 - mae: 0.1408 - val_loss: 6.1115 - val_mae: 1.0087\n",
      "Epoch 180/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5459 - mae: 0.1351 - val_loss: 6.2350 - val_mae: 1.0527\n",
      "Epoch 181/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5454 - mae: 0.1380 - val_loss: 6.0936 - val_mae: 1.0036\n",
      "Epoch 182/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5465 - mae: 0.1368 - val_loss: 6.1340 - val_mae: 1.0212\n",
      "Epoch 183/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5410 - mae: 0.1266 - val_loss: 6.1404 - val_mae: 1.0155\n",
      "Epoch 184/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5426 - mae: 0.1281 - val_loss: 6.1378 - val_mae: 1.0220\n",
      "Epoch 185/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5403 - mae: 0.1266 - val_loss: 6.0877 - val_mae: 1.0015\n",
      "Epoch 186/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5505 - mae: 0.1446 - val_loss: 6.1158 - val_mae: 1.0142\n",
      "Epoch 187/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5524 - mae: 0.1486 - val_loss: 6.2647 - val_mae: 1.0553\n",
      "Epoch 188/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5497 - mae: 0.1441 - val_loss: 6.0847 - val_mae: 1.0063\n",
      "Epoch 189/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5428 - mae: 0.1349 - val_loss: 6.0551 - val_mae: 0.9874\n",
      "Epoch 190/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5421 - mae: 0.1286 - val_loss: 5.9604 - val_mae: 0.9635\n",
      "Epoch 191/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5431 - mae: 0.1377 - val_loss: 6.0321 - val_mae: 0.9835\n",
      "Epoch 192/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5424 - mae: 0.1298 - val_loss: 6.1628 - val_mae: 1.0298\n",
      "Epoch 193/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5403 - mae: 0.1268 - val_loss: 6.0989 - val_mae: 1.0148\n",
      "Epoch 194/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5637 - mae: 0.1746 - val_loss: 6.0145 - val_mae: 0.9818\n",
      "Epoch 195/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5469 - mae: 0.1404 - val_loss: 6.1426 - val_mae: 1.0203\n",
      "Epoch 196/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5410 - mae: 0.1271 - val_loss: 6.0681 - val_mae: 0.9995\n",
      "Epoch 197/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5398 - mae: 0.1272 - val_loss: 6.1040 - val_mae: 1.0089\n",
      "Epoch 198/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5395 - mae: 0.1303 - val_loss: 6.0848 - val_mae: 1.0089\n",
      "Epoch 199/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5400 - mae: 0.1295 - val_loss: 6.2351 - val_mae: 1.0460\n",
      "Epoch 200/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5459 - mae: 0.1404 - val_loss: 5.9775 - val_mae: 0.9671\n",
      "Epoch 201/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5552 - mae: 0.1602 - val_loss: 6.0118 - val_mae: 0.9869\n",
      "Epoch 202/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5402 - mae: 0.1369 - val_loss: 6.0212 - val_mae: 0.9879\n",
      "Epoch 203/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5453 - mae: 0.1399 - val_loss: 6.0395 - val_mae: 0.9830\n",
      "Epoch 204/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5452 - mae: 0.1361 - val_loss: 6.1475 - val_mae: 1.0251\n",
      "Epoch 205/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5367 - mae: 0.1226 - val_loss: 6.1940 - val_mae: 1.0329\n",
      "Epoch 206/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5402 - mae: 0.1278 - val_loss: 6.1176 - val_mae: 1.0192\n",
      "Epoch 207/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5489 - mae: 0.1512 - val_loss: 6.1122 - val_mae: 1.0100\n",
      "Epoch 208/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5459 - mae: 0.1350 - val_loss: 5.9862 - val_mae: 0.9807\n",
      "Epoch 209/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5405 - mae: 0.1371 - val_loss: 6.2104 - val_mae: 1.0423\n",
      "Epoch 210/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5681 - mae: 0.1762 - val_loss: 6.0282 - val_mae: 0.9825\n",
      "Epoch 211/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5387 - mae: 0.1303 - val_loss: 5.9784 - val_mae: 0.9731\n",
      "Epoch 212/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5397 - mae: 0.1347 - val_loss: 6.0660 - val_mae: 1.0014\n",
      "Epoch 213/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5683 - mae: 0.1772 - val_loss: 6.1433 - val_mae: 1.0267\n",
      "Epoch 214/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5553 - mae: 0.1630 - val_loss: 6.1105 - val_mae: 1.0137\n",
      "Epoch 215/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5507 - mae: 0.1496 - val_loss: 6.1797 - val_mae: 1.0353\n",
      "Epoch 216/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5618 - mae: 0.1810 - val_loss: 6.1292 - val_mae: 1.0185\n",
      "Epoch 217/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5478 - mae: 0.1433 - val_loss: 6.1807 - val_mae: 1.0350\n",
      "Epoch 218/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5566 - mae: 0.1615 - val_loss: 5.9750 - val_mae: 0.9664\n",
      "Epoch 219/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5625 - mae: 0.1685 - val_loss: 6.1560 - val_mae: 1.0253\n",
      "Epoch 220/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5475 - mae: 0.1492 - val_loss: 6.0216 - val_mae: 0.9869\n",
      "Epoch 221/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5570 - mae: 0.1655 - val_loss: 6.1699 - val_mae: 1.0315\n",
      "Epoch 222/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5511 - mae: 0.1515 - val_loss: 6.0556 - val_mae: 1.0011\n",
      "Epoch 223/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5634 - mae: 0.1730 - val_loss: 6.0776 - val_mae: 1.0060\n",
      "Epoch 224/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5587 - mae: 0.1717 - val_loss: 6.0013 - val_mae: 0.9802\n",
      "Epoch 225/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5480 - mae: 0.1536 - val_loss: 6.1895 - val_mae: 1.0374\n",
      "Epoch 226/490\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.5666 - mae: 0.1835 - val_loss: 6.0586 - val_mae: 1.0006\n",
      "Epoch 227/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5617 - mae: 0.1789 - val_loss: 6.2977 - val_mae: 1.0640\n",
      "Epoch 228/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5673 - mae: 0.1765 - val_loss: 6.2095 - val_mae: 1.0494\n",
      "Epoch 229/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5361 - mae: 0.1264 - val_loss: 6.3375 - val_mae: 1.0703\n",
      "Epoch 230/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5608 - mae: 0.1635 - val_loss: 6.1859 - val_mae: 1.0442\n",
      "Epoch 231/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5396 - mae: 0.1297 - val_loss: 6.0801 - val_mae: 0.9978\n",
      "Epoch 232/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5358 - mae: 0.1274 - val_loss: 6.2051 - val_mae: 1.0464\n",
      "Epoch 233/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5326 - mae: 0.1254 - val_loss: 6.3025 - val_mae: 1.0629\n",
      "Epoch 234/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5425 - mae: 0.1262 - val_loss: 6.0507 - val_mae: 0.9979\n",
      "Epoch 235/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5321 - mae: 0.1251 - val_loss: 6.2010 - val_mae: 1.0344\n",
      "Epoch 236/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5367 - mae: 0.1257 - val_loss: 6.0724 - val_mae: 1.0081\n",
      "Epoch 237/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5346 - mae: 0.1321 - val_loss: 6.0560 - val_mae: 0.9923\n",
      "Epoch 238/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5512 - mae: 0.1592 - val_loss: 6.1445 - val_mae: 1.0312\n",
      "Epoch 239/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5362 - mae: 0.1389 - val_loss: 6.1008 - val_mae: 1.0055\n",
      "Epoch 240/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5360 - mae: 0.1309 - val_loss: 6.0557 - val_mae: 1.0000\n",
      "Epoch 241/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5325 - mae: 0.1301 - val_loss: 6.0767 - val_mae: 0.9969\n",
      "Epoch 242/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5332 - mae: 0.1256 - val_loss: 6.1197 - val_mae: 1.0211\n",
      "Epoch 243/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5322 - mae: 0.1283 - val_loss: 6.2120 - val_mae: 1.0394\n",
      "Epoch 244/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5398 - mae: 0.1359 - val_loss: 6.0525 - val_mae: 0.9978\n",
      "Epoch 245/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5555 - mae: 0.1749 - val_loss: 6.1253 - val_mae: 1.0145\n",
      "Epoch 246/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5336 - mae: 0.1264 - val_loss: 6.1116 - val_mae: 1.0171\n",
      "Epoch 247/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5320 - mae: 0.1216 - val_loss: 6.2111 - val_mae: 1.0396\n",
      "Epoch 248/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5571 - mae: 0.1669 - val_loss: 6.2850 - val_mae: 1.0722\n",
      "Epoch 249/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5331 - mae: 0.1185 - val_loss: 6.0673 - val_mae: 0.9933\n",
      "Epoch 250/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5417 - mae: 0.1385 - val_loss: 6.0738 - val_mae: 1.0108\n",
      "Epoch 251/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5330 - mae: 0.1338 - val_loss: 6.1204 - val_mae: 1.0105\n",
      "Epoch 252/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5382 - mae: 0.1324 - val_loss: 6.0849 - val_mae: 1.0136\n",
      "Epoch 253/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5505 - mae: 0.1640 - val_loss: 6.2056 - val_mae: 1.0425\n",
      "Epoch 254/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5486 - mae: 0.1544 - val_loss: 6.1901 - val_mae: 1.0396\n",
      "Epoch 255/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5305 - mae: 0.1244 - val_loss: 6.1366 - val_mae: 1.0123\n",
      "Epoch 256/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5345 - mae: 0.1266 - val_loss: 6.0208 - val_mae: 0.9969\n",
      "Epoch 257/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5306 - mae: 0.1322 - val_loss: 6.0010 - val_mae: 0.9692\n",
      "Epoch 258/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5610 - mae: 0.1732 - val_loss: 5.9974 - val_mae: 0.9927\n",
      "Epoch 259/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5558 - mae: 0.1801 - val_loss: 6.0715 - val_mae: 0.9924\n",
      "Epoch 260/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5590 - mae: 0.1673 - val_loss: 5.9920 - val_mae: 0.9893\n",
      "Epoch 261/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5561 - mae: 0.1774 - val_loss: 6.1216 - val_mae: 1.0140\n",
      "Epoch 262/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5530 - mae: 0.1621 - val_loss: 6.0511 - val_mae: 1.0045\n",
      "Epoch 263/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5307 - mae: 0.1368 - val_loss: 6.2411 - val_mae: 1.0547\n",
      "Epoch 264/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5304 - mae: 0.1169 - val_loss: 6.1305 - val_mae: 1.0271\n",
      "Epoch 265/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5440 - mae: 0.1517 - val_loss: 6.1073 - val_mae: 1.0111\n",
      "Epoch 266/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5792 - mae: 0.2059 - val_loss: 6.2350 - val_mae: 1.0528\n",
      "Epoch 267/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5409 - mae: 0.1448 - val_loss: 6.2230 - val_mae: 1.0429\n",
      "Epoch 268/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5299 - mae: 0.1193 - val_loss: 6.1068 - val_mae: 1.0112\n",
      "Epoch 269/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5296 - mae: 0.1241 - val_loss: 6.2165 - val_mae: 1.0403\n",
      "Epoch 270/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5368 - mae: 0.1342 - val_loss: 6.0110 - val_mae: 0.9887\n",
      "Epoch 271/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5274 - mae: 0.1352 - val_loss: 6.0776 - val_mae: 1.0000\n",
      "Epoch 272/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5283 - mae: 0.1252 - val_loss: 6.1203 - val_mae: 1.0181\n",
      "Epoch 273/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5276 - mae: 0.1173 - val_loss: 5.9681 - val_mae: 0.9622\n",
      "Epoch 274/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5552 - mae: 0.1694 - val_loss: 6.1188 - val_mae: 1.0253\n",
      "Epoch 275/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5375 - mae: 0.1447 - val_loss: 6.0207 - val_mae: 0.9877\n",
      "Epoch 276/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5282 - mae: 0.1317 - val_loss: 6.2012 - val_mae: 1.0418\n",
      "Epoch 277/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5489 - mae: 0.1556 - val_loss: 6.1700 - val_mae: 1.0269\n",
      "Epoch 278/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5302 - mae: 0.1235 - val_loss: 6.0759 - val_mae: 1.0056\n",
      "Epoch 279/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5254 - mae: 0.1213 - val_loss: 6.1099 - val_mae: 1.0087\n",
      "Epoch 280/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5284 - mae: 0.1164 - val_loss: 6.0358 - val_mae: 0.9926\n",
      "Epoch 281/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5437 - mae: 0.1552 - val_loss: 6.1254 - val_mae: 1.0195\n",
      "Epoch 282/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5330 - mae: 0.1388 - val_loss: 6.0896 - val_mae: 1.0127\n",
      "Epoch 283/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5446 - mae: 0.1517 - val_loss: 6.0481 - val_mae: 1.0014\n",
      "Epoch 284/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5466 - mae: 0.1700 - val_loss: 6.1470 - val_mae: 1.0284\n",
      "Epoch 285/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5320 - mae: 0.1319 - val_loss: 6.1323 - val_mae: 1.0246\n",
      "Epoch 286/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5397 - mae: 0.1537 - val_loss: 6.0728 - val_mae: 1.0071\n",
      "Epoch 287/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5412 - mae: 0.1489 - val_loss: 6.1431 - val_mae: 1.0290\n",
      "Epoch 288/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5391 - mae: 0.1457 - val_loss: 6.1769 - val_mae: 1.0399\n",
      "Epoch 289/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5282 - mae: 0.1272 - val_loss: 6.1225 - val_mae: 1.0150\n",
      "Epoch 290/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5269 - mae: 0.1172 - val_loss: 6.1776 - val_mae: 1.0382\n",
      "Epoch 291/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5258 - mae: 0.1173 - val_loss: 6.0878 - val_mae: 1.0015\n",
      "Epoch 292/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5320 - mae: 0.1320 - val_loss: 6.0253 - val_mae: 1.0010\n",
      "Epoch 293/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5264 - mae: 0.1379 - val_loss: 6.1524 - val_mae: 1.0274\n",
      "Epoch 294/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5295 - mae: 0.1326 - val_loss: 6.1571 - val_mae: 1.0299\n",
      "Epoch 295/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5234 - mae: 0.1189 - val_loss: 6.0652 - val_mae: 0.9976\n",
      "Epoch 296/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5284 - mae: 0.1252 - val_loss: 6.0746 - val_mae: 1.0122\n",
      "Epoch 297/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5286 - mae: 0.1390 - val_loss: 6.0537 - val_mae: 0.9920\n",
      "Epoch 298/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5413 - mae: 0.1522 - val_loss: 6.0392 - val_mae: 0.9999\n",
      "Epoch 299/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5228 - mae: 0.1272 - val_loss: 6.0488 - val_mae: 0.9890\n",
      "Epoch 300/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5363 - mae: 0.1474 - val_loss: 6.1346 - val_mae: 1.0299\n",
      "Epoch 301/490\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.5256 - mae: 0.1298 - val_loss: 6.0047 - val_mae: 0.9731\n",
      "Epoch 302/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5421 - mae: 0.1485 - val_loss: 5.9820 - val_mae: 0.9891\n",
      "Epoch 303/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5381 - mae: 0.1630 - val_loss: 6.1108 - val_mae: 1.0066\n",
      "Epoch 304/490\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.5264 - mae: 0.1225 - val_loss: 6.0515 - val_mae: 0.9984\n",
      "Epoch 305/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5226 - mae: 0.1224 - val_loss: 6.2035 - val_mae: 1.0347\n",
      "Epoch 306/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5249 - mae: 0.1208 - val_loss: 6.1352 - val_mae: 1.0248\n",
      "Epoch 307/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5257 - mae: 0.1272 - val_loss: 6.1387 - val_mae: 1.0165\n",
      "Epoch 308/490\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.5277 - mae: 0.1260 - val_loss: 6.0633 - val_mae: 1.0019\n",
      "Epoch 309/490\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.5451 - mae: 0.1630 - val_loss: 6.1826 - val_mae: 1.0380\n",
      "Epoch 310/490\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.5273 - mae: 0.1316 - val_loss: 6.0102 - val_mae: 0.9873\n",
      "Epoch 311/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5253 - mae: 0.1290 - val_loss: 6.1270 - val_mae: 1.0149\n",
      "Epoch 312/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5239 - mae: 0.1221 - val_loss: 6.1075 - val_mae: 1.0163\n",
      "Epoch 313/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5246 - mae: 0.1276 - val_loss: 6.1923 - val_mae: 1.0353\n",
      "Epoch 314/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5319 - mae: 0.1292 - val_loss: 6.0096 - val_mae: 0.9853\n",
      "Epoch 315/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5242 - mae: 0.1277 - val_loss: 6.1214 - val_mae: 1.0151\n",
      "Epoch 316/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5273 - mae: 0.1270 - val_loss: 6.0601 - val_mae: 1.0033\n",
      "Epoch 317/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5396 - mae: 0.1616 - val_loss: 6.4607 - val_mae: 1.1063\n",
      "Epoch 318/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5589 - mae: 0.1650 - val_loss: 6.0703 - val_mae: 1.0095\n",
      "Epoch 319/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5196 - mae: 0.1248 - val_loss: 6.0608 - val_mae: 0.9956\n",
      "Epoch 320/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5226 - mae: 0.1208 - val_loss: 6.1542 - val_mae: 1.0350\n",
      "Epoch 321/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5232 - mae: 0.1267 - val_loss: 6.1673 - val_mae: 1.0323\n",
      "Epoch 322/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5255 - mae: 0.1259 - val_loss: 6.1572 - val_mae: 1.0322\n",
      "Epoch 323/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5241 - mae: 0.1239 - val_loss: 6.1603 - val_mae: 1.0309\n",
      "Epoch 324/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5262 - mae: 0.1279 - val_loss: 6.0044 - val_mae: 0.9861\n",
      "Epoch 325/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5205 - mae: 0.1207 - val_loss: 6.1786 - val_mae: 1.0327\n",
      "Epoch 326/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5225 - mae: 0.1246 - val_loss: 6.0451 - val_mae: 0.9987\n",
      "Epoch 327/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5462 - mae: 0.1596 - val_loss: 6.1824 - val_mae: 1.0382\n",
      "Epoch 328/490\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.5358 - mae: 0.1509 - val_loss: 6.2139 - val_mae: 1.0550\n",
      "Epoch 329/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5320 - mae: 0.1335 - val_loss: 5.9978 - val_mae: 0.9841\n",
      "Epoch 330/490\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.5220 - mae: 0.1331 - val_loss: 6.1193 - val_mae: 1.0173\n",
      "Epoch 331/490\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.5257 - mae: 0.1273 - val_loss: 6.0696 - val_mae: 1.0096\n",
      "Epoch 332/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5334 - mae: 0.1512 - val_loss: 6.0198 - val_mae: 0.9864\n",
      "Epoch 333/490\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.5425 - mae: 0.1590 - val_loss: 6.3025 - val_mae: 1.0694\n",
      "Epoch 334/490\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.5294 - mae: 0.1365 - val_loss: 6.1805 - val_mae: 1.0423\n",
      "Epoch 335/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5456 - mae: 0.1528 - val_loss: 6.2376 - val_mae: 1.0526\n",
      "Epoch 336/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5413 - mae: 0.1532 - val_loss: 6.0763 - val_mae: 1.0002\n",
      "Epoch 337/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5450 - mae: 0.1614 - val_loss: 6.1435 - val_mae: 1.0363\n",
      "Epoch 338/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5450 - mae: 0.1715 - val_loss: 6.1754 - val_mae: 1.0363\n",
      "Epoch 339/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5494 - mae: 0.1698 - val_loss: 6.2187 - val_mae: 1.0557\n",
      "Epoch 340/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5443 - mae: 0.1716 - val_loss: 6.0906 - val_mae: 1.0065\n",
      "Epoch 341/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5294 - mae: 0.1395 - val_loss: 6.1346 - val_mae: 1.0320\n",
      "Epoch 342/490\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.5431 - mae: 0.1727 - val_loss: 6.0120 - val_mae: 0.9769\n",
      "Epoch 343/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5333 - mae: 0.1537 - val_loss: 6.1862 - val_mae: 1.0442\n",
      "Epoch 344/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5473 - mae: 0.1757 - val_loss: 6.0317 - val_mae: 0.9870\n",
      "Epoch 345/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5656 - mae: 0.1976 - val_loss: 6.0621 - val_mae: 1.0065\n",
      "Epoch 346/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5269 - mae: 0.1422 - val_loss: 6.0854 - val_mae: 1.0068\n",
      "Epoch 347/490\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.5722 - mae: 0.2099 - val_loss: 6.1850 - val_mae: 1.0458\n",
      "Epoch 348/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5259 - mae: 0.1356 - val_loss: 6.1329 - val_mae: 1.0186\n",
      "Epoch 349/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5187 - mae: 0.1208 - val_loss: 6.2082 - val_mae: 1.0514\n",
      "Epoch 350/490\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.5214 - mae: 0.1177 - val_loss: 6.1664 - val_mae: 1.0316\n",
      "Epoch 351/490\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.5203 - mae: 0.1226 - val_loss: 6.1643 - val_mae: 1.0355\n",
      "Epoch 352/490\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.5199 - mae: 0.1272 - val_loss: 6.1742 - val_mae: 1.0346\n",
      "Epoch 353/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5291 - mae: 0.1399 - val_loss: 6.1748 - val_mae: 1.0436\n",
      "Epoch 354/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5397 - mae: 0.1709 - val_loss: 6.2691 - val_mae: 1.0741\n",
      "Epoch 355/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5740 - mae: 0.2139 - val_loss: 6.0902 - val_mae: 1.0184\n",
      "Epoch 356/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5248 - mae: 0.1392 - val_loss: 6.1545 - val_mae: 1.0300\n",
      "Epoch 357/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5489 - mae: 0.1753 - val_loss: 6.2675 - val_mae: 1.0640\n",
      "Epoch 358/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5438 - mae: 0.1579 - val_loss: 5.9685 - val_mae: 0.9647\n",
      "Epoch 359/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5436 - mae: 0.1704 - val_loss: 6.2175 - val_mae: 1.0526\n",
      "Epoch 360/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5492 - mae: 0.1796 - val_loss: 6.0400 - val_mae: 0.9886\n",
      "Epoch 361/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5464 - mae: 0.1670 - val_loss: 6.0542 - val_mae: 1.0098\n",
      "Epoch 362/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5459 - mae: 0.1771 - val_loss: 6.1345 - val_mae: 1.0250\n",
      "Epoch 363/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5433 - mae: 0.1531 - val_loss: 6.1124 - val_mae: 1.0227\n",
      "Epoch 364/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5199 - mae: 0.1361 - val_loss: 6.0489 - val_mae: 0.9989\n",
      "Epoch 365/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5174 - mae: 0.1244 - val_loss: 6.1466 - val_mae: 1.0287\n",
      "Epoch 366/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5209 - mae: 0.1285 - val_loss: 6.0090 - val_mae: 0.9852\n",
      "Epoch 367/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5299 - mae: 0.1431 - val_loss: 6.1160 - val_mae: 1.0264\n",
      "Epoch 368/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5393 - mae: 0.1700 - val_loss: 6.0219 - val_mae: 0.9836\n",
      "Epoch 369/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5410 - mae: 0.1587 - val_loss: 6.1511 - val_mae: 1.0337\n",
      "Epoch 370/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5341 - mae: 0.1539 - val_loss: 6.0184 - val_mae: 0.9867\n",
      "Epoch 371/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5237 - mae: 0.1358 - val_loss: 6.0773 - val_mae: 1.0097\n",
      "Epoch 372/490\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.5160 - mae: 0.1255 - val_loss: 6.0572 - val_mae: 0.9981\n",
      "Epoch 373/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5309 - mae: 0.1442 - val_loss: 6.1619 - val_mae: 1.0367\n",
      "Epoch 374/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5246 - mae: 0.1384 - val_loss: 6.2111 - val_mae: 1.0458\n",
      "Epoch 375/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5152 - mae: 0.1148 - val_loss: 6.0973 - val_mae: 1.0081\n",
      "Epoch 376/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5191 - mae: 0.1229 - val_loss: 6.0773 - val_mae: 1.0044\n",
      "Epoch 377/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5400 - mae: 0.1610 - val_loss: 6.0908 - val_mae: 1.0179\n",
      "Epoch 378/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5561 - mae: 0.1914 - val_loss: 5.9830 - val_mae: 0.9784\n",
      "Epoch 379/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5149 - mae: 0.1262 - val_loss: 6.1335 - val_mae: 1.0174\n",
      "Epoch 380/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5186 - mae: 0.1245 - val_loss: 6.2231 - val_mae: 1.0599\n",
      "Epoch 381/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5146 - mae: 0.1134 - val_loss: 6.1868 - val_mae: 1.0332\n",
      "Epoch 382/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5160 - mae: 0.1203 - val_loss: 6.2281 - val_mae: 1.0608\n",
      "Epoch 383/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5204 - mae: 0.1277 - val_loss: 6.3231 - val_mae: 1.0711\n",
      "Epoch 384/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5285 - mae: 0.1370 - val_loss: 6.0804 - val_mae: 1.0123\n",
      "Epoch 385/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5120 - mae: 0.1214 - val_loss: 6.1910 - val_mae: 1.0331\n",
      "Epoch 386/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5156 - mae: 0.1130 - val_loss: 6.0851 - val_mae: 1.0164\n",
      "Epoch 387/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5195 - mae: 0.1325 - val_loss: 6.0084 - val_mae: 0.9890\n",
      "Epoch 388/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5278 - mae: 0.1451 - val_loss: 5.9173 - val_mae: 0.9594\n",
      "Epoch 389/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5564 - mae: 0.2033 - val_loss: 6.2688 - val_mae: 1.0570\n",
      "Epoch 390/490\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.5574 - mae: 0.1887 - val_loss: 6.1389 - val_mae: 1.0349\n",
      "Epoch 391/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5319 - mae: 0.1531 - val_loss: 5.9713 - val_mae: 0.9677\n",
      "Epoch 392/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5167 - mae: 0.1287 - val_loss: 6.1015 - val_mae: 1.0226\n",
      "Epoch 393/490\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.5181 - mae: 0.1288 - val_loss: 6.0425 - val_mae: 0.9951\n",
      "Epoch 394/490\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.5173 - mae: 0.1335 - val_loss: 6.0462 - val_mae: 1.0021\n",
      "Epoch 395/490\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.5217 - mae: 0.1449 - val_loss: 6.3008 - val_mae: 1.0666\n",
      "Epoch 396/490\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.5522 - mae: 0.1807 - val_loss: 5.9941 - val_mae: 0.9882\n",
      "Epoch 397/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5248 - mae: 0.1501 - val_loss: 6.1970 - val_mae: 1.0370\n",
      "Epoch 398/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5190 - mae: 0.1238 - val_loss: 5.9977 - val_mae: 0.9912\n",
      "Epoch 399/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5108 - mae: 0.1229 - val_loss: 6.2602 - val_mae: 1.0501\n",
      "Epoch 400/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5219 - mae: 0.1284 - val_loss: 6.1700 - val_mae: 1.0491\n",
      "Epoch 401/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5136 - mae: 0.1276 - val_loss: 6.1725 - val_mae: 1.0246\n",
      "Epoch 402/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5225 - mae: 0.1225 - val_loss: 6.0382 - val_mae: 1.0056\n",
      "Epoch 403/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5082 - mae: 0.1175 - val_loss: 6.1172 - val_mae: 1.0121\n",
      "Epoch 404/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5184 - mae: 0.1287 - val_loss: 6.0611 - val_mae: 1.0161\n",
      "Epoch 405/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5093 - mae: 0.1235 - val_loss: 6.2083 - val_mae: 1.0354\n",
      "Epoch 406/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5164 - mae: 0.1203 - val_loss: 6.0690 - val_mae: 1.0151\n",
      "Epoch 407/490\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.5099 - mae: 0.1240 - val_loss: 6.1796 - val_mae: 1.0276\n",
      "Epoch 408/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5170 - mae: 0.1202 - val_loss: 6.1705 - val_mae: 1.0496\n",
      "Epoch 409/490\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.5164 - mae: 0.1274 - val_loss: 6.1305 - val_mae: 1.0152\n",
      "Epoch 410/490\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.5336 - mae: 0.1591 - val_loss: 6.0798 - val_mae: 1.0251\n",
      "Epoch 411/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5207 - mae: 0.1462 - val_loss: 6.0335 - val_mae: 0.9840\n",
      "Epoch 412/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5208 - mae: 0.1397 - val_loss: 6.1149 - val_mae: 1.0281\n",
      "Epoch 413/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5091 - mae: 0.1160 - val_loss: 6.1982 - val_mae: 1.0356\n",
      "Epoch 414/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5147 - mae: 0.1201 - val_loss: 6.1038 - val_mae: 1.0239\n",
      "Epoch 415/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5098 - mae: 0.1206 - val_loss: 6.1315 - val_mae: 1.0145\n",
      "Epoch 416/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5140 - mae: 0.1197 - val_loss: 6.0482 - val_mae: 1.0070\n",
      "Epoch 417/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5098 - mae: 0.1256 - val_loss: 6.1786 - val_mae: 1.0327\n",
      "Epoch 418/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5175 - mae: 0.1279 - val_loss: 6.0141 - val_mae: 1.0003\n",
      "Epoch 419/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5192 - mae: 0.1412 - val_loss: 5.9433 - val_mae: 0.9493\n",
      "Epoch 420/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5330 - mae: 0.1555 - val_loss: 6.2491 - val_mae: 1.0626\n",
      "Epoch 421/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5115 - mae: 0.1187 - val_loss: 6.0508 - val_mae: 0.9870\n",
      "Epoch 422/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5162 - mae: 0.1244 - val_loss: 6.0335 - val_mae: 1.0052\n",
      "Epoch 423/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5094 - mae: 0.1250 - val_loss: 6.0203 - val_mae: 0.9864\n",
      "Epoch 424/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5183 - mae: 0.1279 - val_loss: 5.9374 - val_mae: 0.9788\n",
      "Epoch 425/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5152 - mae: 0.1373 - val_loss: 6.1591 - val_mae: 1.0309\n",
      "Epoch 426/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5178 - mae: 0.1373 - val_loss: 6.0050 - val_mae: 0.9956\n",
      "Epoch 427/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5072 - mae: 0.1209 - val_loss: 6.1252 - val_mae: 1.0150\n",
      "Epoch 428/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5133 - mae: 0.1164 - val_loss: 6.0899 - val_mae: 1.0194\n",
      "Epoch 429/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5093 - mae: 0.1178 - val_loss: 6.0145 - val_mae: 0.9888\n",
      "Epoch 430/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5144 - mae: 0.1290 - val_loss: 6.1904 - val_mae: 1.0459\n",
      "Epoch 431/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5230 - mae: 0.1357 - val_loss: 6.0631 - val_mae: 1.0028\n",
      "Epoch 432/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5198 - mae: 0.1401 - val_loss: 6.0882 - val_mae: 1.0181\n",
      "Epoch 433/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5446 - mae: 0.1819 - val_loss: 6.1630 - val_mae: 1.0387\n",
      "Epoch 434/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5714 - mae: 0.2274 - val_loss: 6.0942 - val_mae: 1.0190\n",
      "Epoch 435/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5302 - mae: 0.1564 - val_loss: 6.2370 - val_mae: 1.0569\n",
      "Epoch 436/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5439 - mae: 0.1789 - val_loss: 6.1744 - val_mae: 1.0469\n",
      "Epoch 437/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5180 - mae: 0.1339 - val_loss: 6.1874 - val_mae: 1.0412\n",
      "Epoch 438/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5327 - mae: 0.1612 - val_loss: 6.0969 - val_mae: 1.0141\n",
      "Epoch 439/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5146 - mae: 0.1341 - val_loss: 6.1409 - val_mae: 1.0234\n",
      "Epoch 440/490\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.5132 - mae: 0.1283 - val_loss: 6.0490 - val_mae: 1.0014\n",
      "Epoch 441/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5123 - mae: 0.1286 - val_loss: 6.0394 - val_mae: 0.9994\n",
      "Epoch 442/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5166 - mae: 0.1408 - val_loss: 6.2268 - val_mae: 1.0617\n",
      "Epoch 443/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5183 - mae: 0.1279 - val_loss: 6.1716 - val_mae: 1.0354\n",
      "Epoch 444/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5182 - mae: 0.1360 - val_loss: 6.0837 - val_mae: 1.0144\n",
      "Epoch 445/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5333 - mae: 0.1712 - val_loss: 6.1939 - val_mae: 1.0419\n",
      "Epoch 446/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5140 - mae: 0.1284 - val_loss: 6.0523 - val_mae: 1.0049\n",
      "Epoch 447/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5136 - mae: 0.1284 - val_loss: 6.0131 - val_mae: 0.9836\n",
      "Epoch 448/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5085 - mae: 0.1203 - val_loss: 6.1329 - val_mae: 1.0257\n",
      "Epoch 449/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5069 - mae: 0.1153 - val_loss: 6.1073 - val_mae: 1.0153\n",
      "Epoch 450/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5133 - mae: 0.1274 - val_loss: 6.0868 - val_mae: 1.0151\n",
      "Epoch 451/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5160 - mae: 0.1340 - val_loss: 6.2655 - val_mae: 1.0636\n",
      "Epoch 452/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5181 - mae: 0.1333 - val_loss: 6.1309 - val_mae: 1.0263\n",
      "Epoch 453/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5091 - mae: 0.1221 - val_loss: 6.2175 - val_mae: 1.0530\n",
      "Epoch 454/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5113 - mae: 0.1197 - val_loss: 6.1461 - val_mae: 1.0287\n",
      "Epoch 455/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5074 - mae: 0.1170 - val_loss: 6.0781 - val_mae: 1.0047\n",
      "Epoch 456/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5099 - mae: 0.1198 - val_loss: 5.8914 - val_mae: 0.9516\n",
      "Epoch 457/490\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.5143 - mae: 0.1379 - val_loss: 6.1293 - val_mae: 1.0276\n",
      "Epoch 458/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5133 - mae: 0.1402 - val_loss: 6.0371 - val_mae: 0.9984\n",
      "Epoch 459/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5123 - mae: 0.1346 - val_loss: 6.2002 - val_mae: 1.0451\n",
      "Epoch 460/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5099 - mae: 0.1196 - val_loss: 6.0507 - val_mae: 1.0047\n",
      "Epoch 461/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5163 - mae: 0.1391 - val_loss: 5.9558 - val_mae: 0.9834\n",
      "Epoch 462/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5193 - mae: 0.1463 - val_loss: 5.9869 - val_mae: 0.9808\n",
      "Epoch 463/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5488 - mae: 0.1955 - val_loss: 6.1082 - val_mae: 1.0250\n",
      "Epoch 464/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5193 - mae: 0.1463 - val_loss: 6.1641 - val_mae: 1.0398\n",
      "Epoch 465/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5180 - mae: 0.1440 - val_loss: 6.0137 - val_mae: 0.9933\n",
      "Epoch 466/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5208 - mae: 0.1566 - val_loss: 6.0325 - val_mae: 0.9947\n",
      "Epoch 467/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5222 - mae: 0.1515 - val_loss: 6.1327 - val_mae: 1.0226\n",
      "Epoch 468/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5177 - mae: 0.1353 - val_loss: 6.0295 - val_mae: 0.9919\n",
      "Epoch 469/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5182 - mae: 0.1397 - val_loss: 6.0500 - val_mae: 1.0054\n",
      "Epoch 470/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5196 - mae: 0.1508 - val_loss: 6.0545 - val_mae: 1.0010\n",
      "Epoch 471/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5225 - mae: 0.1541 - val_loss: 6.2189 - val_mae: 1.0522\n",
      "Epoch 472/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5399 - mae: 0.1793 - val_loss: 6.0788 - val_mae: 1.0077\n",
      "Epoch 473/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5092 - mae: 0.1252 - val_loss: 6.2364 - val_mae: 1.0527\n",
      "Epoch 474/490\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.5206 - mae: 0.1441 - val_loss: 6.1005 - val_mae: 1.0187\n",
      "Epoch 475/490\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5059 - mae: 0.1156 - val_loss: 6.0541 - val_mae: 1.0063\n",
      "Epoch 476/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5146 - mae: 0.1414 - val_loss: 6.2140 - val_mae: 1.0512\n",
      "Epoch 477/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5072 - mae: 0.1220 - val_loss: 6.0847 - val_mae: 1.0088\n",
      "Epoch 478/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5144 - mae: 0.1294 - val_loss: 6.2773 - val_mae: 1.0771\n",
      "Epoch 479/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5056 - mae: 0.1110 - val_loss: 6.1813 - val_mae: 1.0381\n",
      "Epoch 480/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5110 - mae: 0.1310 - val_loss: 6.0173 - val_mae: 0.9937\n",
      "Epoch 481/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5417 - mae: 0.1763 - val_loss: 6.2290 - val_mae: 1.0536\n",
      "Epoch 482/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5393 - mae: 0.1803 - val_loss: 6.0149 - val_mae: 0.9915\n",
      "Epoch 483/490\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5081 - mae: 0.1280 - val_loss: 6.0461 - val_mae: 0.9967\n",
      "Epoch 484/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5064 - mae: 0.1204 - val_loss: 6.2675 - val_mae: 1.0642\n",
      "Epoch 485/490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5071 - mae: 0.1192 - val_loss: 6.1230 - val_mae: 1.0167\n",
      "Epoch 486/490\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.5066 - mae: 0.1182 - val_loss: 6.1239 - val_mae: 1.0279\n",
      "Epoch 487/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5040 - mae: 0.1186 - val_loss: 6.2174 - val_mae: 1.0549\n",
      "Epoch 488/490\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5198 - mae: 0.1478 - val_loss: 6.1181 - val_mae: 1.0322\n",
      "Epoch 489/490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5046 - mae: 0.1276 - val_loss: 6.1884 - val_mae: 1.0365\n",
      "Epoch 490/490\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5063 - mae: 0.1159 - val_loss: 5.9884 - val_mae: 0.9848\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/mae</td><td>▆█▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_mae</td><td>█▇▅▁▂▁▁▂▂▁▂▂▁▂▂▂▁▂▁▂▂▂▂▂▂▂▁▂▂▂▂▁▂▂▁▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>489</td></tr><tr><td>epoch/learning_rate</td><td>0.00993</td></tr><tr><td>epoch/loss</td><td>4.5063</td></tr><tr><td>epoch/mae</td><td>0.11592</td></tr><tr><td>epoch/val_loss</td><td>5.98843</td></tr><tr><td>epoch/val_mae</td><td>0.9848</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dutiful-sweep-1</strong> at: <a href='https://wandb.ai/grantbell/fred_dnn_sweep/runs/avhlos0q' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/runs/avhlos0q</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230719_171637-avhlos0q\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4yftrasj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 484\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_initializer: he_normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1: 0.16858421143402982\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_l2: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2: 0.2045356052927331\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0010338635605050405\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: mse\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmetrics: mae\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\grant\\OneDrive\\Desktop\\vscode\\py_fin\\wandb\\run-20230719_171713-4yftrasj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/grantbell/fred_dnn_sweep/runs/4yftrasj' target=\"_blank\">pious-sweep-2</a></strong> to <a href='https://wandb.ai/grantbell/fred_dnn_sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/grantbell/fred_dnn_sweep' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/grantbell/fred_dnn_sweep/runs/4yftrasj' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/runs/4yftrasj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/484\n",
      "5/5 [==============================] - 1s 43ms/step - loss: 431.8565 - mae: 7.3515 - val_loss: 391.0743 - val_mae: 3.8609\n",
      "Epoch 2/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 380.7982 - mae: 2.6296 - val_loss: 379.6327 - val_mae: 2.6529\n",
      "Epoch 3/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 372.8768 - mae: 1.7688 - val_loss: 374.3604 - val_mae: 2.3883\n",
      "Epoch 4/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 368.0624 - mae: 1.5643 - val_loss: 369.9568 - val_mae: 2.2845\n",
      "Epoch 5/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 364.0650 - mae: 1.4476 - val_loss: 366.1060 - val_mae: 2.2503\n",
      "Epoch 6/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 360.2786 - mae: 1.3669 - val_loss: 362.3207 - val_mae: 2.2077\n",
      "Epoch 7/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 356.6963 - mae: 1.3102 - val_loss: 358.8593 - val_mae: 2.1937\n",
      "Epoch 8/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 353.2430 - mae: 1.3027 - val_loss: 355.0516 - val_mae: 2.1039\n",
      "Epoch 9/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 349.7373 - mae: 1.2306 - val_loss: 351.7312 - val_mae: 2.1044\n",
      "Epoch 10/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 346.3690 - mae: 1.2001 - val_loss: 348.4465 - val_mae: 2.1064\n",
      "Epoch 11/484\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 342.9961 - mae: 1.1696 - val_loss: 344.8130 - val_mae: 2.0269\n",
      "Epoch 12/484\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 339.6721 - mae: 1.1261 - val_loss: 341.2889 - val_mae: 1.9611\n",
      "Epoch 13/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 336.4350 - mae: 1.0928 - val_loss: 338.3188 - val_mae: 2.0047\n",
      "Epoch 14/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 333.1767 - mae: 1.0772 - val_loss: 334.9683 - val_mae: 1.9678\n",
      "Epoch 15/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 329.9749 - mae: 1.0437 - val_loss: 331.6933 - val_mae: 1.9397\n",
      "Epoch 16/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 326.7986 - mae: 1.0167 - val_loss: 328.5309 - val_mae: 1.9325\n",
      "Epoch 17/484\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 323.6423 - mae: 0.9991 - val_loss: 325.4197 - val_mae: 1.9199\n",
      "Epoch 18/484\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 320.5284 - mae: 0.9885 - val_loss: 321.9771 - val_mae: 1.8462\n",
      "Epoch 19/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 317.4210 - mae: 0.9543 - val_loss: 318.9699 - val_mae: 1.8495\n",
      "Epoch 20/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 314.3480 - mae: 0.9353 - val_loss: 315.8969 - val_mae: 1.8327\n",
      "Epoch 21/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 311.3316 - mae: 0.9302 - val_loss: 312.7291 - val_mae: 1.7928\n",
      "Epoch 22/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 308.3011 - mae: 0.9035 - val_loss: 309.6867 - val_mae: 1.7773\n",
      "Epoch 23/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 305.3284 - mae: 0.8891 - val_loss: 306.6160 - val_mae: 1.7591\n",
      "Epoch 24/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 302.3617 - mae: 0.8641 - val_loss: 303.6801 - val_mae: 1.7505\n",
      "Epoch 25/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 299.4257 - mae: 0.8520 - val_loss: 300.7509 - val_mae: 1.7530\n",
      "Epoch 26/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 296.5171 - mae: 0.8278 - val_loss: 297.8595 - val_mae: 1.7430\n",
      "Epoch 27/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 293.6302 - mae: 0.8279 - val_loss: 294.9606 - val_mae: 1.7311\n",
      "Epoch 28/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 290.7714 - mae: 0.8201 - val_loss: 291.9626 - val_mae: 1.6953\n",
      "Epoch 29/484\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 287.9409 - mae: 0.8005 - val_loss: 289.0485 - val_mae: 1.6726\n",
      "Epoch 30/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 285.1065 - mae: 0.7839 - val_loss: 286.2542 - val_mae: 1.6733\n",
      "Epoch 31/484\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 282.3012 - mae: 0.7682 - val_loss: 283.5342 - val_mae: 1.6877\n",
      "Epoch 32/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 279.5167 - mae: 0.7584 - val_loss: 280.6925 - val_mae: 1.6655\n",
      "Epoch 33/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 276.7779 - mae: 0.7529 - val_loss: 277.8402 - val_mae: 1.6373\n",
      "Epoch 34/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 274.0517 - mae: 0.7382 - val_loss: 275.2325 - val_mae: 1.6668\n",
      "Epoch 35/484\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 271.3475 - mae: 0.7406 - val_loss: 272.4926 - val_mae: 1.6478\n",
      "Epoch 36/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 268.6477 - mae: 0.7218 - val_loss: 269.9368 - val_mae: 1.6712\n",
      "Epoch 37/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 265.9899 - mae: 0.7250 - val_loss: 267.1662 - val_mae: 1.6414\n",
      "Epoch 38/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 263.3276 - mae: 0.7066 - val_loss: 264.4741 - val_mae: 1.6261\n",
      "Epoch 39/484\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 260.7000 - mae: 0.6937 - val_loss: 261.7735 - val_mae: 1.6035\n",
      "Epoch 40/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 258.0904 - mae: 0.6820 - val_loss: 259.5041 - val_mae: 1.6722\n",
      "Epoch 41/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 255.5045 - mae: 0.6989 - val_loss: 256.5952 - val_mae: 1.5989\n",
      "Epoch 42/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 252.9291 - mae: 0.6654 - val_loss: 254.0918 - val_mae: 1.6078\n",
      "Epoch 43/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 250.3719 - mae: 0.6601 - val_loss: 251.6660 - val_mae: 1.6310\n",
      "Epoch 44/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 247.8522 - mae: 0.6666 - val_loss: 249.0870 - val_mae: 1.6163\n",
      "Epoch 45/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 245.3288 - mae: 0.6592 - val_loss: 246.4683 - val_mae: 1.5886\n",
      "Epoch 46/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 242.8437 - mae: 0.6449 - val_loss: 243.9456 - val_mae: 1.5744\n",
      "Epoch 47/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 240.3664 - mae: 0.6363 - val_loss: 241.4749 - val_mae: 1.5699\n",
      "Epoch 48/484\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 237.9221 - mae: 0.6367 - val_loss: 239.0711 - val_mae: 1.5792\n",
      "Epoch 49/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 235.4712 - mae: 0.6279 - val_loss: 236.5492 - val_mae: 1.5515\n",
      "Epoch 50/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 233.0599 - mae: 0.6201 - val_loss: 234.1233 - val_mae: 1.5431\n",
      "Epoch 51/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 230.6633 - mae: 0.6148 - val_loss: 231.7675 - val_mae: 1.5493\n",
      "Epoch 52/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 228.2866 - mae: 0.6124 - val_loss: 229.3284 - val_mae: 1.5269\n",
      "Epoch 53/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 225.9280 - mae: 0.5952 - val_loss: 227.1210 - val_mae: 1.5603\n",
      "Epoch 54/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 223.5798 - mae: 0.6034 - val_loss: 224.6843 - val_mae: 1.5315\n",
      "Epoch 55/484\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 221.2654 - mae: 0.5944 - val_loss: 222.3317 - val_mae: 1.5206\n",
      "Epoch 56/484\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 218.9509 - mae: 0.5874 - val_loss: 220.0650 - val_mae: 1.5250\n",
      "Epoch 57/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 216.6712 - mae: 0.5854 - val_loss: 217.8206 - val_mae: 1.5336\n",
      "Epoch 58/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 214.3949 - mae: 0.5895 - val_loss: 215.5018 - val_mae: 1.5120\n",
      "Epoch 59/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 212.1407 - mae: 0.5765 - val_loss: 213.1707 - val_mae: 1.4940\n",
      "Epoch 60/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 209.9076 - mae: 0.5724 - val_loss: 210.9535 - val_mae: 1.4901\n",
      "Epoch 61/484\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 207.6938 - mae: 0.5691 - val_loss: 208.7104 - val_mae: 1.4828\n",
      "Epoch 62/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 205.4923 - mae: 0.5626 - val_loss: 206.5596 - val_mae: 1.4877\n",
      "Epoch 63/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 203.3134 - mae: 0.5569 - val_loss: 204.4384 - val_mae: 1.4991\n",
      "Epoch 64/484\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 201.1533 - mae: 0.5600 - val_loss: 202.2735 - val_mae: 1.4901\n",
      "Epoch 65/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 199.0128 - mae: 0.5570 - val_loss: 200.0711 - val_mae: 1.4760\n",
      "Epoch 66/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 196.8855 - mae: 0.5590 - val_loss: 197.9304 - val_mae: 1.4612\n",
      "Epoch 67/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 194.7843 - mae: 0.5517 - val_loss: 195.9532 - val_mae: 1.4904\n",
      "Epoch 68/484\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 192.6862 - mae: 0.5474 - val_loss: 193.8183 - val_mae: 1.4784\n",
      "Epoch 69/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 190.6149 - mae: 0.5473 - val_loss: 191.8265 - val_mae: 1.4933\n",
      "Epoch 70/484\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 188.5589 - mae: 0.5520 - val_loss: 189.7606 - val_mae: 1.4862\n",
      "Epoch 71/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 186.5201 - mae: 0.5349 - val_loss: 187.6588 - val_mae: 1.4663\n",
      "Epoch 72/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 184.4953 - mae: 0.5426 - val_loss: 185.5778 - val_mae: 1.4511\n",
      "Epoch 73/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 182.4920 - mae: 0.5398 - val_loss: 183.6479 - val_mae: 1.4630\n",
      "Epoch 74/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 180.5095 - mae: 0.5395 - val_loss: 181.5624 - val_mae: 1.4366\n",
      "Epoch 75/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 178.5367 - mae: 0.5295 - val_loss: 179.7320 - val_mae: 1.4677\n",
      "Epoch 76/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 176.5900 - mae: 0.5384 - val_loss: 177.7575 - val_mae: 1.4626\n",
      "Epoch 77/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 174.6526 - mae: 0.5367 - val_loss: 175.7484 - val_mae: 1.4326\n",
      "Epoch 78/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 172.7340 - mae: 0.5246 - val_loss: 173.9450 - val_mae: 1.4561\n",
      "Epoch 79/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 170.8292 - mae: 0.5207 - val_loss: 171.9166 - val_mae: 1.4296\n",
      "Epoch 80/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 168.9464 - mae: 0.5205 - val_loss: 170.1876 - val_mae: 1.4673\n",
      "Epoch 81/484\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 167.0830 - mae: 0.5309 - val_loss: 168.3104 - val_mae: 1.4532\n",
      "Epoch 82/484\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 165.2270 - mae: 0.5268 - val_loss: 166.3952 - val_mae: 1.4357\n",
      "Epoch 83/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 163.3865 - mae: 0.5185 - val_loss: 164.5650 - val_mae: 1.4290\n",
      "Epoch 84/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 161.5664 - mae: 0.5114 - val_loss: 162.7610 - val_mae: 1.4373\n",
      "Epoch 85/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 159.7589 - mae: 0.5161 - val_loss: 161.0364 - val_mae: 1.4440\n",
      "Epoch 86/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 157.9717 - mae: 0.5100 - val_loss: 159.2379 - val_mae: 1.4417\n",
      "Epoch 87/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 156.2043 - mae: 0.5071 - val_loss: 157.4418 - val_mae: 1.4349\n",
      "Epoch 88/484\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 154.4437 - mae: 0.5127 - val_loss: 155.5977 - val_mae: 1.4065\n",
      "Epoch 89/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 152.7094 - mae: 0.4981 - val_loss: 154.0106 - val_mae: 1.4412\n",
      "Epoch 90/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 150.9854 - mae: 0.5113 - val_loss: 152.2037 - val_mae: 1.4240\n",
      "Epoch 91/484\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 149.2767 - mae: 0.5107 - val_loss: 150.5441 - val_mae: 1.4233\n",
      "Epoch 92/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 147.5825 - mae: 0.4930 - val_loss: 148.7709 - val_mae: 1.4080\n",
      "Epoch 93/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 145.9034 - mae: 0.4973 - val_loss: 147.0851 - val_mae: 1.4073\n",
      "Epoch 94/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 144.2478 - mae: 0.5089 - val_loss: 145.4359 - val_mae: 1.4044\n",
      "Epoch 95/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 142.5885 - mae: 0.5017 - val_loss: 143.8495 - val_mae: 1.4165\n",
      "Epoch 96/484\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 140.9608 - mae: 0.5056 - val_loss: 142.1602 - val_mae: 1.3934\n",
      "Epoch 97/484\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 139.3326 - mae: 0.4886 - val_loss: 140.5723 - val_mae: 1.4054\n",
      "Epoch 98/484\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 137.7228 - mae: 0.4985 - val_loss: 138.9688 - val_mae: 1.4035\n",
      "Epoch 99/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 136.1272 - mae: 0.4975 - val_loss: 137.4214 - val_mae: 1.4048\n",
      "Epoch 100/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 134.5494 - mae: 0.4986 - val_loss: 135.8255 - val_mae: 1.3956\n",
      "Epoch 101/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 132.9819 - mae: 0.4819 - val_loss: 134.3703 - val_mae: 1.4268\n",
      "Epoch 102/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 131.4318 - mae: 0.5019 - val_loss: 132.6974 - val_mae: 1.3847\n",
      "Epoch 103/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 129.8939 - mae: 0.4821 - val_loss: 131.1988 - val_mae: 1.3968\n",
      "Epoch 104/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 128.3738 - mae: 0.4914 - val_loss: 129.5565 - val_mae: 1.3569\n",
      "Epoch 105/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 126.8707 - mae: 0.4764 - val_loss: 128.0636 - val_mae: 1.3607\n",
      "Epoch 106/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 125.3761 - mae: 0.4772 - val_loss: 126.6588 - val_mae: 1.3757\n",
      "Epoch 107/484\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 123.9019 - mae: 0.4762 - val_loss: 125.2597 - val_mae: 1.4022\n",
      "Epoch 108/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 122.4374 - mae: 0.4853 - val_loss: 123.6720 - val_mae: 1.3674\n",
      "Epoch 109/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 120.9857 - mae: 0.4785 - val_loss: 122.2296 - val_mae: 1.3720\n",
      "Epoch 110/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 119.5542 - mae: 0.4811 - val_loss: 120.7578 - val_mae: 1.3571\n",
      "Epoch 111/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 118.1200 - mae: 0.4746 - val_loss: 119.4502 - val_mae: 1.3807\n",
      "Epoch 112/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 116.7123 - mae: 0.4735 - val_loss: 118.0743 - val_mae: 1.3930\n",
      "Epoch 113/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 115.3163 - mae: 0.4858 - val_loss: 116.6275 - val_mae: 1.3753\n",
      "Epoch 114/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 113.9370 - mae: 0.4785 - val_loss: 115.2336 - val_mae: 1.3661\n",
      "Epoch 115/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 112.5683 - mae: 0.4792 - val_loss: 113.8325 - val_mae: 1.3612\n",
      "Epoch 116/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 111.2088 - mae: 0.4763 - val_loss: 112.5643 - val_mae: 1.3708\n",
      "Epoch 117/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 109.8729 - mae: 0.4731 - val_loss: 111.2642 - val_mae: 1.3818\n",
      "Epoch 118/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 108.5492 - mae: 0.4831 - val_loss: 109.8469 - val_mae: 1.3573\n",
      "Epoch 119/484\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 107.2293 - mae: 0.4629 - val_loss: 108.6501 - val_mae: 1.3912\n",
      "Epoch 120/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 105.9307 - mae: 0.4794 - val_loss: 107.3003 - val_mae: 1.3690\n",
      "Epoch 121/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 104.6483 - mae: 0.4729 - val_loss: 106.0585 - val_mae: 1.3804\n",
      "Epoch 122/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 103.3716 - mae: 0.4752 - val_loss: 104.7960 - val_mae: 1.3766\n",
      "Epoch 123/484\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 102.1114 - mae: 0.4719 - val_loss: 103.5674 - val_mae: 1.3761\n",
      "Epoch 124/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 100.8576 - mae: 0.4636 - val_loss: 102.1994 - val_mae: 1.3483\n",
      "Epoch 125/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 99.6180 - mae: 0.4563 - val_loss: 100.9699 - val_mae: 1.3534\n",
      "Epoch 126/484\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 98.3974 - mae: 0.4681 - val_loss: 99.7094 - val_mae: 1.3343\n",
      "Epoch 127/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 97.1836 - mae: 0.4531 - val_loss: 98.5492 - val_mae: 1.3539\n",
      "Epoch 128/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 95.9840 - mae: 0.4597 - val_loss: 97.3624 - val_mae: 1.3575\n",
      "Epoch 129/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 94.7971 - mae: 0.4644 - val_loss: 96.1953 - val_mae: 1.3500\n",
      "Epoch 130/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 93.6190 - mae: 0.4596 - val_loss: 94.9689 - val_mae: 1.3404\n",
      "Epoch 131/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 92.4535 - mae: 0.4559 - val_loss: 93.8176 - val_mae: 1.3521\n",
      "Epoch 132/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 91.2982 - mae: 0.4634 - val_loss: 92.6301 - val_mae: 1.3256\n",
      "Epoch 133/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 90.1544 - mae: 0.4504 - val_loss: 91.5117 - val_mae: 1.3198\n",
      "Epoch 134/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 89.0264 - mae: 0.4494 - val_loss: 90.3595 - val_mae: 1.3186\n",
      "Epoch 135/484\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 87.9122 - mae: 0.4447 - val_loss: 89.3169 - val_mae: 1.3221\n",
      "Epoch 136/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 86.8054 - mae: 0.4349 - val_loss: 88.2610 - val_mae: 1.3401\n",
      "Epoch 137/484\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 85.7052 - mae: 0.4391 - val_loss: 87.1508 - val_mae: 1.3397\n",
      "Epoch 138/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 84.6251 - mae: 0.4462 - val_loss: 85.9952 - val_mae: 1.3128\n",
      "Epoch 139/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 83.5600 - mae: 0.4430 - val_loss: 84.9540 - val_mae: 1.3054\n",
      "Epoch 140/484\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 82.5011 - mae: 0.4222 - val_loss: 83.8794 - val_mae: 1.3213\n",
      "Epoch 141/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 81.4516 - mae: 0.4337 - val_loss: 82.9063 - val_mae: 1.3425\n",
      "Epoch 142/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 80.4203 - mae: 0.4436 - val_loss: 81.7847 - val_mae: 1.3100\n",
      "Epoch 143/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 79.3999 - mae: 0.4295 - val_loss: 80.8438 - val_mae: 1.3294\n",
      "Epoch 144/484\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 78.3889 - mae: 0.4363 - val_loss: 79.7638 - val_mae: 1.3105\n",
      "Epoch 145/484\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 77.3902 - mae: 0.4277 - val_loss: 78.8380 - val_mae: 1.3302\n",
      "Epoch 146/484\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 76.3984 - mae: 0.4307 - val_loss: 77.8678 - val_mae: 1.3382\n",
      "Epoch 147/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 75.4147 - mae: 0.4394 - val_loss: 76.8634 - val_mae: 1.3255\n",
      "Epoch 148/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 74.4437 - mae: 0.4271 - val_loss: 75.9336 - val_mae: 1.3308\n",
      "Epoch 149/484\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 73.4857 - mae: 0.4316 - val_loss: 74.9174 - val_mae: 1.3078\n",
      "Epoch 150/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 72.5397 - mae: 0.4263 - val_loss: 74.0220 - val_mae: 1.3147\n",
      "Epoch 151/484\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 71.5999 - mae: 0.4205 - val_loss: 73.0612 - val_mae: 1.3122\n",
      "Epoch 152/484\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 70.6712 - mae: 0.4165 - val_loss: 72.1245 - val_mae: 1.3134\n",
      "Epoch 153/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 69.7592 - mae: 0.4229 - val_loss: 71.2131 - val_mae: 1.3043\n",
      "Epoch 154/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 68.8463 - mae: 0.4163 - val_loss: 70.3244 - val_mae: 1.3010\n",
      "Epoch 155/484\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 67.9459 - mae: 0.4078 - val_loss: 69.4604 - val_mae: 1.3246\n",
      "Epoch 156/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 67.0605 - mae: 0.4215 - val_loss: 68.5274 - val_mae: 1.2937\n",
      "Epoch 157/484\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 66.1836 - mae: 0.4148 - val_loss: 67.5968 - val_mae: 1.2833\n",
      "Epoch 158/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 65.3188 - mae: 0.4063 - val_loss: 66.8068 - val_mae: 1.2957\n",
      "Epoch 159/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 64.4604 - mae: 0.4120 - val_loss: 65.9474 - val_mae: 1.2936\n",
      "Epoch 160/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 63.6154 - mae: 0.4050 - val_loss: 65.1266 - val_mae: 1.3059\n",
      "Epoch 161/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 62.7783 - mae: 0.4101 - val_loss: 64.3070 - val_mae: 1.3006\n",
      "Epoch 162/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 61.9505 - mae: 0.4050 - val_loss: 63.4916 - val_mae: 1.3054\n",
      "Epoch 163/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 61.1371 - mae: 0.4112 - val_loss: 62.6674 - val_mae: 1.2974\n",
      "Epoch 164/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 60.3279 - mae: 0.4036 - val_loss: 61.7996 - val_mae: 1.2832\n",
      "Epoch 165/484\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 59.5334 - mae: 0.4040 - val_loss: 61.0069 - val_mae: 1.2820\n",
      "Epoch 166/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 58.7435 - mae: 0.3973 - val_loss: 60.3006 - val_mae: 1.2972\n",
      "Epoch 167/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 57.9659 - mae: 0.3957 - val_loss: 59.5308 - val_mae: 1.3061\n",
      "Epoch 168/484\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 57.2020 - mae: 0.4124 - val_loss: 58.7463 - val_mae: 1.2887\n",
      "Epoch 169/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 56.4395 - mae: 0.3978 - val_loss: 58.0006 - val_mae: 1.2912\n",
      "Epoch 170/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 55.6914 - mae: 0.3983 - val_loss: 57.2315 - val_mae: 1.2797\n",
      "Epoch 171/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 54.9447 - mae: 0.3847 - val_loss: 56.4258 - val_mae: 1.2777\n",
      "Epoch 172/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 54.2088 - mae: 0.3967 - val_loss: 55.7522 - val_mae: 1.2820\n",
      "Epoch 173/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 53.4818 - mae: 0.3945 - val_loss: 54.9548 - val_mae: 1.2558\n",
      "Epoch 174/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 52.7645 - mae: 0.3814 - val_loss: 54.2844 - val_mae: 1.2737\n",
      "Epoch 175/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 52.0494 - mae: 0.3875 - val_loss: 53.6031 - val_mae: 1.2701\n",
      "Epoch 176/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 51.3476 - mae: 0.3742 - val_loss: 52.9643 - val_mae: 1.2930\n",
      "Epoch 177/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 50.6581 - mae: 0.3912 - val_loss: 52.2517 - val_mae: 1.2792\n",
      "Epoch 178/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 49.9736 - mae: 0.3828 - val_loss: 51.5707 - val_mae: 1.2736\n",
      "Epoch 179/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 49.3061 - mae: 0.3831 - val_loss: 50.9224 - val_mae: 1.2825\n",
      "Epoch 180/484\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 48.6355 - mae: 0.3829 - val_loss: 50.2385 - val_mae: 1.2811\n",
      "Epoch 181/484\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 47.9745 - mae: 0.3864 - val_loss: 49.5273 - val_mae: 1.2469\n",
      "Epoch 182/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 47.3286 - mae: 0.3598 - val_loss: 48.9003 - val_mae: 1.2677\n",
      "Epoch 183/484\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 46.6878 - mae: 0.3746 - val_loss: 48.3843 - val_mae: 1.2869\n",
      "Epoch 184/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 46.0569 - mae: 0.3721 - val_loss: 47.7190 - val_mae: 1.2793\n",
      "Epoch 185/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 45.4312 - mae: 0.3731 - val_loss: 47.0078 - val_mae: 1.2546\n",
      "Epoch 186/484\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 44.8212 - mae: 0.3677 - val_loss: 46.4212 - val_mae: 1.2667\n",
      "Epoch 187/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 44.2105 - mae: 0.3756 - val_loss: 45.8612 - val_mae: 1.2721\n",
      "Epoch 188/484\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 43.6129 - mae: 0.3718 - val_loss: 45.2225 - val_mae: 1.2498\n",
      "Epoch 189/484\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 43.0228 - mae: 0.3622 - val_loss: 44.6836 - val_mae: 1.2700\n",
      "Epoch 190/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 42.4361 - mae: 0.3675 - val_loss: 44.1076 - val_mae: 1.2702\n",
      "Epoch 191/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 41.8600 - mae: 0.3688 - val_loss: 43.4971 - val_mae: 1.2596\n",
      "Epoch 192/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 41.2896 - mae: 0.3635 - val_loss: 42.9441 - val_mae: 1.2615\n",
      "Epoch 193/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 40.7308 - mae: 0.3629 - val_loss: 42.3843 - val_mae: 1.2568\n",
      "Epoch 194/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 40.1712 - mae: 0.3577 - val_loss: 41.8675 - val_mae: 1.2674\n",
      "Epoch 195/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 39.6242 - mae: 0.3599 - val_loss: 41.2945 - val_mae: 1.2532\n",
      "Epoch 196/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 39.0838 - mae: 0.3551 - val_loss: 40.7640 - val_mae: 1.2580\n",
      "Epoch 197/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 38.5479 - mae: 0.3571 - val_loss: 40.1974 - val_mae: 1.2523\n",
      "Epoch 198/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 38.0219 - mae: 0.3580 - val_loss: 39.6401 - val_mae: 1.2404\n",
      "Epoch 199/484\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 37.5041 - mae: 0.3518 - val_loss: 39.1652 - val_mae: 1.2433\n",
      "Epoch 200/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.9905 - mae: 0.3471 - val_loss: 38.6723 - val_mae: 1.2593\n",
      "Epoch 201/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 36.4809 - mae: 0.3542 - val_loss: 38.1454 - val_mae: 1.2479\n",
      "Epoch 202/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.9790 - mae: 0.3457 - val_loss: 37.6869 - val_mae: 1.2639\n",
      "Epoch 203/484\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 35.4881 - mae: 0.3576 - val_loss: 37.1643 - val_mae: 1.2524\n",
      "Epoch 204/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.9970 - mae: 0.3524 - val_loss: 36.7206 - val_mae: 1.2501\n",
      "Epoch 205/484\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34.5153 - mae: 0.3428 - val_loss: 36.1528 - val_mae: 1.2277\n",
      "Epoch 206/484\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 34.0416 - mae: 0.3437 - val_loss: 35.6845 - val_mae: 1.2289\n",
      "Epoch 207/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.5729 - mae: 0.3376 - val_loss: 35.2449 - val_mae: 1.2373\n",
      "Epoch 208/484\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 33.1093 - mae: 0.3399 - val_loss: 34.7968 - val_mae: 1.2325\n",
      "Epoch 209/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.6565 - mae: 0.3321 - val_loss: 34.3547 - val_mae: 1.2380\n",
      "Epoch 210/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.2089 - mae: 0.3394 - val_loss: 33.8954 - val_mae: 1.2219\n",
      "Epoch 211/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.7676 - mae: 0.3203 - val_loss: 33.4309 - val_mae: 1.2202\n",
      "Epoch 212/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 31.3319 - mae: 0.3214 - val_loss: 33.0569 - val_mae: 1.2308\n",
      "Epoch 213/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.9004 - mae: 0.3251 - val_loss: 32.5763 - val_mae: 1.2184\n",
      "Epoch 214/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 30.4741 - mae: 0.3214 - val_loss: 32.2202 - val_mae: 1.2299\n",
      "Epoch 215/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 30.0560 - mae: 0.3103 - val_loss: 31.7767 - val_mae: 1.2213\n",
      "Epoch 216/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.6428 - mae: 0.3144 - val_loss: 31.4114 - val_mae: 1.2366\n",
      "Epoch 217/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 29.2318 - mae: 0.3189 - val_loss: 30.9730 - val_mae: 1.2300\n",
      "Epoch 218/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.8312 - mae: 0.3181 - val_loss: 30.5353 - val_mae: 1.2160\n",
      "Epoch 219/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.4335 - mae: 0.3123 - val_loss: 30.2121 - val_mae: 1.2328\n",
      "Epoch 220/484\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.0445 - mae: 0.3139 - val_loss: 29.7692 - val_mae: 1.2199\n",
      "Epoch 221/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 27.6606 - mae: 0.3138 - val_loss: 29.4078 - val_mae: 1.2178\n",
      "Epoch 222/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 27.2829 - mae: 0.3071 - val_loss: 29.0256 - val_mae: 1.2207\n",
      "Epoch 223/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 26.9070 - mae: 0.3066 - val_loss: 28.6128 - val_mae: 1.2096\n",
      "Epoch 224/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 26.5403 - mae: 0.3077 - val_loss: 28.2992 - val_mae: 1.2212\n",
      "Epoch 225/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 26.1768 - mae: 0.3080 - val_loss: 27.8991 - val_mae: 1.2088\n",
      "Epoch 226/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 25.8193 - mae: 0.3046 - val_loss: 27.5792 - val_mae: 1.2151\n",
      "Epoch 227/484\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 25.4633 - mae: 0.3014 - val_loss: 27.2016 - val_mae: 1.2068\n",
      "Epoch 228/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 25.1159 - mae: 0.2978 - val_loss: 26.8834 - val_mae: 1.2069\n",
      "Epoch 229/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 24.7767 - mae: 0.2893 - val_loss: 26.5051 - val_mae: 1.2037\n",
      "Epoch 230/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 24.4381 - mae: 0.2991 - val_loss: 26.1365 - val_mae: 1.1850\n",
      "Epoch 231/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 24.1060 - mae: 0.2874 - val_loss: 25.8493 - val_mae: 1.1995\n",
      "Epoch 232/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 23.7739 - mae: 0.2927 - val_loss: 25.5411 - val_mae: 1.2044\n",
      "Epoch 233/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 23.4493 - mae: 0.2940 - val_loss: 25.1780 - val_mae: 1.1875\n",
      "Epoch 234/484\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 23.1315 - mae: 0.2813 - val_loss: 24.9080 - val_mae: 1.2010\n",
      "Epoch 235/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.8175 - mae: 0.2875 - val_loss: 24.5998 - val_mae: 1.2027\n",
      "Epoch 236/484\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 22.5027 - mae: 0.2845 - val_loss: 24.2607 - val_mae: 1.1912\n",
      "Epoch 237/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.1965 - mae: 0.2783 - val_loss: 23.9517 - val_mae: 1.1934\n",
      "Epoch 238/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 21.8948 - mae: 0.2825 - val_loss: 23.6372 - val_mae: 1.1875\n",
      "Epoch 239/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.5959 - mae: 0.2794 - val_loss: 23.3653 - val_mae: 1.1941\n",
      "Epoch 240/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.3030 - mae: 0.2806 - val_loss: 23.0635 - val_mae: 1.1905\n",
      "Epoch 241/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.0138 - mae: 0.2764 - val_loss: 22.7771 - val_mae: 1.1916\n",
      "Epoch 242/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 20.7312 - mae: 0.2833 - val_loss: 22.5421 - val_mae: 1.1935\n",
      "Epoch 243/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 20.4530 - mae: 0.2718 - val_loss: 22.2154 - val_mae: 1.1841\n",
      "Epoch 244/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 20.1739 - mae: 0.2697 - val_loss: 21.9259 - val_mae: 1.1798\n",
      "Epoch 245/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 19.9012 - mae: 0.2682 - val_loss: 21.6931 - val_mae: 1.1845\n",
      "Epoch 246/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 19.6347 - mae: 0.2675 - val_loss: 21.4137 - val_mae: 1.1820\n",
      "Epoch 247/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 19.3697 - mae: 0.2615 - val_loss: 21.1396 - val_mae: 1.1783\n",
      "Epoch 248/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 19.1097 - mae: 0.2613 - val_loss: 20.8991 - val_mae: 1.1854\n",
      "Epoch 249/484\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 18.8560 - mae: 0.2704 - val_loss: 20.6847 - val_mae: 1.1923\n",
      "Epoch 250/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 18.6042 - mae: 0.2663 - val_loss: 20.3652 - val_mae: 1.1723\n",
      "Epoch 251/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 18.3570 - mae: 0.2661 - val_loss: 20.1537 - val_mae: 1.1764\n",
      "Epoch 252/484\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 18.1132 - mae: 0.2567 - val_loss: 19.9515 - val_mae: 1.1852\n",
      "Epoch 253/484\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 17.8744 - mae: 0.2555 - val_loss: 19.6990 - val_mae: 1.1845\n",
      "Epoch 254/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 17.6390 - mae: 0.2617 - val_loss: 19.4352 - val_mae: 1.1726\n",
      "Epoch 255/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 17.4085 - mae: 0.2564 - val_loss: 19.2379 - val_mae: 1.1764\n",
      "Epoch 256/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 17.1797 - mae: 0.2431 - val_loss: 18.9895 - val_mae: 1.1707\n",
      "Epoch 257/484\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 16.9541 - mae: 0.2474 - val_loss: 18.7585 - val_mae: 1.1710\n",
      "Epoch 258/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 16.7339 - mae: 0.2526 - val_loss: 18.5342 - val_mae: 1.1656\n",
      "Epoch 259/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 16.5143 - mae: 0.2448 - val_loss: 18.3307 - val_mae: 1.1688\n",
      "Epoch 260/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 16.2992 - mae: 0.2448 - val_loss: 18.1419 - val_mae: 1.1728\n",
      "Epoch 261/484\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 16.0878 - mae: 0.2406 - val_loss: 17.9075 - val_mae: 1.1687\n",
      "Epoch 262/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 15.8780 - mae: 0.2442 - val_loss: 17.6616 - val_mae: 1.1576\n",
      "Epoch 263/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 15.6717 - mae: 0.2420 - val_loss: 17.4715 - val_mae: 1.1590\n",
      "Epoch 264/484\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 15.4689 - mae: 0.2373 - val_loss: 17.2420 - val_mae: 1.1528\n",
      "Epoch 265/484\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 15.2689 - mae: 0.2360 - val_loss: 17.0616 - val_mae: 1.1569\n",
      "Epoch 266/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 15.0683 - mae: 0.2376 - val_loss: 16.8401 - val_mae: 1.1468\n",
      "Epoch 267/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 14.8750 - mae: 0.2297 - val_loss: 16.6766 - val_mae: 1.1545\n",
      "Epoch 268/484\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 14.6811 - mae: 0.2286 - val_loss: 16.4816 - val_mae: 1.1565\n",
      "Epoch 269/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 14.4918 - mae: 0.2337 - val_loss: 16.3012 - val_mae: 1.1559\n",
      "Epoch 270/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 14.3034 - mae: 0.2304 - val_loss: 16.1075 - val_mae: 1.1544\n",
      "Epoch 271/484\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 14.1187 - mae: 0.2314 - val_loss: 15.9227 - val_mae: 1.1513\n",
      "Epoch 272/484\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13.9357 - mae: 0.2245 - val_loss: 15.7252 - val_mae: 1.1449\n",
      "Epoch 273/484\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13.7546 - mae: 0.2227 - val_loss: 15.5726 - val_mae: 1.1534\n",
      "Epoch 274/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 13.5747 - mae: 0.2243 - val_loss: 15.3279 - val_mae: 1.1340\n",
      "Epoch 275/484\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.3993 - mae: 0.2186 - val_loss: 15.1843 - val_mae: 1.1432\n",
      "Epoch 276/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 13.2236 - mae: 0.2173 - val_loss: 14.9962 - val_mae: 1.1381\n",
      "Epoch 277/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 13.0513 - mae: 0.2188 - val_loss: 14.8470 - val_mae: 1.1433\n",
      "Epoch 278/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 12.8793 - mae: 0.2129 - val_loss: 14.6667 - val_mae: 1.1423\n",
      "Epoch 279/484\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 12.7118 - mae: 0.2209 - val_loss: 14.5185 - val_mae: 1.1474\n",
      "Epoch 280/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 12.5426 - mae: 0.2190 - val_loss: 14.3584 - val_mae: 1.1463\n",
      "Epoch 281/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 12.3774 - mae: 0.2137 - val_loss: 14.1800 - val_mae: 1.1456\n",
      "Epoch 282/484\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12.2137 - mae: 0.2175 - val_loss: 14.0250 - val_mae: 1.1426\n",
      "Epoch 283/484\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 12.0515 - mae: 0.2101 - val_loss: 13.8533 - val_mae: 1.1406\n",
      "Epoch 284/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 11.8908 - mae: 0.2084 - val_loss: 13.6852 - val_mae: 1.1389\n",
      "Epoch 285/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 11.7337 - mae: 0.2089 - val_loss: 13.5213 - val_mae: 1.1383\n",
      "Epoch 286/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 11.5765 - mae: 0.2095 - val_loss: 13.3650 - val_mae: 1.1378\n",
      "Epoch 287/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 11.4213 - mae: 0.2093 - val_loss: 13.2221 - val_mae: 1.1412\n",
      "Epoch 288/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 11.2689 - mae: 0.2115 - val_loss: 13.0543 - val_mae: 1.1353\n",
      "Epoch 289/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 11.1185 - mae: 0.2070 - val_loss: 12.9311 - val_mae: 1.1396\n",
      "Epoch 290/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.9681 - mae: 0.2022 - val_loss: 12.7530 - val_mae: 1.1344\n",
      "Epoch 291/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.8192 - mae: 0.2043 - val_loss: 12.5826 - val_mae: 1.1273\n",
      "Epoch 292/484\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6711 - mae: 0.2027 - val_loss: 12.4650 - val_mae: 1.1322\n",
      "Epoch 293/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 10.5246 - mae: 0.1967 - val_loss: 12.3020 - val_mae: 1.1279\n",
      "Epoch 294/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.3789 - mae: 0.1952 - val_loss: 12.1891 - val_mae: 1.1372\n",
      "Epoch 295/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.2351 - mae: 0.1980 - val_loss: 12.0290 - val_mae: 1.1314\n",
      "Epoch 296/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 10.0922 - mae: 0.1962 - val_loss: 11.8704 - val_mae: 1.1280\n",
      "Epoch 297/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.9518 - mae: 0.1954 - val_loss: 11.7147 - val_mae: 1.1220\n",
      "Epoch 298/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.8128 - mae: 0.1945 - val_loss: 11.5930 - val_mae: 1.1267\n",
      "Epoch 299/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.6737 - mae: 0.1956 - val_loss: 11.4647 - val_mae: 1.1267\n",
      "Epoch 300/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.5366 - mae: 0.1915 - val_loss: 11.3156 - val_mae: 1.1245\n",
      "Epoch 301/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.4008 - mae: 0.1913 - val_loss: 11.2037 - val_mae: 1.1284\n",
      "Epoch 302/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.2667 - mae: 0.1884 - val_loss: 11.0701 - val_mae: 1.1311\n",
      "Epoch 303/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.1340 - mae: 0.1909 - val_loss: 10.9052 - val_mae: 1.1225\n",
      "Epoch 304/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 9.0041 - mae: 0.1953 - val_loss: 10.7774 - val_mae: 1.1166\n",
      "Epoch 305/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.8747 - mae: 0.1814 - val_loss: 10.6618 - val_mae: 1.1253\n",
      "Epoch 306/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.7461 - mae: 0.1898 - val_loss: 10.5361 - val_mae: 1.1230\n",
      "Epoch 307/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.6186 - mae: 0.1878 - val_loss: 10.3907 - val_mae: 1.1184\n",
      "Epoch 308/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 8.4933 - mae: 0.1879 - val_loss: 10.2509 - val_mae: 1.1127\n",
      "Epoch 309/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.3690 - mae: 0.1835 - val_loss: 10.1444 - val_mae: 1.1187\n",
      "Epoch 310/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.2474 - mae: 0.1878 - val_loss: 10.0278 - val_mae: 1.1189\n",
      "Epoch 311/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.1257 - mae: 0.1874 - val_loss: 9.8776 - val_mae: 1.1084\n",
      "Epoch 312/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.0055 - mae: 0.1817 - val_loss: 9.7665 - val_mae: 1.1113\n",
      "Epoch 313/484\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 7.8867 - mae: 0.1805 - val_loss: 9.6577 - val_mae: 1.1125\n",
      "Epoch 314/484\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.7705 - mae: 0.1820 - val_loss: 9.5169 - val_mae: 1.1050\n",
      "Epoch 315/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 7.6542 - mae: 0.1792 - val_loss: 9.4138 - val_mae: 1.1070\n",
      "Epoch 316/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.5399 - mae: 0.1774 - val_loss: 9.2972 - val_mae: 1.1089\n",
      "Epoch 317/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 7.4256 - mae: 0.1796 - val_loss: 9.1664 - val_mae: 1.1021\n",
      "Epoch 318/484\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.3129 - mae: 0.1793 - val_loss: 9.0509 - val_mae: 1.1008\n",
      "Epoch 319/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.2021 - mae: 0.1776 - val_loss: 8.9648 - val_mae: 1.1058\n",
      "Epoch 320/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.0928 - mae: 0.1774 - val_loss: 8.8432 - val_mae: 1.1029\n",
      "Epoch 321/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.9830 - mae: 0.1772 - val_loss: 8.7459 - val_mae: 1.1038\n",
      "Epoch 322/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.8760 - mae: 0.1725 - val_loss: 8.6217 - val_mae: 1.1011\n",
      "Epoch 323/484\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.7680 - mae: 0.1747 - val_loss: 8.5172 - val_mae: 1.1023\n",
      "Epoch 324/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.6619 - mae: 0.1768 - val_loss: 8.4003 - val_mae: 1.0975\n",
      "Epoch 325/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.5579 - mae: 0.1768 - val_loss: 8.2968 - val_mae: 1.0970\n",
      "Epoch 326/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.4544 - mae: 0.1722 - val_loss: 8.1838 - val_mae: 1.0934\n",
      "Epoch 327/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.3528 - mae: 0.1726 - val_loss: 8.0648 - val_mae: 1.0877\n",
      "Epoch 328/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.2518 - mae: 0.1714 - val_loss: 7.9720 - val_mae: 1.0891\n",
      "Epoch 329/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.1526 - mae: 0.1700 - val_loss: 7.8699 - val_mae: 1.0887\n",
      "Epoch 330/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.0536 - mae: 0.1714 - val_loss: 7.7724 - val_mae: 1.0873\n",
      "Epoch 331/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 5.9564 - mae: 0.1678 - val_loss: 7.6552 - val_mae: 1.0824\n",
      "Epoch 332/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 5.8595 - mae: 0.1696 - val_loss: 7.5535 - val_mae: 1.0798\n",
      "Epoch 333/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.7641 - mae: 0.1675 - val_loss: 7.4681 - val_mae: 1.0826\n",
      "Epoch 334/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.6697 - mae: 0.1664 - val_loss: 7.3738 - val_mae: 1.0821\n",
      "Epoch 335/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.5768 - mae: 0.1673 - val_loss: 7.2814 - val_mae: 1.0808\n",
      "Epoch 336/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.4843 - mae: 0.1645 - val_loss: 7.1832 - val_mae: 1.0795\n",
      "Epoch 337/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 5.3928 - mae: 0.1644 - val_loss: 7.0968 - val_mae: 1.0812\n",
      "Epoch 338/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 5.3027 - mae: 0.1692 - val_loss: 7.0057 - val_mae: 1.0794\n",
      "Epoch 339/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.2139 - mae: 0.1647 - val_loss: 6.9054 - val_mae: 1.0762\n",
      "Epoch 340/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.1256 - mae: 0.1642 - val_loss: 6.8304 - val_mae: 1.0791\n",
      "Epoch 341/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.0395 - mae: 0.1628 - val_loss: 6.7206 - val_mae: 1.0717\n",
      "Epoch 342/484\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.9547 - mae: 0.1632 - val_loss: 6.6426 - val_mae: 1.0732\n",
      "Epoch 343/484\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.8723 - mae: 0.1645 - val_loss: 6.5537 - val_mae: 1.0712\n",
      "Epoch 344/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.7877 - mae: 0.1614 - val_loss: 6.4574 - val_mae: 1.0663\n",
      "Epoch 345/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.7055 - mae: 0.1599 - val_loss: 6.3666 - val_mae: 1.0637\n",
      "Epoch 346/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.6247 - mae: 0.1596 - val_loss: 6.2954 - val_mae: 1.0670\n",
      "Epoch 347/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5447 - mae: 0.1632 - val_loss: 6.1982 - val_mae: 1.0607\n",
      "Epoch 348/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.4660 - mae: 0.1602 - val_loss: 6.1311 - val_mae: 1.0630\n",
      "Epoch 349/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.3886 - mae: 0.1609 - val_loss: 6.0418 - val_mae: 1.0594\n",
      "Epoch 350/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.3114 - mae: 0.1565 - val_loss: 5.9767 - val_mae: 1.0622\n",
      "Epoch 351/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.2375 - mae: 0.1603 - val_loss: 5.8921 - val_mae: 1.0582\n",
      "Epoch 352/484\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.1633 - mae: 0.1562 - val_loss: 5.8069 - val_mae: 1.0548\n",
      "Epoch 353/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.0913 - mae: 0.1578 - val_loss: 5.7354 - val_mae: 1.0558\n",
      "Epoch 354/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.0190 - mae: 0.1600 - val_loss: 5.6720 - val_mae: 1.0560\n",
      "Epoch 355/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.9484 - mae: 0.1567 - val_loss: 5.5910 - val_mae: 1.0540\n",
      "Epoch 356/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.8787 - mae: 0.1572 - val_loss: 5.5168 - val_mae: 1.0525\n",
      "Epoch 357/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.8100 - mae: 0.1591 - val_loss: 5.4503 - val_mae: 1.0512\n",
      "Epoch 358/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.7427 - mae: 0.1565 - val_loss: 5.3835 - val_mae: 1.0519\n",
      "Epoch 359/484\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.6765 - mae: 0.1583 - val_loss: 5.3007 - val_mae: 1.0465\n",
      "Epoch 360/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.6110 - mae: 0.1565 - val_loss: 5.2287 - val_mae: 1.0453\n",
      "Epoch 361/484\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.5465 - mae: 0.1576 - val_loss: 5.1586 - val_mae: 1.0433\n",
      "Epoch 362/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.4833 - mae: 0.1579 - val_loss: 5.0850 - val_mae: 1.0407\n",
      "Epoch 363/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4213 - mae: 0.1591 - val_loss: 5.0234 - val_mae: 1.0399\n",
      "Epoch 364/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.3602 - mae: 0.1583 - val_loss: 4.9644 - val_mae: 1.0414\n",
      "Epoch 365/484\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.3005 - mae: 0.1603 - val_loss: 4.8811 - val_mae: 1.0338\n",
      "Epoch 366/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.2418 - mae: 0.1607 - val_loss: 4.8322 - val_mae: 1.0358\n",
      "Epoch 367/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.1845 - mae: 0.1584 - val_loss: 4.7713 - val_mae: 1.0352\n",
      "Epoch 368/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.1282 - mae: 0.1588 - val_loss: 4.7091 - val_mae: 1.0326\n",
      "Epoch 369/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.0731 - mae: 0.1578 - val_loss: 4.6614 - val_mae: 1.0352\n",
      "Epoch 370/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.0181 - mae: 0.1592 - val_loss: 4.5937 - val_mae: 1.0322\n",
      "Epoch 371/484\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2.9638 - mae: 0.1617 - val_loss: 4.5275 - val_mae: 1.0285\n",
      "Epoch 372/484\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.9106 - mae: 0.1611 - val_loss: 4.4706 - val_mae: 1.0276\n",
      "Epoch 373/484\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 2.8584 - mae: 0.1640 - val_loss: 4.3998 - val_mae: 1.0219\n",
      "Epoch 374/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.8066 - mae: 0.1640 - val_loss: 4.3574 - val_mae: 1.0238\n",
      "Epoch 375/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7563 - mae: 0.1632 - val_loss: 4.2956 - val_mae: 1.0217\n",
      "Epoch 376/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7069 - mae: 0.1677 - val_loss: 4.2468 - val_mae: 1.0185\n",
      "Epoch 377/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.6599 - mae: 0.1628 - val_loss: 4.1921 - val_mae: 1.0191\n",
      "Epoch 378/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.6127 - mae: 0.1659 - val_loss: 4.1415 - val_mae: 1.0155\n",
      "Epoch 379/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.5665 - mae: 0.1619 - val_loss: 4.0898 - val_mae: 1.0159\n",
      "Epoch 380/484\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2.5209 - mae: 0.1642 - val_loss: 4.0500 - val_mae: 1.0179\n",
      "Epoch 381/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.4767 - mae: 0.1703 - val_loss: 3.9905 - val_mae: 1.0131\n",
      "Epoch 382/484\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.4328 - mae: 0.1691 - val_loss: 3.9447 - val_mae: 1.0123\n",
      "Epoch 383/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3896 - mae: 0.1688 - val_loss: 3.9006 - val_mae: 1.0128\n",
      "Epoch 384/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3469 - mae: 0.1723 - val_loss: 3.8458 - val_mae: 1.0088\n",
      "Epoch 385/484\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.3055 - mae: 0.1739 - val_loss: 3.8099 - val_mae: 1.0093\n",
      "Epoch 386/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2640 - mae: 0.1713 - val_loss: 3.7678 - val_mae: 1.0090\n",
      "Epoch 387/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2234 - mae: 0.1687 - val_loss: 3.7237 - val_mae: 1.0098\n",
      "Epoch 388/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1837 - mae: 0.1750 - val_loss: 3.6831 - val_mae: 1.0093\n",
      "Epoch 389/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.1439 - mae: 0.1769 - val_loss: 3.6394 - val_mae: 1.0079\n",
      "Epoch 390/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.1054 - mae: 0.1766 - val_loss: 3.5916 - val_mae: 1.0044\n",
      "Epoch 391/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0672 - mae: 0.1755 - val_loss: 3.5558 - val_mae: 1.0052\n",
      "Epoch 392/484\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 2.0301 - mae: 0.1773 - val_loss: 3.5019 - val_mae: 1.0002\n",
      "Epoch 393/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.9937 - mae: 0.1787 - val_loss: 3.4744 - val_mae: 1.0016\n",
      "Epoch 394/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.9583 - mae: 0.1776 - val_loss: 3.4346 - val_mae: 1.0010\n",
      "Epoch 395/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9244 - mae: 0.1791 - val_loss: 3.3858 - val_mae: 0.9972\n",
      "Epoch 396/484\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.8903 - mae: 0.1818 - val_loss: 3.3633 - val_mae: 0.9994\n",
      "Epoch 397/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.8579 - mae: 0.1812 - val_loss: 3.3241 - val_mae: 0.9984\n",
      "Epoch 398/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8251 - mae: 0.1827 - val_loss: 3.2814 - val_mae: 0.9946\n",
      "Epoch 399/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7937 - mae: 0.1827 - val_loss: 3.2468 - val_mae: 0.9937\n",
      "Epoch 400/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.7619 - mae: 0.1832 - val_loss: 3.2102 - val_mae: 0.9921\n",
      "Epoch 401/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7313 - mae: 0.1839 - val_loss: 3.1680 - val_mae: 0.9898\n",
      "Epoch 402/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.7017 - mae: 0.1868 - val_loss: 3.1408 - val_mae: 0.9898\n",
      "Epoch 403/484\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.6721 - mae: 0.1879 - val_loss: 3.1006 - val_mae: 0.9869\n",
      "Epoch 404/484\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.6432 - mae: 0.1899 - val_loss: 3.0651 - val_mae: 0.9841\n",
      "Epoch 405/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.6156 - mae: 0.1898 - val_loss: 3.0285 - val_mae: 0.9822\n",
      "Epoch 406/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5884 - mae: 0.1914 - val_loss: 3.0061 - val_mae: 0.9829\n",
      "Epoch 407/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5621 - mae: 0.1908 - val_loss: 2.9730 - val_mae: 0.9817\n",
      "Epoch 408/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5363 - mae: 0.1921 - val_loss: 2.9420 - val_mae: 0.9796\n",
      "Epoch 409/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.5121 - mae: 0.1934 - val_loss: 2.9193 - val_mae: 0.9814\n",
      "Epoch 410/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.4878 - mae: 0.1961 - val_loss: 2.9063 - val_mae: 0.9848\n",
      "Epoch 411/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4639 - mae: 0.2001 - val_loss: 2.8607 - val_mae: 0.9774\n",
      "Epoch 412/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4392 - mae: 0.1960 - val_loss: 2.8433 - val_mae: 0.9802\n",
      "Epoch 413/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.4164 - mae: 0.1998 - val_loss: 2.8101 - val_mae: 0.9773\n",
      "Epoch 414/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.3929 - mae: 0.1999 - val_loss: 2.7923 - val_mae: 0.9772\n",
      "Epoch 415/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3709 - mae: 0.1975 - val_loss: 2.7558 - val_mae: 0.9732\n",
      "Epoch 416/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.3492 - mae: 0.1968 - val_loss: 2.7383 - val_mae: 0.9751\n",
      "Epoch 417/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3285 - mae: 0.1995 - val_loss: 2.7119 - val_mae: 0.9738\n",
      "Epoch 418/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.3079 - mae: 0.2022 - val_loss: 2.6846 - val_mae: 0.9699\n",
      "Epoch 419/484\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.2882 - mae: 0.2000 - val_loss: 2.6726 - val_mae: 0.9730\n",
      "Epoch 420/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2691 - mae: 0.1999 - val_loss: 2.6514 - val_mae: 0.9723\n",
      "Epoch 421/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.2500 - mae: 0.2006 - val_loss: 2.6215 - val_mae: 0.9698\n",
      "Epoch 422/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2310 - mae: 0.2025 - val_loss: 2.6066 - val_mae: 0.9698\n",
      "Epoch 423/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2134 - mae: 0.2018 - val_loss: 2.5801 - val_mae: 0.9678\n",
      "Epoch 424/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.1960 - mae: 0.2015 - val_loss: 2.5661 - val_mae: 0.9691\n",
      "Epoch 425/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.1787 - mae: 0.2027 - val_loss: 2.5432 - val_mae: 0.9675\n",
      "Epoch 426/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.1619 - mae: 0.2027 - val_loss: 2.5277 - val_mae: 0.9684\n",
      "Epoch 427/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1464 - mae: 0.2057 - val_loss: 2.5027 - val_mae: 0.9647\n",
      "Epoch 428/484\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.1310 - mae: 0.2060 - val_loss: 2.4930 - val_mae: 0.9659\n",
      "Epoch 429/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.1171 - mae: 0.2056 - val_loss: 2.4737 - val_mae: 0.9649\n",
      "Epoch 430/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.1030 - mae: 0.2051 - val_loss: 2.4517 - val_mae: 0.9622\n",
      "Epoch 431/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0904 - mae: 0.2072 - val_loss: 2.4383 - val_mae: 0.9630\n",
      "Epoch 432/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0780 - mae: 0.2100 - val_loss: 2.4265 - val_mae: 0.9595\n",
      "Epoch 433/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0668 - mae: 0.2052 - val_loss: 2.4119 - val_mae: 0.9599\n",
      "Epoch 434/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0548 - mae: 0.2037 - val_loss: 2.3938 - val_mae: 0.9569\n",
      "Epoch 435/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0442 - mae: 0.2026 - val_loss: 2.3857 - val_mae: 0.9603\n",
      "Epoch 436/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0339 - mae: 0.2081 - val_loss: 2.3703 - val_mae: 0.9580\n",
      "Epoch 437/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.0242 - mae: 0.2072 - val_loss: 2.3558 - val_mae: 0.9575\n",
      "Epoch 438/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0140 - mae: 0.2092 - val_loss: 2.3419 - val_mae: 0.9560\n",
      "Epoch 439/484\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0046 - mae: 0.2081 - val_loss: 2.3317 - val_mae: 0.9561\n",
      "Epoch 440/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.9948 - mae: 0.2109 - val_loss: 2.3109 - val_mae: 0.9516\n",
      "Epoch 441/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.9853 - mae: 0.2097 - val_loss: 2.3022 - val_mae: 0.9535\n",
      "Epoch 442/484\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9761 - mae: 0.2122 - val_loss: 2.2924 - val_mae: 0.9507\n",
      "Epoch 443/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.9681 - mae: 0.2086 - val_loss: 2.2793 - val_mae: 0.9506\n",
      "Epoch 444/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.9605 - mae: 0.2108 - val_loss: 2.2703 - val_mae: 0.9508\n",
      "Epoch 445/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.9529 - mae: 0.2108 - val_loss: 2.2643 - val_mae: 0.9524\n",
      "Epoch 446/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.9463 - mae: 0.2141 - val_loss: 2.2404 - val_mae: 0.9453\n",
      "Epoch 447/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.9395 - mae: 0.2128 - val_loss: 2.2457 - val_mae: 0.9510\n",
      "Epoch 448/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.9325 - mae: 0.2152 - val_loss: 2.2311 - val_mae: 0.9464\n",
      "Epoch 449/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.9260 - mae: 0.2123 - val_loss: 2.2245 - val_mae: 0.9481\n",
      "Epoch 450/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.9196 - mae: 0.2141 - val_loss: 2.2119 - val_mae: 0.9449\n",
      "Epoch 451/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.9138 - mae: 0.2131 - val_loss: 2.2023 - val_mae: 0.9446\n",
      "Epoch 452/484\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.9077 - mae: 0.2135 - val_loss: 2.1986 - val_mae: 0.9453\n",
      "Epoch 453/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.9019 - mae: 0.2136 - val_loss: 2.1834 - val_mae: 0.9417\n",
      "Epoch 454/484\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.8959 - mae: 0.2136 - val_loss: 2.1823 - val_mae: 0.9427\n",
      "Epoch 455/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8906 - mae: 0.2142 - val_loss: 2.1801 - val_mae: 0.9434\n",
      "Epoch 456/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8852 - mae: 0.2105 - val_loss: 2.1728 - val_mae: 0.9443\n",
      "Epoch 457/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.8795 - mae: 0.2135 - val_loss: 2.1756 - val_mae: 0.9478\n",
      "Epoch 458/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8748 - mae: 0.2139 - val_loss: 2.1728 - val_mae: 0.9493\n",
      "Epoch 459/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8697 - mae: 0.2172 - val_loss: 2.1598 - val_mae: 0.9463\n",
      "Epoch 460/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8633 - mae: 0.2163 - val_loss: 2.1520 - val_mae: 0.9453\n",
      "Epoch 461/484\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8583 - mae: 0.2172 - val_loss: 2.1499 - val_mae: 0.9456\n",
      "Epoch 462/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8541 - mae: 0.2159 - val_loss: 2.1380 - val_mae: 0.9410\n",
      "Epoch 463/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8485 - mae: 0.2118 - val_loss: 2.1347 - val_mae: 0.9433\n",
      "Epoch 464/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8442 - mae: 0.2156 - val_loss: 2.1318 - val_mae: 0.9424\n",
      "Epoch 465/484\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8392 - mae: 0.2106 - val_loss: 2.1325 - val_mae: 0.9466\n",
      "Epoch 466/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8351 - mae: 0.2162 - val_loss: 2.1265 - val_mae: 0.9457\n",
      "Epoch 467/484\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.8309 - mae: 0.2148 - val_loss: 2.1243 - val_mae: 0.9465\n",
      "Epoch 468/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.8269 - mae: 0.2148 - val_loss: 2.1163 - val_mae: 0.9448\n",
      "Epoch 469/484\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.8225 - mae: 0.2164 - val_loss: 2.1038 - val_mae: 0.9408\n",
      "Epoch 470/484\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.8184 - mae: 0.2128 - val_loss: 2.1040 - val_mae: 0.9438\n",
      "Epoch 471/484\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.8138 - mae: 0.2141 - val_loss: 2.1023 - val_mae: 0.9447\n",
      "Epoch 472/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8098 - mae: 0.2144 - val_loss: 2.1021 - val_mae: 0.9465\n",
      "Epoch 473/484\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.8061 - mae: 0.2154 - val_loss: 2.0952 - val_mae: 0.9454\n",
      "Epoch 474/484\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8018 - mae: 0.2179 - val_loss: 2.0875 - val_mae: 0.9409\n",
      "Epoch 475/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.7987 - mae: 0.2119 - val_loss: 2.0872 - val_mae: 0.9445\n",
      "Epoch 476/484\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7942 - mae: 0.2141 - val_loss: 2.0842 - val_mae: 0.9440\n",
      "Epoch 477/484\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7900 - mae: 0.2135 - val_loss: 2.0790 - val_mae: 0.9437\n",
      "Epoch 478/484\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.7860 - mae: 0.2112 - val_loss: 2.0853 - val_mae: 0.9480\n",
      "Epoch 479/484\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7827 - mae: 0.2142 - val_loss: 2.0738 - val_mae: 0.9460\n",
      "Epoch 480/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.7786 - mae: 0.2176 - val_loss: 2.0720 - val_mae: 0.9448\n",
      "Epoch 481/484\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7745 - mae: 0.2132 - val_loss: 2.0690 - val_mae: 0.9458\n",
      "Epoch 482/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7707 - mae: 0.2147 - val_loss: 2.0630 - val_mae: 0.9452\n",
      "Epoch 483/484\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7672 - mae: 0.2125 - val_loss: 2.0601 - val_mae: 0.9450\n",
      "Epoch 484/484\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.7636 - mae: 0.2126 - val_loss: 2.0605 - val_mae: 0.9477\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▇▇▆▅▅▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/mae</td><td>█▅▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_loss</td><td>█▇▇▆▅▅▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_mae</td><td>█▆▅▅▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>483</td></tr><tr><td>epoch/learning_rate</td><td>0.00103</td></tr><tr><td>epoch/loss</td><td>0.76362</td></tr><tr><td>epoch/mae</td><td>0.21257</td></tr><tr><td>epoch/val_loss</td><td>2.06047</td></tr><tr><td>epoch/val_mae</td><td>0.94774</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pious-sweep-2</strong> at: <a href='https://wandb.ai/grantbell/fred_dnn_sweep/runs/4yftrasj' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/runs/4yftrasj</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230719_171713-4yftrasj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: amwohd7n with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 76\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_initializer: he_normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1: 0.30055761673592907\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_l2: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2: 0.20888743744142613\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.005720544313771081\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: mse\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmetrics: mae\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\grant\\OneDrive\\Desktop\\vscode\\py_fin\\wandb\\run-20230719_171750-amwohd7n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/grantbell/fred_dnn_sweep/runs/amwohd7n' target=\"_blank\">laced-sweep-3</a></strong> to <a href='https://wandb.ai/grantbell/fred_dnn_sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/grantbell/fred_dnn_sweep' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/grantbell/fred_dnn_sweep/runs/amwohd7n' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/runs/amwohd7n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/76\n",
      "5/5 [==============================] - 1s 50ms/step - loss: 631.5177 - mae: 5.0188 - val_loss: 569.7927 - val_mae: 2.7928\n",
      "Epoch 2/76\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 549.1469 - mae: 1.7432 - val_loss: 523.8062 - val_mae: 2.1411\n",
      "Epoch 3/76\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 506.0340 - mae: 1.5058 - val_loss: 481.3390 - val_mae: 2.0551\n",
      "Epoch 4/76\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 464.8987 - mae: 1.1530 - val_loss: 443.3271 - val_mae: 1.9925\n",
      "Epoch 5/76\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 427.2667 - mae: 1.0590 - val_loss: 406.0296 - val_mae: 1.7436\n",
      "Epoch 6/76\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 391.8877 - mae: 0.9744 - val_loss: 372.2145 - val_mae: 1.7173\n",
      "Epoch 7/76\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 358.5997 - mae: 0.8579 - val_loss: 341.1224 - val_mae: 1.8500\n",
      "Epoch 8/76\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 327.7706 - mae: 0.8280 - val_loss: 312.7189 - val_mae: 1.8481\n",
      "Epoch 9/76\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 299.7700 - mae: 1.0302 - val_loss: 283.6780 - val_mae: 1.6232\n",
      "Epoch 10/76\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 272.1639 - mae: 0.7159 - val_loss: 258.7655 - val_mae: 1.7968\n",
      "Epoch 11/76\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 247.4604 - mae: 0.7905 - val_loss: 234.6852 - val_mae: 1.6121\n",
      "Epoch 12/76\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 224.3996 - mae: 0.6996 - val_loss: 213.1135 - val_mae: 1.6349\n",
      "Epoch 13/76\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 203.1881 - mae: 0.7214 - val_loss: 192.7802 - val_mae: 1.6973\n",
      "Epoch 14/76\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 183.4074 - mae: 0.6593 - val_loss: 173.4829 - val_mae: 1.4923\n",
      "Epoch 15/76\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 165.4144 - mae: 0.6340 - val_loss: 157.6423 - val_mae: 1.6875\n",
      "Epoch 16/76\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 149.2495 - mae: 0.7096 - val_loss: 141.6177 - val_mae: 1.6273\n",
      "Epoch 17/76\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 134.4672 - mae: 0.7708 - val_loss: 127.2577 - val_mae: 1.4998\n",
      "Epoch 18/76\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 120.3026 - mae: 0.5592 - val_loss: 114.0522 - val_mae: 1.4466\n",
      "Epoch 19/76\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 108.0303 - mae: 0.5823 - val_loss: 102.9266 - val_mae: 1.5143\n",
      "Epoch 20/76\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 96.7086 - mae: 0.5540 - val_loss: 93.5087 - val_mae: 1.5997\n",
      "Epoch 21/76\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 87.3559 - mae: 0.8361 - val_loss: 84.2200 - val_mae: 1.8603\n",
      "Epoch 22/76\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 78.5595 - mae: 0.9393 - val_loss: 75.3135 - val_mae: 1.5040\n",
      "Epoch 23/76\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 69.3776 - mae: 0.5441 - val_loss: 66.5440 - val_mae: 1.4421\n",
      "Epoch 24/76\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 61.9213 - mae: 0.5036 - val_loss: 59.9245 - val_mae: 1.3562\n",
      "Epoch 25/76\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 55.5513 - mae: 0.4796 - val_loss: 54.4146 - val_mae: 1.5695\n",
      "Epoch 26/76\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 49.9461 - mae: 0.5988 - val_loss: 48.2391 - val_mae: 1.2149\n",
      "Epoch 27/76\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 44.5537 - mae: 0.3875 - val_loss: 43.6645 - val_mae: 1.3165\n",
      "Epoch 28/76\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 40.1922 - mae: 0.4349 - val_loss: 39.3874 - val_mae: 1.1807\n",
      "Epoch 29/76\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 36.1594 - mae: 0.3368 - val_loss: 35.7924 - val_mae: 1.2367\n",
      "Epoch 30/76\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.6778 - mae: 0.3405 - val_loss: 32.6881 - val_mae: 1.2489\n",
      "Epoch 31/76\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.6473 - mae: 0.3409 - val_loss: 29.7703 - val_mae: 1.1945\n",
      "Epoch 32/76\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 26.9564 - mae: 0.3203 - val_loss: 27.4198 - val_mae: 1.1912\n",
      "Epoch 33/76\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 24.5171 - mae: 0.2963 - val_loss: 24.8560 - val_mae: 1.1524\n",
      "Epoch 34/76\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 22.3319 - mae: 0.3105 - val_loss: 22.7629 - val_mae: 1.1149\n",
      "Epoch 35/76\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 20.3182 - mae: 0.2710 - val_loss: 21.2138 - val_mae: 1.1855\n",
      "Epoch 36/76\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 18.4378 - mae: 0.2528 - val_loss: 19.0683 - val_mae: 1.1084\n",
      "Epoch 37/76\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 16.7030 - mae: 0.2448 - val_loss: 17.4455 - val_mae: 1.0998\n",
      "Epoch 38/76\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 15.1098 - mae: 0.2208 - val_loss: 15.9673 - val_mae: 1.0971\n",
      "Epoch 39/76\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 13.6618 - mae: 0.2091 - val_loss: 14.5303 - val_mae: 1.0707\n",
      "Epoch 40/76\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 12.3292 - mae: 0.1977 - val_loss: 13.2427 - val_mae: 1.0734\n",
      "Epoch 41/76\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 11.1272 - mae: 0.1900 - val_loss: 12.0759 - val_mae: 1.0560\n",
      "Epoch 42/76\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.0418 - mae: 0.1860 - val_loss: 11.0449 - val_mae: 1.0380\n",
      "Epoch 43/76\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.1048 - mae: 0.1736 - val_loss: 10.0258 - val_mae: 1.0131\n",
      "Epoch 44/76\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.2835 - mae: 0.2037 - val_loss: 9.2620 - val_mae: 1.0096\n",
      "Epoch 45/76\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.5789 - mae: 0.2085 - val_loss: 8.7636 - val_mae: 1.0114\n",
      "Epoch 46/76\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.9878 - mae: 0.2012 - val_loss: 8.0013 - val_mae: 0.9775\n",
      "Epoch 47/76\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 6.4441 - mae: 0.2054 - val_loss: 7.3987 - val_mae: 0.9511\n",
      "Epoch 48/76\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.9963 - mae: 0.2323 - val_loss: 7.0030 - val_mae: 0.9549\n",
      "Epoch 49/76\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.5869 - mae: 0.2290 - val_loss: 6.6146 - val_mae: 0.9459\n",
      "Epoch 50/76\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 5.2497 - mae: 0.2453 - val_loss: 6.3339 - val_mae: 0.9480\n",
      "Epoch 51/76\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.9800 - mae: 0.2463 - val_loss: 6.0594 - val_mae: 0.9493\n",
      "Epoch 52/76\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.7627 - mae: 0.2710 - val_loss: 5.9102 - val_mae: 0.9153\n",
      "Epoch 53/76\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.5764 - mae: 0.2295 - val_loss: 5.7255 - val_mae: 0.9501\n",
      "Epoch 54/76\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.4429 - mae: 0.2744 - val_loss: 5.5056 - val_mae: 0.9039\n",
      "Epoch 55/76\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.3323 - mae: 0.2607 - val_loss: 5.4024 - val_mae: 0.9118\n",
      "Epoch 56/76\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.2624 - mae: 0.2891 - val_loss: 5.3124 - val_mae: 0.9013\n",
      "Epoch 57/76\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.2011 - mae: 0.2877 - val_loss: 5.3418 - val_mae: 0.9288\n",
      "Epoch 58/76\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.1543 - mae: 0.2966 - val_loss: 5.1825 - val_mae: 0.8770\n",
      "Epoch 59/76\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.1066 - mae: 0.2795 - val_loss: 5.1259 - val_mae: 0.8813\n",
      "Epoch 60/76\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.0597 - mae: 0.2870 - val_loss: 5.1209 - val_mae: 0.8818\n",
      "Epoch 61/76\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.0251 - mae: 0.2795 - val_loss: 5.1352 - val_mae: 0.9057\n",
      "Epoch 62/76\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.9810 - mae: 0.2718 - val_loss: 5.0594 - val_mae: 0.8880\n",
      "Epoch 63/76\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.9619 - mae: 0.2797 - val_loss: 5.0831 - val_mae: 0.9267\n",
      "Epoch 64/76\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.9179 - mae: 0.2909 - val_loss: 4.9915 - val_mae: 0.8809\n",
      "Epoch 65/76\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.8944 - mae: 0.2677 - val_loss: 5.0700 - val_mae: 0.9291\n",
      "Epoch 66/76\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.8709 - mae: 0.2802 - val_loss: 5.1346 - val_mae: 0.9470\n",
      "Epoch 67/76\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.8581 - mae: 0.2584 - val_loss: 5.0429 - val_mae: 0.9307\n",
      "Epoch 68/76\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.8327 - mae: 0.2630 - val_loss: 5.0911 - val_mae: 0.9462\n",
      "Epoch 69/76\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.8302 - mae: 0.2671 - val_loss: 5.0078 - val_mae: 0.9130\n",
      "Epoch 70/76\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.8081 - mae: 0.2505 - val_loss: 5.0665 - val_mae: 0.9441\n",
      "Epoch 71/76\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.8018 - mae: 0.2470 - val_loss: 4.9690 - val_mae: 0.9094\n",
      "Epoch 72/76\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.7868 - mae: 0.2500 - val_loss: 5.0069 - val_mae: 0.9308\n",
      "Epoch 73/76\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.7736 - mae: 0.2357 - val_loss: 5.0200 - val_mae: 0.9424\n",
      "Epoch 74/76\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.7741 - mae: 0.2606 - val_loss: 5.0416 - val_mae: 0.9476\n",
      "Epoch 75/76\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.7599 - mae: 0.2389 - val_loss: 5.0043 - val_mae: 0.9339\n",
      "Epoch 76/76\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.7561 - mae: 0.2474 - val_loss: 5.0271 - val_mae: 0.9500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▇▆▅▅▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/mae</td><td>█▃▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_loss</td><td>█▇▆▆▅▄▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_mae</td><td>█▆▅▄▅▄▄▃▄▃▄▃▃▂▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>75</td></tr><tr><td>epoch/learning_rate</td><td>0.00572</td></tr><tr><td>epoch/loss</td><td>3.75615</td></tr><tr><td>epoch/mae</td><td>0.24743</td></tr><tr><td>epoch/val_loss</td><td>5.02714</td></tr><tr><td>epoch/val_mae</td><td>0.94998</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">laced-sweep-3</strong> at: <a href='https://wandb.ai/grantbell/fred_dnn_sweep/runs/amwohd7n' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/runs/amwohd7n</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230719_171750-amwohd7n\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: huq1hlym with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_initializer: he_normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1: 0.2816872928017892\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_l2: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2: 0.46532365636753914\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.007327698238825228\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: mse\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmetrics: mae\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\grant\\OneDrive\\Desktop\\vscode\\py_fin\\wandb\\run-20230719_171806-huq1hlym</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/grantbell/fred_dnn_sweep/runs/huq1hlym' target=\"_blank\">robust-sweep-4</a></strong> to <a href='https://wandb.ai/grantbell/fred_dnn_sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/grantbell/fred_dnn_sweep' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/grantbell/fred_dnn_sweep/runs/huq1hlym' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/runs/huq1hlym</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "5/5 [==============================] - 1s 44ms/step - loss: 694.4127 - mae: 5.0678 - val_loss: 622.9541 - val_mae: 4.4654\n",
      "Epoch 2/12\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 577.0451 - mae: 1.6000 - val_loss: 557.1376 - val_mae: 5.1446\n",
      "Epoch 3/12\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 510.2419 - mae: 1.9601 - val_loss: 501.0309 - val_mae: 5.7136\n",
      "Epoch 4/12\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 445.4297 - mae: 1.2936 - val_loss: 442.3664 - val_mae: 6.0093\n",
      "Epoch 5/12\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 388.2289 - mae: 1.4508 - val_loss: 392.5383 - val_mae: 6.2991\n",
      "Epoch 6/12\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 335.9203 - mae: 0.8954 - val_loss: 345.1489 - val_mae: 6.1335\n",
      "Epoch 7/12\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 291.6606 - mae: 1.2175 - val_loss: 306.3336 - val_mae: 6.5645\n",
      "Epoch 8/12\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 251.3867 - mae: 1.3417 - val_loss: 269.0715 - val_mae: 6.6023\n",
      "Epoch 9/12\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 216.1550 - mae: 1.4136 - val_loss: 237.9062 - val_mae: 6.6720\n",
      "Epoch 10/12\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 185.3766 - mae: 1.3731 - val_loss: 208.6457 - val_mae: 6.5949\n",
      "Epoch 11/12\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 161.5679 - mae: 2.1016 - val_loss: 181.3857 - val_mae: 6.4156\n",
      "Epoch 12/12\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 132.0091 - mae: 0.7471 - val_loss: 159.7991 - val_mae: 6.4826\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▇▆▅▄▄▃▂▂▂▁▁</td></tr><tr><td>epoch/mae</td><td>█▂▃▂▂▁▂▂▂▂▃▁</td></tr><tr><td>epoch/val_loss</td><td>█▇▆▅▅▄▃▃▂▂▁▁</td></tr><tr><td>epoch/val_mae</td><td>▁▃▅▆▇▆████▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>11</td></tr><tr><td>epoch/learning_rate</td><td>0.00733</td></tr><tr><td>epoch/loss</td><td>132.00909</td></tr><tr><td>epoch/mae</td><td>0.74708</td></tr><tr><td>epoch/val_loss</td><td>159.79912</td></tr><tr><td>epoch/val_mae</td><td>6.48263</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">robust-sweep-4</strong> at: <a href='https://wandb.ai/grantbell/fred_dnn_sweep/runs/huq1hlym' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/runs/huq1hlym</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230719_171806-huq1hlym\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7hwb0a2q with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 416\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_initializer: he_normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1: 0.23776516570007872\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_l2: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2: 0.38694187537240354\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.009221580247094276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: mse\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmetrics: mae\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\grant\\OneDrive\\Desktop\\vscode\\py_fin\\wandb\\run-20230719_171817-7hwb0a2q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/grantbell/fred_dnn_sweep/runs/7hwb0a2q' target=\"_blank\">rich-sweep-5</a></strong> to <a href='https://wandb.ai/grantbell/fred_dnn_sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/grantbell/fred_dnn_sweep' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/grantbell/fred_dnn_sweep/runs/7hwb0a2q' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/runs/7hwb0a2q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/416\n",
      "5/5 [==============================] - 1s 45ms/step - loss: 572.6754 - mae: 4.2822 - val_loss: 515.8318 - val_mae: 4.2687\n",
      "Epoch 2/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 477.9486 - mae: 2.1427 - val_loss: 472.9443 - val_mae: 5.8499\n",
      "Epoch 3/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 415.4454 - mae: 1.7160 - val_loss: 418.6173 - val_mae: 6.4520\n",
      "Epoch 4/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 360.1468 - mae: 1.4302 - val_loss: 365.2140 - val_mae: 6.0367\n",
      "Epoch 5/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 309.4904 - mae: 0.7824 - val_loss: 326.3656 - val_mae: 6.6887\n",
      "Epoch 6/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 267.0529 - mae: 1.1626 - val_loss: 286.8483 - val_mae: 6.4955\n",
      "Epoch 7/416\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 232.3289 - mae: 1.8037 - val_loss: 253.2244 - val_mae: 6.8515\n",
      "Epoch 8/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 195.3082 - mae: 0.8795 - val_loss: 222.4129 - val_mae: 6.9465\n",
      "Epoch 9/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 166.8041 - mae: 1.2958 - val_loss: 198.9377 - val_mae: 6.7349\n",
      "Epoch 10/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 160.2863 - mae: 3.6273 - val_loss: 173.9832 - val_mae: 6.8218\n",
      "Epoch 11/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 123.7156 - mae: 1.7064 - val_loss: 151.5677 - val_mae: 6.6210\n",
      "Epoch 12/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 104.2499 - mae: 1.7613 - val_loss: 132.6017 - val_mae: 6.0452\n",
      "Epoch 13/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 91.2025 - mae: 2.0157 - val_loss: 113.2537 - val_mae: 5.8779\n",
      "Epoch 14/416\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 78.6333 - mae: 2.1147 - val_loss: 111.6800 - val_mae: 6.3299\n",
      "Epoch 15/416\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 77.5742 - mae: 2.9760 - val_loss: 95.3940 - val_mae: 6.1302\n",
      "Epoch 16/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 66.1631 - mae: 2.6787 - val_loss: 87.0020 - val_mae: 5.7165\n",
      "Epoch 17/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 71.5627 - mae: 3.8334 - val_loss: 82.1474 - val_mae: 5.8201\n",
      "Epoch 18/416\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 44.0635 - mae: 1.1956 - val_loss: 63.9797 - val_mae: 5.2796\n",
      "Epoch 19/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 38.1972 - mae: 1.8175 - val_loss: 54.3606 - val_mae: 4.3174\n",
      "Epoch 20/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 31.4928 - mae: 1.2150 - val_loss: 45.4938 - val_mae: 4.4067\n",
      "Epoch 21/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 53.2390 - mae: 3.4092 - val_loss: 112.1315 - val_mae: 6.6160\n",
      "Epoch 22/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 102.3076 - mae: 5.3638 - val_loss: 90.9694 - val_mae: 5.1890\n",
      "Epoch 23/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 61.3965 - mae: 3.3819 - val_loss: 64.6129 - val_mae: 4.8217\n",
      "Epoch 24/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 46.5359 - mae: 2.5368 - val_loss: 51.0489 - val_mae: 3.6199\n",
      "Epoch 25/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.5954 - mae: 1.6926 - val_loss: 47.6838 - val_mae: 4.3083\n",
      "Epoch 26/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.4956 - mae: 1.5270 - val_loss: 40.5992 - val_mae: 4.1364\n",
      "Epoch 27/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 25.3772 - mae: 1.7269 - val_loss: 32.5343 - val_mae: 3.0565\n",
      "Epoch 28/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 24.8195 - mae: 1.8517 - val_loss: 39.9696 - val_mae: 4.0428\n",
      "Epoch 29/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.5183 - mae: 3.0098 - val_loss: 32.3293 - val_mae: 3.4059\n",
      "Epoch 30/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 20.6640 - mae: 1.5228 - val_loss: 27.3256 - val_mae: 3.1206\n",
      "Epoch 31/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 19.9914 - mae: 1.5731 - val_loss: 23.0282 - val_mae: 2.9632\n",
      "Epoch 32/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 14.4111 - mae: 1.2224 - val_loss: 18.1397 - val_mae: 2.3461\n",
      "Epoch 33/416\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.1279 - mae: 1.0171 - val_loss: 17.4839 - val_mae: 1.4772\n",
      "Epoch 34/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 21.4244 - mae: 2.0137 - val_loss: 19.9890 - val_mae: 2.2938\n",
      "Epoch 35/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 14.9589 - mae: 1.2076 - val_loss: 17.9242 - val_mae: 2.1464\n",
      "Epoch 36/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 10.1402 - mae: 0.5101 - val_loss: 12.4665 - val_mae: 1.6607\n",
      "Epoch 37/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.4362 - mae: 0.5840 - val_loss: 10.4461 - val_mae: 1.1795\n",
      "Epoch 38/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 10.2415 - mae: 1.1951 - val_loss: 9.4758 - val_mae: 1.1615\n",
      "Epoch 39/416\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.2517 - mae: 1.1255 - val_loss: 8.4374 - val_mae: 0.8671\n",
      "Epoch 40/416\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.2155 - mae: 1.1779 - val_loss: 8.7208 - val_mae: 0.8830\n",
      "Epoch 41/416\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.4130 - mae: 0.9809 - val_loss: 7.5067 - val_mae: 0.8676\n",
      "Epoch 42/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 6.4217 - mae: 0.5689 - val_loss: 5.6806 - val_mae: 0.6296\n",
      "Epoch 43/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 5.5248 - mae: 0.6067 - val_loss: 5.4590 - val_mae: 0.6913\n",
      "Epoch 44/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.7693 - mae: 0.3842 - val_loss: 5.5113 - val_mae: 0.7467\n",
      "Epoch 45/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5564 - mae: 0.2940 - val_loss: 4.9827 - val_mae: 0.6844\n",
      "Epoch 46/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.1326 - mae: 0.2539 - val_loss: 4.7998 - val_mae: 0.6638\n",
      "Epoch 47/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.0494 - mae: 0.3269 - val_loss: 6.3399 - val_mae: 1.0544\n",
      "Epoch 48/416\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.6350 - mae: 0.3817 - val_loss: 5.0638 - val_mae: 0.7604\n",
      "Epoch 49/416\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.1705 - mae: 0.2497 - val_loss: 4.5025 - val_mae: 0.6832\n",
      "Epoch 50/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.0404 - mae: 0.3224 - val_loss: 5.0309 - val_mae: 0.9617\n",
      "Epoch 51/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.7645 - mae: 0.2634 - val_loss: 4.3784 - val_mae: 0.7198\n",
      "Epoch 52/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.7535 - mae: 0.3136 - val_loss: 5.2640 - val_mae: 0.9219\n",
      "Epoch 53/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.1163 - mae: 0.4405 - val_loss: 4.7234 - val_mae: 0.8015\n",
      "Epoch 54/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.8250 - mae: 0.3060 - val_loss: 4.2079 - val_mae: 0.6060\n",
      "Epoch 55/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.8136 - mae: 0.2506 - val_loss: 4.2604 - val_mae: 0.6440\n",
      "Epoch 56/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.0799 - mae: 0.3211 - val_loss: 5.4293 - val_mae: 1.0711\n",
      "Epoch 57/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.8542 - mae: 0.2667 - val_loss: 4.6337 - val_mae: 0.8909\n",
      "Epoch 58/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.8512 - mae: 0.3353 - val_loss: 4.2629 - val_mae: 0.7315\n",
      "Epoch 59/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5867 - mae: 0.2213 - val_loss: 4.4457 - val_mae: 0.8491\n",
      "Epoch 60/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.7002 - mae: 0.2767 - val_loss: 4.1275 - val_mae: 0.6755\n",
      "Epoch 61/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5955 - mae: 0.2357 - val_loss: 4.2689 - val_mae: 0.7098\n",
      "Epoch 62/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.8439 - mae: 0.2731 - val_loss: 4.9984 - val_mae: 0.9114\n",
      "Epoch 63/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.7322 - mae: 0.2049 - val_loss: 4.9266 - val_mae: 0.9318\n",
      "Epoch 64/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6524 - mae: 0.1944 - val_loss: 5.0451 - val_mae: 0.9192\n",
      "Epoch 65/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.8646 - mae: 0.2800 - val_loss: 4.6143 - val_mae: 0.7683\n",
      "Epoch 66/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6852 - mae: 0.2109 - val_loss: 5.7849 - val_mae: 1.1200\n",
      "Epoch 67/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.8046 - mae: 0.2441 - val_loss: 4.5580 - val_mae: 0.8364\n",
      "Epoch 68/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5713 - mae: 0.1790 - val_loss: 4.4485 - val_mae: 0.7673\n",
      "Epoch 69/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5797 - mae: 0.1714 - val_loss: 4.1431 - val_mae: 0.6744\n",
      "Epoch 70/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6299 - mae: 0.2726 - val_loss: 4.3239 - val_mae: 0.7813\n",
      "Epoch 71/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5701 - mae: 0.2288 - val_loss: 4.4576 - val_mae: 0.7693\n",
      "Epoch 72/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6291 - mae: 0.2197 - val_loss: 4.0362 - val_mae: 0.6082\n",
      "Epoch 73/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.9611 - mae: 0.4350 - val_loss: 7.6939 - val_mae: 1.4721\n",
      "Epoch 74/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.1042 - mae: 0.2254 - val_loss: 4.8242 - val_mae: 0.7890\n",
      "Epoch 75/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.2305 - mae: 0.3410 - val_loss: 5.4611 - val_mae: 1.0393\n",
      "Epoch 76/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.8493 - mae: 0.2402 - val_loss: 4.9350 - val_mae: 0.8871\n",
      "Epoch 77/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.7934 - mae: 0.3108 - val_loss: 5.0964 - val_mae: 0.9982\n",
      "Epoch 78/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6849 - mae: 0.2548 - val_loss: 4.4039 - val_mae: 0.7779\n",
      "Epoch 79/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5918 - mae: 0.2422 - val_loss: 4.3245 - val_mae: 0.7230\n",
      "Epoch 80/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5826 - mae: 0.2170 - val_loss: 4.5063 - val_mae: 0.8169\n",
      "Epoch 81/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6332 - mae: 0.2452 - val_loss: 4.8140 - val_mae: 0.9178\n",
      "Epoch 82/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.8278 - mae: 0.2770 - val_loss: 4.8184 - val_mae: 0.8613\n",
      "Epoch 83/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.7445 - mae: 0.2749 - val_loss: 4.4946 - val_mae: 0.7973\n",
      "Epoch 84/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6364 - mae: 0.2407 - val_loss: 5.6105 - val_mae: 1.1057\n",
      "Epoch 85/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6020 - mae: 0.1683 - val_loss: 4.2240 - val_mae: 0.7199\n",
      "Epoch 86/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.7530 - mae: 0.2881 - val_loss: 4.6238 - val_mae: 0.8570\n",
      "Epoch 87/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.0281 - mae: 0.2968 - val_loss: 5.6743 - val_mae: 1.0815\n",
      "Epoch 88/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.8733 - mae: 0.2449 - val_loss: 5.3667 - val_mae: 1.0429\n",
      "Epoch 89/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.7551 - mae: 0.2332 - val_loss: 5.1950 - val_mae: 1.0024\n",
      "Epoch 90/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.6497 - mae: 0.1647 - val_loss: 4.5865 - val_mae: 0.8447\n",
      "Epoch 91/416\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.7542 - mae: 0.2608 - val_loss: 4.4214 - val_mae: 0.7830\n",
      "Epoch 92/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.7047 - mae: 0.3125 - val_loss: 4.2008 - val_mae: 0.6812\n",
      "Epoch 93/416\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.6240 - mae: 0.2864 - val_loss: 5.7349 - val_mae: 1.1022\n",
      "Epoch 94/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.8045 - mae: 0.2162 - val_loss: 4.8539 - val_mae: 0.8720\n",
      "Epoch 95/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.7437 - mae: 0.2668 - val_loss: 5.1116 - val_mae: 0.9599\n",
      "Epoch 96/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.7045 - mae: 0.2642 - val_loss: 4.3171 - val_mae: 0.7356\n",
      "Epoch 97/416\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.5661 - mae: 0.1969 - val_loss: 4.2260 - val_mae: 0.7546\n",
      "Epoch 98/416\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.7498 - mae: 0.3387 - val_loss: 5.2096 - val_mae: 1.0087\n",
      "Epoch 99/416\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.6641 - mae: 0.2044 - val_loss: 4.4292 - val_mae: 0.7645\n",
      "Epoch 100/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.6117 - mae: 0.2474 - val_loss: 4.3435 - val_mae: 0.7535\n",
      "Epoch 101/416\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.5223 - mae: 0.1806 - val_loss: 4.3851 - val_mae: 0.7946\n",
      "Epoch 102/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.6325 - mae: 0.3374 - val_loss: 4.2973 - val_mae: 0.7176\n",
      "Epoch 103/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.5704 - mae: 0.2116 - val_loss: 4.2025 - val_mae: 0.7400\n",
      "Epoch 104/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.5582 - mae: 0.2458 - val_loss: 4.3469 - val_mae: 0.7949\n",
      "Epoch 105/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.5843 - mae: 0.2297 - val_loss: 4.0659 - val_mae: 0.6478\n",
      "Epoch 106/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.7561 - mae: 0.2460 - val_loss: 4.6622 - val_mae: 0.8624\n",
      "Epoch 107/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.7792 - mae: 0.2711 - val_loss: 5.1069 - val_mae: 1.0193\n",
      "Epoch 108/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6367 - mae: 0.2137 - val_loss: 4.2632 - val_mae: 0.7440\n",
      "Epoch 109/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6948 - mae: 0.2360 - val_loss: 4.5314 - val_mae: 0.8268\n",
      "Epoch 110/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6252 - mae: 0.2211 - val_loss: 4.2838 - val_mae: 0.7456\n",
      "Epoch 111/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6191 - mae: 0.2149 - val_loss: 4.6736 - val_mae: 0.8475\n",
      "Epoch 112/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5784 - mae: 0.2105 - val_loss: 4.4540 - val_mae: 0.8123\n",
      "Epoch 113/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5328 - mae: 0.2087 - val_loss: 4.4146 - val_mae: 0.7876\n",
      "Epoch 114/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6039 - mae: 0.2846 - val_loss: 4.7009 - val_mae: 0.8789\n",
      "Epoch 115/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6345 - mae: 0.2670 - val_loss: 4.2341 - val_mae: 0.7037\n",
      "Epoch 116/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5504 - mae: 0.2030 - val_loss: 4.2261 - val_mae: 0.7488\n",
      "Epoch 117/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5828 - mae: 0.2554 - val_loss: 4.6830 - val_mae: 0.8975\n",
      "Epoch 118/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5345 - mae: 0.1929 - val_loss: 4.6552 - val_mae: 0.8752\n",
      "Epoch 119/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5928 - mae: 0.2370 - val_loss: 4.1111 - val_mae: 0.6706\n",
      "Epoch 120/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.7249 - mae: 0.2865 - val_loss: 6.5791 - val_mae: 1.3146\n",
      "Epoch 121/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.7058 - mae: 0.2712 - val_loss: 4.7203 - val_mae: 0.9358\n",
      "Epoch 122/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5503 - mae: 0.2073 - val_loss: 4.2722 - val_mae: 0.7370\n",
      "Epoch 123/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5502 - mae: 0.2205 - val_loss: 4.2432 - val_mae: 0.7324\n",
      "Epoch 124/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5848 - mae: 0.2312 - val_loss: 4.2268 - val_mae: 0.7366\n",
      "Epoch 125/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5672 - mae: 0.2590 - val_loss: 4.8347 - val_mae: 0.9134\n",
      "Epoch 126/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5123 - mae: 0.1428 - val_loss: 4.2636 - val_mae: 0.7576\n",
      "Epoch 127/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6191 - mae: 0.2314 - val_loss: 4.8193 - val_mae: 0.9448\n",
      "Epoch 128/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6069 - mae: 0.2506 - val_loss: 4.9398 - val_mae: 0.9622\n",
      "Epoch 129/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6277 - mae: 0.2989 - val_loss: 5.3835 - val_mae: 1.0457\n",
      "Epoch 130/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5569 - mae: 0.1514 - val_loss: 4.7860 - val_mae: 0.9009\n",
      "Epoch 131/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5531 - mae: 0.2372 - val_loss: 4.7173 - val_mae: 0.8820\n",
      "Epoch 132/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5123 - mae: 0.1809 - val_loss: 4.4120 - val_mae: 0.8108\n",
      "Epoch 133/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6533 - mae: 0.2337 - val_loss: 5.0686 - val_mae: 0.9891\n",
      "Epoch 134/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5581 - mae: 0.1868 - val_loss: 4.3016 - val_mae: 0.7704\n",
      "Epoch 135/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5630 - mae: 0.2416 - val_loss: 4.6113 - val_mae: 0.8649\n",
      "Epoch 136/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6373 - mae: 0.2820 - val_loss: 4.9242 - val_mae: 0.9456\n",
      "Epoch 137/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5456 - mae: 0.1894 - val_loss: 4.4854 - val_mae: 0.8449\n",
      "Epoch 138/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6776 - mae: 0.2913 - val_loss: 8.2597 - val_mae: 1.6414\n",
      "Epoch 139/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.7174 - mae: 0.2472 - val_loss: 4.7222 - val_mae: 0.9049\n",
      "Epoch 140/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6288 - mae: 0.2346 - val_loss: 4.7828 - val_mae: 0.9020\n",
      "Epoch 141/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.8370 - mae: 0.2697 - val_loss: 7.5461 - val_mae: 1.5186\n",
      "Epoch 142/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.9619 - mae: 0.3061 - val_loss: 7.2351 - val_mae: 1.4535\n",
      "Epoch 143/416\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.7618 - mae: 0.2191 - val_loss: 4.7557 - val_mae: 0.8720\n",
      "Epoch 144/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5970 - mae: 0.2153 - val_loss: 4.5057 - val_mae: 0.8246\n",
      "Epoch 145/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5127 - mae: 0.2044 - val_loss: 5.1308 - val_mae: 1.0054\n",
      "Epoch 146/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5925 - mae: 0.2289 - val_loss: 4.8463 - val_mae: 0.9237\n",
      "Epoch 147/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6087 - mae: 0.2747 - val_loss: 4.5588 - val_mae: 0.8591\n",
      "Epoch 148/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5387 - mae: 0.2194 - val_loss: 4.7761 - val_mae: 0.9102\n",
      "Epoch 149/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5673 - mae: 0.2437 - val_loss: 4.6631 - val_mae: 0.8948\n",
      "Epoch 150/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5292 - mae: 0.1880 - val_loss: 4.3371 - val_mae: 0.7558\n",
      "Epoch 151/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4936 - mae: 0.1718 - val_loss: 4.1611 - val_mae: 0.7152\n",
      "Epoch 152/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5141 - mae: 0.1766 - val_loss: 4.3380 - val_mae: 0.7480\n",
      "Epoch 153/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5451 - mae: 0.2054 - val_loss: 4.5216 - val_mae: 0.8446\n",
      "Epoch 154/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.6524 - mae: 0.3481 - val_loss: 6.1067 - val_mae: 1.2434\n",
      "Epoch 155/416\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.6513 - mae: 0.2169 - val_loss: 4.7163 - val_mae: 0.8762\n",
      "Epoch 156/416\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.5426 - mae: 0.1777 - val_loss: 5.4738 - val_mae: 1.1025\n",
      "Epoch 157/416\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.6460 - mae: 0.2997 - val_loss: 5.3241 - val_mae: 1.0555\n",
      "Epoch 158/416\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.6033 - mae: 0.2600 - val_loss: 6.0277 - val_mae: 1.2034\n",
      "Epoch 159/416\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.6457 - mae: 0.1755 - val_loss: 4.7827 - val_mae: 0.9185\n",
      "Epoch 160/416\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.5998 - mae: 0.2305 - val_loss: 7.1348 - val_mae: 1.4729\n",
      "Epoch 161/416\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.7380 - mae: 0.2387 - val_loss: 5.2452 - val_mae: 1.0332\n",
      "Epoch 162/416\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.6000 - mae: 0.1512 - val_loss: 5.7288 - val_mae: 1.1411\n",
      "Epoch 163/416\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.5516 - mae: 0.1291 - val_loss: 4.3832 - val_mae: 0.8053\n",
      "Epoch 164/416\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.5660 - mae: 0.2054 - val_loss: 4.3993 - val_mae: 0.7888\n",
      "Epoch 165/416\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.5138 - mae: 0.2064 - val_loss: 4.1345 - val_mae: 0.6768\n",
      "Epoch 166/416\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.5904 - mae: 0.2086 - val_loss: 4.5905 - val_mae: 0.8632\n",
      "Epoch 167/416\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.5313 - mae: 0.2195 - val_loss: 4.8494 - val_mae: 0.9342\n",
      "Epoch 168/416\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.5217 - mae: 0.2229 - val_loss: 4.5780 - val_mae: 0.8521\n",
      "Epoch 169/416\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.5305 - mae: 0.2278 - val_loss: 5.6640 - val_mae: 1.1614\n",
      "Epoch 170/416\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.7250 - mae: 0.3195 - val_loss: 5.1850 - val_mae: 1.0285\n",
      "Epoch 171/416\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.7517 - mae: 0.2864 - val_loss: 6.6711 - val_mae: 1.3504\n",
      "Epoch 172/416\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.7800 - mae: 0.3832 - val_loss: 4.5959 - val_mae: 0.8363\n",
      "Epoch 173/416\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.5380 - mae: 0.2322 - val_loss: 4.5452 - val_mae: 0.8134\n",
      "Epoch 174/416\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.6703 - mae: 0.3738 - val_loss: 6.6329 - val_mae: 1.3607\n",
      "Epoch 175/416\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.6749 - mae: 0.2251 - val_loss: 4.6119 - val_mae: 0.8595\n",
      "Epoch 176/416\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.5403 - mae: 0.1963 - val_loss: 4.5965 - val_mae: 0.8474\n",
      "Epoch 177/416\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.5497 - mae: 0.2207 - val_loss: 4.4239 - val_mae: 0.7998\n",
      "Epoch 178/416\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.5620 - mae: 0.2440 - val_loss: 4.7597 - val_mae: 0.9209\n",
      "Epoch 179/416\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.6273 - mae: 0.2888 - val_loss: 4.4881 - val_mae: 0.8384\n",
      "Epoch 180/416\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.5782 - mae: 0.2552 - val_loss: 5.4776 - val_mae: 1.0700\n",
      "Epoch 181/416\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.7684 - mae: 0.2262 - val_loss: 5.8148 - val_mae: 1.1908\n",
      "Epoch 182/416\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.5886 - mae: 0.2418 - val_loss: 4.5214 - val_mae: 0.8528\n",
      "Epoch 183/416\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.5113 - mae: 0.1866 - val_loss: 4.2427 - val_mae: 0.7524\n",
      "Epoch 184/416\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.5864 - mae: 0.2279 - val_loss: 4.2046 - val_mae: 0.7110\n",
      "Epoch 185/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.8061 - mae: 0.2934 - val_loss: 6.7133 - val_mae: 1.3644\n",
      "Epoch 186/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.6689 - mae: 0.2455 - val_loss: 7.2457 - val_mae: 1.4597\n",
      "Epoch 187/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6647 - mae: 0.2416 - val_loss: 4.7028 - val_mae: 0.8534\n",
      "Epoch 188/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6852 - mae: 0.3876 - val_loss: 4.0382 - val_mae: 0.5952\n",
      "Epoch 189/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.2021 - mae: 0.6493 - val_loss: 5.9676 - val_mae: 0.9763\n",
      "Epoch 190/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.3644 - mae: 0.6031 - val_loss: 18.3060 - val_mae: 3.1957\n",
      "Epoch 191/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.1658 - mae: 0.9455 - val_loss: 11.7223 - val_mae: 2.0298\n",
      "Epoch 192/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.6700 - mae: 1.1559 - val_loss: 15.0434 - val_mae: 2.5074\n",
      "Epoch 193/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.8368 - mae: 0.4976 - val_loss: 5.2151 - val_mae: 0.9126\n",
      "Epoch 194/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.0429 - mae: 0.3422 - val_loss: 4.6803 - val_mae: 0.8295\n",
      "Epoch 195/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.7378 - mae: 0.2671 - val_loss: 4.4605 - val_mae: 0.7830\n",
      "Epoch 196/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5534 - mae: 0.1597 - val_loss: 4.2988 - val_mae: 0.7569\n",
      "Epoch 197/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5061 - mae: 0.1842 - val_loss: 4.2286 - val_mae: 0.7422\n",
      "Epoch 198/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5090 - mae: 0.2101 - val_loss: 4.1328 - val_mae: 0.6853\n",
      "Epoch 199/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5145 - mae: 0.1650 - val_loss: 4.1703 - val_mae: 0.7078\n",
      "Epoch 200/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6144 - mae: 0.2824 - val_loss: 4.2962 - val_mae: 0.7520\n",
      "Epoch 201/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5183 - mae: 0.1836 - val_loss: 4.1407 - val_mae: 0.7197\n",
      "Epoch 202/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.0946 - mae: 0.3220 - val_loss: 7.6796 - val_mae: 1.5102\n",
      "Epoch 203/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.9523 - mae: 0.2160 - val_loss: 6.0564 - val_mae: 1.2063\n",
      "Epoch 204/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.8036 - mae: 0.2109 - val_loss: 5.1563 - val_mae: 0.9793\n",
      "Epoch 205/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6781 - mae: 0.2322 - val_loss: 4.6381 - val_mae: 0.8380\n",
      "Epoch 206/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5736 - mae: 0.2243 - val_loss: 4.2766 - val_mae: 0.7549\n",
      "Epoch 207/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4723 - mae: 0.1557 - val_loss: 4.2646 - val_mae: 0.7338\n",
      "Epoch 208/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5499 - mae: 0.2321 - val_loss: 4.4581 - val_mae: 0.8063\n",
      "Epoch 209/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5928 - mae: 0.2762 - val_loss: 4.3814 - val_mae: 0.7903\n",
      "Epoch 210/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5303 - mae: 0.1784 - val_loss: 4.0967 - val_mae: 0.6554\n",
      "Epoch 211/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4916 - mae: 0.1810 - val_loss: 4.1245 - val_mae: 0.7072\n",
      "Epoch 212/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5237 - mae: 0.1976 - val_loss: 4.1774 - val_mae: 0.6992\n",
      "Epoch 213/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5507 - mae: 0.2571 - val_loss: 4.6258 - val_mae: 0.8195\n",
      "Epoch 214/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5869 - mae: 0.2466 - val_loss: 4.1752 - val_mae: 0.6962\n",
      "Epoch 215/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6151 - mae: 0.3186 - val_loss: 4.1321 - val_mae: 0.7075\n",
      "Epoch 216/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4888 - mae: 0.1983 - val_loss: 4.2930 - val_mae: 0.7634\n",
      "Epoch 217/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5290 - mae: 0.2476 - val_loss: 4.4233 - val_mae: 0.8122\n",
      "Epoch 218/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6740 - mae: 0.3335 - val_loss: 4.2630 - val_mae: 0.7422\n",
      "Epoch 219/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.8470 - mae: 0.2987 - val_loss: 6.3972 - val_mae: 1.2967\n",
      "Epoch 220/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6812 - mae: 0.1788 - val_loss: 5.2170 - val_mae: 1.0151\n",
      "Epoch 221/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6870 - mae: 0.1888 - val_loss: 5.8451 - val_mae: 1.1647\n",
      "Epoch 222/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6679 - mae: 0.2475 - val_loss: 4.9047 - val_mae: 0.9667\n",
      "Epoch 223/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5870 - mae: 0.2542 - val_loss: 4.3319 - val_mae: 0.7879\n",
      "Epoch 224/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.9594 - mae: 0.3109 - val_loss: 7.0347 - val_mae: 1.3604\n",
      "Epoch 225/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.1514 - mae: 0.2613 - val_loss: 7.0103 - val_mae: 1.3701\n",
      "Epoch 226/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.9286 - mae: 0.2148 - val_loss: 6.2450 - val_mae: 1.2242\n",
      "Epoch 227/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.1179 - mae: 0.4140 - val_loss: 5.3756 - val_mae: 0.9763\n",
      "Epoch 228/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.8484 - mae: 0.2206 - val_loss: 5.0941 - val_mae: 0.9716\n",
      "Epoch 229/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6490 - mae: 0.1892 - val_loss: 4.7216 - val_mae: 0.8874\n",
      "Epoch 230/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5980 - mae: 0.2147 - val_loss: 4.5056 - val_mae: 0.8123\n",
      "Epoch 231/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5358 - mae: 0.1797 - val_loss: 4.3719 - val_mae: 0.8095\n",
      "Epoch 232/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4926 - mae: 0.1946 - val_loss: 4.3730 - val_mae: 0.7714\n",
      "Epoch 233/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5387 - mae: 0.2329 - val_loss: 4.8615 - val_mae: 0.8141\n",
      "Epoch 234/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.8246 - mae: 0.2418 - val_loss: 5.0814 - val_mae: 0.9784\n",
      "Epoch 235/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6266 - mae: 0.2491 - val_loss: 4.7475 - val_mae: 0.8914\n",
      "Epoch 236/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5047 - mae: 0.1485 - val_loss: 4.3766 - val_mae: 0.7819\n",
      "Epoch 237/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4740 - mae: 0.1566 - val_loss: 4.3598 - val_mae: 0.7946\n",
      "Epoch 238/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.5318 - mae: 0.2558 - val_loss: 4.4174 - val_mae: 0.8396\n",
      "Epoch 239/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6438 - mae: 0.3278 - val_loss: 4.2253 - val_mae: 0.6585\n",
      "Epoch 240/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6181 - mae: 0.3281 - val_loss: 4.1899 - val_mae: 0.6972\n",
      "Epoch 241/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5874 - mae: 0.3078 - val_loss: 4.5083 - val_mae: 0.8208\n",
      "Epoch 242/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6238 - mae: 0.3002 - val_loss: 4.3581 - val_mae: 0.7859\n",
      "Epoch 243/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5358 - mae: 0.2221 - val_loss: 4.4174 - val_mae: 0.8190\n",
      "Epoch 244/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5998 - mae: 0.3367 - val_loss: 4.7641 - val_mae: 0.8854\n",
      "Epoch 245/416\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.6076 - mae: 0.2622 - val_loss: 4.3181 - val_mae: 0.7635\n",
      "Epoch 246/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.5417 - mae: 0.2893 - val_loss: 4.2066 - val_mae: 0.7052\n",
      "Epoch 247/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.5805 - mae: 0.2701 - val_loss: 5.0256 - val_mae: 0.9861\n",
      "Epoch 248/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6561 - mae: 0.3135 - val_loss: 4.3509 - val_mae: 0.7769\n",
      "Epoch 249/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4881 - mae: 0.1900 - val_loss: 4.1500 - val_mae: 0.7331\n",
      "Epoch 250/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4799 - mae: 0.1916 - val_loss: 4.2429 - val_mae: 0.7403\n",
      "Epoch 251/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5146 - mae: 0.2420 - val_loss: 5.0213 - val_mae: 0.9611\n",
      "Epoch 252/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6030 - mae: 0.2747 - val_loss: 4.6069 - val_mae: 0.8403\n",
      "Epoch 253/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4927 - mae: 0.1861 - val_loss: 4.5289 - val_mae: 0.8479\n",
      "Epoch 254/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4730 - mae: 0.1681 - val_loss: 4.6380 - val_mae: 0.8666\n",
      "Epoch 255/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4855 - mae: 0.1624 - val_loss: 4.7663 - val_mae: 0.9009\n",
      "Epoch 256/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5427 - mae: 0.2639 - val_loss: 4.3863 - val_mae: 0.8210\n",
      "Epoch 257/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5138 - mae: 0.2311 - val_loss: 4.0723 - val_mae: 0.5761\n",
      "Epoch 258/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.3089 - mae: 0.4753 - val_loss: 6.3185 - val_mae: 1.2160\n",
      "Epoch 259/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.0105 - mae: 0.3073 - val_loss: 8.5354 - val_mae: 1.6790\n",
      "Epoch 260/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.8047 - mae: 0.2138 - val_loss: 6.3987 - val_mae: 1.2922\n",
      "Epoch 261/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.7336 - mae: 0.2231 - val_loss: 6.4789 - val_mae: 1.3063\n",
      "Epoch 262/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6767 - mae: 0.2418 - val_loss: 5.2360 - val_mae: 1.0199\n",
      "Epoch 263/416\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.6388 - mae: 0.2535 - val_loss: 4.3270 - val_mae: 0.7594\n",
      "Epoch 264/416\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.5198 - mae: 0.2143 - val_loss: 4.5980 - val_mae: 0.8718\n",
      "Epoch 265/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6960 - mae: 0.3561 - val_loss: 5.3891 - val_mae: 1.0967\n",
      "Epoch 266/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6113 - mae: 0.2194 - val_loss: 4.5593 - val_mae: 0.8409\n",
      "Epoch 267/416\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.5236 - mae: 0.2127 - val_loss: 4.2070 - val_mae: 0.7403\n",
      "Epoch 268/416\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.5099 - mae: 0.2199 - val_loss: 4.2785 - val_mae: 0.7513\n",
      "Epoch 269/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5140 - mae: 0.2372 - val_loss: 4.1330 - val_mae: 0.6916\n",
      "Epoch 270/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.5362 - mae: 0.2357 - val_loss: 4.1941 - val_mae: 0.7326\n",
      "Epoch 271/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5090 - mae: 0.2353 - val_loss: 4.3224 - val_mae: 0.7749\n",
      "Epoch 272/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4783 - mae: 0.1907 - val_loss: 4.3276 - val_mae: 0.7879\n",
      "Epoch 273/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4810 - mae: 0.1729 - val_loss: 4.4777 - val_mae: 0.8187\n",
      "Epoch 274/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4716 - mae: 0.1830 - val_loss: 4.1451 - val_mae: 0.7092\n",
      "Epoch 275/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6727 - mae: 0.3330 - val_loss: 4.8003 - val_mae: 0.9338\n",
      "Epoch 276/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5066 - mae: 0.1903 - val_loss: 4.3429 - val_mae: 0.7998\n",
      "Epoch 277/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5292 - mae: 0.2922 - val_loss: 4.2202 - val_mae: 0.7071\n",
      "Epoch 278/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5655 - mae: 0.2712 - val_loss: 4.6676 - val_mae: 0.9069\n",
      "Epoch 279/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5066 - mae: 0.2523 - val_loss: 4.1812 - val_mae: 0.7513\n",
      "Epoch 280/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4691 - mae: 0.1942 - val_loss: 4.3597 - val_mae: 0.8101\n",
      "Epoch 281/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5150 - mae: 0.2482 - val_loss: 5.4827 - val_mae: 1.1113\n",
      "Epoch 282/416\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.5067 - mae: 0.1694 - val_loss: 4.5902 - val_mae: 0.8559\n",
      "Epoch 283/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4963 - mae: 0.2215 - val_loss: 5.4957 - val_mae: 1.0904\n",
      "Epoch 284/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6459 - mae: 0.2627 - val_loss: 5.0628 - val_mae: 1.0004\n",
      "Epoch 285/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4945 - mae: 0.1622 - val_loss: 4.4437 - val_mae: 0.8121\n",
      "Epoch 286/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4598 - mae: 0.2046 - val_loss: 4.3059 - val_mae: 0.7829\n",
      "Epoch 287/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5284 - mae: 0.2547 - val_loss: 4.3320 - val_mae: 0.7613\n",
      "Epoch 288/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5518 - mae: 0.3196 - val_loss: 5.1956 - val_mae: 1.0537\n",
      "Epoch 289/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4944 - mae: 0.1863 - val_loss: 4.2558 - val_mae: 0.6962\n",
      "Epoch 290/416\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.6673 - mae: 0.3665 - val_loss: 5.1304 - val_mae: 1.0298\n",
      "Epoch 291/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.4858 - mae: 0.1696 - val_loss: 4.5473 - val_mae: 0.8508\n",
      "Epoch 292/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4508 - mae: 0.1687 - val_loss: 4.3389 - val_mae: 0.8012\n",
      "Epoch 293/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6128 - mae: 0.2650 - val_loss: 6.2369 - val_mae: 1.2729\n",
      "Epoch 294/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6668 - mae: 0.2468 - val_loss: 5.5325 - val_mae: 1.1306\n",
      "Epoch 295/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5289 - mae: 0.1725 - val_loss: 4.7089 - val_mae: 0.8901\n",
      "Epoch 296/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4945 - mae: 0.2131 - val_loss: 4.5533 - val_mae: 0.8504\n",
      "Epoch 297/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4582 - mae: 0.1947 - val_loss: 4.5592 - val_mae: 0.8491\n",
      "Epoch 298/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4806 - mae: 0.2196 - val_loss: 5.0831 - val_mae: 1.0137\n",
      "Epoch 299/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5815 - mae: 0.2458 - val_loss: 4.9499 - val_mae: 0.9957\n",
      "Epoch 300/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4643 - mae: 0.1760 - val_loss: 4.7754 - val_mae: 0.9227\n",
      "Epoch 301/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5744 - mae: 0.3254 - val_loss: 4.8268 - val_mae: 0.9496\n",
      "Epoch 302/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4403 - mae: 0.1431 - val_loss: 4.3310 - val_mae: 0.7984\n",
      "Epoch 303/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5272 - mae: 0.2438 - val_loss: 4.8834 - val_mae: 0.9655\n",
      "Epoch 304/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4816 - mae: 0.2010 - val_loss: 5.4641 - val_mae: 1.1055\n",
      "Epoch 305/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5050 - mae: 0.2436 - val_loss: 4.2713 - val_mae: 0.7569\n",
      "Epoch 306/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5168 - mae: 0.2666 - val_loss: 4.3318 - val_mae: 0.7441\n",
      "Epoch 307/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5194 - mae: 0.2757 - val_loss: 4.4692 - val_mae: 0.8504\n",
      "Epoch 308/416\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.5133 - mae: 0.2405 - val_loss: 4.8894 - val_mae: 0.9582\n",
      "Epoch 309/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.5308 - mae: 0.2485 - val_loss: 4.2137 - val_mae: 0.7609\n",
      "Epoch 310/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.4378 - mae: 0.1687 - val_loss: 4.4125 - val_mae: 0.8294\n",
      "Epoch 311/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4947 - mae: 0.2245 - val_loss: 4.7953 - val_mae: 0.9341\n",
      "Epoch 312/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4738 - mae: 0.2052 - val_loss: 5.8580 - val_mae: 1.1900\n",
      "Epoch 313/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5069 - mae: 0.2031 - val_loss: 4.6700 - val_mae: 0.8803\n",
      "Epoch 314/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4972 - mae: 0.2284 - val_loss: 4.4906 - val_mae: 0.8524\n",
      "Epoch 315/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6969 - mae: 0.3797 - val_loss: 6.6851 - val_mae: 1.4066\n",
      "Epoch 316/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.5187 - mae: 0.1730 - val_loss: 5.4109 - val_mae: 1.0963\n",
      "Epoch 317/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4571 - mae: 0.1415 - val_loss: 4.4828 - val_mae: 0.8298\n",
      "Epoch 318/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4361 - mae: 0.1597 - val_loss: 5.1947 - val_mae: 1.0580\n",
      "Epoch 319/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5460 - mae: 0.2303 - val_loss: 4.6552 - val_mae: 0.8898\n",
      "Epoch 320/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4869 - mae: 0.2282 - val_loss: 4.5730 - val_mae: 0.8554\n",
      "Epoch 321/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5073 - mae: 0.2395 - val_loss: 4.5344 - val_mae: 0.8685\n",
      "Epoch 322/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4571 - mae: 0.1792 - val_loss: 4.4420 - val_mae: 0.8244\n",
      "Epoch 323/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5125 - mae: 0.2866 - val_loss: 4.8934 - val_mae: 0.9830\n",
      "Epoch 324/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5681 - mae: 0.3268 - val_loss: 4.1499 - val_mae: 0.6621\n",
      "Epoch 325/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6576 - mae: 0.3614 - val_loss: 4.7104 - val_mae: 0.9196\n",
      "Epoch 326/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5211 - mae: 0.2617 - val_loss: 5.0797 - val_mae: 1.0151\n",
      "Epoch 327/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.4785 - mae: 0.2273 - val_loss: 4.5531 - val_mae: 0.8674\n",
      "Epoch 328/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6345 - mae: 0.2696 - val_loss: 5.8740 - val_mae: 1.2198\n",
      "Epoch 329/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5315 - mae: 0.1989 - val_loss: 4.9667 - val_mae: 0.9825\n",
      "Epoch 330/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5275 - mae: 0.2794 - val_loss: 4.4346 - val_mae: 0.8218\n",
      "Epoch 331/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4421 - mae: 0.1650 - val_loss: 4.5439 - val_mae: 0.8556\n",
      "Epoch 332/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5267 - mae: 0.2413 - val_loss: 5.0199 - val_mae: 1.0167\n",
      "Epoch 333/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4745 - mae: 0.1850 - val_loss: 4.1808 - val_mae: 0.7409\n",
      "Epoch 334/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4557 - mae: 0.1942 - val_loss: 4.9303 - val_mae: 0.9869\n",
      "Epoch 335/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5558 - mae: 0.3122 - val_loss: 4.7559 - val_mae: 0.9206\n",
      "Epoch 336/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4718 - mae: 0.1945 - val_loss: 4.5134 - val_mae: 0.8392\n",
      "Epoch 337/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4518 - mae: 0.1712 - val_loss: 4.1459 - val_mae: 0.6943\n",
      "Epoch 338/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5555 - mae: 0.2578 - val_loss: 5.0505 - val_mae: 1.0118\n",
      "Epoch 339/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5013 - mae: 0.2567 - val_loss: 4.3377 - val_mae: 0.8260\n",
      "Epoch 340/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4610 - mae: 0.2016 - val_loss: 4.3008 - val_mae: 0.7750\n",
      "Epoch 341/416\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.4803 - mae: 0.2166 - val_loss: 4.5591 - val_mae: 0.8732\n",
      "Epoch 342/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4522 - mae: 0.2090 - val_loss: 4.3588 - val_mae: 0.8125\n",
      "Epoch 343/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4729 - mae: 0.2098 - val_loss: 4.5594 - val_mae: 0.8833\n",
      "Epoch 344/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5369 - mae: 0.2606 - val_loss: 6.2677 - val_mae: 1.3168\n",
      "Epoch 345/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5530 - mae: 0.2407 - val_loss: 4.6967 - val_mae: 0.8813\n",
      "Epoch 346/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6110 - mae: 0.3038 - val_loss: 5.4209 - val_mae: 1.1152\n",
      "Epoch 347/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4861 - mae: 0.2254 - val_loss: 4.2083 - val_mae: 0.7501\n",
      "Epoch 348/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5450 - mae: 0.2714 - val_loss: 5.0261 - val_mae: 1.0169\n",
      "Epoch 349/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4737 - mae: 0.2200 - val_loss: 4.1966 - val_mae: 0.7233\n",
      "Epoch 350/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5744 - mae: 0.2808 - val_loss: 5.6498 - val_mae: 1.1610\n",
      "Epoch 351/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4963 - mae: 0.2226 - val_loss: 4.4551 - val_mae: 0.8216\n",
      "Epoch 352/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4844 - mae: 0.2257 - val_loss: 5.3593 - val_mae: 1.0901\n",
      "Epoch 353/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4399 - mae: 0.1698 - val_loss: 4.3367 - val_mae: 0.7822\n",
      "Epoch 354/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4484 - mae: 0.1934 - val_loss: 4.5378 - val_mae: 0.8753\n",
      "Epoch 355/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5650 - mae: 0.2505 - val_loss: 6.3267 - val_mae: 1.3296\n",
      "Epoch 356/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5340 - mae: 0.2290 - val_loss: 5.2314 - val_mae: 1.0756\n",
      "Epoch 357/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4730 - mae: 0.2110 - val_loss: 6.0327 - val_mae: 1.2755\n",
      "Epoch 358/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6410 - mae: 0.3164 - val_loss: 4.7020 - val_mae: 0.9100\n",
      "Epoch 359/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5011 - mae: 0.2266 - val_loss: 4.2575 - val_mae: 0.7764\n",
      "Epoch 360/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4459 - mae: 0.1909 - val_loss: 4.5289 - val_mae: 0.8600\n",
      "Epoch 361/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4758 - mae: 0.2128 - val_loss: 5.0292 - val_mae: 1.0229\n",
      "Epoch 362/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5220 - mae: 0.2916 - val_loss: 4.3825 - val_mae: 0.8009\n",
      "Epoch 363/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5499 - mae: 0.2796 - val_loss: 4.7618 - val_mae: 0.9278\n",
      "Epoch 364/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4445 - mae: 0.2024 - val_loss: 5.5018 - val_mae: 1.1399\n",
      "Epoch 365/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.4629 - mae: 0.1685 - val_loss: 4.0564 - val_mae: 0.6487\n",
      "Epoch 366/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6426 - mae: 0.2652 - val_loss: 7.8284 - val_mae: 1.6569\n",
      "Epoch 367/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5324 - mae: 0.2075 - val_loss: 4.7253 - val_mae: 0.9124\n",
      "Epoch 368/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4755 - mae: 0.2220 - val_loss: 4.8810 - val_mae: 0.9740\n",
      "Epoch 369/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5132 - mae: 0.2942 - val_loss: 6.0438 - val_mae: 1.2885\n",
      "Epoch 370/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6690 - mae: 0.4062 - val_loss: 4.3875 - val_mae: 0.8032\n",
      "Epoch 371/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5199 - mae: 0.3059 - val_loss: 5.7732 - val_mae: 1.2034\n",
      "Epoch 372/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5270 - mae: 0.2514 - val_loss: 4.7416 - val_mae: 0.9301\n",
      "Epoch 373/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4809 - mae: 0.2348 - val_loss: 5.6114 - val_mae: 1.1502\n",
      "Epoch 374/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4902 - mae: 0.2385 - val_loss: 4.4470 - val_mae: 0.8262\n",
      "Epoch 375/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4575 - mae: 0.1917 - val_loss: 5.5191 - val_mae: 1.1668\n",
      "Epoch 376/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5371 - mae: 0.2891 - val_loss: 4.6792 - val_mae: 0.9064\n",
      "Epoch 377/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5111 - mae: 0.2576 - val_loss: 5.1485 - val_mae: 1.0471\n",
      "Epoch 378/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4782 - mae: 0.2308 - val_loss: 4.2229 - val_mae: 0.7389\n",
      "Epoch 379/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4771 - mae: 0.1998 - val_loss: 4.4730 - val_mae: 0.8356\n",
      "Epoch 380/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5012 - mae: 0.2644 - val_loss: 4.6143 - val_mae: 0.9044\n",
      "Epoch 381/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4692 - mae: 0.2036 - val_loss: 5.4723 - val_mae: 1.1248\n",
      "Epoch 382/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4685 - mae: 0.1912 - val_loss: 4.2560 - val_mae: 0.7688\n",
      "Epoch 383/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4369 - mae: 0.1751 - val_loss: 4.8279 - val_mae: 0.9625\n",
      "Epoch 384/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4421 - mae: 0.1878 - val_loss: 5.6207 - val_mae: 1.1829\n",
      "Epoch 385/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5087 - mae: 0.2668 - val_loss: 4.4852 - val_mae: 0.8451\n",
      "Epoch 386/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4842 - mae: 0.1931 - val_loss: 4.6437 - val_mae: 0.8930\n",
      "Epoch 387/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.4166 - mae: 0.1539 - val_loss: 4.6297 - val_mae: 0.9118\n",
      "Epoch 388/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4815 - mae: 0.2294 - val_loss: 4.6630 - val_mae: 0.9062\n",
      "Epoch 389/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5302 - mae: 0.2900 - val_loss: 8.2043 - val_mae: 1.6892\n",
      "Epoch 390/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.7298 - mae: 0.3157 - val_loss: 7.4939 - val_mae: 1.5649\n",
      "Epoch 391/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5635 - mae: 0.2297 - val_loss: 5.6480 - val_mae: 1.1915\n",
      "Epoch 392/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5140 - mae: 0.2276 - val_loss: 4.8087 - val_mae: 0.9449\n",
      "Epoch 393/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4515 - mae: 0.2110 - val_loss: 4.4161 - val_mae: 0.8336\n",
      "Epoch 394/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5848 - mae: 0.2712 - val_loss: 4.9220 - val_mae: 0.9727\n",
      "Epoch 395/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5345 - mae: 0.2461 - val_loss: 4.6885 - val_mae: 0.9056\n",
      "Epoch 396/416\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.4329 - mae: 0.1792 - val_loss: 4.0673 - val_mae: 0.6684\n",
      "Epoch 397/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.6132 - mae: 0.2795 - val_loss: 5.2467 - val_mae: 1.0461\n",
      "Epoch 398/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5127 - mae: 0.2433 - val_loss: 4.8139 - val_mae: 0.9571\n",
      "Epoch 399/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5708 - mae: 0.2918 - val_loss: 7.0595 - val_mae: 1.4791\n",
      "Epoch 400/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5815 - mae: 0.2576 - val_loss: 5.1203 - val_mae: 1.0260\n",
      "Epoch 401/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4696 - mae: 0.1960 - val_loss: 4.2863 - val_mae: 0.7656\n",
      "Epoch 402/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4701 - mae: 0.2268 - val_loss: 4.4370 - val_mae: 0.8184\n",
      "Epoch 403/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4835 - mae: 0.2296 - val_loss: 7.2226 - val_mae: 1.4728\n",
      "Epoch 404/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5257 - mae: 0.1984 - val_loss: 4.6750 - val_mae: 0.8913\n",
      "Epoch 405/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4591 - mae: 0.1800 - val_loss: 4.5446 - val_mae: 0.8715\n",
      "Epoch 406/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4414 - mae: 0.1753 - val_loss: 5.0448 - val_mae: 0.9912\n",
      "Epoch 407/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4609 - mae: 0.2005 - val_loss: 4.3883 - val_mae: 0.8018\n",
      "Epoch 408/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.4736 - mae: 0.2315 - val_loss: 4.3222 - val_mae: 0.7908\n",
      "Epoch 409/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4324 - mae: 0.1579 - val_loss: 4.7318 - val_mae: 0.9399\n",
      "Epoch 410/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5063 - mae: 0.2086 - val_loss: 4.6171 - val_mae: 0.8752\n",
      "Epoch 411/416\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5130 - mae: 0.2886 - val_loss: 4.8278 - val_mae: 0.9584\n",
      "Epoch 412/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4627 - mae: 0.2094 - val_loss: 4.8596 - val_mae: 0.9678\n",
      "Epoch 413/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5002 - mae: 0.2565 - val_loss: 4.5982 - val_mae: 0.8890\n",
      "Epoch 414/416\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.4984 - mae: 0.2407 - val_loss: 5.3392 - val_mae: 1.1041\n",
      "Epoch 415/416\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4952 - mae: 0.2237 - val_loss: 4.3318 - val_mae: 0.7942\n",
      "Epoch 416/416\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.6266 - mae: 0.3645 - val_loss: 5.0730 - val_mae: 1.0197\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/mae</td><td>▅▆█▄▂▂▁▁▁▁▁▁▁▁▁▁▂▁▄▁▁▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>epoch/val_loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_mae</td><td>██▅▃▁▁▁▁▁▁▁▂▁▁▁▂▁▁▃▁▁▂▁▁▁▁▁▁▁▁▁▂▁▂▁▁▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>415</td></tr><tr><td>epoch/learning_rate</td><td>0.00922</td></tr><tr><td>epoch/loss</td><td>3.62659</td></tr><tr><td>epoch/mae</td><td>0.36454</td></tr><tr><td>epoch/val_loss</td><td>5.07303</td></tr><tr><td>epoch/val_mae</td><td>1.01974</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rich-sweep-5</strong> at: <a href='https://wandb.ai/grantbell/fred_dnn_sweep/runs/7hwb0a2q' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/runs/7hwb0a2q</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230719_171817-7hwb0a2q\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: r4av16n8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 412\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_initializer: he_normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1: 0.33053881905193166\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_l2: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2: 0.2370409823710122\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0047515366320530035\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: mse\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmetrics: mae\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\grant\\OneDrive\\Desktop\\vscode\\py_fin\\wandb\\run-20230719_171900-r4av16n8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/grantbell/fred_dnn_sweep/runs/r4av16n8' target=\"_blank\">expert-sweep-6</a></strong> to <a href='https://wandb.ai/grantbell/fred_dnn_sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/grantbell/fred_dnn_sweep' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/grantbell/fred_dnn_sweep/runs/r4av16n8' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/runs/r4av16n8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/412\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 686.9512 - mae: 5.0529 - val_loss: 626.7362 - val_mae: 2.7005\n",
      "Epoch 2/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 605.6407 - mae: 1.6690 - val_loss: 576.7087 - val_mae: 1.7816\n",
      "Epoch 3/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 559.9196 - mae: 1.1854 - val_loss: 534.3871 - val_mae: 1.6628\n",
      "Epoch 4/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 518.4536 - mae: 0.9683 - val_loss: 495.2191 - val_mae: 1.6828\n",
      "Epoch 5/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 479.6792 - mae: 0.8643 - val_loss: 457.4217 - val_mae: 1.5035\n",
      "Epoch 6/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 443.0617 - mae: 0.7676 - val_loss: 422.9987 - val_mae: 1.6960\n",
      "Epoch 7/412\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 408.7134 - mae: 0.7389 - val_loss: 389.2877 - val_mae: 1.5043\n",
      "Epoch 8/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 376.3201 - mae: 0.6755 - val_loss: 358.7883 - val_mae: 1.6548\n",
      "Epoch 9/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 345.9296 - mae: 0.6565 - val_loss: 328.8141 - val_mae: 1.4126\n",
      "Epoch 10/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 317.5293 - mae: 0.6461 - val_loss: 302.1556 - val_mae: 1.5546\n",
      "Epoch 11/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 290.9548 - mae: 0.6159 - val_loss: 277.1500 - val_mae: 1.6088\n",
      "Epoch 12/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 266.3479 - mae: 0.6322 - val_loss: 253.6534 - val_mae: 1.5630\n",
      "Epoch 13/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 243.4529 - mae: 0.6075 - val_loss: 231.6804 - val_mae: 1.5303\n",
      "Epoch 14/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 222.2999 - mae: 0.6257 - val_loss: 211.0993 - val_mae: 1.3911\n",
      "Epoch 15/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 202.7397 - mae: 0.6399 - val_loss: 192.9502 - val_mae: 1.5560\n",
      "Epoch 16/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 184.7167 - mae: 0.6846 - val_loss: 175.9257 - val_mae: 1.3729\n",
      "Epoch 17/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 167.9277 - mae: 0.5790 - val_loss: 159.4623 - val_mae: 1.3448\n",
      "Epoch 18/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 152.5816 - mae: 0.6051 - val_loss: 144.8977 - val_mae: 1.3333\n",
      "Epoch 19/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 138.4767 - mae: 0.5891 - val_loss: 132.4199 - val_mae: 1.5086\n",
      "Epoch 20/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 125.5957 - mae: 0.5216 - val_loss: 119.8159 - val_mae: 1.3861\n",
      "Epoch 21/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 113.9149 - mae: 0.5269 - val_loss: 109.5537 - val_mae: 1.6019\n",
      "Epoch 22/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 103.6617 - mae: 0.7105 - val_loss: 98.6265 - val_mae: 1.3028\n",
      "Epoch 23/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 93.6582 - mae: 0.5436 - val_loss: 90.0420 - val_mae: 1.4338\n",
      "Epoch 24/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 84.9836 - mae: 0.5195 - val_loss: 81.7936 - val_mae: 1.3856\n",
      "Epoch 25/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 77.1078 - mae: 0.5089 - val_loss: 75.2046 - val_mae: 1.4166\n",
      "Epoch 26/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 70.3482 - mae: 0.5606 - val_loss: 68.0532 - val_mae: 1.3438\n",
      "Epoch 27/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 63.7874 - mae: 0.4461 - val_loss: 62.3419 - val_mae: 1.3856\n",
      "Epoch 28/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 58.1447 - mae: 0.5148 - val_loss: 56.7398 - val_mae: 1.3591\n",
      "Epoch 29/412\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 52.9069 - mae: 0.4508 - val_loss: 51.5865 - val_mae: 1.2642\n",
      "Epoch 30/412\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 48.2650 - mae: 0.4667 - val_loss: 47.6218 - val_mae: 1.2958\n",
      "Epoch 31/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 44.0309 - mae: 0.4022 - val_loss: 43.4328 - val_mae: 1.2151\n",
      "Epoch 32/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 40.2675 - mae: 0.4000 - val_loss: 40.0109 - val_mae: 1.3029\n",
      "Epoch 33/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 36.8302 - mae: 0.3963 - val_loss: 36.6766 - val_mae: 1.2249\n",
      "Epoch 34/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 33.7104 - mae: 0.3745 - val_loss: 33.9124 - val_mae: 1.2288\n",
      "Epoch 35/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 30.8928 - mae: 0.3611 - val_loss: 30.9571 - val_mae: 1.1903\n",
      "Epoch 36/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.2297 - mae: 0.3326 - val_loss: 28.4444 - val_mae: 1.1771\n",
      "Epoch 37/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 25.8221 - mae: 0.3330 - val_loss: 26.1822 - val_mae: 1.1799\n",
      "Epoch 38/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 23.5716 - mae: 0.3250 - val_loss: 24.0604 - val_mae: 1.1764\n",
      "Epoch 39/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.5220 - mae: 0.3277 - val_loss: 22.1536 - val_mae: 1.1586\n",
      "Epoch 40/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 19.6485 - mae: 0.3024 - val_loss: 20.2623 - val_mae: 1.1458\n",
      "Epoch 41/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 17.8724 - mae: 0.2954 - val_loss: 18.3956 - val_mae: 1.1013\n",
      "Epoch 42/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 16.2447 - mae: 0.2944 - val_loss: 16.9862 - val_mae: 1.1201\n",
      "Epoch 43/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 14.7331 - mae: 0.2743 - val_loss: 15.4968 - val_mae: 1.1081\n",
      "Epoch 44/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 13.3507 - mae: 0.2756 - val_loss: 14.2698 - val_mae: 1.1074\n",
      "Epoch 45/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 12.1133 - mae: 0.2560 - val_loss: 12.9650 - val_mae: 1.0904\n",
      "Epoch 46/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.9923 - mae: 0.2796 - val_loss: 11.9838 - val_mae: 1.0778\n",
      "Epoch 47/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 9.9972 - mae: 0.2534 - val_loss: 10.9496 - val_mae: 1.0534\n",
      "Epoch 48/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 9.1200 - mae: 0.2646 - val_loss: 10.2110 - val_mae: 1.0571\n",
      "Epoch 49/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 8.3528 - mae: 0.2611 - val_loss: 9.2584 - val_mae: 1.0175\n",
      "Epoch 50/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.6666 - mae: 0.2839 - val_loss: 8.6352 - val_mae: 1.0038\n",
      "Epoch 51/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.0723 - mae: 0.2994 - val_loss: 7.9071 - val_mae: 0.9545\n",
      "Epoch 52/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.5486 - mae: 0.3097 - val_loss: 7.4488 - val_mae: 0.9374\n",
      "Epoch 53/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.0905 - mae: 0.3101 - val_loss: 6.9543 - val_mae: 0.9461\n",
      "Epoch 54/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.6843 - mae: 0.3316 - val_loss: 6.5878 - val_mae: 0.9330\n",
      "Epoch 55/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.3482 - mae: 0.3480 - val_loss: 6.1690 - val_mae: 0.9131\n",
      "Epoch 56/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.0563 - mae: 0.3617 - val_loss: 5.9472 - val_mae: 0.9110\n",
      "Epoch 57/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.8356 - mae: 0.3770 - val_loss: 5.6214 - val_mae: 0.8838\n",
      "Epoch 58/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.6656 - mae: 0.3841 - val_loss: 5.4904 - val_mae: 0.8686\n",
      "Epoch 59/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5524 - mae: 0.4050 - val_loss: 5.2916 - val_mae: 0.8571\n",
      "Epoch 60/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.4282 - mae: 0.3849 - val_loss: 5.3083 - val_mae: 0.8834\n",
      "Epoch 61/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.3716 - mae: 0.4225 - val_loss: 5.1215 - val_mae: 0.8589\n",
      "Epoch 62/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.2907 - mae: 0.4092 - val_loss: 5.1317 - val_mae: 0.8705\n",
      "Epoch 63/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.2452 - mae: 0.4232 - val_loss: 4.9544 - val_mae: 0.8410\n",
      "Epoch 64/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.1989 - mae: 0.4221 - val_loss: 4.9628 - val_mae: 0.8353\n",
      "Epoch 65/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.1610 - mae: 0.4173 - val_loss: 4.8709 - val_mae: 0.8369\n",
      "Epoch 66/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.1215 - mae: 0.4231 - val_loss: 4.9184 - val_mae: 0.8563\n",
      "Epoch 67/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.1170 - mae: 0.4358 - val_loss: 4.7938 - val_mae: 0.8271\n",
      "Epoch 68/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.0812 - mae: 0.4325 - val_loss: 4.9026 - val_mae: 0.8670\n",
      "Epoch 69/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.0475 - mae: 0.4255 - val_loss: 4.7832 - val_mae: 0.8410\n",
      "Epoch 70/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.0120 - mae: 0.4246 - val_loss: 4.7401 - val_mae: 0.8077\n",
      "Epoch 71/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.0009 - mae: 0.4069 - val_loss: 4.6904 - val_mae: 0.8159\n",
      "Epoch 72/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.9769 - mae: 0.4091 - val_loss: 4.7340 - val_mae: 0.8320\n",
      "Epoch 73/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.9586 - mae: 0.4009 - val_loss: 4.7751 - val_mae: 0.8533\n",
      "Epoch 74/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.9513 - mae: 0.4085 - val_loss: 4.7261 - val_mae: 0.8138\n",
      "Epoch 75/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.9545 - mae: 0.3879 - val_loss: 4.7733 - val_mae: 0.8541\n",
      "Epoch 76/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.9356 - mae: 0.3938 - val_loss: 4.8002 - val_mae: 0.8630\n",
      "Epoch 77/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.9340 - mae: 0.3952 - val_loss: 4.7248 - val_mae: 0.8389\n",
      "Epoch 78/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.9287 - mae: 0.3909 - val_loss: 4.7357 - val_mae: 0.8330\n",
      "Epoch 79/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.9282 - mae: 0.3770 - val_loss: 4.9697 - val_mae: 0.9178\n",
      "Epoch 80/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.9366 - mae: 0.3944 - val_loss: 4.7915 - val_mae: 0.8607\n",
      "Epoch 81/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.9294 - mae: 0.3864 - val_loss: 4.7980 - val_mae: 0.8591\n",
      "Epoch 82/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.9404 - mae: 0.3937 - val_loss: 4.8089 - val_mae: 0.8579\n",
      "Epoch 83/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.9147 - mae: 0.3622 - val_loss: 4.8089 - val_mae: 0.8576\n",
      "Epoch 84/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.9107 - mae: 0.3591 - val_loss: 4.8137 - val_mae: 0.8574\n",
      "Epoch 85/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.9074 - mae: 0.3605 - val_loss: 4.8163 - val_mae: 0.8583\n",
      "Epoch 86/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.9053 - mae: 0.3569 - val_loss: 4.7814 - val_mae: 0.8417\n",
      "Epoch 87/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.9146 - mae: 0.3528 - val_loss: 4.7951 - val_mae: 0.8409\n",
      "Epoch 88/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.9101 - mae: 0.3484 - val_loss: 4.8712 - val_mae: 0.8767\n",
      "Epoch 89/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.9071 - mae: 0.3522 - val_loss: 4.7971 - val_mae: 0.8521\n",
      "Epoch 90/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.9122 - mae: 0.3528 - val_loss: 4.8290 - val_mae: 0.8629\n",
      "Epoch 91/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8967 - mae: 0.3391 - val_loss: 4.8526 - val_mae: 0.8787\n",
      "Epoch 92/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8907 - mae: 0.3486 - val_loss: 4.8447 - val_mae: 0.8601\n",
      "Epoch 93/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8934 - mae: 0.3390 - val_loss: 4.8010 - val_mae: 0.8587\n",
      "Epoch 94/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8988 - mae: 0.3442 - val_loss: 4.8977 - val_mae: 0.8833\n",
      "Epoch 95/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8940 - mae: 0.3384 - val_loss: 4.8109 - val_mae: 0.8713\n",
      "Epoch 96/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8796 - mae: 0.3483 - val_loss: 4.9411 - val_mae: 0.8871\n",
      "Epoch 97/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8837 - mae: 0.3317 - val_loss: 4.7873 - val_mae: 0.8537\n",
      "Epoch 98/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8865 - mae: 0.3345 - val_loss: 4.8741 - val_mae: 0.8596\n",
      "Epoch 99/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8843 - mae: 0.3273 - val_loss: 4.8489 - val_mae: 0.8700\n",
      "Epoch 100/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8775 - mae: 0.3185 - val_loss: 4.8733 - val_mae: 0.8680\n",
      "Epoch 101/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8791 - mae: 0.3263 - val_loss: 4.8322 - val_mae: 0.8715\n",
      "Epoch 102/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8721 - mae: 0.3202 - val_loss: 4.8871 - val_mae: 0.8735\n",
      "Epoch 103/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8784 - mae: 0.3329 - val_loss: 4.8167 - val_mae: 0.8623\n",
      "Epoch 104/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8715 - mae: 0.3216 - val_loss: 4.9103 - val_mae: 0.8734\n",
      "Epoch 105/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8770 - mae: 0.3131 - val_loss: 4.8428 - val_mae: 0.8655\n",
      "Epoch 106/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8743 - mae: 0.3140 - val_loss: 4.9263 - val_mae: 0.8866\n",
      "Epoch 107/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8900 - mae: 0.3276 - val_loss: 4.8935 - val_mae: 0.8970\n",
      "Epoch 108/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8656 - mae: 0.3238 - val_loss: 4.9507 - val_mae: 0.8945\n",
      "Epoch 109/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8690 - mae: 0.3144 - val_loss: 4.8751 - val_mae: 0.8895\n",
      "Epoch 110/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8626 - mae: 0.3193 - val_loss: 4.8816 - val_mae: 0.8669\n",
      "Epoch 111/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8756 - mae: 0.3088 - val_loss: 4.8782 - val_mae: 0.8878\n",
      "Epoch 112/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.8583 - mae: 0.3171 - val_loss: 4.9421 - val_mae: 0.8831\n",
      "Epoch 113/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8690 - mae: 0.3003 - val_loss: 4.9195 - val_mae: 0.9028\n",
      "Epoch 114/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8546 - mae: 0.3060 - val_loss: 5.0187 - val_mae: 0.9220\n",
      "Epoch 115/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8609 - mae: 0.3162 - val_loss: 4.8798 - val_mae: 0.8749\n",
      "Epoch 116/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8563 - mae: 0.2935 - val_loss: 4.9318 - val_mae: 0.8857\n",
      "Epoch 117/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8568 - mae: 0.3001 - val_loss: 4.9231 - val_mae: 0.9025\n",
      "Epoch 118/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8554 - mae: 0.3052 - val_loss: 4.9513 - val_mae: 0.8846\n",
      "Epoch 119/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8581 - mae: 0.2908 - val_loss: 4.9114 - val_mae: 0.8908\n",
      "Epoch 120/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8560 - mae: 0.2971 - val_loss: 4.9602 - val_mae: 0.8902\n",
      "Epoch 121/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8539 - mae: 0.2910 - val_loss: 4.9369 - val_mae: 0.8991\n",
      "Epoch 122/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8495 - mae: 0.2911 - val_loss: 5.0408 - val_mae: 0.9286\n",
      "Epoch 123/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.8502 - mae: 0.2953 - val_loss: 4.9098 - val_mae: 0.8952\n",
      "Epoch 124/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8424 - mae: 0.2898 - val_loss: 4.9565 - val_mae: 0.8981\n",
      "Epoch 125/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8490 - mae: 0.2879 - val_loss: 4.9341 - val_mae: 0.8988\n",
      "Epoch 126/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8407 - mae: 0.2845 - val_loss: 5.0143 - val_mae: 0.9165\n",
      "Epoch 127/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8430 - mae: 0.2893 - val_loss: 4.9461 - val_mae: 0.9027\n",
      "Epoch 128/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8382 - mae: 0.2783 - val_loss: 4.9521 - val_mae: 0.8853\n",
      "Epoch 129/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8461 - mae: 0.2821 - val_loss: 4.9941 - val_mae: 0.9198\n",
      "Epoch 130/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8362 - mae: 0.2766 - val_loss: 4.9599 - val_mae: 0.8835\n",
      "Epoch 131/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8440 - mae: 0.2721 - val_loss: 5.0030 - val_mae: 0.9266\n",
      "Epoch 132/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8417 - mae: 0.2771 - val_loss: 4.9795 - val_mae: 0.9017\n",
      "Epoch 133/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8417 - mae: 0.2809 - val_loss: 4.9528 - val_mae: 0.9071\n",
      "Epoch 134/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8327 - mae: 0.2685 - val_loss: 5.0681 - val_mae: 0.9379\n",
      "Epoch 135/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8422 - mae: 0.2826 - val_loss: 4.9632 - val_mae: 0.9091\n",
      "Epoch 136/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8329 - mae: 0.2716 - val_loss: 5.0041 - val_mae: 0.9084\n",
      "Epoch 137/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.8391 - mae: 0.2764 - val_loss: 5.0121 - val_mae: 0.9317\n",
      "Epoch 138/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8404 - mae: 0.2780 - val_loss: 5.0126 - val_mae: 0.9168\n",
      "Epoch 139/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.8316 - mae: 0.2709 - val_loss: 4.9669 - val_mae: 0.9132\n",
      "Epoch 140/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8281 - mae: 0.2724 - val_loss: 5.0100 - val_mae: 0.9178\n",
      "Epoch 141/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8348 - mae: 0.2719 - val_loss: 4.9690 - val_mae: 0.9152\n",
      "Epoch 142/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8263 - mae: 0.2703 - val_loss: 5.0074 - val_mae: 0.9082\n",
      "Epoch 143/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8287 - mae: 0.2602 - val_loss: 4.9976 - val_mae: 0.9157\n",
      "Epoch 144/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8303 - mae: 0.2631 - val_loss: 5.0057 - val_mae: 0.9071\n",
      "Epoch 145/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.8316 - mae: 0.2593 - val_loss: 4.9838 - val_mae: 0.9152\n",
      "Epoch 146/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8287 - mae: 0.2606 - val_loss: 5.0170 - val_mae: 0.9183\n",
      "Epoch 147/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8281 - mae: 0.2600 - val_loss: 5.0220 - val_mae: 0.9199\n",
      "Epoch 148/412\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.8228 - mae: 0.2501 - val_loss: 5.0125 - val_mae: 0.9161\n",
      "Epoch 149/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8254 - mae: 0.2595 - val_loss: 5.0361 - val_mae: 0.9362\n",
      "Epoch 150/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8380 - mae: 0.2731 - val_loss: 5.0071 - val_mae: 0.9172\n",
      "Epoch 151/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8220 - mae: 0.2585 - val_loss: 5.0058 - val_mae: 0.9182\n",
      "Epoch 152/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8195 - mae: 0.2556 - val_loss: 5.0078 - val_mae: 0.9096\n",
      "Epoch 153/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8247 - mae: 0.2541 - val_loss: 4.9928 - val_mae: 0.9139\n",
      "Epoch 154/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8185 - mae: 0.2508 - val_loss: 5.0322 - val_mae: 0.9265\n",
      "Epoch 155/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.8188 - mae: 0.2517 - val_loss: 5.0081 - val_mae: 0.9202\n",
      "Epoch 156/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8234 - mae: 0.2567 - val_loss: 5.0370 - val_mae: 0.9310\n",
      "Epoch 157/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8190 - mae: 0.2613 - val_loss: 5.0430 - val_mae: 0.9341\n",
      "Epoch 158/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8146 - mae: 0.2514 - val_loss: 5.0408 - val_mae: 0.9294\n",
      "Epoch 159/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8162 - mae: 0.2559 - val_loss: 4.9956 - val_mae: 0.9171\n",
      "Epoch 160/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.8167 - mae: 0.2551 - val_loss: 5.0129 - val_mae: 0.9170\n",
      "Epoch 161/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8156 - mae: 0.2497 - val_loss: 5.0043 - val_mae: 0.9168\n",
      "Epoch 162/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8130 - mae: 0.2416 - val_loss: 5.1263 - val_mae: 0.9550\n",
      "Epoch 163/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8176 - mae: 0.2447 - val_loss: 5.0592 - val_mae: 0.9467\n",
      "Epoch 164/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.8167 - mae: 0.2617 - val_loss: 5.0827 - val_mae: 0.9406\n",
      "Epoch 165/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8122 - mae: 0.2485 - val_loss: 5.0410 - val_mae: 0.9318\n",
      "Epoch 166/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8097 - mae: 0.2448 - val_loss: 5.0581 - val_mae: 0.9275\n",
      "Epoch 167/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8120 - mae: 0.2376 - val_loss: 4.9809 - val_mae: 0.9191\n",
      "Epoch 168/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8105 - mae: 0.2514 - val_loss: 5.0961 - val_mae: 0.9476\n",
      "Epoch 169/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.8159 - mae: 0.2480 - val_loss: 5.0543 - val_mae: 0.9444\n",
      "Epoch 170/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8109 - mae: 0.2518 - val_loss: 5.0208 - val_mae: 0.9177\n",
      "Epoch 171/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8114 - mae: 0.2460 - val_loss: 5.0255 - val_mae: 0.9242\n",
      "Epoch 172/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.8103 - mae: 0.2354 - val_loss: 5.0790 - val_mae: 0.9403\n",
      "Epoch 173/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8084 - mae: 0.2439 - val_loss: 5.0399 - val_mae: 0.9350\n",
      "Epoch 174/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8047 - mae: 0.2386 - val_loss: 5.0629 - val_mae: 0.9327\n",
      "Epoch 175/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8103 - mae: 0.2351 - val_loss: 5.1337 - val_mae: 0.9701\n",
      "Epoch 176/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8132 - mae: 0.2460 - val_loss: 5.1078 - val_mae: 0.9500\n",
      "Epoch 177/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8071 - mae: 0.2428 - val_loss: 5.0169 - val_mae: 0.9277\n",
      "Epoch 178/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8032 - mae: 0.2388 - val_loss: 5.0478 - val_mae: 0.9242\n",
      "Epoch 179/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8144 - mae: 0.2394 - val_loss: 5.0280 - val_mae: 0.9284\n",
      "Epoch 180/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8037 - mae: 0.2397 - val_loss: 5.0817 - val_mae: 0.9436\n",
      "Epoch 181/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8093 - mae: 0.2434 - val_loss: 5.0314 - val_mae: 0.9355\n",
      "Epoch 182/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8017 - mae: 0.2420 - val_loss: 5.0506 - val_mae: 0.9231\n",
      "Epoch 183/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8036 - mae: 0.2311 - val_loss: 5.0405 - val_mae: 0.9315\n",
      "Epoch 184/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7999 - mae: 0.2322 - val_loss: 5.0614 - val_mae: 0.9215\n",
      "Epoch 185/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.8054 - mae: 0.2231 - val_loss: 5.0171 - val_mae: 0.9280\n",
      "Epoch 186/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7982 - mae: 0.2321 - val_loss: 5.0690 - val_mae: 0.9320\n",
      "Epoch 187/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8010 - mae: 0.2320 - val_loss: 5.0940 - val_mae: 0.9544\n",
      "Epoch 188/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7975 - mae: 0.2318 - val_loss: 5.1094 - val_mae: 0.9508\n",
      "Epoch 189/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8002 - mae: 0.2332 - val_loss: 5.0338 - val_mae: 0.9337\n",
      "Epoch 190/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8019 - mae: 0.2361 - val_loss: 5.1385 - val_mae: 0.9624\n",
      "Epoch 191/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8034 - mae: 0.2394 - val_loss: 5.0381 - val_mae: 0.9352\n",
      "Epoch 192/412\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.7960 - mae: 0.2337 - val_loss: 5.0338 - val_mae: 0.9166\n",
      "Epoch 193/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7984 - mae: 0.2279 - val_loss: 5.0573 - val_mae: 0.9392\n",
      "Epoch 194/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7937 - mae: 0.2259 - val_loss: 5.1073 - val_mae: 0.9509\n",
      "Epoch 195/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7969 - mae: 0.2353 - val_loss: 5.0449 - val_mae: 0.9346\n",
      "Epoch 196/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7945 - mae: 0.2282 - val_loss: 5.0798 - val_mae: 0.9397\n",
      "Epoch 197/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7994 - mae: 0.2292 - val_loss: 4.9911 - val_mae: 0.9121\n",
      "Epoch 198/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7989 - mae: 0.2314 - val_loss: 5.0463 - val_mae: 0.9337\n",
      "Epoch 199/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7970 - mae: 0.2329 - val_loss: 5.0966 - val_mae: 0.9570\n",
      "Epoch 200/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7917 - mae: 0.2317 - val_loss: 5.0195 - val_mae: 0.9130\n",
      "Epoch 201/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7968 - mae: 0.2247 - val_loss: 5.0275 - val_mae: 0.9301\n",
      "Epoch 202/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8124 - mae: 0.2408 - val_loss: 5.0886 - val_mae: 0.9480\n",
      "Epoch 203/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7956 - mae: 0.2283 - val_loss: 5.1309 - val_mae: 0.9694\n",
      "Epoch 204/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7929 - mae: 0.2382 - val_loss: 5.0737 - val_mae: 0.9312\n",
      "Epoch 205/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7916 - mae: 0.2176 - val_loss: 5.0926 - val_mae: 0.9583\n",
      "Epoch 206/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7968 - mae: 0.2326 - val_loss: 5.1004 - val_mae: 0.9446\n",
      "Epoch 207/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7908 - mae: 0.2201 - val_loss: 5.0287 - val_mae: 0.9352\n",
      "Epoch 208/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7873 - mae: 0.2242 - val_loss: 5.0968 - val_mae: 0.9481\n",
      "Epoch 209/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7913 - mae: 0.2272 - val_loss: 4.9948 - val_mae: 0.9218\n",
      "Epoch 210/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7857 - mae: 0.2250 - val_loss: 5.0792 - val_mae: 0.9358\n",
      "Epoch 211/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7938 - mae: 0.2273 - val_loss: 5.1689 - val_mae: 0.9802\n",
      "Epoch 212/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7950 - mae: 0.2292 - val_loss: 5.1039 - val_mae: 0.9434\n",
      "Epoch 213/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7885 - mae: 0.2185 - val_loss: 5.0615 - val_mae: 0.9539\n",
      "Epoch 214/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7896 - mae: 0.2338 - val_loss: 5.0677 - val_mae: 0.9195\n",
      "Epoch 215/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8013 - mae: 0.2170 - val_loss: 5.0303 - val_mae: 0.9427\n",
      "Epoch 216/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7835 - mae: 0.2260 - val_loss: 5.0833 - val_mae: 0.9342\n",
      "Epoch 217/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7876 - mae: 0.2147 - val_loss: 5.0585 - val_mae: 0.9495\n",
      "Epoch 218/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7910 - mae: 0.2326 - val_loss: 5.0480 - val_mae: 0.9129\n",
      "Epoch 219/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7926 - mae: 0.2165 - val_loss: 5.0495 - val_mae: 0.9455\n",
      "Epoch 220/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7788 - mae: 0.2158 - val_loss: 5.1103 - val_mae: 0.9532\n",
      "Epoch 221/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7871 - mae: 0.2240 - val_loss: 5.0245 - val_mae: 0.9315\n",
      "Epoch 222/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7791 - mae: 0.2139 - val_loss: 5.1736 - val_mae: 0.9715\n",
      "Epoch 223/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7883 - mae: 0.2218 - val_loss: 5.0497 - val_mae: 0.9328\n",
      "Epoch 224/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7802 - mae: 0.2068 - val_loss: 5.1295 - val_mae: 0.9583\n",
      "Epoch 225/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7830 - mae: 0.2176 - val_loss: 5.0416 - val_mae: 0.9402\n",
      "Epoch 226/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7864 - mae: 0.2229 - val_loss: 5.0885 - val_mae: 0.9425\n",
      "Epoch 227/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7806 - mae: 0.2093 - val_loss: 5.0970 - val_mae: 0.9622\n",
      "Epoch 228/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7864 - mae: 0.2250 - val_loss: 5.0780 - val_mae: 0.9425\n",
      "Epoch 229/412\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.7799 - mae: 0.2221 - val_loss: 5.0607 - val_mae: 0.9479\n",
      "Epoch 230/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7762 - mae: 0.2163 - val_loss: 5.1373 - val_mae: 0.9620\n",
      "Epoch 231/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7796 - mae: 0.2202 - val_loss: 5.0564 - val_mae: 0.9433\n",
      "Epoch 232/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7780 - mae: 0.2157 - val_loss: 5.0500 - val_mae: 0.9279\n",
      "Epoch 233/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7818 - mae: 0.2139 - val_loss: 5.1461 - val_mae: 0.9742\n",
      "Epoch 234/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7766 - mae: 0.2093 - val_loss: 5.1070 - val_mae: 0.9566\n",
      "Epoch 235/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7769 - mae: 0.2149 - val_loss: 5.0541 - val_mae: 0.9459\n",
      "Epoch 236/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7744 - mae: 0.2137 - val_loss: 5.0873 - val_mae: 0.9526\n",
      "Epoch 237/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7757 - mae: 0.2162 - val_loss: 5.0998 - val_mae: 0.9588\n",
      "Epoch 238/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7733 - mae: 0.2141 - val_loss: 5.0783 - val_mae: 0.9497\n",
      "Epoch 239/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7760 - mae: 0.2175 - val_loss: 5.0875 - val_mae: 0.9534\n",
      "Epoch 240/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7731 - mae: 0.2151 - val_loss: 5.0494 - val_mae: 0.9283\n",
      "Epoch 241/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7775 - mae: 0.2094 - val_loss: 5.0732 - val_mae: 0.9379\n",
      "Epoch 242/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7731 - mae: 0.2042 - val_loss: 5.1265 - val_mae: 0.9621\n",
      "Epoch 243/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7749 - mae: 0.2094 - val_loss: 5.0944 - val_mae: 0.9555\n",
      "Epoch 244/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7758 - mae: 0.2214 - val_loss: 5.0650 - val_mae: 0.9348\n",
      "Epoch 245/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7729 - mae: 0.2006 - val_loss: 5.1137 - val_mae: 0.9585\n",
      "Epoch 246/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7734 - mae: 0.2088 - val_loss: 5.0898 - val_mae: 0.9465\n",
      "Epoch 247/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7745 - mae: 0.2085 - val_loss: 5.0867 - val_mae: 0.9483\n",
      "Epoch 248/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7696 - mae: 0.2014 - val_loss: 5.0997 - val_mae: 0.9550\n",
      "Epoch 249/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7693 - mae: 0.2065 - val_loss: 5.1810 - val_mae: 0.9833\n",
      "Epoch 250/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7749 - mae: 0.2117 - val_loss: 5.0906 - val_mae: 0.9505\n",
      "Epoch 251/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7705 - mae: 0.2041 - val_loss: 5.1241 - val_mae: 0.9662\n",
      "Epoch 252/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7712 - mae: 0.2089 - val_loss: 5.0720 - val_mae: 0.9426\n",
      "Epoch 253/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7675 - mae: 0.2059 - val_loss: 5.0778 - val_mae: 0.9418\n",
      "Epoch 254/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7692 - mae: 0.2048 - val_loss: 5.0921 - val_mae: 0.9526\n",
      "Epoch 255/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7671 - mae: 0.2018 - val_loss: 5.1038 - val_mae: 0.9544\n",
      "Epoch 256/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7671 - mae: 0.2026 - val_loss: 5.1776 - val_mae: 0.9829\n",
      "Epoch 257/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7681 - mae: 0.2081 - val_loss: 5.1110 - val_mae: 0.9523\n",
      "Epoch 258/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7687 - mae: 0.2021 - val_loss: 5.0957 - val_mae: 0.9576\n",
      "Epoch 259/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7652 - mae: 0.2038 - val_loss: 5.1165 - val_mae: 0.9503\n",
      "Epoch 260/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7731 - mae: 0.2056 - val_loss: 5.0962 - val_mae: 0.9550\n",
      "Epoch 261/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7655 - mae: 0.2005 - val_loss: 5.1289 - val_mae: 0.9629\n",
      "Epoch 262/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7662 - mae: 0.2047 - val_loss: 5.1029 - val_mae: 0.9493\n",
      "Epoch 263/412\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.7657 - mae: 0.1924 - val_loss: 5.0912 - val_mae: 0.9463\n",
      "Epoch 264/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7656 - mae: 0.2005 - val_loss: 5.0454 - val_mae: 0.9416\n",
      "Epoch 265/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7633 - mae: 0.2021 - val_loss: 5.0995 - val_mae: 0.9571\n",
      "Epoch 266/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7634 - mae: 0.2051 - val_loss: 5.1104 - val_mae: 0.9648\n",
      "Epoch 267/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7644 - mae: 0.2077 - val_loss: 5.0486 - val_mae: 0.9293\n",
      "Epoch 268/412\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.7678 - mae: 0.1974 - val_loss: 5.0586 - val_mae: 0.9473\n",
      "Epoch 269/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7675 - mae: 0.2091 - val_loss: 5.0661 - val_mae: 0.9378\n",
      "Epoch 270/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7706 - mae: 0.2056 - val_loss: 5.0748 - val_mae: 0.9492\n",
      "Epoch 271/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7612 - mae: 0.2050 - val_loss: 5.0406 - val_mae: 0.9272\n",
      "Epoch 272/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7665 - mae: 0.1975 - val_loss: 5.1529 - val_mae: 0.9739\n",
      "Epoch 273/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7617 - mae: 0.2019 - val_loss: 5.0938 - val_mae: 0.9471\n",
      "Epoch 274/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7611 - mae: 0.1942 - val_loss: 5.0476 - val_mae: 0.9402\n",
      "Epoch 275/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7649 - mae: 0.2048 - val_loss: 5.0904 - val_mae: 0.9547\n",
      "Epoch 276/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7598 - mae: 0.2032 - val_loss: 5.1301 - val_mae: 0.9676\n",
      "Epoch 277/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7617 - mae: 0.2048 - val_loss: 5.1073 - val_mae: 0.9619\n",
      "Epoch 278/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7595 - mae: 0.1985 - val_loss: 5.1246 - val_mae: 0.9648\n",
      "Epoch 279/412\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.7656 - mae: 0.2076 - val_loss: 5.0361 - val_mae: 0.9353\n",
      "Epoch 280/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7588 - mae: 0.1989 - val_loss: 5.0906 - val_mae: 0.9452\n",
      "Epoch 281/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7604 - mae: 0.1951 - val_loss: 5.0797 - val_mae: 0.9486\n",
      "Epoch 282/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7580 - mae: 0.1948 - val_loss: 5.1152 - val_mae: 0.9584\n",
      "Epoch 283/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7594 - mae: 0.2022 - val_loss: 5.1370 - val_mae: 0.9753\n",
      "Epoch 284/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7584 - mae: 0.1987 - val_loss: 5.1026 - val_mae: 0.9464\n",
      "Epoch 285/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7595 - mae: 0.1949 - val_loss: 5.0851 - val_mae: 0.9585\n",
      "Epoch 286/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7574 - mae: 0.1987 - val_loss: 5.0929 - val_mae: 0.9502\n",
      "Epoch 287/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7644 - mae: 0.2077 - val_loss: 5.0895 - val_mae: 0.9606\n",
      "Epoch 288/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7548 - mae: 0.1995 - val_loss: 5.1494 - val_mae: 0.9662\n",
      "Epoch 289/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7579 - mae: 0.1949 - val_loss: 5.1445 - val_mae: 0.9787\n",
      "Epoch 290/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7592 - mae: 0.2042 - val_loss: 5.0845 - val_mae: 0.9397\n",
      "Epoch 291/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7617 - mae: 0.1916 - val_loss: 5.1202 - val_mae: 0.9692\n",
      "Epoch 292/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7617 - mae: 0.2043 - val_loss: 5.1082 - val_mae: 0.9561\n",
      "Epoch 293/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7551 - mae: 0.1905 - val_loss: 5.2528 - val_mae: 1.0054\n",
      "Epoch 294/412\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.7682 - mae: 0.2049 - val_loss: 5.1235 - val_mae: 0.9628\n",
      "Epoch 295/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7594 - mae: 0.1993 - val_loss: 5.1834 - val_mae: 0.9865\n",
      "Epoch 296/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7600 - mae: 0.2009 - val_loss: 5.0613 - val_mae: 0.9395\n",
      "Epoch 297/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7549 - mae: 0.1918 - val_loss: 5.1801 - val_mae: 0.9842\n",
      "Epoch 298/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7564 - mae: 0.1944 - val_loss: 5.1313 - val_mae: 0.9603\n",
      "Epoch 299/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7564 - mae: 0.1940 - val_loss: 5.0512 - val_mae: 0.9420\n",
      "Epoch 300/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7520 - mae: 0.1893 - val_loss: 5.0581 - val_mae: 0.9350\n",
      "Epoch 301/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7534 - mae: 0.1921 - val_loss: 5.0883 - val_mae: 0.9544\n",
      "Epoch 302/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7511 - mae: 0.1958 - val_loss: 5.1089 - val_mae: 0.9603\n",
      "Epoch 303/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7566 - mae: 0.1986 - val_loss: 5.1003 - val_mae: 0.9543\n",
      "Epoch 304/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7516 - mae: 0.1914 - val_loss: 5.1039 - val_mae: 0.9623\n",
      "Epoch 305/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7525 - mae: 0.1978 - val_loss: 5.1214 - val_mae: 0.9663\n",
      "Epoch 306/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7493 - mae: 0.1955 - val_loss: 5.1096 - val_mae: 0.9606\n",
      "Epoch 307/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7500 - mae: 0.1974 - val_loss: 5.0876 - val_mae: 0.9556\n",
      "Epoch 308/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7498 - mae: 0.1924 - val_loss: 5.1284 - val_mae: 0.9578\n",
      "Epoch 309/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7502 - mae: 0.1873 - val_loss: 5.0779 - val_mae: 0.9533\n",
      "Epoch 310/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7486 - mae: 0.1914 - val_loss: 5.1120 - val_mae: 0.9642\n",
      "Epoch 311/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7515 - mae: 0.1966 - val_loss: 5.1368 - val_mae: 0.9728\n",
      "Epoch 312/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7475 - mae: 0.1956 - val_loss: 5.1674 - val_mae: 0.9705\n",
      "Epoch 313/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7579 - mae: 0.1914 - val_loss: 5.0965 - val_mae: 0.9623\n",
      "Epoch 314/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7459 - mae: 0.1950 - val_loss: 5.0844 - val_mae: 0.9463\n",
      "Epoch 315/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7489 - mae: 0.1888 - val_loss: 5.1074 - val_mae: 0.9608\n",
      "Epoch 316/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7480 - mae: 0.1893 - val_loss: 5.0792 - val_mae: 0.9533\n",
      "Epoch 317/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7495 - mae: 0.2001 - val_loss: 5.0906 - val_mae: 0.9594\n",
      "Epoch 318/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7497 - mae: 0.1949 - val_loss: 5.1437 - val_mae: 0.9720\n",
      "Epoch 319/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7525 - mae: 0.1948 - val_loss: 5.1620 - val_mae: 0.9846\n",
      "Epoch 320/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7541 - mae: 0.2001 - val_loss: 5.1952 - val_mae: 0.9870\n",
      "Epoch 321/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7480 - mae: 0.1957 - val_loss: 5.1488 - val_mae: 0.9773\n",
      "Epoch 322/412\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.7447 - mae: 0.1876 - val_loss: 5.1301 - val_mae: 0.9683\n",
      "Epoch 323/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7463 - mae: 0.1935 - val_loss: 5.1436 - val_mae: 0.9730\n",
      "Epoch 324/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7432 - mae: 0.1877 - val_loss: 5.1240 - val_mae: 0.9633\n",
      "Epoch 325/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7486 - mae: 0.1943 - val_loss: 5.1614 - val_mae: 0.9697\n",
      "Epoch 326/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7489 - mae: 0.1809 - val_loss: 5.1954 - val_mae: 0.9887\n",
      "Epoch 327/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7455 - mae: 0.1909 - val_loss: 5.0761 - val_mae: 0.9459\n",
      "Epoch 328/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7476 - mae: 0.1886 - val_loss: 5.1386 - val_mae: 0.9743\n",
      "Epoch 329/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7440 - mae: 0.1863 - val_loss: 5.1396 - val_mae: 0.9737\n",
      "Epoch 330/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7472 - mae: 0.1982 - val_loss: 5.1259 - val_mae: 0.9566\n",
      "Epoch 331/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7508 - mae: 0.1835 - val_loss: 5.1397 - val_mae: 0.9698\n",
      "Epoch 332/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7431 - mae: 0.1884 - val_loss: 5.1322 - val_mae: 0.9600\n",
      "Epoch 333/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7475 - mae: 0.1820 - val_loss: 5.1437 - val_mae: 0.9709\n",
      "Epoch 334/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7454 - mae: 0.1864 - val_loss: 5.1919 - val_mae: 0.9917\n",
      "Epoch 335/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7438 - mae: 0.1904 - val_loss: 5.1494 - val_mae: 0.9680\n",
      "Epoch 336/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7420 - mae: 0.1806 - val_loss: 5.1786 - val_mae: 0.9868\n",
      "Epoch 337/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7420 - mae: 0.1878 - val_loss: 5.1365 - val_mae: 0.9632\n",
      "Epoch 338/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7400 - mae: 0.1801 - val_loss: 5.1027 - val_mae: 0.9586\n",
      "Epoch 339/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7390 - mae: 0.1837 - val_loss: 5.1200 - val_mae: 0.9622\n",
      "Epoch 340/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7405 - mae: 0.1828 - val_loss: 5.1034 - val_mae: 0.9604\n",
      "Epoch 341/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7381 - mae: 0.1832 - val_loss: 5.1072 - val_mae: 0.9610\n",
      "Epoch 342/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7389 - mae: 0.1880 - val_loss: 5.1446 - val_mae: 0.9773\n",
      "Epoch 343/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7414 - mae: 0.1862 - val_loss: 5.1503 - val_mae: 0.9635\n",
      "Epoch 344/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7507 - mae: 0.1862 - val_loss: 5.1477 - val_mae: 0.9813\n",
      "Epoch 345/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7391 - mae: 0.1884 - val_loss: 5.1461 - val_mae: 0.9721\n",
      "Epoch 346/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7385 - mae: 0.1869 - val_loss: 5.0972 - val_mae: 0.9539\n",
      "Epoch 347/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7410 - mae: 0.1772 - val_loss: 5.0893 - val_mae: 0.9525\n",
      "Epoch 348/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7381 - mae: 0.1840 - val_loss: 5.1105 - val_mae: 0.9658\n",
      "Epoch 349/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7359 - mae: 0.1823 - val_loss: 5.1944 - val_mae: 0.9901\n",
      "Epoch 350/412\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.7401 - mae: 0.1862 - val_loss: 5.1286 - val_mae: 0.9722\n",
      "Epoch 351/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7362 - mae: 0.1853 - val_loss: 5.1240 - val_mae: 0.9667\n",
      "Epoch 352/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7359 - mae: 0.1831 - val_loss: 5.0788 - val_mae: 0.9489\n",
      "Epoch 353/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7378 - mae: 0.1828 - val_loss: 5.1307 - val_mae: 0.9696\n",
      "Epoch 354/412\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.7359 - mae: 0.1797 - val_loss: 5.1133 - val_mae: 0.9633\n",
      "Epoch 355/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7394 - mae: 0.1878 - val_loss: 5.1126 - val_mae: 0.9675\n",
      "Epoch 356/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7353 - mae: 0.1827 - val_loss: 5.1085 - val_mae: 0.9646\n",
      "Epoch 357/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7409 - mae: 0.1904 - val_loss: 5.0770 - val_mae: 0.9528\n",
      "Epoch 358/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7359 - mae: 0.1891 - val_loss: 5.0905 - val_mae: 0.9522\n",
      "Epoch 359/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7427 - mae: 0.1875 - val_loss: 5.1423 - val_mae: 0.9755\n",
      "Epoch 360/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7344 - mae: 0.1852 - val_loss: 5.1888 - val_mae: 0.9899\n",
      "Epoch 361/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7388 - mae: 0.1875 - val_loss: 5.1648 - val_mae: 0.9720\n",
      "Epoch 362/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7388 - mae: 0.1706 - val_loss: 5.1064 - val_mae: 0.9601\n",
      "Epoch 363/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7340 - mae: 0.1766 - val_loss: 5.1669 - val_mae: 0.9867\n",
      "Epoch 364/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7402 - mae: 0.1941 - val_loss: 5.2015 - val_mae: 0.9940\n",
      "Epoch 365/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7364 - mae: 0.1863 - val_loss: 5.1598 - val_mae: 0.9810\n",
      "Epoch 366/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7378 - mae: 0.1824 - val_loss: 5.1102 - val_mae: 0.9571\n",
      "Epoch 367/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7380 - mae: 0.1821 - val_loss: 5.1776 - val_mae: 0.9889\n",
      "Epoch 368/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7329 - mae: 0.1827 - val_loss: 5.1066 - val_mae: 0.9573\n",
      "Epoch 369/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7354 - mae: 0.1790 - val_loss: 5.2002 - val_mae: 0.9952\n",
      "Epoch 370/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7361 - mae: 0.1879 - val_loss: 5.1117 - val_mae: 0.9537\n",
      "Epoch 371/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7378 - mae: 0.1765 - val_loss: 5.1371 - val_mae: 0.9735\n",
      "Epoch 372/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7328 - mae: 0.1759 - val_loss: 5.0920 - val_mae: 0.9542\n",
      "Epoch 373/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7402 - mae: 0.1896 - val_loss: 5.2566 - val_mae: 1.0096\n",
      "Epoch 374/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7474 - mae: 0.1911 - val_loss: 5.0967 - val_mae: 0.9520\n",
      "Epoch 375/412\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.7313 - mae: 0.1741 - val_loss: 5.1402 - val_mae: 0.9746\n",
      "Epoch 376/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7352 - mae: 0.1833 - val_loss: 5.1187 - val_mae: 0.9605\n",
      "Epoch 377/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7358 - mae: 0.1809 - val_loss: 5.0903 - val_mae: 0.9543\n",
      "Epoch 378/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7294 - mae: 0.1750 - val_loss: 5.0708 - val_mae: 0.9455\n",
      "Epoch 379/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7351 - mae: 0.1821 - val_loss: 5.1627 - val_mae: 0.9811\n",
      "Epoch 380/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7327 - mae: 0.1801 - val_loss: 5.1052 - val_mae: 0.9580\n",
      "Epoch 381/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7319 - mae: 0.1784 - val_loss: 5.2385 - val_mae: 1.0054\n",
      "Epoch 382/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7338 - mae: 0.1784 - val_loss: 5.1165 - val_mae: 0.9613\n",
      "Epoch 383/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7350 - mae: 0.1805 - val_loss: 5.1854 - val_mae: 0.9920\n",
      "Epoch 384/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7359 - mae: 0.1828 - val_loss: 5.1863 - val_mae: 0.9872\n",
      "Epoch 385/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7288 - mae: 0.1732 - val_loss: 5.1660 - val_mae: 0.9864\n",
      "Epoch 386/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7315 - mae: 0.1803 - val_loss: 5.1092 - val_mae: 0.9616\n",
      "Epoch 387/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7270 - mae: 0.1760 - val_loss: 5.1275 - val_mae: 0.9723\n",
      "Epoch 388/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7316 - mae: 0.1801 - val_loss: 5.0909 - val_mae: 0.9487\n",
      "Epoch 389/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7301 - mae: 0.1768 - val_loss: 5.1104 - val_mae: 0.9588\n",
      "Epoch 390/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7314 - mae: 0.1760 - val_loss: 5.1212 - val_mae: 0.9574\n",
      "Epoch 391/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7372 - mae: 0.1763 - val_loss: 5.1460 - val_mae: 0.9741\n",
      "Epoch 392/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7260 - mae: 0.1714 - val_loss: 5.1634 - val_mae: 0.9787\n",
      "Epoch 393/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7266 - mae: 0.1741 - val_loss: 5.0978 - val_mae: 0.9570\n",
      "Epoch 394/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7254 - mae: 0.1710 - val_loss: 5.1911 - val_mae: 0.9911\n",
      "Epoch 395/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7283 - mae: 0.1810 - val_loss: 5.1728 - val_mae: 0.9844\n",
      "Epoch 396/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7268 - mae: 0.1716 - val_loss: 5.2281 - val_mae: 1.0036\n",
      "Epoch 397/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7271 - mae: 0.1798 - val_loss: 5.1049 - val_mae: 0.9662\n",
      "Epoch 398/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7245 - mae: 0.1809 - val_loss: 5.1020 - val_mae: 0.9529\n",
      "Epoch 399/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7340 - mae: 0.1774 - val_loss: 5.1635 - val_mae: 0.9832\n",
      "Epoch 400/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7259 - mae: 0.1778 - val_loss: 5.2035 - val_mae: 0.9958\n",
      "Epoch 401/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7269 - mae: 0.1767 - val_loss: 5.1738 - val_mae: 0.9843\n",
      "Epoch 402/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7250 - mae: 0.1744 - val_loss: 5.1488 - val_mae: 0.9702\n",
      "Epoch 403/412\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.7265 - mae: 0.1699 - val_loss: 5.2068 - val_mae: 0.9952\n",
      "Epoch 404/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7246 - mae: 0.1715 - val_loss: 5.1510 - val_mae: 0.9732\n",
      "Epoch 405/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7236 - mae: 0.1692 - val_loss: 5.2297 - val_mae: 0.9986\n",
      "Epoch 406/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7241 - mae: 0.1688 - val_loss: 5.1671 - val_mae: 0.9784\n",
      "Epoch 407/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7263 - mae: 0.1727 - val_loss: 5.1341 - val_mae: 0.9718\n",
      "Epoch 408/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7231 - mae: 0.1716 - val_loss: 5.1551 - val_mae: 0.9799\n",
      "Epoch 409/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7222 - mae: 0.1713 - val_loss: 5.1106 - val_mae: 0.9620\n",
      "Epoch 410/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7245 - mae: 0.1718 - val_loss: 5.1045 - val_mae: 0.9659\n",
      "Epoch 411/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7233 - mae: 0.1795 - val_loss: 5.1296 - val_mae: 0.9724\n",
      "Epoch 412/412\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7208 - mae: 0.1726 - val_loss: 5.1562 - val_mae: 0.9823\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▅▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/mae</td><td>█▅▄▃▂▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_loss</td><td>█▅▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_mae</td><td>█▇▆▅▃▂▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>411</td></tr><tr><td>epoch/learning_rate</td><td>0.00475</td></tr><tr><td>epoch/loss</td><td>3.72078</td></tr><tr><td>epoch/mae</td><td>0.17261</td></tr><tr><td>epoch/val_loss</td><td>5.1562</td></tr><tr><td>epoch/val_mae</td><td>0.98227</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">expert-sweep-6</strong> at: <a href='https://wandb.ai/grantbell/fred_dnn_sweep/runs/r4av16n8' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/runs/r4av16n8</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230719_171900-r4av16n8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6siusqdd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 288\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_initializer: he_normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1: 0.26867202662497414\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_l2: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2: 0.19774442550160665\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.007082729104910236\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: mse\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmetrics: mae\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\grant\\OneDrive\\Desktop\\vscode\\py_fin\\wandb\\run-20230719_171928-6siusqdd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/grantbell/fred_dnn_sweep/runs/6siusqdd' target=\"_blank\">icy-sweep-7</a></strong> to <a href='https://wandb.ai/grantbell/fred_dnn_sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/grantbell/fred_dnn_sweep' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/grantbell/fred_dnn_sweep/runs/6siusqdd' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/runs/6siusqdd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/288\n",
      "5/5 [==============================] - 1s 45ms/step - loss: 578.4039 - mae: 5.1451 - val_loss: 522.2782 - val_mae: 4.2093\n",
      "Epoch 2/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 488.9352 - mae: 1.2031 - val_loss: 486.1814 - val_mae: 5.0270\n",
      "Epoch 3/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 446.3044 - mae: 0.9644 - val_loss: 446.0082 - val_mae: 4.9997\n",
      "Epoch 4/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 406.9226 - mae: 0.8777 - val_loss: 415.6548 - val_mae: 5.6922\n",
      "Epoch 5/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 371.1560 - mae: 1.1842 - val_loss: 384.2841 - val_mae: 5.8870\n",
      "Epoch 6/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 336.8256 - mae: 1.0124 - val_loss: 354.0834 - val_mae: 6.2570\n",
      "Epoch 7/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 304.5487 - mae: 0.8163 - val_loss: 324.8632 - val_mae: 6.2371\n",
      "Epoch 8/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 275.1095 - mae: 0.7409 - val_loss: 298.5038 - val_mae: 6.4183\n",
      "Epoch 9/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 248.0750 - mae: 0.7954 - val_loss: 269.4625 - val_mae: 6.1412\n",
      "Epoch 10/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 228.8537 - mae: 2.0240 - val_loss: 255.5276 - val_mae: 6.6345\n",
      "Epoch 11/288\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 205.0711 - mae: 1.7587 - val_loss: 228.0791 - val_mae: 6.3292\n",
      "Epoch 12/288\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 180.2820 - mae: 0.7357 - val_loss: 207.0309 - val_mae: 6.2015\n",
      "Epoch 13/288\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 161.6906 - mae: 0.8534 - val_loss: 188.4317 - val_mae: 6.1862\n",
      "Epoch 14/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 144.8176 - mae: 1.0219 - val_loss: 173.5769 - val_mae: 6.0663\n",
      "Epoch 15/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 130.5548 - mae: 1.1079 - val_loss: 157.4758 - val_mae: 6.2043\n",
      "Epoch 16/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 120.1111 - mae: 1.8897 - val_loss: 147.4996 - val_mae: 5.8374\n",
      "Epoch 17/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 111.1583 - mae: 2.4932 - val_loss: 133.3147 - val_mae: 5.8365\n",
      "Epoch 18/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 97.8929 - mae: 1.8245 - val_loss: 117.5146 - val_mae: 5.4552\n",
      "Epoch 19/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 91.2228 - mae: 2.5057 - val_loss: 115.6838 - val_mae: 5.2642\n",
      "Epoch 20/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 82.2638 - mae: 1.9708 - val_loss: 99.2890 - val_mae: 5.3701\n",
      "Epoch 21/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 73.1379 - mae: 2.3674 - val_loss: 89.4441 - val_mae: 5.2135\n",
      "Epoch 22/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 60.6694 - mae: 1.2332 - val_loss: 79.6552 - val_mae: 4.8503\n",
      "Epoch 23/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 56.4560 - mae: 1.6842 - val_loss: 76.3907 - val_mae: 4.4687\n",
      "Epoch 24/288\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 50.4129 - mae: 1.2534 - val_loss: 66.6239 - val_mae: 4.4959\n",
      "Epoch 25/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 46.5251 - mae: 1.5752 - val_loss: 66.7212 - val_mae: 4.3870\n",
      "Epoch 26/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 67.9138 - mae: 4.3881 - val_loss: 102.9875 - val_mae: 5.7159\n",
      "Epoch 27/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 65.1208 - mae: 2.4772 - val_loss: 65.8822 - val_mae: 4.4910\n",
      "Epoch 28/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 43.2645 - mae: 1.1199 - val_loss: 61.2279 - val_mae: 4.6661\n",
      "Epoch 29/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 37.2710 - mae: 1.2134 - val_loss: 58.6098 - val_mae: 4.1277\n",
      "Epoch 30/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 50.8763 - mae: 3.0174 - val_loss: 52.8604 - val_mae: 4.2868\n",
      "Epoch 31/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.7352 - mae: 1.5498 - val_loss: 48.5503 - val_mae: 3.3674\n",
      "Epoch 32/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 38.5562 - mae: 2.5354 - val_loss: 43.6729 - val_mae: 4.2281\n",
      "Epoch 33/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 24.1517 - mae: 0.8957 - val_loss: 35.1883 - val_mae: 3.6817\n",
      "Epoch 34/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 20.4109 - mae: 0.7646 - val_loss: 30.4943 - val_mae: 3.2685\n",
      "Epoch 35/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 24.9692 - mae: 2.1615 - val_loss: 30.8953 - val_mae: 3.1682\n",
      "Epoch 36/288\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 21.3018 - mae: 1.6586 - val_loss: 25.5973 - val_mae: 2.7774\n",
      "Epoch 37/288\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 22.0290 - mae: 2.0703 - val_loss: 26.7242 - val_mae: 2.9129\n",
      "Epoch 38/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 19.6067 - mae: 1.8082 - val_loss: 26.8449 - val_mae: 2.7990\n",
      "Epoch 39/288\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 20.2759 - mae: 1.8791 - val_loss: 28.7962 - val_mae: 3.3565\n",
      "Epoch 40/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 14.5504 - mae: 0.8544 - val_loss: 20.5666 - val_mae: 2.0572\n",
      "Epoch 41/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 20.3204 - mae: 2.1388 - val_loss: 30.7729 - val_mae: 2.7445\n",
      "Epoch 42/288\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 36.0180 - mae: 3.7756 - val_loss: 42.9912 - val_mae: 4.4001\n",
      "Epoch 43/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.8744 - mae: 1.5392 - val_loss: 25.5548 - val_mae: 2.9956\n",
      "Epoch 44/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 18.3523 - mae: 1.8689 - val_loss: 18.6948 - val_mae: 2.0842\n",
      "Epoch 45/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 15.1644 - mae: 1.3486 - val_loss: 18.7782 - val_mae: 2.2659\n",
      "Epoch 46/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 11.8585 - mae: 0.7547 - val_loss: 16.5582 - val_mae: 2.1037\n",
      "Epoch 47/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.2412 - mae: 0.6912 - val_loss: 15.0489 - val_mae: 1.9890\n",
      "Epoch 48/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.8431 - mae: 0.8210 - val_loss: 12.8577 - val_mae: 1.6946\n",
      "Epoch 49/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.9393 - mae: 1.3352 - val_loss: 15.4529 - val_mae: 1.8606\n",
      "Epoch 50/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 11.0490 - mae: 0.8142 - val_loss: 10.6288 - val_mae: 1.2147\n",
      "Epoch 51/288\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 9.2037 - mae: 0.9529 - val_loss: 12.3175 - val_mae: 1.4747\n",
      "Epoch 52/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 18.2958 - mae: 2.4859 - val_loss: 16.3603 - val_mae: 2.0163\n",
      "Epoch 53/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 12.2388 - mae: 1.2532 - val_loss: 11.8049 - val_mae: 1.4871\n",
      "Epoch 54/288\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 9.7640 - mae: 0.9610 - val_loss: 9.5775 - val_mae: 1.1361\n",
      "Epoch 55/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.3655 - mae: 0.7661 - val_loss: 8.5736 - val_mae: 1.0780\n",
      "Epoch 56/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.0291 - mae: 0.6776 - val_loss: 9.7760 - val_mae: 1.4742\n",
      "Epoch 57/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.2048 - mae: 1.5907 - val_loss: 12.5225 - val_mae: 1.8632\n",
      "Epoch 58/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.1437 - mae: 0.5828 - val_loss: 8.8928 - val_mae: 1.1753\n",
      "Epoch 59/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.3724 - mae: 0.7305 - val_loss: 7.2996 - val_mae: 0.9431\n",
      "Epoch 60/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.0773 - mae: 0.8195 - val_loss: 7.5977 - val_mae: 1.1147\n",
      "Epoch 61/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 6.9249 - mae: 0.9664 - val_loss: 6.3338 - val_mae: 0.7762\n",
      "Epoch 62/288\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 5.8419 - mae: 0.6768 - val_loss: 6.3267 - val_mae: 0.9039\n",
      "Epoch 63/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.0897 - mae: 0.4781 - val_loss: 4.9925 - val_mae: 0.6157\n",
      "Epoch 64/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.7144 - mae: 0.5102 - val_loss: 5.0719 - val_mae: 0.6930\n",
      "Epoch 65/288\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.2321 - mae: 0.2765 - val_loss: 4.6698 - val_mae: 0.6165\n",
      "Epoch 66/288\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.1479 - mae: 0.3160 - val_loss: 4.9541 - val_mae: 0.7577\n",
      "Epoch 67/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.3692 - mae: 0.3128 - val_loss: 5.6783 - val_mae: 0.9756\n",
      "Epoch 68/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.1253 - mae: 0.2200 - val_loss: 4.8964 - val_mae: 0.8270\n",
      "Epoch 69/288\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.9181 - mae: 0.2185 - val_loss: 4.6270 - val_mae: 0.6985\n",
      "Epoch 70/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.7675 - mae: 0.2116 - val_loss: 4.5525 - val_mae: 0.7044\n",
      "Epoch 71/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.7095 - mae: 0.2242 - val_loss: 4.2888 - val_mae: 0.6952\n",
      "Epoch 72/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5759 - mae: 0.1649 - val_loss: 4.3720 - val_mae: 0.7600\n",
      "Epoch 73/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6504 - mae: 0.2712 - val_loss: 4.1389 - val_mae: 0.6610\n",
      "Epoch 74/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6646 - mae: 0.2863 - val_loss: 4.5525 - val_mae: 0.8690\n",
      "Epoch 75/288\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.6581 - mae: 0.3388 - val_loss: 4.1330 - val_mae: 0.6433\n",
      "Epoch 76/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5643 - mae: 0.2150 - val_loss: 4.1636 - val_mae: 0.7318\n",
      "Epoch 77/288\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.5675 - mae: 0.2738 - val_loss: 4.2178 - val_mae: 0.6598\n",
      "Epoch 78/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6108 - mae: 0.2588 - val_loss: 4.3935 - val_mae: 0.6935\n",
      "Epoch 79/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5546 - mae: 0.1861 - val_loss: 4.3824 - val_mae: 0.7687\n",
      "Epoch 80/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5307 - mae: 0.2315 - val_loss: 4.3733 - val_mae: 0.7542\n",
      "Epoch 81/288\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.5574 - mae: 0.2172 - val_loss: 4.5953 - val_mae: 0.7788\n",
      "Epoch 82/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6420 - mae: 0.2421 - val_loss: 4.1727 - val_mae: 0.7037\n",
      "Epoch 83/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5769 - mae: 0.2582 - val_loss: 4.7371 - val_mae: 0.9118\n",
      "Epoch 84/288\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.5387 - mae: 0.2135 - val_loss: 4.2378 - val_mae: 0.7006\n",
      "Epoch 85/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4967 - mae: 0.2005 - val_loss: 6.0124 - val_mae: 1.1765\n",
      "Epoch 86/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.7676 - mae: 0.2627 - val_loss: 4.5546 - val_mae: 0.8205\n",
      "Epoch 87/288\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.5275 - mae: 0.2038 - val_loss: 4.3238 - val_mae: 0.8117\n",
      "Epoch 88/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5851 - mae: 0.2307 - val_loss: 4.3205 - val_mae: 0.7779\n",
      "Epoch 89/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4980 - mae: 0.2120 - val_loss: 4.4083 - val_mae: 0.8269\n",
      "Epoch 90/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5812 - mae: 0.2899 - val_loss: 5.1854 - val_mae: 1.0318\n",
      "Epoch 91/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6085 - mae: 0.1926 - val_loss: 4.3770 - val_mae: 0.7936\n",
      "Epoch 92/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6194 - mae: 0.2951 - val_loss: 4.3130 - val_mae: 0.7809\n",
      "Epoch 93/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4954 - mae: 0.2098 - val_loss: 6.0714 - val_mae: 1.2467\n",
      "Epoch 94/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6359 - mae: 0.2013 - val_loss: 4.7999 - val_mae: 0.9081\n",
      "Epoch 95/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5614 - mae: 0.2178 - val_loss: 4.3306 - val_mae: 0.7473\n",
      "Epoch 96/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6205 - mae: 0.2551 - val_loss: 4.2618 - val_mae: 0.7530\n",
      "Epoch 97/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4704 - mae: 0.1911 - val_loss: 4.3479 - val_mae: 0.7445\n",
      "Epoch 98/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.7758 - mae: 0.3125 - val_loss: 4.9666 - val_mae: 0.9242\n",
      "Epoch 99/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.0070 - mae: 0.2856 - val_loss: 8.8643 - val_mae: 1.7176\n",
      "Epoch 100/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.9547 - mae: 0.2068 - val_loss: 7.3190 - val_mae: 1.4663\n",
      "Epoch 101/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.8807 - mae: 0.2578 - val_loss: 5.8174 - val_mae: 1.1429\n",
      "Epoch 102/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.7725 - mae: 0.2065 - val_loss: 5.2405 - val_mae: 1.0292\n",
      "Epoch 103/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.7918 - mae: 0.2764 - val_loss: 4.6480 - val_mae: 0.7988\n",
      "Epoch 104/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.1591 - mae: 0.3430 - val_loss: 5.3043 - val_mae: 1.0171\n",
      "Epoch 105/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.7718 - mae: 0.2628 - val_loss: 4.7612 - val_mae: 0.8941\n",
      "Epoch 106/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6137 - mae: 0.2325 - val_loss: 4.3695 - val_mae: 0.7991\n",
      "Epoch 107/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5199 - mae: 0.2502 - val_loss: 4.2665 - val_mae: 0.7801\n",
      "Epoch 108/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4957 - mae: 0.2072 - val_loss: 4.3269 - val_mae: 0.7782\n",
      "Epoch 109/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4846 - mae: 0.1806 - val_loss: 4.2392 - val_mae: 0.7460\n",
      "Epoch 110/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4964 - mae: 0.2148 - val_loss: 4.1454 - val_mae: 0.6832\n",
      "Epoch 111/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4767 - mae: 0.1891 - val_loss: 4.0820 - val_mae: 0.6805\n",
      "Epoch 112/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5227 - mae: 0.2755 - val_loss: 4.0141 - val_mae: 0.6610\n",
      "Epoch 113/288\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7956 - mae: 0.2952 - val_loss: 5.1477 - val_mae: 1.0002\n",
      "Epoch 114/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6648 - mae: 0.2284 - val_loss: 4.4979 - val_mae: 0.8228\n",
      "Epoch 115/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5095 - mae: 0.1879 - val_loss: 4.2483 - val_mae: 0.7447\n",
      "Epoch 116/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5715 - mae: 0.3005 - val_loss: 4.0803 - val_mae: 0.6926\n",
      "Epoch 117/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5355 - mae: 0.3013 - val_loss: 4.2779 - val_mae: 0.7932\n",
      "Epoch 118/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.8680 - mae: 0.3701 - val_loss: 4.9123 - val_mae: 0.9181\n",
      "Epoch 119/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6414 - mae: 0.2875 - val_loss: 4.5329 - val_mae: 0.8365\n",
      "Epoch 120/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4686 - mae: 0.1710 - val_loss: 4.1793 - val_mae: 0.7352\n",
      "Epoch 121/288\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.4805 - mae: 0.2180 - val_loss: 4.3998 - val_mae: 0.7684\n",
      "Epoch 122/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.7395 - mae: 0.3355 - val_loss: 5.6374 - val_mae: 1.1505\n",
      "Epoch 123/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6934 - mae: 0.2553 - val_loss: 4.9632 - val_mae: 0.9712\n",
      "Epoch 124/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6867 - mae: 0.3199 - val_loss: 4.8176 - val_mae: 0.9482\n",
      "Epoch 125/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5690 - mae: 0.2405 - val_loss: 4.4071 - val_mae: 0.7914\n",
      "Epoch 126/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4845 - mae: 0.2058 - val_loss: 4.2235 - val_mae: 0.7530\n",
      "Epoch 127/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4384 - mae: 0.1603 - val_loss: 4.0238 - val_mae: 0.6661\n",
      "Epoch 128/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.9570 - mae: 0.3275 - val_loss: 8.7513 - val_mae: 1.7297\n",
      "Epoch 129/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.8321 - mae: 0.2459 - val_loss: 7.0358 - val_mae: 1.4385\n",
      "Epoch 130/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.7869 - mae: 0.2780 - val_loss: 5.5508 - val_mae: 1.0960\n",
      "Epoch 131/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.7336 - mae: 0.2233 - val_loss: 5.5334 - val_mae: 1.1207\n",
      "Epoch 132/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6007 - mae: 0.2126 - val_loss: 4.5873 - val_mae: 0.8347\n",
      "Epoch 133/288\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.6328 - mae: 0.2302 - val_loss: 4.4168 - val_mae: 0.8178\n",
      "Epoch 134/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5171 - mae: 0.2688 - val_loss: 4.3730 - val_mae: 0.7604\n",
      "Epoch 135/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4575 - mae: 0.1808 - val_loss: 4.0720 - val_mae: 0.7076\n",
      "Epoch 136/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4934 - mae: 0.2440 - val_loss: 4.3212 - val_mae: 0.7939\n",
      "Epoch 137/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4481 - mae: 0.1898 - val_loss: 5.0140 - val_mae: 0.9183\n",
      "Epoch 138/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6800 - mae: 0.2390 - val_loss: 5.0529 - val_mae: 0.9930\n",
      "Epoch 139/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5383 - mae: 0.1704 - val_loss: 4.3597 - val_mae: 0.7890\n",
      "Epoch 140/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5050 - mae: 0.2466 - val_loss: 4.2899 - val_mae: 0.7207\n",
      "Epoch 141/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4611 - mae: 0.1857 - val_loss: 4.1583 - val_mae: 0.7411\n",
      "Epoch 142/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5510 - mae: 0.2902 - val_loss: 4.3637 - val_mae: 0.7990\n",
      "Epoch 143/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5837 - mae: 0.3192 - val_loss: 4.4812 - val_mae: 0.8233\n",
      "Epoch 144/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6329 - mae: 0.2609 - val_loss: 6.7237 - val_mae: 1.3603\n",
      "Epoch 145/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.7540 - mae: 0.2694 - val_loss: 5.6222 - val_mae: 1.0997\n",
      "Epoch 146/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6271 - mae: 0.1930 - val_loss: 5.2204 - val_mae: 1.0573\n",
      "Epoch 147/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6099 - mae: 0.2218 - val_loss: 5.3643 - val_mae: 1.0853\n",
      "Epoch 148/288\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.6807 - mae: 0.3450 - val_loss: 4.3262 - val_mae: 0.7640\n",
      "Epoch 149/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5498 - mae: 0.2986 - val_loss: 4.2385 - val_mae: 0.6856\n",
      "Epoch 150/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6766 - mae: 0.3297 - val_loss: 4.1078 - val_mae: 0.6790\n",
      "Epoch 151/288\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.5113 - mae: 0.2213 - val_loss: 4.2583 - val_mae: 0.7752\n",
      "Epoch 152/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4995 - mae: 0.2409 - val_loss: 4.7673 - val_mae: 0.9254\n",
      "Epoch 153/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4831 - mae: 0.2057 - val_loss: 4.1867 - val_mae: 0.7013\n",
      "Epoch 154/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4610 - mae: 0.2126 - val_loss: 4.2936 - val_mae: 0.7673\n",
      "Epoch 155/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5048 - mae: 0.1997 - val_loss: 5.6572 - val_mae: 1.1554\n",
      "Epoch 156/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5641 - mae: 0.2240 - val_loss: 4.7200 - val_mae: 0.8777\n",
      "Epoch 157/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5020 - mae: 0.2093 - val_loss: 4.4414 - val_mae: 0.7881\n",
      "Epoch 158/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4758 - mae: 0.2209 - val_loss: 4.4763 - val_mae: 0.8498\n",
      "Epoch 159/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5170 - mae: 0.2678 - val_loss: 4.2956 - val_mae: 0.7639\n",
      "Epoch 160/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4498 - mae: 0.1933 - val_loss: 4.3021 - val_mae: 0.7690\n",
      "Epoch 161/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4431 - mae: 0.1799 - val_loss: 4.8969 - val_mae: 0.9676\n",
      "Epoch 162/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5137 - mae: 0.2257 - val_loss: 4.3870 - val_mae: 0.8005\n",
      "Epoch 163/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4822 - mae: 0.2517 - val_loss: 4.1097 - val_mae: 0.7017\n",
      "Epoch 164/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4618 - mae: 0.2148 - val_loss: 4.0834 - val_mae: 0.7225\n",
      "Epoch 165/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4656 - mae: 0.2305 - val_loss: 4.3827 - val_mae: 0.8254\n",
      "Epoch 166/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4929 - mae: 0.2651 - val_loss: 5.6823 - val_mae: 1.1786\n",
      "Epoch 167/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5873 - mae: 0.2817 - val_loss: 4.8720 - val_mae: 0.9372\n",
      "Epoch 168/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5453 - mae: 0.2656 - val_loss: 4.3383 - val_mae: 0.7333\n",
      "Epoch 169/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6583 - mae: 0.3242 - val_loss: 4.4402 - val_mae: 0.8296\n",
      "Epoch 170/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4130 - mae: 0.1551 - val_loss: 4.3013 - val_mae: 0.8004\n",
      "Epoch 171/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5063 - mae: 0.2674 - val_loss: 4.4361 - val_mae: 0.8290\n",
      "Epoch 172/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4356 - mae: 0.2116 - val_loss: 4.7201 - val_mae: 0.8982\n",
      "Epoch 173/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4899 - mae: 0.2477 - val_loss: 4.2377 - val_mae: 0.7789\n",
      "Epoch 174/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4378 - mae: 0.2257 - val_loss: 4.3089 - val_mae: 0.8073\n",
      "Epoch 175/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4682 - mae: 0.2753 - val_loss: 4.8369 - val_mae: 0.9723\n",
      "Epoch 176/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4327 - mae: 0.2016 - val_loss: 4.1206 - val_mae: 0.6815\n",
      "Epoch 177/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4722 - mae: 0.2456 - val_loss: 4.3155 - val_mae: 0.7855\n",
      "Epoch 178/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6292 - mae: 0.3299 - val_loss: 7.0310 - val_mae: 1.4852\n",
      "Epoch 179/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5588 - mae: 0.2507 - val_loss: 5.1077 - val_mae: 1.0511\n",
      "Epoch 180/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4307 - mae: 0.1985 - val_loss: 4.3561 - val_mae: 0.7978\n",
      "Epoch 181/288\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.5597 - mae: 0.3029 - val_loss: 4.2072 - val_mae: 0.7734\n",
      "Epoch 182/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5573 - mae: 0.2600 - val_loss: 4.8251 - val_mae: 0.9442\n",
      "Epoch 183/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5474 - mae: 0.2924 - val_loss: 4.5504 - val_mae: 0.8746\n",
      "Epoch 184/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4512 - mae: 0.2460 - val_loss: 4.2844 - val_mae: 0.7541\n",
      "Epoch 185/288\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.5998 - mae: 0.2864 - val_loss: 5.1933 - val_mae: 1.0526\n",
      "Epoch 186/288\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.5005 - mae: 0.2539 - val_loss: 5.0049 - val_mae: 1.0168\n",
      "Epoch 187/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4169 - mae: 0.1753 - val_loss: 4.5264 - val_mae: 0.8596\n",
      "Epoch 188/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4210 - mae: 0.1979 - val_loss: 4.3119 - val_mae: 0.7860\n",
      "Epoch 189/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4368 - mae: 0.2168 - val_loss: 5.1887 - val_mae: 1.0746\n",
      "Epoch 190/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4598 - mae: 0.2452 - val_loss: 5.0497 - val_mae: 1.0169\n",
      "Epoch 191/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4521 - mae: 0.1795 - val_loss: 4.3300 - val_mae: 0.8048\n",
      "Epoch 192/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6856 - mae: 0.2712 - val_loss: 10.6011 - val_mae: 2.0437\n",
      "Epoch 193/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.9488 - mae: 0.2934 - val_loss: 9.7434 - val_mae: 1.9109\n",
      "Epoch 194/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.8797 - mae: 0.3096 - val_loss: 8.8856 - val_mae: 1.7774\n",
      "Epoch 195/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.7738 - mae: 0.2725 - val_loss: 7.8439 - val_mae: 1.6073\n",
      "Epoch 196/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6984 - mae: 0.2747 - val_loss: 6.3627 - val_mae: 1.3128\n",
      "Epoch 197/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6517 - mae: 0.2310 - val_loss: 5.7857 - val_mae: 1.2024\n",
      "Epoch 198/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6768 - mae: 0.3652 - val_loss: 4.9128 - val_mae: 0.9830\n",
      "Epoch 199/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5194 - mae: 0.2385 - val_loss: 4.4776 - val_mae: 0.8480\n",
      "Epoch 200/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4654 - mae: 0.2252 - val_loss: 4.3021 - val_mae: 0.7728\n",
      "Epoch 201/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5080 - mae: 0.2889 - val_loss: 4.1828 - val_mae: 0.6910\n",
      "Epoch 202/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4186 - mae: 0.1815 - val_loss: 4.4834 - val_mae: 0.8518\n",
      "Epoch 203/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5091 - mae: 0.3026 - val_loss: 4.3940 - val_mae: 0.8211\n",
      "Epoch 204/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6105 - mae: 0.3870 - val_loss: 4.1382 - val_mae: 0.6956\n",
      "Epoch 205/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5365 - mae: 0.2369 - val_loss: 5.1606 - val_mae: 1.0514\n",
      "Epoch 206/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4998 - mae: 0.2089 - val_loss: 4.4488 - val_mae: 0.8377\n",
      "Epoch 207/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4540 - mae: 0.2334 - val_loss: 4.2552 - val_mae: 0.7772\n",
      "Epoch 208/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.3979 - mae: 0.1615 - val_loss: 5.3519 - val_mae: 1.0822\n",
      "Epoch 209/288\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.6054 - mae: 0.2738 - val_loss: 4.8252 - val_mae: 0.9472\n",
      "Epoch 210/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4923 - mae: 0.2162 - val_loss: 4.3083 - val_mae: 0.7847\n",
      "Epoch 211/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4365 - mae: 0.2030 - val_loss: 4.1689 - val_mae: 0.7433\n",
      "Epoch 212/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.3920 - mae: 0.1731 - val_loss: 4.0572 - val_mae: 0.7036\n",
      "Epoch 213/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5011 - mae: 0.2432 - val_loss: 4.7246 - val_mae: 0.9295\n",
      "Epoch 214/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4688 - mae: 0.2324 - val_loss: 4.3557 - val_mae: 0.8163\n",
      "Epoch 215/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5093 - mae: 0.3095 - val_loss: 4.3759 - val_mae: 0.8007\n",
      "Epoch 216/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4968 - mae: 0.2752 - val_loss: 4.9094 - val_mae: 0.9703\n",
      "Epoch 217/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4614 - mae: 0.1985 - val_loss: 4.3983 - val_mae: 0.7940\n",
      "Epoch 218/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4433 - mae: 0.2355 - val_loss: 4.2415 - val_mae: 0.7530\n",
      "Epoch 219/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4355 - mae: 0.2329 - val_loss: 4.3316 - val_mae: 0.8044\n",
      "Epoch 220/288\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.4268 - mae: 0.2186 - val_loss: 4.2739 - val_mae: 0.7977\n",
      "Epoch 221/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4259 - mae: 0.2166 - val_loss: 5.2234 - val_mae: 1.0832\n",
      "Epoch 222/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4415 - mae: 0.1849 - val_loss: 4.3319 - val_mae: 0.8103\n",
      "Epoch 223/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4291 - mae: 0.2228 - val_loss: 4.3292 - val_mae: 0.7712\n",
      "Epoch 224/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4650 - mae: 0.2257 - val_loss: 4.4478 - val_mae: 0.8391\n",
      "Epoch 225/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4668 - mae: 0.2673 - val_loss: 5.1783 - val_mae: 1.0532\n",
      "Epoch 226/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4401 - mae: 0.1878 - val_loss: 4.4450 - val_mae: 0.8218\n",
      "Epoch 227/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4296 - mae: 0.2106 - val_loss: 4.4334 - val_mae: 0.8304\n",
      "Epoch 228/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4400 - mae: 0.2216 - val_loss: 4.4859 - val_mae: 0.8494\n",
      "Epoch 229/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.3934 - mae: 0.1711 - val_loss: 4.1503 - val_mae: 0.7473\n",
      "Epoch 230/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5264 - mae: 0.3197 - val_loss: 4.4966 - val_mae: 0.8237\n",
      "Epoch 231/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4260 - mae: 0.2037 - val_loss: 4.3803 - val_mae: 0.8372\n",
      "Epoch 232/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5482 - mae: 0.2778 - val_loss: 5.1926 - val_mae: 1.0611\n",
      "Epoch 233/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4608 - mae: 0.2152 - val_loss: 4.7079 - val_mae: 0.9208\n",
      "Epoch 234/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4492 - mae: 0.2543 - val_loss: 5.5382 - val_mae: 1.1504\n",
      "Epoch 235/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5657 - mae: 0.2956 - val_loss: 4.7263 - val_mae: 0.9385\n",
      "Epoch 236/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4641 - mae: 0.2611 - val_loss: 4.2271 - val_mae: 0.7437\n",
      "Epoch 237/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4602 - mae: 0.2158 - val_loss: 5.0416 - val_mae: 1.0177\n",
      "Epoch 238/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4044 - mae: 0.1715 - val_loss: 4.3603 - val_mae: 0.8148\n",
      "Epoch 239/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4051 - mae: 0.1833 - val_loss: 5.2161 - val_mae: 1.0535\n",
      "Epoch 240/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4426 - mae: 0.2015 - val_loss: 4.5839 - val_mae: 0.9009\n",
      "Epoch 241/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4068 - mae: 0.2041 - val_loss: 4.4294 - val_mae: 0.8341\n",
      "Epoch 242/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4219 - mae: 0.2130 - val_loss: 4.4924 - val_mae: 0.8726\n",
      "Epoch 243/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4126 - mae: 0.1919 - val_loss: 7.3310 - val_mae: 1.5457\n",
      "Epoch 244/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5194 - mae: 0.2351 - val_loss: 5.6302 - val_mae: 1.1804\n",
      "Epoch 245/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4660 - mae: 0.2468 - val_loss: 4.7035 - val_mae: 0.8880\n",
      "Epoch 246/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4576 - mae: 0.2273 - val_loss: 4.9103 - val_mae: 0.9866\n",
      "Epoch 247/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4140 - mae: 0.1956 - val_loss: 4.4181 - val_mae: 0.8208\n",
      "Epoch 248/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4654 - mae: 0.2423 - val_loss: 4.7250 - val_mae: 0.9192\n",
      "Epoch 249/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.3800 - mae: 0.1541 - val_loss: 5.0127 - val_mae: 1.0269\n",
      "Epoch 250/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4187 - mae: 0.2105 - val_loss: 4.6865 - val_mae: 0.9354\n",
      "Epoch 251/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4332 - mae: 0.2110 - val_loss: 4.6534 - val_mae: 0.8931\n",
      "Epoch 252/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4261 - mae: 0.2003 - val_loss: 5.7175 - val_mae: 1.1956\n",
      "Epoch 253/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4573 - mae: 0.1910 - val_loss: 4.7613 - val_mae: 0.9400\n",
      "Epoch 254/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4294 - mae: 0.2268 - val_loss: 4.2812 - val_mae: 0.7777\n",
      "Epoch 255/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4797 - mae: 0.2694 - val_loss: 4.4695 - val_mae: 0.8313\n",
      "Epoch 256/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4466 - mae: 0.1942 - val_loss: 4.3684 - val_mae: 0.8413\n",
      "Epoch 257/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4393 - mae: 0.2734 - val_loss: 5.5443 - val_mae: 1.1600\n",
      "Epoch 258/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5037 - mae: 0.2992 - val_loss: 4.3242 - val_mae: 0.7698\n",
      "Epoch 259/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4966 - mae: 0.2804 - val_loss: 5.3496 - val_mae: 1.1025\n",
      "Epoch 260/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4444 - mae: 0.2205 - val_loss: 4.3954 - val_mae: 0.8011\n",
      "Epoch 261/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4259 - mae: 0.2149 - val_loss: 4.4768 - val_mae: 0.8479\n",
      "Epoch 262/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.3786 - mae: 0.1587 - val_loss: 5.1594 - val_mae: 1.0869\n",
      "Epoch 263/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4056 - mae: 0.1973 - val_loss: 4.5854 - val_mae: 0.8923\n",
      "Epoch 264/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.3846 - mae: 0.1495 - val_loss: 4.2333 - val_mae: 0.7807\n",
      "Epoch 265/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4638 - mae: 0.2309 - val_loss: 5.1619 - val_mae: 1.0696\n",
      "Epoch 266/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4313 - mae: 0.2276 - val_loss: 4.2761 - val_mae: 0.7964\n",
      "Epoch 267/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4409 - mae: 0.2285 - val_loss: 4.9578 - val_mae: 1.0062\n",
      "Epoch 268/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.3821 - mae: 0.1579 - val_loss: 4.3045 - val_mae: 0.8023\n",
      "Epoch 269/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5294 - mae: 0.2668 - val_loss: 5.3312 - val_mae: 1.1026\n",
      "Epoch 270/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5169 - mae: 0.2680 - val_loss: 4.5274 - val_mae: 0.8799\n",
      "Epoch 271/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4489 - mae: 0.2376 - val_loss: 4.5881 - val_mae: 0.8953\n",
      "Epoch 272/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4238 - mae: 0.2053 - val_loss: 5.9552 - val_mae: 1.2829\n",
      "Epoch 273/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4397 - mae: 0.2128 - val_loss: 4.5255 - val_mae: 0.8646\n",
      "Epoch 274/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4270 - mae: 0.2287 - val_loss: 4.6596 - val_mae: 0.9201\n",
      "Epoch 275/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.3947 - mae: 0.1821 - val_loss: 4.4559 - val_mae: 0.8538\n",
      "Epoch 276/288\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.3982 - mae: 0.2047 - val_loss: 4.1868 - val_mae: 0.7520\n",
      "Epoch 277/288\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.4743 - mae: 0.3075 - val_loss: 4.3346 - val_mae: 0.8299\n",
      "Epoch 278/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5820 - mae: 0.3052 - val_loss: 6.1211 - val_mae: 1.2861\n",
      "Epoch 279/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4795 - mae: 0.2373 - val_loss: 5.3124 - val_mae: 1.1074\n",
      "Epoch 280/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4919 - mae: 0.2705 - val_loss: 6.9496 - val_mae: 1.4764\n",
      "Epoch 281/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4945 - mae: 0.2031 - val_loss: 5.0311 - val_mae: 1.0195\n",
      "Epoch 282/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4160 - mae: 0.1960 - val_loss: 4.3565 - val_mae: 0.8322\n",
      "Epoch 283/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.3786 - mae: 0.1803 - val_loss: 4.0601 - val_mae: 0.7122\n",
      "Epoch 284/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4827 - mae: 0.2729 - val_loss: 4.9027 - val_mae: 1.0027\n",
      "Epoch 285/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4021 - mae: 0.1861 - val_loss: 4.3431 - val_mae: 0.8550\n",
      "Epoch 286/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.7597 - mae: 0.3558 - val_loss: 8.1839 - val_mae: 1.7269\n",
      "Epoch 287/288\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6119 - mae: 0.2660 - val_loss: 6.5003 - val_mae: 1.3625\n",
      "Epoch 288/288\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4752 - mae: 0.2110 - val_loss: 4.8754 - val_mae: 0.9701\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▆▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/mae</td><td>▃▃▆▄█▃▆█▃▁▁▁▁▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_loss</td><td>█▆▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_mae</td><td>▇█▇▆▅▃▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁▁▁▁▂▁▁▁▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>287</td></tr><tr><td>epoch/learning_rate</td><td>0.00708</td></tr><tr><td>epoch/loss</td><td>3.47519</td></tr><tr><td>epoch/mae</td><td>0.21103</td></tr><tr><td>epoch/val_loss</td><td>4.87541</td></tr><tr><td>epoch/val_mae</td><td>0.97013</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">icy-sweep-7</strong> at: <a href='https://wandb.ai/grantbell/fred_dnn_sweep/runs/6siusqdd' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/runs/6siusqdd</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230719_171928-6siusqdd\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jkcgsthb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 297\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_initializer: he_normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1: 0.07715228532368303\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_l2: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2: 0.4979071626758049\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001233896796728304\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: mse\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmetrics: mae\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\grant\\OneDrive\\Desktop\\vscode\\py_fin\\wandb\\run-20230719_171953-jkcgsthb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/grantbell/fred_dnn_sweep/runs/jkcgsthb' target=\"_blank\">easy-sweep-8</a></strong> to <a href='https://wandb.ai/grantbell/fred_dnn_sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/grantbell/fred_dnn_sweep' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/grantbell/fred_dnn_sweep/runs/jkcgsthb' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/runs/jkcgsthb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/297\n",
      "5/5 [==============================] - 1s 52ms/step - loss: 433.5210 - mae: 9.8061 - val_loss: 383.7780 - val_mae: 6.9070\n",
      "Epoch 2/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 360.8963 - mae: 5.3111 - val_loss: 354.5771 - val_mae: 4.7152\n",
      "Epoch 3/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 335.0398 - mae: 2.6117 - val_loss: 342.9778 - val_mae: 3.9788\n",
      "Epoch 4/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 326.3664 - mae: 1.8449 - val_loss: 337.5956 - val_mae: 3.8792\n",
      "Epoch 5/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 321.1408 - mae: 1.6206 - val_loss: 333.6373 - val_mae: 3.9330\n",
      "Epoch 6/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 316.4341 - mae: 1.5291 - val_loss: 329.3765 - val_mae: 3.9267\n",
      "Epoch 7/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 312.0375 - mae: 1.5365 - val_loss: 324.7634 - val_mae: 3.8992\n",
      "Epoch 8/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 309.4554 - mae: 1.7562 - val_loss: 320.4118 - val_mae: 3.9013\n",
      "Epoch 9/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 301.2156 - mae: 0.7958 - val_loss: 316.0909 - val_mae: 3.8937\n",
      "Epoch 10/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 299.5342 - mae: 1.5111 - val_loss: 311.9789 - val_mae: 3.9293\n",
      "Epoch 11/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 294.6310 - mae: 1.3144 - val_loss: 309.2433 - val_mae: 4.0315\n",
      "Epoch 12/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 289.3875 - mae: 0.9171 - val_loss: 304.4800 - val_mae: 3.9558\n",
      "Epoch 13/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 286.3665 - mae: 1.1487 - val_loss: 299.3422 - val_mae: 3.8668\n",
      "Epoch 14/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 281.8105 - mae: 0.9614 - val_loss: 295.6487 - val_mae: 3.8475\n",
      "Epoch 15/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 278.4508 - mae: 1.1219 - val_loss: 291.3808 - val_mae: 3.8487\n",
      "Epoch 16/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 274.1402 - mae: 0.9732 - val_loss: 287.1257 - val_mae: 3.7985\n",
      "Epoch 17/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 270.4431 - mae: 0.9702 - val_loss: 283.6386 - val_mae: 3.7987\n",
      "Epoch 18/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 266.2576 - mae: 0.7896 - val_loss: 279.5766 - val_mae: 3.7546\n",
      "Epoch 19/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 263.3975 - mae: 1.0235 - val_loss: 276.0718 - val_mae: 3.7175\n",
      "Epoch 20/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 258.8691 - mae: 0.6372 - val_loss: 271.2534 - val_mae: 3.6772\n",
      "Epoch 21/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 255.9737 - mae: 0.9601 - val_loss: 267.9164 - val_mae: 3.6760\n",
      "Epoch 22/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 251.6600 - mae: 0.6635 - val_loss: 264.5092 - val_mae: 3.6499\n",
      "Epoch 23/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 248.4062 - mae: 0.7619 - val_loss: 260.3530 - val_mae: 3.5860\n",
      "Epoch 24/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 245.3145 - mae: 0.8592 - val_loss: 256.2233 - val_mae: 3.5342\n",
      "Epoch 25/297\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 241.5828 - mae: 0.7730 - val_loss: 252.8614 - val_mae: 3.5056\n",
      "Epoch 26/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 238.4425 - mae: 0.7431 - val_loss: 248.8826 - val_mae: 3.5221\n",
      "Epoch 27/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 234.8707 - mae: 0.7923 - val_loss: 245.4119 - val_mae: 3.4260\n",
      "Epoch 28/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 231.4926 - mae: 0.6703 - val_loss: 242.3854 - val_mae: 3.4215\n",
      "Epoch 29/297\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 228.2090 - mae: 0.6887 - val_loss: 238.6537 - val_mae: 3.3370\n",
      "Epoch 30/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 224.9907 - mae: 0.6042 - val_loss: 235.6119 - val_mae: 3.3102\n",
      "Epoch 31/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 221.7116 - mae: 0.5770 - val_loss: 231.4081 - val_mae: 3.2369\n",
      "Epoch 32/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 218.7044 - mae: 0.6199 - val_loss: 227.8067 - val_mae: 3.1451\n",
      "Epoch 33/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 215.8288 - mae: 0.6469 - val_loss: 225.0642 - val_mae: 3.1304\n",
      "Epoch 34/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 213.7876 - mae: 1.0525 - val_loss: 222.1593 - val_mae: 3.0955\n",
      "Epoch 35/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 210.2848 - mae: 0.7894 - val_loss: 218.0421 - val_mae: 3.0287\n",
      "Epoch 36/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 207.1375 - mae: 0.7283 - val_loss: 214.6017 - val_mae: 3.0537\n",
      "Epoch 37/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 203.5758 - mae: 0.4776 - val_loss: 211.5041 - val_mae: 2.9630\n",
      "Epoch 38/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 200.8319 - mae: 0.5671 - val_loss: 208.9531 - val_mae: 2.9180\n",
      "Epoch 39/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 199.1142 - mae: 1.1113 - val_loss: 205.8932 - val_mae: 2.8541\n",
      "Epoch 40/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 195.8762 - mae: 0.8306 - val_loss: 202.4561 - val_mae: 2.8312\n",
      "Epoch 41/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 192.5504 - mae: 0.6560 - val_loss: 199.3490 - val_mae: 2.8179\n",
      "Epoch 42/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 190.5211 - mae: 0.9388 - val_loss: 196.3906 - val_mae: 2.8109\n",
      "Epoch 43/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 187.0282 - mae: 0.5535 - val_loss: 194.0125 - val_mae: 2.7657\n",
      "Epoch 44/297\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 184.4631 - mae: 0.6739 - val_loss: 191.2235 - val_mae: 2.7399\n",
      "Epoch 45/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 182.2533 - mae: 0.8113 - val_loss: 188.0487 - val_mae: 2.6594\n",
      "Epoch 46/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 179.0691 - mae: 0.4587 - val_loss: 185.0922 - val_mae: 2.5839\n",
      "Epoch 47/297\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 177.3668 - mae: 0.9406 - val_loss: 182.1080 - val_mae: 2.5452\n",
      "Epoch 48/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 174.3897 - mae: 0.7020 - val_loss: 179.8110 - val_mae: 2.5383\n",
      "Epoch 49/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 171.9240 - mae: 0.7110 - val_loss: 177.0992 - val_mae: 2.4905\n",
      "Epoch 50/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 168.9308 - mae: 0.4262 - val_loss: 174.7819 - val_mae: 2.4866\n",
      "Epoch 51/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 166.5540 - mae: 0.4810 - val_loss: 172.1375 - val_mae: 2.4095\n",
      "Epoch 52/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 164.8567 - mae: 0.8264 - val_loss: 169.4355 - val_mae: 2.3978\n",
      "Epoch 53/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 161.8335 - mae: 0.5136 - val_loss: 167.5350 - val_mae: 2.3982\n",
      "Epoch 54/297\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 160.3477 - mae: 0.9193 - val_loss: 164.9540 - val_mae: 2.3444\n",
      "Epoch 55/297\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 157.3495 - mae: 0.6060 - val_loss: 162.1841 - val_mae: 2.2769\n",
      "Epoch 56/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 155.2716 - mae: 0.6671 - val_loss: 159.8312 - val_mae: 2.2871\n",
      "Epoch 57/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 152.7023 - mae: 0.5468 - val_loss: 157.1839 - val_mae: 2.2330\n",
      "Epoch 58/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 150.3820 - mae: 0.4463 - val_loss: 154.8392 - val_mae: 2.2343\n",
      "Epoch 59/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 148.2130 - mae: 0.4906 - val_loss: 152.3736 - val_mae: 2.1834\n",
      "Epoch 60/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 145.9750 - mae: 0.4390 - val_loss: 150.2837 - val_mae: 2.1434\n",
      "Epoch 61/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 144.3519 - mae: 0.7543 - val_loss: 148.0157 - val_mae: 2.1687\n",
      "Epoch 62/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 142.0509 - mae: 0.5901 - val_loss: 146.1558 - val_mae: 2.1027\n",
      "Epoch 63/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 140.1617 - mae: 0.6857 - val_loss: 144.1354 - val_mae: 2.0306\n",
      "Epoch 64/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 138.4923 - mae: 0.7948 - val_loss: 141.2349 - val_mae: 2.0276\n",
      "Epoch 65/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 135.9242 - mae: 0.6129 - val_loss: 139.6301 - val_mae: 2.0002\n",
      "Epoch 66/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 134.5164 - mae: 0.8644 - val_loss: 137.5486 - val_mae: 1.9233\n",
      "Epoch 67/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 132.1785 - mae: 0.7771 - val_loss: 135.6863 - val_mae: 1.9722\n",
      "Epoch 68/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 129.9245 - mae: 0.5717 - val_loss: 133.1312 - val_mae: 1.8995\n",
      "Epoch 69/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 128.1304 - mae: 0.6695 - val_loss: 131.5589 - val_mae: 1.8952\n",
      "Epoch 70/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 126.0098 - mae: 0.4929 - val_loss: 129.6294 - val_mae: 1.8691\n",
      "Epoch 71/297\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 124.3537 - mae: 0.6439 - val_loss: 127.6679 - val_mae: 1.8715\n",
      "Epoch 72/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 122.6592 - mae: 0.7144 - val_loss: 125.8168 - val_mae: 1.8716\n",
      "Epoch 73/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 120.3856 - mae: 0.4426 - val_loss: 123.5132 - val_mae: 1.8259\n",
      "Epoch 74/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 118.8973 - mae: 0.5793 - val_loss: 122.2735 - val_mae: 1.8154\n",
      "Epoch 75/297\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 117.1156 - mae: 0.6603 - val_loss: 119.9741 - val_mae: 1.8252\n",
      "Epoch 76/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 115.2344 - mae: 0.5619 - val_loss: 118.1295 - val_mae: 1.7781\n",
      "Epoch 77/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 113.9174 - mae: 0.6962 - val_loss: 116.1377 - val_mae: 1.7686\n",
      "Epoch 78/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 111.6841 - mae: 0.4645 - val_loss: 114.8634 - val_mae: 1.7484\n",
      "Epoch 79/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 110.0168 - mae: 0.4723 - val_loss: 112.7767 - val_mae: 1.7346\n",
      "Epoch 80/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 108.4021 - mae: 0.5115 - val_loss: 110.9069 - val_mae: 1.6878\n",
      "Epoch 81/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 107.0678 - mae: 0.6719 - val_loss: 109.0210 - val_mae: 1.6275\n",
      "Epoch 82/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 105.5056 - mae: 0.7208 - val_loss: 107.6907 - val_mae: 1.6060\n",
      "Epoch 83/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 103.6277 - mae: 0.5386 - val_loss: 105.8620 - val_mae: 1.6103\n",
      "Epoch 84/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 102.2649 - mae: 0.6434 - val_loss: 105.1920 - val_mae: 1.6823\n",
      "Epoch 85/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 100.9401 - mae: 0.6012 - val_loss: 102.5963 - val_mae: 1.6117\n",
      "Epoch 86/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 99.2208 - mae: 0.6844 - val_loss: 101.5360 - val_mae: 1.6415\n",
      "Epoch 87/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 97.4030 - mae: 0.4521 - val_loss: 100.6336 - val_mae: 1.6866\n",
      "Epoch 88/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 96.0595 - mae: 0.6031 - val_loss: 98.7146 - val_mae: 1.6080\n",
      "Epoch 89/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 94.6242 - mae: 0.5934 - val_loss: 97.6299 - val_mae: 1.6682\n",
      "Epoch 90/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 93.1726 - mae: 0.5275 - val_loss: 95.5913 - val_mae: 1.6151\n",
      "Epoch 91/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 92.0976 - mae: 0.7829 - val_loss: 94.4821 - val_mae: 1.6218\n",
      "Epoch 92/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 90.1285 - mae: 0.4896 - val_loss: 92.4613 - val_mae: 1.5763\n",
      "Epoch 93/297\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 89.4478 - mae: 0.6735 - val_loss: 91.9965 - val_mae: 1.6190\n",
      "Epoch 94/297\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 87.5282 - mae: 0.4794 - val_loss: 89.2797 - val_mae: 1.4688\n",
      "Epoch 95/297\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 86.2228 - mae: 0.5894 - val_loss: 87.9173 - val_mae: 1.4832\n",
      "Epoch 96/297\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 84.9460 - mae: 0.6233 - val_loss: 87.1444 - val_mae: 1.5250\n",
      "Epoch 97/297\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 83.3188 - mae: 0.4153 - val_loss: 85.8089 - val_mae: 1.5346\n",
      "Epoch 98/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 82.0083 - mae: 0.4332 - val_loss: 84.2612 - val_mae: 1.5383\n",
      "Epoch 99/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 80.6702 - mae: 0.4171 - val_loss: 83.1165 - val_mae: 1.5319\n",
      "Epoch 100/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 79.4502 - mae: 0.4442 - val_loss: 81.9127 - val_mae: 1.5384\n",
      "Epoch 101/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 78.3042 - mae: 0.5242 - val_loss: 81.3861 - val_mae: 1.6189\n",
      "Epoch 102/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 77.4442 - mae: 0.7073 - val_loss: 79.0331 - val_mae: 1.4990\n",
      "Epoch 103/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 76.6143 - mae: 0.8793 - val_loss: 77.6652 - val_mae: 1.4334\n",
      "Epoch 104/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 74.7151 - mae: 0.5709 - val_loss: 77.1106 - val_mae: 1.4931\n",
      "Epoch 105/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 73.7373 - mae: 0.6563 - val_loss: 76.6494 - val_mae: 1.6254\n",
      "Epoch 106/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 72.2278 - mae: 0.4219 - val_loss: 74.7660 - val_mae: 1.4956\n",
      "Epoch 107/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 71.3820 - mae: 0.6629 - val_loss: 73.9766 - val_mae: 1.5507\n",
      "Epoch 108/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 70.0813 - mae: 0.5177 - val_loss: 72.3787 - val_mae: 1.4768\n",
      "Epoch 109/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 68.7724 - mae: 0.4172 - val_loss: 71.5409 - val_mae: 1.5324\n",
      "Epoch 110/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 68.0749 - mae: 0.6579 - val_loss: 70.6906 - val_mae: 1.5722\n",
      "Epoch 111/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 66.7033 - mae: 0.5008 - val_loss: 68.7297 - val_mae: 1.4360\n",
      "Epoch 112/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 65.9820 - mae: 0.6124 - val_loss: 68.2532 - val_mae: 1.5112\n",
      "Epoch 113/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 64.4616 - mae: 0.3590 - val_loss: 66.9712 - val_mae: 1.4864\n",
      "Epoch 114/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 63.6074 - mae: 0.5291 - val_loss: 65.9708 - val_mae: 1.4580\n",
      "Epoch 115/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 62.8584 - mae: 0.6942 - val_loss: 65.4065 - val_mae: 1.5575\n",
      "Epoch 116/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 61.8172 - mae: 0.7019 - val_loss: 65.1927 - val_mae: 1.7061\n",
      "Epoch 117/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 60.4292 - mae: 0.4289 - val_loss: 62.3504 - val_mae: 1.3833\n",
      "Epoch 118/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 59.5008 - mae: 0.4343 - val_loss: 61.4393 - val_mae: 1.3858\n",
      "Epoch 119/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 58.3806 - mae: 0.3469 - val_loss: 60.9278 - val_mae: 1.4443\n",
      "Epoch 120/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 57.6707 - mae: 0.5658 - val_loss: 59.5315 - val_mae: 1.3808\n",
      "Epoch 121/297\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 56.6518 - mae: 0.4144 - val_loss: 58.4445 - val_mae: 1.4128\n",
      "Epoch 122/297\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 55.8008 - mae: 0.5177 - val_loss: 57.4719 - val_mae: 1.3870\n",
      "Epoch 123/297\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 54.7612 - mae: 0.4896 - val_loss: 57.4728 - val_mae: 1.4988\n",
      "Epoch 124/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 53.9403 - mae: 0.5260 - val_loss: 56.2193 - val_mae: 1.4531\n",
      "Epoch 125/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 53.0305 - mae: 0.4497 - val_loss: 54.7180 - val_mae: 1.3540\n",
      "Epoch 126/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 52.1693 - mae: 0.4500 - val_loss: 54.0119 - val_mae: 1.3978\n",
      "Epoch 127/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 51.3885 - mae: 0.5779 - val_loss: 53.3890 - val_mae: 1.3810\n",
      "Epoch 128/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 50.7969 - mae: 0.6757 - val_loss: 52.5465 - val_mae: 1.4032\n",
      "Epoch 129/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 49.5212 - mae: 0.4485 - val_loss: 51.3331 - val_mae: 1.3365\n",
      "Epoch 130/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 49.0182 - mae: 0.5955 - val_loss: 50.6061 - val_mae: 1.3612\n",
      "Epoch 131/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 47.7590 - mae: 0.3341 - val_loss: 50.0181 - val_mae: 1.3911\n",
      "Epoch 132/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 47.3667 - mae: 0.5922 - val_loss: 50.0630 - val_mae: 1.5252\n",
      "Epoch 133/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 46.4194 - mae: 0.5510 - val_loss: 48.8018 - val_mae: 1.4444\n",
      "Epoch 134/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 45.6523 - mae: 0.5551 - val_loss: 48.3911 - val_mae: 1.5058\n",
      "Epoch 135/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.7093 - mae: 0.3994 - val_loss: 46.7755 - val_mae: 1.3532\n",
      "Epoch 136/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 43.8543 - mae: 0.3102 - val_loss: 46.5222 - val_mae: 1.4368\n",
      "Epoch 137/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 43.2886 - mae: 0.4721 - val_loss: 46.3511 - val_mae: 1.5337\n",
      "Epoch 138/297\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 42.5365 - mae: 0.4154 - val_loss: 44.5134 - val_mae: 1.3497\n",
      "Epoch 139/297\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 42.1909 - mae: 0.6056 - val_loss: 43.8098 - val_mae: 1.3595\n",
      "Epoch 140/297\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 41.0425 - mae: 0.3781 - val_loss: 43.4686 - val_mae: 1.3929\n",
      "Epoch 141/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 40.6007 - mae: 0.5086 - val_loss: 42.2916 - val_mae: 1.3733\n",
      "Epoch 142/297\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 40.0201 - mae: 0.6366 - val_loss: 42.0754 - val_mae: 1.3932\n",
      "Epoch 143/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 38.8580 - mae: 0.2794 - val_loss: 41.2166 - val_mae: 1.3951\n",
      "Epoch 144/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 38.5051 - mae: 0.5475 - val_loss: 41.4768 - val_mae: 1.5427\n",
      "Epoch 145/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 37.9888 - mae: 0.5972 - val_loss: 40.6922 - val_mae: 1.5060\n",
      "Epoch 146/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 37.1740 - mae: 0.4796 - val_loss: 39.5702 - val_mae: 1.4148\n",
      "Epoch 147/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.6691 - mae: 0.5998 - val_loss: 38.7085 - val_mae: 1.3577\n",
      "Epoch 148/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.7363 - mae: 0.3924 - val_loss: 37.9926 - val_mae: 1.3677\n",
      "Epoch 149/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.3163 - mae: 0.5665 - val_loss: 38.1755 - val_mae: 1.5008\n",
      "Epoch 150/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 34.5865 - mae: 0.4543 - val_loss: 36.8348 - val_mae: 1.3607\n",
      "Epoch 151/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.9559 - mae: 0.4358 - val_loss: 36.6842 - val_mae: 1.4527\n",
      "Epoch 152/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.4795 - mae: 0.4901 - val_loss: 37.0493 - val_mae: 1.6376\n",
      "Epoch 153/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.9641 - mae: 0.5693 - val_loss: 35.6193 - val_mae: 1.4753\n",
      "Epoch 154/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.2963 - mae: 0.9673 - val_loss: 34.7596 - val_mae: 1.4108\n",
      "Epoch 155/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 31.9385 - mae: 0.5895 - val_loss: 33.7986 - val_mae: 1.3661\n",
      "Epoch 156/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.1062 - mae: 0.4437 - val_loss: 32.8975 - val_mae: 1.2996\n",
      "Epoch 157/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.5189 - mae: 0.3872 - val_loss: 33.7985 - val_mae: 1.5565\n",
      "Epoch 158/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.9949 - mae: 0.4499 - val_loss: 32.3852 - val_mae: 1.4222\n",
      "Epoch 159/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.5039 - mae: 0.4293 - val_loss: 33.4236 - val_mae: 1.6564\n",
      "Epoch 160/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.3715 - mae: 0.6339 - val_loss: 31.8235 - val_mae: 1.4658\n",
      "Epoch 161/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.4322 - mae: 0.4506 - val_loss: 30.5067 - val_mae: 1.3308\n",
      "Epoch 162/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28.2504 - mae: 0.5719 - val_loss: 29.7886 - val_mae: 1.3352\n",
      "Epoch 163/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.0304 - mae: 0.7481 - val_loss: 30.6942 - val_mae: 1.5116\n",
      "Epoch 164/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.3431 - mae: 0.6298 - val_loss: 29.0965 - val_mae: 1.3041\n",
      "Epoch 165/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 26.5280 - mae: 0.4369 - val_loss: 29.6358 - val_mae: 1.5113\n",
      "Epoch 166/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 26.3027 - mae: 0.6234 - val_loss: 29.0505 - val_mae: 1.4844\n",
      "Epoch 167/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 25.5328 - mae: 0.3918 - val_loss: 27.9036 - val_mae: 1.3731\n",
      "Epoch 168/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 24.9295 - mae: 0.3153 - val_loss: 27.6813 - val_mae: 1.4060\n",
      "Epoch 169/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 24.7998 - mae: 0.5002 - val_loss: 26.4128 - val_mae: 1.2743\n",
      "Epoch 170/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 24.1533 - mae: 0.3740 - val_loss: 27.1846 - val_mae: 1.4801\n",
      "Epoch 171/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 23.8854 - mae: 0.5238 - val_loss: 26.8791 - val_mae: 1.4968\n",
      "Epoch 172/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 23.8493 - mae: 0.7193 - val_loss: 26.0277 - val_mae: 1.3967\n",
      "Epoch 173/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.8338 - mae: 0.3188 - val_loss: 25.2750 - val_mae: 1.3895\n",
      "Epoch 174/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 22.4327 - mae: 0.4084 - val_loss: 24.8315 - val_mae: 1.3670\n",
      "Epoch 175/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.1628 - mae: 0.4954 - val_loss: 24.2486 - val_mae: 1.3556\n",
      "Epoch 176/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.6820 - mae: 0.4466 - val_loss: 24.6450 - val_mae: 1.4770\n",
      "Epoch 177/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 21.3920 - mae: 0.5123 - val_loss: 23.1556 - val_mae: 1.3083\n",
      "Epoch 178/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 20.9252 - mae: 0.4450 - val_loss: 23.4546 - val_mae: 1.3841\n",
      "Epoch 179/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 20.4573 - mae: 0.3886 - val_loss: 22.7487 - val_mae: 1.3700\n",
      "Epoch 180/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 20.0767 - mae: 0.3669 - val_loss: 22.4191 - val_mae: 1.3980\n",
      "Epoch 181/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 20.0883 - mae: 0.6546 - val_loss: 24.1240 - val_mae: 1.7107\n",
      "Epoch 182/297\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 19.9525 - mae: 0.6697 - val_loss: 21.2761 - val_mae: 1.2941\n",
      "Epoch 183/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 19.4319 - mae: 0.5665 - val_loss: 21.2518 - val_mae: 1.3249\n",
      "Epoch 184/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 18.7128 - mae: 0.4065 - val_loss: 20.7110 - val_mae: 1.3127\n",
      "Epoch 185/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 18.7045 - mae: 0.6334 - val_loss: 20.5809 - val_mae: 1.3355\n",
      "Epoch 186/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 17.9610 - mae: 0.3348 - val_loss: 20.5278 - val_mae: 1.3760\n",
      "Epoch 187/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 18.6246 - mae: 0.8694 - val_loss: 21.4147 - val_mae: 1.5918\n",
      "Epoch 188/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 18.3833 - mae: 0.8536 - val_loss: 19.3048 - val_mae: 1.2381\n",
      "Epoch 189/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 17.1999 - mae: 0.4584 - val_loss: 20.9842 - val_mae: 1.6287\n",
      "Epoch 190/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 17.1624 - mae: 0.6381 - val_loss: 22.0000 - val_mae: 1.9243\n",
      "Epoch 191/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 17.0381 - mae: 0.6912 - val_loss: 18.6930 - val_mae: 1.3654\n",
      "Epoch 192/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 16.9495 - mae: 0.8451 - val_loss: 18.7612 - val_mae: 1.3805\n",
      "Epoch 193/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 16.4633 - mae: 0.7015 - val_loss: 18.2044 - val_mae: 1.3272\n",
      "Epoch 194/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 15.7773 - mae: 0.4906 - val_loss: 20.0380 - val_mae: 1.7809\n",
      "Epoch 195/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 15.4420 - mae: 0.4601 - val_loss: 17.0314 - val_mae: 1.2522\n",
      "Epoch 196/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 15.7827 - mae: 0.7443 - val_loss: 18.6434 - val_mae: 1.5745\n",
      "Epoch 197/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 14.6800 - mae: 0.3241 - val_loss: 16.9535 - val_mae: 1.2958\n",
      "Epoch 198/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 14.5078 - mae: 0.4433 - val_loss: 17.5560 - val_mae: 1.4672\n",
      "Epoch 199/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 14.2402 - mae: 0.3562 - val_loss: 16.5850 - val_mae: 1.3298\n",
      "Epoch 200/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 14.2533 - mae: 0.5712 - val_loss: 16.6363 - val_mae: 1.3945\n",
      "Epoch 201/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 13.6877 - mae: 0.3636 - val_loss: 16.6415 - val_mae: 1.4454\n",
      "Epoch 202/297\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 13.5464 - mae: 0.4747 - val_loss: 15.3638 - val_mae: 1.2535\n",
      "Epoch 203/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 13.5254 - mae: 0.6081 - val_loss: 17.3243 - val_mae: 1.6712\n",
      "Epoch 204/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 13.2465 - mae: 0.5751 - val_loss: 15.5919 - val_mae: 1.3786\n",
      "Epoch 205/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 13.2028 - mae: 0.6549 - val_loss: 15.5472 - val_mae: 1.4281\n",
      "Epoch 206/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 12.5884 - mae: 0.4354 - val_loss: 14.4702 - val_mae: 1.2768\n",
      "Epoch 207/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 12.2420 - mae: 0.3619 - val_loss: 14.4053 - val_mae: 1.2772\n",
      "Epoch 208/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 12.6939 - mae: 0.7796 - val_loss: 14.0592 - val_mae: 1.2417\n",
      "Epoch 209/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 11.8535 - mae: 0.4176 - val_loss: 15.9374 - val_mae: 1.6644\n",
      "Epoch 210/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 12.0758 - mae: 0.6655 - val_loss: 16.1702 - val_mae: 1.7759\n",
      "Epoch 211/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 12.0240 - mae: 0.7722 - val_loss: 13.1824 - val_mae: 1.2561\n",
      "Epoch 212/297\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11.3349 - mae: 0.4559 - val_loss: 14.1067 - val_mae: 1.4352\n",
      "Epoch 213/297\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11.2237 - mae: 0.5144 - val_loss: 15.1952 - val_mae: 1.7073\n",
      "Epoch 214/297\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 10.9866 - mae: 0.5197 - val_loss: 14.7415 - val_mae: 1.6476\n",
      "Epoch 215/297\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 10.6073 - mae: 0.4339 - val_loss: 13.4111 - val_mae: 1.4203\n",
      "Epoch 216/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 11.2842 - mae: 0.8875 - val_loss: 15.7386 - val_mae: 2.0271\n",
      "Epoch 217/297\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 10.6192 - mae: 0.5435 - val_loss: 14.2176 - val_mae: 1.6780\n",
      "Epoch 218/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 10.2886 - mae: 0.5936 - val_loss: 14.9840 - val_mae: 1.8756\n",
      "Epoch 219/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.9983 - mae: 0.4939 - val_loss: 11.9823 - val_mae: 1.2663\n",
      "Epoch 220/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.8541 - mae: 0.4744 - val_loss: 11.8678 - val_mae: 1.2679\n",
      "Epoch 221/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.4601 - mae: 0.3400 - val_loss: 11.3284 - val_mae: 1.2078\n",
      "Epoch 222/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.3200 - mae: 0.4038 - val_loss: 11.7121 - val_mae: 1.3380\n",
      "Epoch 223/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.1131 - mae: 0.4116 - val_loss: 11.4919 - val_mae: 1.3308\n",
      "Epoch 224/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.7125 - mae: 0.7142 - val_loss: 11.0971 - val_mae: 1.2398\n",
      "Epoch 225/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.7341 - mae: 0.3143 - val_loss: 11.2221 - val_mae: 1.3073\n",
      "Epoch 226/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.5407 - mae: 0.3064 - val_loss: 11.2457 - val_mae: 1.3579\n",
      "Epoch 227/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.7277 - mae: 0.5509 - val_loss: 10.3925 - val_mae: 1.2671\n",
      "Epoch 228/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.4328 - mae: 0.4627 - val_loss: 10.7214 - val_mae: 1.3021\n",
      "Epoch 229/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.4323 - mae: 0.5858 - val_loss: 10.5808 - val_mae: 1.2999\n",
      "Epoch 230/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.1750 - mae: 0.4478 - val_loss: 9.7782 - val_mae: 1.2179\n",
      "Epoch 231/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.4998 - mae: 0.7154 - val_loss: 9.8769 - val_mae: 1.2382\n",
      "Epoch 232/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.8815 - mae: 0.4046 - val_loss: 9.8912 - val_mae: 1.2477\n",
      "Epoch 233/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.6203 - mae: 0.3652 - val_loss: 9.6085 - val_mae: 1.2046\n",
      "Epoch 234/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.6164 - mae: 0.4637 - val_loss: 9.1595 - val_mae: 1.2066\n",
      "Epoch 235/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.5003 - mae: 0.4640 - val_loss: 9.0316 - val_mae: 1.2044\n",
      "Epoch 236/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.3284 - mae: 0.4171 - val_loss: 9.7889 - val_mae: 1.3466\n",
      "Epoch 237/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.1673 - mae: 0.4078 - val_loss: 8.5529 - val_mae: 1.1195\n",
      "Epoch 238/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.4438 - mae: 0.6121 - val_loss: 9.2268 - val_mae: 1.3009\n",
      "Epoch 239/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.9574 - mae: 0.4497 - val_loss: 9.0182 - val_mae: 1.2458\n",
      "Epoch 240/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.7037 - mae: 0.8116 - val_loss: 9.2493 - val_mae: 1.3496\n",
      "Epoch 241/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 6.5651 - mae: 0.2803 - val_loss: 8.9681 - val_mae: 1.2824\n",
      "Epoch 242/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 6.4598 - mae: 0.3391 - val_loss: 9.0571 - val_mae: 1.3313\n",
      "Epoch 243/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.4531 - mae: 0.4096 - val_loss: 8.4363 - val_mae: 1.2070\n",
      "Epoch 244/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 6.4531 - mae: 0.4735 - val_loss: 8.7215 - val_mae: 1.2949\n",
      "Epoch 245/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.8494 - mae: 0.7512 - val_loss: 8.2647 - val_mae: 1.2442\n",
      "Epoch 246/297\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.3505 - mae: 0.4874 - val_loss: 8.5802 - val_mae: 1.3147\n",
      "Epoch 247/297\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.0077 - mae: 0.3912 - val_loss: 8.0033 - val_mae: 1.2012\n",
      "Epoch 248/297\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 5.8934 - mae: 0.3976 - val_loss: 8.1749 - val_mae: 1.2673\n",
      "Epoch 249/297\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.7721 - mae: 0.3845 - val_loss: 7.5592 - val_mae: 1.1611\n",
      "Epoch 250/297\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 5.6931 - mae: 0.3912 - val_loss: 7.9923 - val_mae: 1.2518\n",
      "Epoch 251/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.5724 - mae: 0.8275 - val_loss: 8.1208 - val_mae: 1.3210\n",
      "Epoch 252/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.4137 - mae: 0.2978 - val_loss: 8.3829 - val_mae: 1.3744\n",
      "Epoch 253/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.3001 - mae: 0.2495 - val_loss: 7.9723 - val_mae: 1.3424\n",
      "Epoch 254/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 5.1855 - mae: 0.2183 - val_loss: 7.8252 - val_mae: 1.3252\n",
      "Epoch 255/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.7112 - mae: 0.6953 - val_loss: 8.8050 - val_mae: 1.5651\n",
      "Epoch 256/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.3537 - mae: 0.4461 - val_loss: 10.4458 - val_mae: 1.9532\n",
      "Epoch 257/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 5.1091 - mae: 0.3601 - val_loss: 7.2364 - val_mae: 1.2358\n",
      "Epoch 258/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.1372 - mae: 0.4792 - val_loss: 7.2680 - val_mae: 1.2718\n",
      "Epoch 259/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.0971 - mae: 0.5386 - val_loss: 6.5511 - val_mae: 1.1435\n",
      "Epoch 260/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.9643 - mae: 0.5082 - val_loss: 7.2175 - val_mae: 1.2920\n",
      "Epoch 261/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.9131 - mae: 0.4879 - val_loss: 7.5633 - val_mae: 1.3966\n",
      "Epoch 262/297\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5861 - mae: 0.2996 - val_loss: 6.4396 - val_mae: 1.1724\n",
      "Epoch 263/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.5036 - mae: 0.8509 - val_loss: 7.2542 - val_mae: 1.3474\n",
      "Epoch 264/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.6602 - mae: 0.4275 - val_loss: 7.1310 - val_mae: 1.3361\n",
      "Epoch 265/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5044 - mae: 0.4226 - val_loss: 6.0070 - val_mae: 1.1537\n",
      "Epoch 266/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.3433 - mae: 0.8039 - val_loss: 6.5556 - val_mae: 1.2295\n",
      "Epoch 267/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.4643 - mae: 0.4823 - val_loss: 6.1007 - val_mae: 1.2364\n",
      "Epoch 268/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5186 - mae: 0.5353 - val_loss: 5.8054 - val_mae: 1.0882\n",
      "Epoch 269/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.2178 - mae: 0.4040 - val_loss: 6.6542 - val_mae: 1.3210\n",
      "Epoch 270/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.4009 - mae: 0.5994 - val_loss: 7.6963 - val_mae: 1.5727\n",
      "Epoch 271/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.3648 - mae: 0.5851 - val_loss: 5.6769 - val_mae: 1.0987\n",
      "Epoch 272/297\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.1588 - mae: 0.5165 - val_loss: 7.8106 - val_mae: 1.6473\n",
      "Epoch 273/297\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.0473 - mae: 0.4642 - val_loss: 5.2638 - val_mae: 1.0885\n",
      "Epoch 274/297\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.1437 - mae: 0.5657 - val_loss: 5.3574 - val_mae: 1.1434\n",
      "Epoch 275/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.4677 - mae: 0.7689 - val_loss: 5.4429 - val_mae: 1.1488\n",
      "Epoch 276/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.8125 - mae: 0.4191 - val_loss: 7.9437 - val_mae: 1.7446\n",
      "Epoch 277/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.7187 - mae: 0.2940 - val_loss: 5.3875 - val_mae: 1.1322\n",
      "Epoch 278/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.0528 - mae: 0.6343 - val_loss: 5.1678 - val_mae: 1.0979\n",
      "Epoch 279/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5618 - mae: 0.3466 - val_loss: 5.5233 - val_mae: 1.1791\n",
      "Epoch 280/297\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.7373 - mae: 0.5072 - val_loss: 5.6094 - val_mae: 1.2089\n",
      "Epoch 281/297\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.9103 - mae: 0.6779 - val_loss: 4.8227 - val_mae: 1.0726\n",
      "Epoch 282/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.3652 - mae: 0.3064 - val_loss: 5.2909 - val_mae: 1.1563\n",
      "Epoch 283/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.3413 - mae: 0.3274 - val_loss: 4.8583 - val_mae: 1.0737\n",
      "Epoch 284/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.2224 - mae: 0.2846 - val_loss: 5.2690 - val_mae: 1.1719\n",
      "Epoch 285/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.7461 - mae: 0.5792 - val_loss: 7.2166 - val_mae: 1.6828\n",
      "Epoch 286/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4130 - mae: 0.4302 - val_loss: 5.6280 - val_mae: 1.2999\n",
      "Epoch 287/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.0412 - mae: 0.2199 - val_loss: 4.7183 - val_mae: 1.1047\n",
      "Epoch 288/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.0789 - mae: 0.3237 - val_loss: 5.3929 - val_mae: 1.2457\n",
      "Epoch 289/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.3214 - mae: 0.5406 - val_loss: 5.1923 - val_mae: 1.2121\n",
      "Epoch 290/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.0651 - mae: 0.3953 - val_loss: 5.1897 - val_mae: 1.1985\n",
      "Epoch 291/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.9227 - mae: 0.2955 - val_loss: 5.5227 - val_mae: 1.2893\n",
      "Epoch 292/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.1052 - mae: 0.4435 - val_loss: 7.5369 - val_mae: 1.8426\n",
      "Epoch 293/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.3533 - mae: 0.6273 - val_loss: 8.4507 - val_mae: 2.0944\n",
      "Epoch 294/297\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.9241 - mae: 0.8636 - val_loss: 4.9155 - val_mae: 1.1557\n",
      "Epoch 295/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.8839 - mae: 0.4172 - val_loss: 5.7387 - val_mae: 1.4012\n",
      "Epoch 296/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.9860 - mae: 0.5131 - val_loss: 4.9590 - val_mae: 1.2220\n",
      "Epoch 297/297\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.8747 - mae: 0.4444 - val_loss: 5.9921 - val_mae: 1.4865\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>██▇▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/mae</td><td>██▄▄▂▃▃▃▂▂▂▃▂▂▂▃▂▃▁▂▂▂▁▂▁▃▃▂▂▂▂▁▃▁▂▂▂▂▁▂</td></tr><tr><td>epoch/val_loss</td><td>██▇▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_mae</td><td>███▇▆▅▄▄▃▃▂▂▂▂▂▂▁▂▂▂▂▂▂▂▁▁▂▁▂▁▁▁▁▁▃▁▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>296</td></tr><tr><td>epoch/learning_rate</td><td>0.00123</td></tr><tr><td>epoch/loss</td><td>2.8747</td></tr><tr><td>epoch/mae</td><td>0.44439</td></tr><tr><td>epoch/val_loss</td><td>5.99209</td></tr><tr><td>epoch/val_mae</td><td>1.48645</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">easy-sweep-8</strong> at: <a href='https://wandb.ai/grantbell/fred_dnn_sweep/runs/jkcgsthb' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/runs/jkcgsthb</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230719_171953-jkcgsthb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zrnxzt9u with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_initializer: he_normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1: 0.014125660153224388\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_l2: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2: 0.2963311884818635\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.009609942956007188\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: mse\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmetrics: mae\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\grant\\OneDrive\\Desktop\\vscode\\py_fin\\wandb\\run-20230719_172019-zrnxzt9u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/grantbell/fred_dnn_sweep/runs/zrnxzt9u' target=\"_blank\">resilient-sweep-9</a></strong> to <a href='https://wandb.ai/grantbell/fred_dnn_sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/grantbell/fred_dnn_sweep' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/grantbell/fred_dnn_sweep/runs/zrnxzt9u' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/runs/zrnxzt9u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/392\n",
      "5/5 [==============================] - 1s 53ms/step - loss: 186.4918 - mae: 4.4206 - val_loss: 154.6499 - val_mae: 3.6466\n",
      "Epoch 2/392\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 140.3049 - mae: 2.1173 - val_loss: 156.2762 - val_mae: 4.6788\n",
      "Epoch 3/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 129.1065 - mae: 1.4226 - val_loss: 154.5132 - val_mae: 5.0845\n",
      "Epoch 4/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 122.9298 - mae: 1.4882 - val_loss: 144.4313 - val_mae: 4.9880\n",
      "Epoch 5/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 114.8048 - mae: 1.3163 - val_loss: 138.6186 - val_mae: 5.1523\n",
      "Epoch 6/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 107.0694 - mae: 0.7151 - val_loss: 138.4131 - val_mae: 5.8096\n",
      "Epoch 7/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 101.2252 - mae: 0.8134 - val_loss: 130.9526 - val_mae: 5.5996\n",
      "Epoch 8/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 96.1377 - mae: 1.0539 - val_loss: 128.7011 - val_mae: 5.6047\n",
      "Epoch 9/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 94.0394 - mae: 1.6481 - val_loss: 123.1019 - val_mae: 5.8615\n",
      "Epoch 10/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 85.4700 - mae: 0.8671 - val_loss: 119.2373 - val_mae: 5.9037\n",
      "Epoch 11/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 80.9961 - mae: 0.8784 - val_loss: 112.5700 - val_mae: 5.7925\n",
      "Epoch 12/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 75.8587 - mae: 0.6672 - val_loss: 109.7578 - val_mae: 5.9412\n",
      "Epoch 13/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 71.8253 - mae: 0.7618 - val_loss: 103.5906 - val_mae: 5.7847\n",
      "Epoch 14/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 67.4995 - mae: 0.5860 - val_loss: 101.0856 - val_mae: 5.9582\n",
      "Epoch 15/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 64.6148 - mae: 1.0283 - val_loss: 95.3260 - val_mae: 5.8048\n",
      "Epoch 16/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 60.3377 - mae: 0.6912 - val_loss: 92.1860 - val_mae: 5.7270\n",
      "Epoch 17/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 57.1496 - mae: 0.7905 - val_loss: 89.1040 - val_mae: 5.6537\n",
      "Epoch 18/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 55.2863 - mae: 1.2347 - val_loss: 83.2032 - val_mae: 5.5845\n",
      "Epoch 19/392\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 50.6939 - mae: 0.5756 - val_loss: 82.0968 - val_mae: 5.7370\n",
      "Epoch 20/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 49.5903 - mae: 1.1724 - val_loss: 74.8777 - val_mae: 5.1660\n",
      "Epoch 21/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 45.6159 - mae: 0.7573 - val_loss: 74.1001 - val_mae: 5.3552\n",
      "Epoch 22/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.3803 - mae: 1.3040 - val_loss: 68.5034 - val_mae: 5.1969\n",
      "Epoch 23/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 40.4653 - mae: 0.6643 - val_loss: 66.6789 - val_mae: 5.2613\n",
      "Epoch 24/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 38.1512 - mae: 0.6391 - val_loss: 64.4719 - val_mae: 5.2488\n",
      "Epoch 25/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.2820 - mae: 0.7603 - val_loss: 61.0856 - val_mae: 5.1005\n",
      "Epoch 26/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.8720 - mae: 0.5051 - val_loss: 59.5686 - val_mae: 5.0911\n",
      "Epoch 27/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.7238 - mae: 0.9179 - val_loss: 54.6092 - val_mae: 4.7552\n",
      "Epoch 28/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.3326 - mae: 0.9577 - val_loss: 51.8555 - val_mae: 4.7118\n",
      "Epoch 29/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 30.5100 - mae: 1.2164 - val_loss: 52.7279 - val_mae: 4.9695\n",
      "Epoch 30/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 27.4741 - mae: 0.7056 - val_loss: 48.7359 - val_mae: 4.6786\n",
      "Epoch 31/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 25.5044 - mae: 0.5058 - val_loss: 46.5133 - val_mae: 4.6304\n",
      "Epoch 32/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 25.2309 - mae: 1.0542 - val_loss: 44.0505 - val_mae: 4.4902\n",
      "Epoch 33/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 23.0466 - mae: 0.6677 - val_loss: 41.5813 - val_mae: 4.2499\n",
      "Epoch 34/392\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 22.8048 - mae: 1.0857 - val_loss: 41.0339 - val_mae: 4.4267\n",
      "Epoch 35/392\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 20.8857 - mae: 0.7509 - val_loss: 42.1809 - val_mae: 4.3465\n",
      "Epoch 36/392\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 22.6769 - mae: 1.5144 - val_loss: 36.4709 - val_mae: 4.1160\n",
      "Epoch 37/392\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 18.8038 - mae: 0.6868 - val_loss: 37.9943 - val_mae: 4.3230\n",
      "Epoch 38/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 17.7967 - mae: 0.7197 - val_loss: 34.8853 - val_mae: 4.0982\n",
      "Epoch 39/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 16.6369 - mae: 0.6971 - val_loss: 31.4094 - val_mae: 3.8164\n",
      "Epoch 40/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 15.6433 - mae: 0.6718 - val_loss: 34.1599 - val_mae: 4.2579\n",
      "Epoch 41/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 18.2649 - mae: 1.6734 - val_loss: 26.4296 - val_mae: 3.3890\n",
      "Epoch 42/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 14.5762 - mae: 0.7550 - val_loss: 27.4914 - val_mae: 3.5223\n",
      "Epoch 43/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 13.5461 - mae: 0.6744 - val_loss: 26.1176 - val_mae: 3.3158\n",
      "Epoch 44/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 13.0874 - mae: 0.7561 - val_loss: 25.7997 - val_mae: 3.5880\n",
      "Epoch 45/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 12.6774 - mae: 0.8781 - val_loss: 26.0077 - val_mae: 3.6369\n",
      "Epoch 46/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 11.0576 - mae: 0.4540 - val_loss: 24.5245 - val_mae: 3.5049\n",
      "Epoch 47/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 11.5439 - mae: 0.9768 - val_loss: 24.1147 - val_mae: 3.4474\n",
      "Epoch 48/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 12.6080 - mae: 1.4065 - val_loss: 26.9681 - val_mae: 3.5837\n",
      "Epoch 49/392\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.1737 - mae: 1.7874 - val_loss: 21.3757 - val_mae: 3.2362\n",
      "Epoch 50/392\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10.5802 - mae: 1.0707 - val_loss: 20.0481 - val_mae: 3.2533\n",
      "Epoch 51/392\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 8.8053 - mae: 0.5355 - val_loss: 17.8017 - val_mae: 2.7873\n",
      "Epoch 52/392\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 9.1949 - mae: 0.9521 - val_loss: 20.7632 - val_mae: 3.4389\n",
      "Epoch 53/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.0261 - mae: 0.5999 - val_loss: 18.8407 - val_mae: 3.0041\n",
      "Epoch 54/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.7666 - mae: 1.3514 - val_loss: 18.7887 - val_mae: 2.8820\n",
      "Epoch 55/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 10.0245 - mae: 1.3940 - val_loss: 16.7943 - val_mae: 2.9174\n",
      "Epoch 56/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.5208 - mae: 0.7573 - val_loss: 16.9050 - val_mae: 3.0918\n",
      "Epoch 57/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.4237 - mae: 0.8844 - val_loss: 15.7225 - val_mae: 2.7624\n",
      "Epoch 58/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.8691 - mae: 0.8627 - val_loss: 15.2317 - val_mae: 2.6964\n",
      "Epoch 59/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.8327 - mae: 0.4604 - val_loss: 16.4025 - val_mae: 2.8895\n",
      "Epoch 60/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.4776 - mae: 0.8966 - val_loss: 15.8809 - val_mae: 2.8626\n",
      "Epoch 61/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.9957 - mae: 1.5048 - val_loss: 18.8247 - val_mae: 3.2676\n",
      "Epoch 62/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.8224 - mae: 1.2104 - val_loss: 13.8756 - val_mae: 2.8203\n",
      "Epoch 63/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.3850 - mae: 0.6788 - val_loss: 16.9789 - val_mae: 3.0976\n",
      "Epoch 64/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.9660 - mae: 1.4212 - val_loss: 14.2919 - val_mae: 2.7275\n",
      "Epoch 65/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 5.4747 - mae: 0.7771 - val_loss: 14.1210 - val_mae: 2.6758\n",
      "Epoch 66/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 5.4794 - mae: 0.9648 - val_loss: 13.7256 - val_mae: 2.6959\n",
      "Epoch 67/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.4781 - mae: 0.6091 - val_loss: 12.8748 - val_mae: 2.7434\n",
      "Epoch 68/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.8528 - mae: 0.8578 - val_loss: 13.5962 - val_mae: 2.7847\n",
      "Epoch 69/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 5.8928 - mae: 1.2283 - val_loss: 13.0266 - val_mae: 2.6190\n",
      "Epoch 70/392\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 6.9925 - mae: 1.5575 - val_loss: 19.3280 - val_mae: 3.1469\n",
      "Epoch 71/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 17.0001 - mae: 3.3072 - val_loss: 24.5170 - val_mae: 3.3243\n",
      "Epoch 72/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 11.7502 - mae: 2.0276 - val_loss: 9.1895 - val_mae: 2.0457\n",
      "Epoch 73/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.3809 - mae: 0.8032 - val_loss: 8.5346 - val_mae: 1.7935\n",
      "Epoch 74/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5711 - mae: 0.6296 - val_loss: 6.8355 - val_mae: 1.4563\n",
      "Epoch 75/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.8525 - mae: 0.8711 - val_loss: 10.0153 - val_mae: 2.0417\n",
      "Epoch 76/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.3948 - mae: 0.7162 - val_loss: 10.2845 - val_mae: 2.0336\n",
      "Epoch 77/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.9929 - mae: 0.9968 - val_loss: 7.9813 - val_mae: 1.7857\n",
      "Epoch 78/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.9803 - mae: 0.7021 - val_loss: 8.7950 - val_mae: 1.9837\n",
      "Epoch 79/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.3037 - mae: 0.9157 - val_loss: 8.6374 - val_mae: 1.9204\n",
      "Epoch 80/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.9841 - mae: 0.8030 - val_loss: 8.3546 - val_mae: 1.9923\n",
      "Epoch 81/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.2865 - mae: 0.5487 - val_loss: 6.7383 - val_mae: 1.6240\n",
      "Epoch 82/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.7624 - mae: 0.8482 - val_loss: 7.0624 - val_mae: 1.8245\n",
      "Epoch 83/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4170 - mae: 0.7515 - val_loss: 9.0990 - val_mae: 2.1227\n",
      "Epoch 84/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.6243 - mae: 1.5083 - val_loss: 6.9038 - val_mae: 1.9133\n",
      "Epoch 85/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.2477 - mae: 0.6967 - val_loss: 5.9276 - val_mae: 1.5355\n",
      "Epoch 86/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.1325 - mae: 1.0783 - val_loss: 6.7411 - val_mae: 1.8728\n",
      "Epoch 87/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.8553 - mae: 0.6258 - val_loss: 7.3855 - val_mae: 1.7737\n",
      "Epoch 88/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.2003 - mae: 0.7891 - val_loss: 6.8438 - val_mae: 1.8592\n",
      "Epoch 89/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3326 - mae: 0.3925 - val_loss: 6.2036 - val_mae: 1.7036\n",
      "Epoch 90/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5205 - mae: 0.6092 - val_loss: 5.9556 - val_mae: 1.7215\n",
      "Epoch 91/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.2526 - mae: 0.9692 - val_loss: 6.0142 - val_mae: 1.6397\n",
      "Epoch 92/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.8122 - mae: 1.0859 - val_loss: 5.6006 - val_mae: 1.6667\n",
      "Epoch 93/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1967 - mae: 0.4485 - val_loss: 7.5187 - val_mae: 2.0659\n",
      "Epoch 94/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.1297 - mae: 1.3255 - val_loss: 5.8553 - val_mae: 1.6708\n",
      "Epoch 95/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5597 - mae: 0.7119 - val_loss: 5.7208 - val_mae: 1.5711\n",
      "Epoch 96/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7629 - mae: 0.8206 - val_loss: 6.0566 - val_mae: 1.6278\n",
      "Epoch 97/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.6353 - mae: 1.5735 - val_loss: 6.6235 - val_mae: 1.9389\n",
      "Epoch 98/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.0108 - mae: 1.2352 - val_loss: 4.7566 - val_mae: 1.4267\n",
      "Epoch 99/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.8410 - mae: 0.8522 - val_loss: 9.3973 - val_mae: 2.2188\n",
      "Epoch 100/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.8820 - mae: 1.6609 - val_loss: 4.7379 - val_mae: 1.3986\n",
      "Epoch 101/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.6690 - mae: 0.7236 - val_loss: 4.1653 - val_mae: 1.3371\n",
      "Epoch 102/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.3170 - mae: 2.1984 - val_loss: 15.1129 - val_mae: 2.8371\n",
      "Epoch 103/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.5122 - mae: 1.9549 - val_loss: 4.1644 - val_mae: 1.2071\n",
      "Epoch 104/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.9682 - mae: 0.7280 - val_loss: 6.0621 - val_mae: 1.6719\n",
      "Epoch 105/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.6882 - mae: 0.6255 - val_loss: 4.2376 - val_mae: 1.2893\n",
      "Epoch 106/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0877 - mae: 0.3297 - val_loss: 6.0075 - val_mae: 1.7156\n",
      "Epoch 107/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.4922 - mae: 0.5625 - val_loss: 4.5145 - val_mae: 1.4388\n",
      "Epoch 108/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5243 - mae: 0.7475 - val_loss: 4.9572 - val_mae: 1.4626\n",
      "Epoch 109/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.8001 - mae: 1.1696 - val_loss: 4.8666 - val_mae: 1.4650\n",
      "Epoch 110/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7515 - mae: 0.8543 - val_loss: 11.1549 - val_mae: 2.7084\n",
      "Epoch 111/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 5.3181 - mae: 1.4490 - val_loss: 12.9183 - val_mae: 3.0029\n",
      "Epoch 112/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.8570 - mae: 1.2856 - val_loss: 4.9980 - val_mae: 1.4465\n",
      "Epoch 113/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.0675 - mae: 1.1107 - val_loss: 6.0934 - val_mae: 1.6371\n",
      "Epoch 114/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5320 - mae: 0.6985 - val_loss: 4.4977 - val_mae: 1.2570\n",
      "Epoch 115/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.9421 - mae: 0.4619 - val_loss: 4.2193 - val_mae: 1.2555\n",
      "Epoch 116/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8585 - mae: 0.3953 - val_loss: 4.4811 - val_mae: 1.4591\n",
      "Epoch 117/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5974 - mae: 0.8696 - val_loss: 4.2176 - val_mae: 1.2899\n",
      "Epoch 118/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8703 - mae: 0.5571 - val_loss: 3.7400 - val_mae: 1.1866\n",
      "Epoch 119/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0129 - mae: 0.6493 - val_loss: 2.6390 - val_mae: 0.9361\n",
      "Epoch 120/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5276 - mae: 0.4005 - val_loss: 2.2884 - val_mae: 0.8726\n",
      "Epoch 121/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0144 - mae: 0.7557 - val_loss: 5.4805 - val_mae: 1.7765\n",
      "Epoch 122/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6245 - mae: 0.4891 - val_loss: 3.7274 - val_mae: 1.2979\n",
      "Epoch 123/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.4966 - mae: 0.4760 - val_loss: 2.2536 - val_mae: 0.8330\n",
      "Epoch 124/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8115 - mae: 0.6374 - val_loss: 2.1219 - val_mae: 0.8440\n",
      "Epoch 125/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.1393 - mae: 0.2122 - val_loss: 1.9225 - val_mae: 0.8069\n",
      "Epoch 126/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3685 - mae: 0.5090 - val_loss: 3.7871 - val_mae: 1.3951\n",
      "Epoch 127/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.4731 - mae: 0.9575 - val_loss: 2.9882 - val_mae: 1.1424\n",
      "Epoch 128/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5931 - mae: 0.6761 - val_loss: 2.2311 - val_mae: 0.8844\n",
      "Epoch 129/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.1655 - mae: 0.3713 - val_loss: 3.1657 - val_mae: 1.1922\n",
      "Epoch 130/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0152 - mae: 0.2639 - val_loss: 1.9679 - val_mae: 0.8796\n",
      "Epoch 131/392\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.4826 - mae: 0.6985 - val_loss: 2.5897 - val_mae: 1.0363\n",
      "Epoch 132/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2441 - mae: 0.5450 - val_loss: 3.9473 - val_mae: 1.4983\n",
      "Epoch 133/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4336 - mae: 0.6636 - val_loss: 1.9064 - val_mae: 0.9024\n",
      "Epoch 134/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8733 - mae: 0.2541 - val_loss: 2.8413 - val_mae: 1.2017\n",
      "Epoch 135/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.4176 - mae: 0.6265 - val_loss: 2.1059 - val_mae: 1.0085\n",
      "Epoch 136/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2117 - mae: 0.5385 - val_loss: 1.4494 - val_mae: 0.7260\n",
      "Epoch 137/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3854 - mae: 0.7198 - val_loss: 1.9332 - val_mae: 0.8922\n",
      "Epoch 138/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6398 - mae: 0.8454 - val_loss: 7.8300 - val_mae: 2.4176\n",
      "Epoch 139/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.7106 - mae: 1.5052 - val_loss: 10.1706 - val_mae: 2.6118\n",
      "Epoch 140/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 22.6510 - mae: 3.9428 - val_loss: 72.0507 - val_mae: 7.5678\n",
      "Epoch 141/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.0156 - mae: 1.6168 - val_loss: 8.2703 - val_mae: 1.9542\n",
      "Epoch 142/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4092 - mae: 0.6996 - val_loss: 9.3936 - val_mae: 2.1039\n",
      "Epoch 143/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.0487 - mae: 0.6441 - val_loss: 15.4747 - val_mae: 3.0261\n",
      "Epoch 144/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.8533 - mae: 0.5933 - val_loss: 6.2546 - val_mae: 1.6905\n",
      "Epoch 145/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.5094 - mae: 0.4359 - val_loss: 9.5206 - val_mae: 2.3754\n",
      "Epoch 146/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.8707 - mae: 0.7800 - val_loss: 10.0445 - val_mae: 2.4509\n",
      "Epoch 147/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.3054 - mae: 0.4535 - val_loss: 3.5677 - val_mae: 1.1131\n",
      "Epoch 148/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.5700 - mae: 0.6435 - val_loss: 2.8065 - val_mae: 0.8847\n",
      "Epoch 149/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.6168 - mae: 0.8219 - val_loss: 3.9819 - val_mae: 1.2902\n",
      "Epoch 150/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.9889 - mae: 0.4686 - val_loss: 2.4858 - val_mae: 0.8057\n",
      "Epoch 151/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2366 - mae: 0.6745 - val_loss: 2.9905 - val_mae: 0.9963\n",
      "Epoch 152/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.5421 - mae: 0.2306 - val_loss: 2.6821 - val_mae: 0.9624\n",
      "Epoch 153/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4905 - mae: 0.3096 - val_loss: 2.5968 - val_mae: 0.9116\n",
      "Epoch 154/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.6555 - mae: 0.5006 - val_loss: 7.2567 - val_mae: 2.1266\n",
      "Epoch 155/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.9842 - mae: 1.1378 - val_loss: 2.4309 - val_mae: 0.9782\n",
      "Epoch 156/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7521 - mae: 0.6404 - val_loss: 3.6369 - val_mae: 1.2701\n",
      "Epoch 157/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2859 - mae: 0.3793 - val_loss: 2.5781 - val_mae: 0.9656\n",
      "Epoch 158/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1071 - mae: 0.2410 - val_loss: 2.3897 - val_mae: 0.9264\n",
      "Epoch 159/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0562 - mae: 0.2485 - val_loss: 2.8794 - val_mae: 1.1046\n",
      "Epoch 160/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2457 - mae: 0.5102 - val_loss: 1.8849 - val_mae: 0.8090\n",
      "Epoch 161/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.9978 - mae: 0.3104 - val_loss: 2.7906 - val_mae: 1.1275\n",
      "Epoch 162/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.8988 - mae: 0.2375 - val_loss: 2.1079 - val_mae: 0.9024\n",
      "Epoch 163/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.9870 - mae: 0.3897 - val_loss: 1.7354 - val_mae: 0.8144\n",
      "Epoch 164/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.9763 - mae: 0.4518 - val_loss: 2.8869 - val_mae: 1.2090\n",
      "Epoch 165/392\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.9873 - mae: 0.4486 - val_loss: 1.6819 - val_mae: 0.7732\n",
      "Epoch 166/392\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.8604 - mae: 0.4061 - val_loss: 1.8201 - val_mae: 0.8837\n",
      "Epoch 167/392\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.6376 - mae: 0.2014 - val_loss: 1.6194 - val_mae: 0.8189\n",
      "Epoch 168/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5846 - mae: 0.1645 - val_loss: 1.5986 - val_mae: 0.8191\n",
      "Epoch 169/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5377 - mae: 0.1364 - val_loss: 1.3105 - val_mae: 0.7549\n",
      "Epoch 170/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5298 - mae: 0.2018 - val_loss: 1.7261 - val_mae: 0.9136\n",
      "Epoch 171/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5125 - mae: 0.2241 - val_loss: 1.2408 - val_mae: 0.7150\n",
      "Epoch 172/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5080 - mae: 0.2643 - val_loss: 1.3544 - val_mae: 0.7758\n",
      "Epoch 173/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3939 - mae: 0.1136 - val_loss: 1.2510 - val_mae: 0.7733\n",
      "Epoch 174/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3948 - mae: 0.1864 - val_loss: 1.3672 - val_mae: 0.8303\n",
      "Epoch 175/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4001 - mae: 0.2207 - val_loss: 1.0959 - val_mae: 0.6817\n",
      "Epoch 176/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3232 - mae: 0.1164 - val_loss: 1.0906 - val_mae: 0.7171\n",
      "Epoch 177/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3486 - mae: 0.2248 - val_loss: 1.2331 - val_mae: 0.7786\n",
      "Epoch 178/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4616 - mae: 0.3783 - val_loss: 1.1807 - val_mae: 0.8026\n",
      "Epoch 179/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2754 - mae: 0.1445 - val_loss: 1.2110 - val_mae: 0.8174\n",
      "Epoch 180/392\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2953 - mae: 0.2169 - val_loss: 1.0547 - val_mae: 0.7566\n",
      "Epoch 181/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2452 - mae: 0.1550 - val_loss: 0.9663 - val_mae: 0.6903\n",
      "Epoch 182/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2213 - mae: 0.1423 - val_loss: 1.2650 - val_mae: 0.8549\n",
      "Epoch 183/392\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2140 - mae: 0.1624 - val_loss: 0.9681 - val_mae: 0.6928\n",
      "Epoch 184/392\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2049 - mae: 0.1562 - val_loss: 1.0856 - val_mae: 0.7847\n",
      "Epoch 185/392\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2363 - mae: 0.2396 - val_loss: 0.9244 - val_mae: 0.6601\n",
      "Epoch 186/392\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2043 - mae: 0.2154 - val_loss: 1.1892 - val_mae: 0.8336\n",
      "Epoch 187/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2002 - mae: 0.1892 - val_loss: 1.2744 - val_mae: 0.8787\n",
      "Epoch 188/392\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1667 - mae: 0.1743 - val_loss: 1.0109 - val_mae: 0.7880\n",
      "Epoch 189/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1469 - mae: 0.1362 - val_loss: 1.0603 - val_mae: 0.8107\n",
      "Epoch 190/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1498 - mae: 0.1648 - val_loss: 1.1120 - val_mae: 0.8240\n",
      "Epoch 191/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1613 - mae: 0.1580 - val_loss: 0.8439 - val_mae: 0.6645\n",
      "Epoch 192/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1738 - mae: 0.1982 - val_loss: 1.3343 - val_mae: 0.9412\n",
      "Epoch 193/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2153 - mae: 0.2875 - val_loss: 1.2378 - val_mae: 0.9135\n",
      "Epoch 194/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1660 - mae: 0.1844 - val_loss: 1.6409 - val_mae: 0.9962\n",
      "Epoch 195/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1262 - mae: 0.1183 - val_loss: 1.1526 - val_mae: 0.8476\n",
      "Epoch 196/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1575 - mae: 0.2304 - val_loss: 0.9212 - val_mae: 0.7620\n",
      "Epoch 197/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1543 - mae: 0.1957 - val_loss: 1.8458 - val_mae: 1.0572\n",
      "Epoch 198/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2305 - mae: 0.3044 - val_loss: 1.3343 - val_mae: 0.9459\n",
      "Epoch 199/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1308 - mae: 0.1655 - val_loss: 1.0171 - val_mae: 0.7982\n",
      "Epoch 200/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1076 - mae: 0.1403 - val_loss: 1.4500 - val_mae: 0.9500\n",
      "Epoch 201/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1370 - mae: 0.1943 - val_loss: 1.5677 - val_mae: 1.0403\n",
      "Epoch 202/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2065 - mae: 0.2832 - val_loss: 1.4029 - val_mae: 0.9361\n",
      "Epoch 203/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1502 - mae: 0.2295 - val_loss: 1.0905 - val_mae: 0.8241\n",
      "Epoch 204/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1311 - mae: 0.1770 - val_loss: 1.6036 - val_mae: 1.0553\n",
      "Epoch 205/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1890 - mae: 0.2687 - val_loss: 1.4419 - val_mae: 0.9501\n",
      "Epoch 206/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1381 - mae: 0.1917 - val_loss: 1.5024 - val_mae: 0.9716\n",
      "Epoch 207/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1456 - mae: 0.2290 - val_loss: 1.1360 - val_mae: 0.8485\n",
      "Epoch 208/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1230 - mae: 0.1802 - val_loss: 1.3744 - val_mae: 0.9293\n",
      "Epoch 209/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0948 - mae: 0.1163 - val_loss: 1.0313 - val_mae: 0.8117\n",
      "Epoch 210/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1185 - mae: 0.1774 - val_loss: 1.1830 - val_mae: 0.8651\n",
      "Epoch 211/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0887 - mae: 0.1224 - val_loss: 1.4181 - val_mae: 0.9393\n",
      "Epoch 212/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1098 - mae: 0.1524 - val_loss: 1.0336 - val_mae: 0.8080\n",
      "Epoch 213/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1289 - mae: 0.2036 - val_loss: 1.2817 - val_mae: 0.8868\n",
      "Epoch 214/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2360 - mae: 0.3320 - val_loss: 1.1269 - val_mae: 0.8452\n",
      "Epoch 215/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1145 - mae: 0.1788 - val_loss: 1.6952 - val_mae: 1.0276\n",
      "Epoch 216/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1868 - mae: 0.2636 - val_loss: 1.1376 - val_mae: 0.8211\n",
      "Epoch 217/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1350 - mae: 0.1827 - val_loss: 1.0741 - val_mae: 0.8206\n",
      "Epoch 218/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0980 - mae: 0.1280 - val_loss: 1.3051 - val_mae: 0.9085\n",
      "Epoch 219/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0940 - mae: 0.1366 - val_loss: 1.3223 - val_mae: 0.9166\n",
      "Epoch 220/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1380 - mae: 0.2349 - val_loss: 1.5019 - val_mae: 0.9729\n",
      "Epoch 221/392\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1252 - mae: 0.1928 - val_loss: 1.7793 - val_mae: 1.0227\n",
      "Epoch 222/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0910 - mae: 0.1112 - val_loss: 1.4667 - val_mae: 0.9607\n",
      "Epoch 223/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1632 - mae: 0.2481 - val_loss: 1.6403 - val_mae: 0.9833\n",
      "Epoch 224/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1023 - mae: 0.1562 - val_loss: 1.6102 - val_mae: 1.0053\n",
      "Epoch 225/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1558 - mae: 0.2316 - val_loss: 1.2262 - val_mae: 0.8639\n",
      "Epoch 226/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1345 - mae: 0.1861 - val_loss: 1.5475 - val_mae: 0.9858\n",
      "Epoch 227/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2485 - mae: 0.3715 - val_loss: 1.1358 - val_mae: 0.8195\n",
      "Epoch 228/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1137 - mae: 0.1738 - val_loss: 1.6129 - val_mae: 1.0058\n",
      "Epoch 229/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1421 - mae: 0.2132 - val_loss: 1.3834 - val_mae: 0.9383\n",
      "Epoch 230/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2235 - mae: 0.3287 - val_loss: 0.8583 - val_mae: 0.7405\n",
      "Epoch 231/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2262 - mae: 0.3235 - val_loss: 1.9826 - val_mae: 1.0892\n",
      "Epoch 232/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1214 - mae: 0.1812 - val_loss: 1.4217 - val_mae: 0.9203\n",
      "Epoch 233/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1340 - mae: 0.1845 - val_loss: 1.7927 - val_mae: 1.0357\n",
      "Epoch 234/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0977 - mae: 0.1366 - val_loss: 1.8083 - val_mae: 1.0378\n",
      "Epoch 235/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0888 - mae: 0.1065 - val_loss: 1.5847 - val_mae: 0.9758\n",
      "Epoch 236/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0841 - mae: 0.1040 - val_loss: 1.5515 - val_mae: 0.9893\n",
      "Epoch 237/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1147 - mae: 0.1728 - val_loss: 2.1112 - val_mae: 1.1331\n",
      "Epoch 238/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1094 - mae: 0.1291 - val_loss: 1.7467 - val_mae: 1.0214\n",
      "Epoch 239/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1244 - mae: 0.1957 - val_loss: 1.5188 - val_mae: 0.9578\n",
      "Epoch 240/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1491 - mae: 0.2170 - val_loss: 1.7802 - val_mae: 1.0415\n",
      "Epoch 241/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1149 - mae: 0.1638 - val_loss: 1.7248 - val_mae: 1.0208\n",
      "Epoch 242/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1569 - mae: 0.2273 - val_loss: 1.9999 - val_mae: 1.1236\n",
      "Epoch 243/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1449 - mae: 0.2200 - val_loss: 1.0582 - val_mae: 0.8190\n",
      "Epoch 244/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1231 - mae: 0.1829 - val_loss: 1.2670 - val_mae: 0.8808\n",
      "Epoch 245/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1518 - mae: 0.2294 - val_loss: 1.8024 - val_mae: 1.0508\n",
      "Epoch 246/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1012 - mae: 0.1583 - val_loss: 1.7048 - val_mae: 1.0109\n",
      "Epoch 247/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1292 - mae: 0.1858 - val_loss: 1.5150 - val_mae: 0.9785\n",
      "Epoch 248/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2093 - mae: 0.2885 - val_loss: 1.1965 - val_mae: 0.8439\n",
      "Epoch 249/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1037 - mae: 0.1519 - val_loss: 1.4714 - val_mae: 0.9379\n",
      "Epoch 250/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0872 - mae: 0.1189 - val_loss: 1.9004 - val_mae: 1.0763\n",
      "Epoch 251/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1171 - mae: 0.2005 - val_loss: 1.3516 - val_mae: 0.8963\n",
      "Epoch 252/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1156 - mae: 0.1858 - val_loss: 1.8737 - val_mae: 1.0729\n",
      "Epoch 253/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1546 - mae: 0.2675 - val_loss: 1.4691 - val_mae: 0.9404\n",
      "Epoch 254/392\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1749 - mae: 0.2745 - val_loss: 1.6720 - val_mae: 1.0080\n",
      "Epoch 255/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1042 - mae: 0.1639 - val_loss: 1.9761 - val_mae: 1.0872\n",
      "Epoch 256/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1012 - mae: 0.1463 - val_loss: 1.8710 - val_mae: 1.0793\n",
      "Epoch 257/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1635 - mae: 0.2535 - val_loss: 1.5235 - val_mae: 0.9777\n",
      "Epoch 258/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1549 - mae: 0.2235 - val_loss: 2.0458 - val_mae: 1.1191\n",
      "Epoch 259/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1304 - mae: 0.2045 - val_loss: 1.3258 - val_mae: 0.8920\n",
      "Epoch 260/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1185 - mae: 0.1902 - val_loss: 1.9558 - val_mae: 1.0658\n",
      "Epoch 261/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0935 - mae: 0.1447 - val_loss: 2.3331 - val_mae: 1.2082\n",
      "Epoch 262/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1285 - mae: 0.2031 - val_loss: 2.1802 - val_mae: 1.1689\n",
      "Epoch 263/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1263 - mae: 0.2001 - val_loss: 1.6392 - val_mae: 0.9905\n",
      "Epoch 264/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1373 - mae: 0.2285 - val_loss: 1.3953 - val_mae: 0.9160\n",
      "Epoch 265/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0956 - mae: 0.1383 - val_loss: 1.5449 - val_mae: 0.9686\n",
      "Epoch 266/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0961 - mae: 0.1437 - val_loss: 1.0139 - val_mae: 0.7966\n",
      "Epoch 267/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2055 - mae: 0.2936 - val_loss: 1.4006 - val_mae: 0.9257\n",
      "Epoch 268/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1758 - mae: 0.2605 - val_loss: 1.8498 - val_mae: 1.0765\n",
      "Epoch 269/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1265 - mae: 0.1900 - val_loss: 1.3082 - val_mae: 0.8814\n",
      "Epoch 270/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1172 - mae: 0.1950 - val_loss: 1.9621 - val_mae: 1.0920\n",
      "Epoch 271/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0767 - mae: 0.0973 - val_loss: 1.3560 - val_mae: 0.9251\n",
      "Epoch 272/392\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1242 - mae: 0.2036 - val_loss: 1.8118 - val_mae: 1.0518\n",
      "Epoch 273/392\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1031 - mae: 0.1589 - val_loss: 1.9070 - val_mae: 1.0735\n",
      "Epoch 274/392\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1790 - mae: 0.3058 - val_loss: 1.2295 - val_mae: 0.8642\n",
      "Epoch 275/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1102 - mae: 0.1797 - val_loss: 1.8577 - val_mae: 1.0714\n",
      "Epoch 276/392\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1340 - mae: 0.2197 - val_loss: 1.5775 - val_mae: 0.9870\n",
      "Epoch 277/392\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0778 - mae: 0.1142 - val_loss: 1.5850 - val_mae: 0.9846\n",
      "Epoch 278/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0854 - mae: 0.1361 - val_loss: 1.5563 - val_mae: 0.9800\n",
      "Epoch 279/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1173 - mae: 0.1898 - val_loss: 1.2285 - val_mae: 0.8652\n",
      "Epoch 280/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1831 - mae: 0.2666 - val_loss: 2.3674 - val_mae: 1.2030\n",
      "Epoch 281/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0900 - mae: 0.1296 - val_loss: 1.4687 - val_mae: 0.9532\n",
      "Epoch 282/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1233 - mae: 0.2167 - val_loss: 1.7101 - val_mae: 1.0234\n",
      "Epoch 283/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0923 - mae: 0.1441 - val_loss: 1.3019 - val_mae: 0.8894\n",
      "Epoch 284/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1301 - mae: 0.2170 - val_loss: 2.5267 - val_mae: 1.2733\n",
      "Epoch 285/392\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1002 - mae: 0.1566 - val_loss: 2.7932 - val_mae: 1.3644\n",
      "Epoch 286/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0909 - mae: 0.1224 - val_loss: 1.7781 - val_mae: 1.0395\n",
      "Epoch 287/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0937 - mae: 0.1505 - val_loss: 1.4402 - val_mae: 0.9355\n",
      "Epoch 288/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1021 - mae: 0.1589 - val_loss: 1.9167 - val_mae: 1.0822\n",
      "Epoch 289/392\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1280 - mae: 0.2063 - val_loss: 2.5781 - val_mae: 1.3177\n",
      "Epoch 290/392\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1188 - mae: 0.1800 - val_loss: 0.8466 - val_mae: 0.7318\n",
      "Epoch 291/392\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2173 - mae: 0.2547 - val_loss: 2.3231 - val_mae: 1.1986\n",
      "Epoch 292/392\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1580 - mae: 0.2456 - val_loss: 2.6286 - val_mae: 1.2982\n",
      "Epoch 293/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1107 - mae: 0.1647 - val_loss: 2.8184 - val_mae: 1.3578\n",
      "Epoch 294/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1481 - mae: 0.2319 - val_loss: 2.0931 - val_mae: 1.1324\n",
      "Epoch 295/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1157 - mae: 0.1872 - val_loss: 2.5625 - val_mae: 1.2729\n",
      "Epoch 296/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0863 - mae: 0.1166 - val_loss: 1.6341 - val_mae: 0.9956\n",
      "Epoch 297/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1095 - mae: 0.1694 - val_loss: 1.4787 - val_mae: 0.9392\n",
      "Epoch 298/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1163 - mae: 0.1810 - val_loss: 1.1737 - val_mae: 0.8436\n",
      "Epoch 299/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1151 - mae: 0.1667 - val_loss: 2.1165 - val_mae: 1.1738\n",
      "Epoch 300/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1074 - mae: 0.1618 - val_loss: 1.4397 - val_mae: 0.9363\n",
      "Epoch 301/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1328 - mae: 0.1983 - val_loss: 2.1152 - val_mae: 1.1399\n",
      "Epoch 302/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2017 - mae: 0.2673 - val_loss: 1.9395 - val_mae: 1.0812\n",
      "Epoch 303/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1289 - mae: 0.2133 - val_loss: 2.0579 - val_mae: 1.1181\n",
      "Epoch 304/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0921 - mae: 0.1395 - val_loss: 2.2920 - val_mae: 1.2235\n",
      "Epoch 305/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1165 - mae: 0.1753 - val_loss: 1.8046 - val_mae: 1.0492\n",
      "Epoch 306/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2280 - mae: 0.3204 - val_loss: 1.9121 - val_mae: 1.0844\n",
      "Epoch 307/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1250 - mae: 0.2001 - val_loss: 1.9547 - val_mae: 1.0997\n",
      "Epoch 308/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1074 - mae: 0.1599 - val_loss: 1.7034 - val_mae: 1.0154\n",
      "Epoch 309/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1738 - mae: 0.2680 - val_loss: 1.0780 - val_mae: 0.8290\n",
      "Epoch 310/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0890 - mae: 0.1242 - val_loss: 1.9172 - val_mae: 1.1060\n",
      "Epoch 311/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0913 - mae: 0.1244 - val_loss: 1.1561 - val_mae: 0.8368\n",
      "Epoch 312/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1167 - mae: 0.1851 - val_loss: 2.1519 - val_mae: 1.1346\n",
      "Epoch 313/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1025 - mae: 0.1573 - val_loss: 2.1322 - val_mae: 1.1323\n",
      "Epoch 314/392\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0813 - mae: 0.1089 - val_loss: 1.9198 - val_mae: 1.0685\n",
      "Epoch 315/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1157 - mae: 0.2037 - val_loss: 1.6956 - val_mae: 1.0332\n",
      "Epoch 316/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1410 - mae: 0.2453 - val_loss: 0.9118 - val_mae: 0.7637\n",
      "Epoch 317/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2063 - mae: 0.3140 - val_loss: 1.7224 - val_mae: 1.0650\n",
      "Epoch 318/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1876 - mae: 0.2681 - val_loss: 2.0816 - val_mae: 1.1846\n",
      "Epoch 319/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1233 - mae: 0.1563 - val_loss: 1.9235 - val_mae: 1.0873\n",
      "Epoch 320/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0949 - mae: 0.1241 - val_loss: 1.8018 - val_mae: 1.0523\n",
      "Epoch 321/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1281 - mae: 0.2026 - val_loss: 2.1323 - val_mae: 1.1374\n",
      "Epoch 322/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0973 - mae: 0.1364 - val_loss: 1.5394 - val_mae: 0.9764\n",
      "Epoch 323/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1389 - mae: 0.2260 - val_loss: 1.0883 - val_mae: 0.8104\n",
      "Epoch 324/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1428 - mae: 0.2186 - val_loss: 1.3134 - val_mae: 0.8854\n",
      "Epoch 325/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0821 - mae: 0.1133 - val_loss: 1.8768 - val_mae: 1.0661\n",
      "Epoch 326/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1050 - mae: 0.1753 - val_loss: 1.5614 - val_mae: 0.9667\n",
      "Epoch 327/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0772 - mae: 0.1104 - val_loss: 1.6726 - val_mae: 1.0041\n",
      "Epoch 328/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1033 - mae: 0.1555 - val_loss: 1.6059 - val_mae: 0.9918\n",
      "Epoch 329/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1084 - mae: 0.1742 - val_loss: 1.5491 - val_mae: 0.9620\n",
      "Epoch 330/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0798 - mae: 0.1206 - val_loss: 1.3952 - val_mae: 0.9346\n",
      "Epoch 331/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1130 - mae: 0.1811 - val_loss: 1.4584 - val_mae: 0.9339\n",
      "Epoch 332/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1322 - mae: 0.1810 - val_loss: 1.6603 - val_mae: 1.0108\n",
      "Epoch 333/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1137 - mae: 0.1860 - val_loss: 1.9689 - val_mae: 1.0966\n",
      "Epoch 334/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1142 - mae: 0.1759 - val_loss: 1.3855 - val_mae: 0.9213\n",
      "Epoch 335/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1388 - mae: 0.2168 - val_loss: 2.0104 - val_mae: 1.1214\n",
      "Epoch 336/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2064 - mae: 0.3057 - val_loss: 1.4548 - val_mae: 0.9752\n",
      "Epoch 337/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1806 - mae: 0.2676 - val_loss: 2.0677 - val_mae: 1.1232\n",
      "Epoch 338/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2406 - mae: 0.3525 - val_loss: 1.8582 - val_mae: 1.0523\n",
      "Epoch 339/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1397 - mae: 0.2390 - val_loss: 2.0705 - val_mae: 1.1188\n",
      "Epoch 340/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0801 - mae: 0.1069 - val_loss: 1.5555 - val_mae: 0.9915\n",
      "Epoch 341/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1162 - mae: 0.1838 - val_loss: 1.1311 - val_mae: 0.8211\n",
      "Epoch 342/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1501 - mae: 0.2375 - val_loss: 1.8114 - val_mae: 1.0465\n",
      "Epoch 343/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1125 - mae: 0.1963 - val_loss: 2.0310 - val_mae: 1.1137\n",
      "Epoch 344/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0771 - mae: 0.1037 - val_loss: 1.5074 - val_mae: 0.9550\n",
      "Epoch 345/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1054 - mae: 0.1876 - val_loss: 1.5280 - val_mae: 0.9785\n",
      "Epoch 346/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1270 - mae: 0.2131 - val_loss: 1.3776 - val_mae: 0.9177\n",
      "Epoch 347/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1954 - mae: 0.2640 - val_loss: 2.1796 - val_mae: 1.1419\n",
      "Epoch 348/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1187 - mae: 0.2035 - val_loss: 1.8662 - val_mae: 1.0554\n",
      "Epoch 349/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1066 - mae: 0.1754 - val_loss: 2.3773 - val_mae: 1.2044\n",
      "Epoch 350/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1694 - mae: 0.2253 - val_loss: 1.8812 - val_mae: 1.0849\n",
      "Epoch 351/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1392 - mae: 0.2145 - val_loss: 1.7166 - val_mae: 1.0406\n",
      "Epoch 352/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1113 - mae: 0.1852 - val_loss: 2.0990 - val_mae: 1.1302\n",
      "Epoch 353/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1008 - mae: 0.1595 - val_loss: 1.5654 - val_mae: 0.9767\n",
      "Epoch 354/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1506 - mae: 0.2474 - val_loss: 1.6855 - val_mae: 1.0125\n",
      "Epoch 355/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0647 - mae: 0.0748 - val_loss: 1.8122 - val_mae: 1.0479\n",
      "Epoch 356/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0932 - mae: 0.1616 - val_loss: 2.0928 - val_mae: 1.1215\n",
      "Epoch 357/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1089 - mae: 0.1621 - val_loss: 1.9858 - val_mae: 1.0969\n",
      "Epoch 358/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1054 - mae: 0.1717 - val_loss: 1.8644 - val_mae: 1.0554\n",
      "Epoch 359/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1415 - mae: 0.2261 - val_loss: 1.1394 - val_mae: 0.8344\n",
      "Epoch 360/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1032 - mae: 0.1791 - val_loss: 1.8182 - val_mae: 1.0311\n",
      "Epoch 361/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1070 - mae: 0.1891 - val_loss: 1.4805 - val_mae: 0.9459\n",
      "Epoch 362/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0790 - mae: 0.1256 - val_loss: 1.9973 - val_mae: 1.0960\n",
      "Epoch 363/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0901 - mae: 0.1414 - val_loss: 2.4906 - val_mae: 1.2158\n",
      "Epoch 364/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1995 - mae: 0.3169 - val_loss: 2.8027 - val_mae: 1.2951\n",
      "Epoch 365/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1360 - mae: 0.2150 - val_loss: 1.4844 - val_mae: 0.9700\n",
      "Epoch 366/392\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1105 - mae: 0.1760 - val_loss: 2.0232 - val_mae: 1.1080\n",
      "Epoch 367/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0868 - mae: 0.1354 - val_loss: 2.2338 - val_mae: 1.1612\n",
      "Epoch 368/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0812 - mae: 0.1244 - val_loss: 1.4350 - val_mae: 0.9476\n",
      "Epoch 369/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1260 - mae: 0.2078 - val_loss: 1.4849 - val_mae: 0.9506\n",
      "Epoch 370/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1583 - mae: 0.2400 - val_loss: 1.6909 - val_mae: 1.0454\n",
      "Epoch 371/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2053 - mae: 0.3352 - val_loss: 1.7591 - val_mae: 1.0311\n",
      "Epoch 372/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0894 - mae: 0.1411 - val_loss: 1.6753 - val_mae: 1.0110\n",
      "Epoch 373/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1177 - mae: 0.2175 - val_loss: 1.6990 - val_mae: 1.0244\n",
      "Epoch 374/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1206 - mae: 0.1728 - val_loss: 1.5216 - val_mae: 0.9728\n",
      "Epoch 375/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0928 - mae: 0.1399 - val_loss: 1.5308 - val_mae: 0.9720\n",
      "Epoch 376/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1122 - mae: 0.1944 - val_loss: 1.3803 - val_mae: 0.9288\n",
      "Epoch 377/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1387 - mae: 0.2202 - val_loss: 1.5317 - val_mae: 0.9759\n",
      "Epoch 378/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1578 - mae: 0.2817 - val_loss: 1.4798 - val_mae: 0.9421\n",
      "Epoch 379/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1214 - mae: 0.2051 - val_loss: 1.6892 - val_mae: 1.0105\n",
      "Epoch 380/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1206 - mae: 0.2242 - val_loss: 2.3756 - val_mae: 1.1960\n",
      "Epoch 381/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0801 - mae: 0.1184 - val_loss: 1.4492 - val_mae: 0.9481\n",
      "Epoch 382/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1537 - mae: 0.2524 - val_loss: 1.9450 - val_mae: 1.0901\n",
      "Epoch 383/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1194 - mae: 0.2060 - val_loss: 1.5410 - val_mae: 0.9710\n",
      "Epoch 384/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1443 - mae: 0.2202 - val_loss: 1.8718 - val_mae: 1.0752\n",
      "Epoch 385/392\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0739 - mae: 0.0989 - val_loss: 1.6198 - val_mae: 1.0002\n",
      "Epoch 386/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1151 - mae: 0.1990 - val_loss: 2.4770 - val_mae: 1.2115\n",
      "Epoch 387/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1040 - mae: 0.1650 - val_loss: 1.8669 - val_mae: 1.0629\n",
      "Epoch 388/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0856 - mae: 0.1464 - val_loss: 1.8101 - val_mae: 1.0541\n",
      "Epoch 389/392\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1177 - mae: 0.1639 - val_loss: 2.5557 - val_mae: 1.2620\n",
      "Epoch 390/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1268 - mae: 0.2052 - val_loss: 1.9252 - val_mae: 1.0933\n",
      "Epoch 391/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0940 - mae: 0.1688 - val_loss: 1.8523 - val_mae: 1.0641\n",
      "Epoch 392/392\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0754 - mae: 0.1054 - val_loss: 2.2518 - val_mae: 1.1720\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▅▄▂▂▂▁▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/mae</td><td>▄▂▃▃▂▃▂▅▂▃▄▃▂▂█▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_loss</td><td>█▆▅▃▃▂▂▁▁▁▁▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_mae</td><td>▅▆▆▅▅▄▃▂▂▂▂▂▁▂█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>391</td></tr><tr><td>epoch/learning_rate</td><td>0.00961</td></tr><tr><td>epoch/loss</td><td>0.07545</td></tr><tr><td>epoch/mae</td><td>0.10536</td></tr><tr><td>epoch/val_loss</td><td>2.25178</td></tr><tr><td>epoch/val_mae</td><td>1.17202</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resilient-sweep-9</strong> at: <a href='https://wandb.ai/grantbell/fred_dnn_sweep/runs/zrnxzt9u' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/runs/zrnxzt9u</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230719_172019-zrnxzt9u\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qtcthvo0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 193\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_initializer: he_normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1: 0.4936476396644862\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_l2: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2: 0.1012483242517488\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.006587154491989599\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: mse\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmetrics: mae\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\grant\\OneDrive\\Desktop\\vscode\\py_fin\\wandb\\run-20230719_172051-qtcthvo0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/grantbell/fred_dnn_sweep/runs/qtcthvo0' target=\"_blank\">cool-sweep-10</a></strong> to <a href='https://wandb.ai/grantbell/fred_dnn_sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/grantbell/fred_dnn_sweep' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/sweeps/texsheds</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/grantbell/fred_dnn_sweep/runs/qtcthvo0' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/runs/qtcthvo0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/193\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 905.6235 - mae: 5.7412 - val_loss: 798.1454 - val_mae: 2.4191\n",
      "Epoch 2/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 760.0655 - mae: 1.7069 - val_loss: 697.4252 - val_mae: 1.6602\n",
      "Epoch 3/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 664.8269 - mae: 1.4101 - val_loss: 612.9308 - val_mae: 2.4940\n",
      "Epoch 4/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 579.5765 - mae: 1.3725 - val_loss: 529.9196 - val_mae: 1.8092\n",
      "Epoch 5/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 501.5380 - mae: 0.9384 - val_loss: 458.7227 - val_mae: 1.8213\n",
      "Epoch 6/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 434.2468 - mae: 1.2304 - val_loss: 395.8134 - val_mae: 1.4041\n",
      "Epoch 7/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 374.4805 - mae: 1.3488 - val_loss: 345.0327 - val_mae: 2.7943\n",
      "Epoch 8/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 321.0918 - mae: 1.2858 - val_loss: 289.4223 - val_mae: 1.2568\n",
      "Epoch 9/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 272.8642 - mae: 0.8613 - val_loss: 249.0839 - val_mae: 1.9685\n",
      "Epoch 10/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 232.3981 - mae: 0.9365 - val_loss: 211.3293 - val_mae: 1.2207\n",
      "Epoch 11/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 202.7594 - mae: 1.8805 - val_loss: 188.9885 - val_mae: 3.0810\n",
      "Epoch 12/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 171.5105 - mae: 1.4964 - val_loss: 153.5145 - val_mae: 1.2130\n",
      "Epoch 13/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 144.4319 - mae: 0.8418 - val_loss: 134.4680 - val_mae: 2.1248\n",
      "Epoch 14/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 126.7615 - mae: 1.6044 - val_loss: 118.6372 - val_mae: 1.5278\n",
      "Epoch 15/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 112.3352 - mae: 1.9638 - val_loss: 99.4753 - val_mae: 1.8742\n",
      "Epoch 16/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 91.8632 - mae: 0.9112 - val_loss: 87.8620 - val_mae: 1.8410\n",
      "Epoch 17/193\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 80.8628 - mae: 1.1521 - val_loss: 76.2513 - val_mae: 1.9060\n",
      "Epoch 18/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 69.5023 - mae: 0.8724 - val_loss: 65.1824 - val_mae: 1.1876\n",
      "Epoch 19/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 60.7355 - mae: 0.6417 - val_loss: 57.6989 - val_mae: 1.4081\n",
      "Epoch 20/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 53.2712 - mae: 0.5335 - val_loss: 51.6135 - val_mae: 1.3613\n",
      "Epoch 21/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 46.9340 - mae: 0.4198 - val_loss: 45.1718 - val_mae: 1.3504\n",
      "Epoch 22/193\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 41.2006 - mae: 0.3865 - val_loss: 40.0230 - val_mae: 1.2502\n",
      "Epoch 23/193\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36.2624 - mae: 0.3512 - val_loss: 35.2440 - val_mae: 1.2160\n",
      "Epoch 24/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 31.8722 - mae: 0.3117 - val_loss: 31.4837 - val_mae: 1.2186\n",
      "Epoch 25/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.1064 - mae: 0.3103 - val_loss: 27.4355 - val_mae: 1.1078\n",
      "Epoch 26/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 24.8040 - mae: 0.2963 - val_loss: 24.6047 - val_mae: 1.0877\n",
      "Epoch 27/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 22.0558 - mae: 0.3002 - val_loss: 22.1670 - val_mae: 1.1201\n",
      "Epoch 28/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 19.6930 - mae: 0.2904 - val_loss: 19.9965 - val_mae: 1.0811\n",
      "Epoch 29/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 17.7465 - mae: 0.3199 - val_loss: 17.9655 - val_mae: 1.0021\n",
      "Epoch 30/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 16.1212 - mae: 0.3024 - val_loss: 16.5580 - val_mae: 0.9924\n",
      "Epoch 31/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 14.8077 - mae: 0.3245 - val_loss: 15.2897 - val_mae: 0.9840\n",
      "Epoch 32/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 13.7012 - mae: 0.3169 - val_loss: 14.4947 - val_mae: 1.0066\n",
      "Epoch 33/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 12.8597 - mae: 0.3359 - val_loss: 13.5336 - val_mae: 0.9606\n",
      "Epoch 34/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 12.1696 - mae: 0.3374 - val_loss: 13.0550 - val_mae: 0.9654\n",
      "Epoch 35/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 11.7061 - mae: 0.3673 - val_loss: 12.5203 - val_mae: 0.9086\n",
      "Epoch 36/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 11.4156 - mae: 0.3406 - val_loss: 12.4581 - val_mae: 0.9214\n",
      "Epoch 37/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 11.2594 - mae: 0.3493 - val_loss: 12.0601 - val_mae: 0.8743\n",
      "Epoch 38/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 11.1328 - mae: 0.3594 - val_loss: 12.0426 - val_mae: 0.8713\n",
      "Epoch 39/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 11.0544 - mae: 0.3628 - val_loss: 11.9425 - val_mae: 0.8997\n",
      "Epoch 40/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.9909 - mae: 0.3852 - val_loss: 12.0172 - val_mae: 0.8972\n",
      "Epoch 41/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.9809 - mae: 0.3770 - val_loss: 11.8564 - val_mae: 0.8972\n",
      "Epoch 42/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.9451 - mae: 0.3966 - val_loss: 11.8293 - val_mae: 0.8488\n",
      "Epoch 43/193\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10.9214 - mae: 0.3720 - val_loss: 11.7200 - val_mae: 0.8653\n",
      "Epoch 44/193\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 10.8955 - mae: 0.3770 - val_loss: 11.8476 - val_mae: 0.8614\n",
      "Epoch 45/193\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 10.8913 - mae: 0.3773 - val_loss: 11.6654 - val_mae: 0.8592\n",
      "Epoch 46/193\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 10.8952 - mae: 0.3926 - val_loss: 11.8012 - val_mae: 0.8505\n",
      "Epoch 47/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.8660 - mae: 0.3774 - val_loss: 11.5600 - val_mae: 0.8283\n",
      "Epoch 48/193\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 10.8409 - mae: 0.3762 - val_loss: 11.7351 - val_mae: 0.8224\n",
      "Epoch 49/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.8522 - mae: 0.3782 - val_loss: 11.5838 - val_mae: 0.8343\n",
      "Epoch 50/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.8088 - mae: 0.3660 - val_loss: 11.7600 - val_mae: 0.8534\n",
      "Epoch 51/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.8130 - mae: 0.3749 - val_loss: 11.5705 - val_mae: 0.8544\n",
      "Epoch 52/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.8009 - mae: 0.3793 - val_loss: 11.6760 - val_mae: 0.8135\n",
      "Epoch 53/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.8101 - mae: 0.3694 - val_loss: 11.5636 - val_mae: 0.8430\n",
      "Epoch 54/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.7636 - mae: 0.3577 - val_loss: 11.7927 - val_mae: 0.8665\n",
      "Epoch 55/193\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 10.7889 - mae: 0.3697 - val_loss: 11.5319 - val_mae: 0.8518\n",
      "Epoch 56/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.7514 - mae: 0.3541 - val_loss: 11.7114 - val_mae: 0.8488\n",
      "Epoch 57/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.7716 - mae: 0.3619 - val_loss: 11.5689 - val_mae: 0.8334\n",
      "Epoch 58/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.7549 - mae: 0.3366 - val_loss: 11.8390 - val_mae: 0.8867\n",
      "Epoch 59/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.7656 - mae: 0.3466 - val_loss: 11.5786 - val_mae: 0.8650\n",
      "Epoch 60/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.7533 - mae: 0.3517 - val_loss: 11.7195 - val_mae: 0.8561\n",
      "Epoch 61/193\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 10.7660 - mae: 0.3536 - val_loss: 11.6204 - val_mae: 0.8658\n",
      "Epoch 62/193\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10.7686 - mae: 0.3424 - val_loss: 11.7429 - val_mae: 0.8589\n",
      "Epoch 63/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.7455 - mae: 0.3315 - val_loss: 11.6838 - val_mae: 0.8714\n",
      "Epoch 64/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.7412 - mae: 0.3363 - val_loss: 11.8069 - val_mae: 0.8649\n",
      "Epoch 65/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.7765 - mae: 0.3356 - val_loss: 11.6809 - val_mae: 0.8860\n",
      "Epoch 66/193\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 10.7300 - mae: 0.3230 - val_loss: 11.7767 - val_mae: 0.8824\n",
      "Epoch 67/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.7424 - mae: 0.3414 - val_loss: 11.5993 - val_mae: 0.8514\n",
      "Epoch 68/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.7351 - mae: 0.3217 - val_loss: 11.7565 - val_mae: 0.8661\n",
      "Epoch 69/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.7372 - mae: 0.3200 - val_loss: 11.6361 - val_mae: 0.8708\n",
      "Epoch 70/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.7211 - mae: 0.3269 - val_loss: 11.8136 - val_mae: 0.8645\n",
      "Epoch 71/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.7337 - mae: 0.3112 - val_loss: 11.7228 - val_mae: 0.8837\n",
      "Epoch 72/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.7182 - mae: 0.3042 - val_loss: 11.7944 - val_mae: 0.8647\n",
      "Epoch 73/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.7385 - mae: 0.3193 - val_loss: 11.6599 - val_mae: 0.8863\n",
      "Epoch 74/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.7093 - mae: 0.3085 - val_loss: 11.7796 - val_mae: 0.8765\n",
      "Epoch 75/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.7224 - mae: 0.3222 - val_loss: 11.7258 - val_mae: 0.9018\n",
      "Epoch 76/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.7082 - mae: 0.3110 - val_loss: 11.8034 - val_mae: 0.8694\n",
      "Epoch 77/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.7294 - mae: 0.3105 - val_loss: 11.7025 - val_mae: 0.9002\n",
      "Epoch 78/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.7126 - mae: 0.3145 - val_loss: 11.7458 - val_mae: 0.8636\n",
      "Epoch 79/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.7155 - mae: 0.3187 - val_loss: 11.6606 - val_mae: 0.8747\n",
      "Epoch 80/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.7018 - mae: 0.2988 - val_loss: 11.8680 - val_mae: 0.9055\n",
      "Epoch 81/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.7129 - mae: 0.3091 - val_loss: 11.6857 - val_mae: 0.8814\n",
      "Epoch 82/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.7044 - mae: 0.2924 - val_loss: 11.9334 - val_mae: 0.9244\n",
      "Epoch 83/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.7121 - mae: 0.3038 - val_loss: 11.7298 - val_mae: 0.8955\n",
      "Epoch 84/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6974 - mae: 0.2840 - val_loss: 11.8171 - val_mae: 0.8802\n",
      "Epoch 85/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.7055 - mae: 0.2860 - val_loss: 11.6957 - val_mae: 0.8944\n",
      "Epoch 86/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.6903 - mae: 0.2851 - val_loss: 11.8437 - val_mae: 0.8832\n",
      "Epoch 87/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.7051 - mae: 0.2770 - val_loss: 11.7997 - val_mae: 0.9245\n",
      "Epoch 88/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6850 - mae: 0.2821 - val_loss: 11.8087 - val_mae: 0.8753\n",
      "Epoch 89/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.7017 - mae: 0.2688 - val_loss: 11.7763 - val_mae: 0.9132\n",
      "Epoch 90/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6853 - mae: 0.2831 - val_loss: 11.8988 - val_mae: 0.8935\n",
      "Epoch 91/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.7030 - mae: 0.2662 - val_loss: 11.7450 - val_mae: 0.8947\n",
      "Epoch 92/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.6912 - mae: 0.2694 - val_loss: 11.9347 - val_mae: 0.9264\n",
      "Epoch 93/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.6951 - mae: 0.2750 - val_loss: 11.7375 - val_mae: 0.8918\n",
      "Epoch 94/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.6896 - mae: 0.2670 - val_loss: 11.8747 - val_mae: 0.8995\n",
      "Epoch 95/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6995 - mae: 0.2699 - val_loss: 11.7771 - val_mae: 0.9001\n",
      "Epoch 96/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6848 - mae: 0.2642 - val_loss: 11.9311 - val_mae: 0.9263\n",
      "Epoch 97/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.6908 - mae: 0.2622 - val_loss: 11.7606 - val_mae: 0.9071\n",
      "Epoch 98/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6827 - mae: 0.2661 - val_loss: 11.8527 - val_mae: 0.8988\n",
      "Epoch 99/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6898 - mae: 0.2593 - val_loss: 11.7950 - val_mae: 0.9172\n",
      "Epoch 100/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6801 - mae: 0.2650 - val_loss: 11.8405 - val_mae: 0.9028\n",
      "Epoch 101/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6852 - mae: 0.2610 - val_loss: 11.8632 - val_mae: 0.9297\n",
      "Epoch 102/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6828 - mae: 0.2668 - val_loss: 11.8763 - val_mae: 0.9054\n",
      "Epoch 103/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.6915 - mae: 0.2526 - val_loss: 11.8602 - val_mae: 0.9266\n",
      "Epoch 104/193\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 10.6833 - mae: 0.2606 - val_loss: 11.9713 - val_mae: 0.9425\n",
      "Epoch 105/193\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 10.6832 - mae: 0.2470 - val_loss: 11.8773 - val_mae: 0.9204\n",
      "Epoch 106/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6791 - mae: 0.2499 - val_loss: 11.7649 - val_mae: 0.8828\n",
      "Epoch 107/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.6874 - mae: 0.2587 - val_loss: 11.8090 - val_mae: 0.9031\n",
      "Epoch 108/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.6830 - mae: 0.2560 - val_loss: 11.7421 - val_mae: 0.8659\n",
      "Epoch 109/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6987 - mae: 0.2595 - val_loss: 11.9452 - val_mae: 0.9354\n",
      "Epoch 110/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6831 - mae: 0.2490 - val_loss: 11.8174 - val_mae: 0.9075\n",
      "Epoch 111/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6785 - mae: 0.2558 - val_loss: 11.9321 - val_mae: 0.9323\n",
      "Epoch 112/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6856 - mae: 0.2496 - val_loss: 11.8246 - val_mae: 0.8967\n",
      "Epoch 113/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6761 - mae: 0.2352 - val_loss: 11.8921 - val_mae: 0.9163\n",
      "Epoch 114/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6787 - mae: 0.2482 - val_loss: 11.9055 - val_mae: 0.9319\n",
      "Epoch 115/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6785 - mae: 0.2464 - val_loss: 12.0080 - val_mae: 0.9598\n",
      "Epoch 116/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.6787 - mae: 0.2484 - val_loss: 11.8790 - val_mae: 0.9362\n",
      "Epoch 117/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.6767 - mae: 0.2539 - val_loss: 11.8697 - val_mae: 0.9123\n",
      "Epoch 118/193\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 10.6800 - mae: 0.2404 - val_loss: 11.8319 - val_mae: 0.9098\n",
      "Epoch 119/193\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 10.6723 - mae: 0.2431 - val_loss: 12.0087 - val_mae: 0.9557\n",
      "Epoch 120/193\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 10.6739 - mae: 0.2420 - val_loss: 11.8439 - val_mae: 0.9219\n",
      "Epoch 121/193\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 10.6747 - mae: 0.2471 - val_loss: 12.0025 - val_mae: 0.9565\n",
      "Epoch 122/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.6769 - mae: 0.2432 - val_loss: 11.9231 - val_mae: 0.9395\n",
      "Epoch 123/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.6662 - mae: 0.2347 - val_loss: 11.9229 - val_mae: 0.9251\n",
      "Epoch 124/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.6758 - mae: 0.2379 - val_loss: 11.8082 - val_mae: 0.9136\n",
      "Epoch 125/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.6684 - mae: 0.2453 - val_loss: 11.9284 - val_mae: 0.9305\n",
      "Epoch 126/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.6697 - mae: 0.2309 - val_loss: 12.0548 - val_mae: 0.9828\n",
      "Epoch 127/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.6683 - mae: 0.2386 - val_loss: 11.9081 - val_mae: 0.9256\n",
      "Epoch 128/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.6666 - mae: 0.2340 - val_loss: 11.8735 - val_mae: 0.9232\n",
      "Epoch 129/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6648 - mae: 0.2239 - val_loss: 12.0202 - val_mae: 0.9572\n",
      "Epoch 130/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6856 - mae: 0.2411 - val_loss: 11.8786 - val_mae: 0.9351\n",
      "Epoch 131/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6624 - mae: 0.2357 - val_loss: 12.0031 - val_mae: 0.9553\n",
      "Epoch 132/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6670 - mae: 0.2345 - val_loss: 11.8717 - val_mae: 0.9388\n",
      "Epoch 133/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6587 - mae: 0.2354 - val_loss: 11.9232 - val_mae: 0.9263\n",
      "Epoch 134/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6634 - mae: 0.2358 - val_loss: 11.9001 - val_mae: 0.9478\n",
      "Epoch 135/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.6580 - mae: 0.2378 - val_loss: 11.9238 - val_mae: 0.9215\n",
      "Epoch 136/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.6664 - mae: 0.2241 - val_loss: 11.8578 - val_mae: 0.9322\n",
      "Epoch 137/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6613 - mae: 0.2278 - val_loss: 11.9260 - val_mae: 0.9221\n",
      "Epoch 138/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6655 - mae: 0.2253 - val_loss: 11.8823 - val_mae: 0.9476\n",
      "Epoch 139/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6550 - mae: 0.2334 - val_loss: 12.0198 - val_mae: 0.9574\n",
      "Epoch 140/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6674 - mae: 0.2396 - val_loss: 11.7934 - val_mae: 0.9043\n",
      "Epoch 141/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6624 - mae: 0.2263 - val_loss: 11.9445 - val_mae: 0.9304\n",
      "Epoch 142/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6631 - mae: 0.2285 - val_loss: 12.0075 - val_mae: 0.9766\n",
      "Epoch 143/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.6549 - mae: 0.2220 - val_loss: 11.8884 - val_mae: 0.9132\n",
      "Epoch 144/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6621 - mae: 0.2284 - val_loss: 11.9736 - val_mae: 0.9674\n",
      "Epoch 145/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.6532 - mae: 0.2242 - val_loss: 11.9344 - val_mae: 0.9215\n",
      "Epoch 146/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6602 - mae: 0.2131 - val_loss: 11.9300 - val_mae: 0.9566\n",
      "Epoch 147/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6531 - mae: 0.2328 - val_loss: 12.1146 - val_mae: 0.9849\n",
      "Epoch 148/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6655 - mae: 0.2289 - val_loss: 11.8977 - val_mae: 0.9409\n",
      "Epoch 149/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.6530 - mae: 0.2138 - val_loss: 11.9647 - val_mae: 0.9442\n",
      "Epoch 150/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.6582 - mae: 0.2388 - val_loss: 11.8560 - val_mae: 0.9328\n",
      "Epoch 151/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6478 - mae: 0.2197 - val_loss: 11.9651 - val_mae: 0.9343\n",
      "Epoch 152/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6573 - mae: 0.2175 - val_loss: 12.0154 - val_mae: 0.9807\n",
      "Epoch 153/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6517 - mae: 0.2239 - val_loss: 12.0203 - val_mae: 0.9619\n",
      "Epoch 154/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6548 - mae: 0.2207 - val_loss: 11.9218 - val_mae: 0.9469\n",
      "Epoch 155/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6499 - mae: 0.2205 - val_loss: 12.0140 - val_mae: 0.9557\n",
      "Epoch 156/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6544 - mae: 0.2180 - val_loss: 11.8669 - val_mae: 0.9280\n",
      "Epoch 157/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6467 - mae: 0.2170 - val_loss: 11.9880 - val_mae: 0.9497\n",
      "Epoch 158/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.6546 - mae: 0.2248 - val_loss: 11.9488 - val_mae: 0.9565\n",
      "Epoch 159/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6549 - mae: 0.2178 - val_loss: 11.9975 - val_mae: 0.9547\n",
      "Epoch 160/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6500 - mae: 0.2218 - val_loss: 11.9572 - val_mae: 0.9504\n",
      "Epoch 161/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6453 - mae: 0.2124 - val_loss: 11.9863 - val_mae: 0.9571\n",
      "Epoch 162/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6488 - mae: 0.2176 - val_loss: 11.9990 - val_mae: 0.9681\n",
      "Epoch 163/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.6567 - mae: 0.2315 - val_loss: 11.9548 - val_mae: 0.9418\n",
      "Epoch 164/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6501 - mae: 0.2178 - val_loss: 11.9442 - val_mae: 0.9506\n",
      "Epoch 165/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6511 - mae: 0.2136 - val_loss: 11.9616 - val_mae: 0.9311\n",
      "Epoch 166/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6558 - mae: 0.2143 - val_loss: 12.0613 - val_mae: 0.9826\n",
      "Epoch 167/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6491 - mae: 0.2168 - val_loss: 11.9803 - val_mae: 0.9553\n",
      "Epoch 168/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6437 - mae: 0.2168 - val_loss: 11.8623 - val_mae: 0.9186\n",
      "Epoch 169/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6439 - mae: 0.2173 - val_loss: 11.9275 - val_mae: 0.9323\n",
      "Epoch 170/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.6644 - mae: 0.2298 - val_loss: 11.9796 - val_mae: 0.9660\n",
      "Epoch 171/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6446 - mae: 0.2243 - val_loss: 11.8660 - val_mae: 0.9108\n",
      "Epoch 172/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6625 - mae: 0.2308 - val_loss: 11.9085 - val_mae: 0.9419\n",
      "Epoch 173/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6464 - mae: 0.2278 - val_loss: 11.9067 - val_mae: 0.9295\n",
      "Epoch 174/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6570 - mae: 0.2222 - val_loss: 12.2388 - val_mae: 1.0264\n",
      "Epoch 175/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6786 - mae: 0.2306 - val_loss: 11.9166 - val_mae: 0.9223\n",
      "Epoch 176/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6554 - mae: 0.2158 - val_loss: 12.0026 - val_mae: 0.9548\n",
      "Epoch 177/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6438 - mae: 0.2072 - val_loss: 11.9818 - val_mae: 0.9559\n",
      "Epoch 178/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6448 - mae: 0.2054 - val_loss: 12.0046 - val_mae: 0.9726\n",
      "Epoch 179/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6412 - mae: 0.2166 - val_loss: 11.8682 - val_mae: 0.9241\n",
      "Epoch 180/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6468 - mae: 0.2185 - val_loss: 12.1123 - val_mae: 0.9976\n",
      "Epoch 181/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6475 - mae: 0.2153 - val_loss: 12.0120 - val_mae: 0.9720\n",
      "Epoch 182/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6406 - mae: 0.2233 - val_loss: 11.9738 - val_mae: 0.9442\n",
      "Epoch 183/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6407 - mae: 0.2068 - val_loss: 11.9228 - val_mae: 0.9470\n",
      "Epoch 184/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6382 - mae: 0.2235 - val_loss: 11.9610 - val_mae: 0.9519\n",
      "Epoch 185/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6420 - mae: 0.2012 - val_loss: 11.9142 - val_mae: 0.9323\n",
      "Epoch 186/193\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.6384 - mae: 0.2130 - val_loss: 11.9479 - val_mae: 0.9517\n",
      "Epoch 187/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6415 - mae: 0.2168 - val_loss: 11.9053 - val_mae: 0.9282\n",
      "Epoch 188/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6434 - mae: 0.2084 - val_loss: 11.9036 - val_mae: 0.9404\n",
      "Epoch 189/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6404 - mae: 0.2130 - val_loss: 11.9831 - val_mae: 0.9620\n",
      "Epoch 190/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6462 - mae: 0.2137 - val_loss: 11.8824 - val_mae: 0.9307\n",
      "Epoch 191/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6419 - mae: 0.2122 - val_loss: 12.2241 - val_mae: 1.0216\n",
      "Epoch 192/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6700 - mae: 0.2241 - val_loss: 11.9241 - val_mae: 0.9397\n",
      "Epoch 193/193\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.6325 - mae: 0.2030 - val_loss: 11.9323 - val_mae: 0.9372\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/mae</td><td>█▆▄▄▃▁▁▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_loss</td><td>█▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_mae</td><td>▇▅▄█▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▁▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>192</td></tr><tr><td>epoch/learning_rate</td><td>0.00659</td></tr><tr><td>epoch/loss</td><td>10.63251</td></tr><tr><td>epoch/mae</td><td>0.20297</td></tr><tr><td>epoch/val_loss</td><td>11.93227</td></tr><tr><td>epoch/val_mae</td><td>0.93724</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cool-sweep-10</strong> at: <a href='https://wandb.ai/grantbell/fred_dnn_sweep/runs/qtcthvo0' target=\"_blank\">https://wandb.ai/grantbell/fred_dnn_sweep/runs/qtcthvo0</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230719_172051-qtcthvo0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sweep_config = {\n",
    "    'method': 'bayes',  # can be grid, random, or bayes\n",
    "    'metric': {\n",
    "        'name': 'val_loss',\n",
    "        'goal': 'minimize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'learning_rate': {\n",
    "            'min': 0.0001,\n",
    "            'max': 0.01\n",
    "        },\n",
    "        'activation': {\n",
    "            'values': ['relu']\n",
    "        }, \n",
    "        'kernel_initializer': {\n",
    "            'values': ['he_normal']\n",
    "        }, \n",
    "        'loss': {\n",
    "            'values': ['mse']\n",
    "        }, \n",
    "        # 'activation': {\n",
    "        #     'values': ['relu', 'tanh', 'sigmoid', 'elu', 'selu', 'softplus']  # more activation functions\n",
    "        # }, \n",
    "        # 'kernel_initializer': {\n",
    "        #     'values': ['he_normal', 'glorot_uniform', 'glorot_normal', 'lecun_normal']  # more initializers\n",
    "        # }, \n",
    "        # 'loss': {\n",
    "        #     'values': ['mse', 'mae', 'logcosh', 'huber']  # more loss functions\n",
    "        # }, \n",
    "        'epoch': {\n",
    "            'min': 10,\n",
    "            'max': 500\n",
    "        },\n",
    "        'batch_norm': {\n",
    "            'values': [True, False]\n",
    "        }, \n",
    "        'l1_l2': {\n",
    "            'values': [True]\n",
    "        },        \n",
    "        'l1': {\n",
    "            'min': 0.0001,\n",
    "            'max': 0.5\n",
    "        },\n",
    "        'l2': {\n",
    "            'min': 0.0001,\n",
    "            'max': 0.5\n",
    "        },\n",
    "        'metrics': {\n",
    "            'values': ['mae']\n",
    "        }\n",
    "        # 'metrics': {\n",
    "        #     'values': ['mae', 'mse', 'mape', 'msle']  # adding more metrics\n",
    "        # }\n",
    "    }\n",
    "}\n",
    "\n",
    "def train(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "        model = train_model(\n",
    "            X_train=X_train_scaled, y_train=y_train_log,\n",
    "            X_valid=X_test_scaled, y_valid=y_valid_log,\n",
    "            activation=config.activation, kernel_initializer=config.kernel_initializer, \n",
    "            loss=config.loss, learning_rate=config.learning_rate, \n",
    "            epochs=config.epoch, batch_norm=config.batch_norm, \n",
    "            l1_l2=config.l1_l2, l1=config.l1, l2=config.l2, \n",
    "            metrics=config.metrics)\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"fred_dnn_sweep\")\n",
    "# wandb.agent(sweep_id, train, count=100)\n",
    "wandb.agent(sweep_id, train, count=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
