{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e5e3e18f",
   "metadata": {},
   "source": [
    "In this project we'll train agents that choose to run, pass, kick or punt based on the current yards to first, yards to goal, and down.\n",
    "\n",
    "First we need to create a stable baselines3 compliant custom environment (SB3's guide - https://stable-baselines3.readthedocs.io/en/master/guide/custom_env.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66467bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "from scipy import stats\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "# the function provides the other team's expected points when there is a change of possession.\n",
    "def calc_ep(ydsToGo, ydsToGo_ep_intercept=5.211187389603027, ydsToGo_coef=-0.06155063):\n",
    "    return ydsToGo_ep_intercept + ydsToGo * ydsToGo_coef\n",
    "\n",
    "touchback_ep = calc_ep(80)\n",
    "\n",
    "def normalize_continuous(value, min_value, max_value):\n",
    "    return (value - min_value) / (max_value - min_value)\n",
    "\n",
    "class NflEnv(gym.Env):\n",
    "    \n",
    "    def __init__(self, init_yds_to_goal = 80):\n",
    "        super(NflEnv, self).__init__()\n",
    "        \n",
    "        # Define action and observation space\n",
    "        # They must be gym.spaces objects\n",
    "        self.action_space = spaces.Discrete(4)  # 0 - run, 1 - pass, 2 - kick, 3 - punt\n",
    "\n",
    "        \n",
    "        self.observation_space = spaces.Dict({\n",
    "            \"yds_to_goal\": spaces.Box(low=0, high=100, shape=(1,), dtype=np.float32),\n",
    "            \"yds_to_first\": spaces.Box(low=0, high=100, shape=(1,), dtype=np.float32),\n",
    "            \"down\": spaces.Discrete(4)\n",
    "        })\n",
    "\n",
    "        \n",
    "        self.init_yds_to_goal = init_yds_to_goal\n",
    "        self.init_down = 0\n",
    "        self.init_yds_to_first = 10\n",
    "        \n",
    "        self.comp_percent=.642\n",
    "        self.int_rate=.023\n",
    "        self.sack_rate=.067\n",
    "        self.sack_avg=-5\n",
    "        self.sack_sd=1\n",
    "        self.fmb_rate=.5 / (21.4 + 27.3)\n",
    "\n",
    "    def step(self, action):\n",
    "        \n",
    "        prev_down = self.down\n",
    "        prev_yds_to_first = self.yds_to_first\n",
    "        prev_yds_to_goal = self.yds_to_goal\n",
    "        \n",
    "        self.down += 1\n",
    "        score = 0\n",
    "        yds = 0\n",
    "        turnover = False\n",
    "\n",
    "        # kick\n",
    "        if action == 2:\n",
    "            prob = random.rand()\n",
    "            # made fg\n",
    "            # https://www.reddit.com/r/nfl/comments/d4h2r0/kicker_accuracy_accounting_for_distance/\n",
    "            if ((self.yds_to_goal < 60) & (self.yds_to_goal >= 50) & (prob <= .54)) \\\n",
    "                    | ((self.yds_to_goal < 50) & (self.yds_to_goal >= 40) & (prob <= .79)) \\\n",
    "                    | ((self.yds_to_goal < 40) & (self.yds_to_goal >= 30) & (prob <= .90)) \\\n",
    "                    | ((self.yds_to_goal < 30) & (prob <= .95)):\n",
    "                yds = self.yds_to_goal\n",
    "                self.yds_to_goal = 0\n",
    "                self.yds_to_first = 0\n",
    "                score = 3\n",
    "                self.reward = score - touchback_ep\n",
    "            # missed fg\n",
    "            else:\n",
    "                score = 0\n",
    "                self.reward = score - calc_ep(100 - self.yds_to_goal)\n",
    "            self.done = True\n",
    "        # punt\n",
    "        elif action == 3:  \n",
    "            potential_yds = random.normal(loc=45, scale=5)\n",
    "            if potential_yds >= self.yds_to_goal:\n",
    "                touchback = (np.random.rand() < 0.1)\n",
    "                if touchback:\n",
    "                    yds = self.yds_to_goal - 20\n",
    "                    self.yds_to_goal = 20\n",
    "                else:\n",
    "                    yds = self.yds_to_goal - 1\n",
    "                    self.yds_to_goal = 1\n",
    "            else:\n",
    "                yds = potential_yds\n",
    "                self.yds_to_goal = self.yds_to_goal - yds\n",
    "    \n",
    "            self.reward += ((yds / 100) - calc_ep(100 - self.yds_to_goal))\n",
    "            self.done = True\n",
    "\n",
    "        # run\n",
    "        elif action == 0:\n",
    "            yds = stats.lognorm.rvs(s=0.25558500132474415, loc=-15.189614313924665, scale=18.92331909863129, size=1)[0]\n",
    "            # fumble?\n",
    "            if np.random.rand() <= self.fmb_rate:\n",
    "                turnover = True\n",
    "        # pass\n",
    "        elif action == 1:\n",
    "            # sack?\n",
    "            if np.random.rand() <= self.sack_rate:\n",
    "                yds = random.normal(loc=self.sack_avg, scale=self.sack_sd)\n",
    "                # fumble?\n",
    "                if np.random.rand() <= self.fmb_rate:\n",
    "                    turnover = True\n",
    "            else:\n",
    "                if self.yds_to_goal <= 20:\n",
    "                    air_yds = \\\n",
    "                        stats.lognorm.rvs(s=0.18033921317690882, loc=-20.781271075327744, scale=27.083791999969066,\n",
    "                                          size=1)[\n",
    "                            0]\n",
    "                else:\n",
    "                    air_yds = \\\n",
    "                        stats.lognorm.rvs(s=0.3868256330626365, loc=-11.72666357691477, scale=21.714746429166233,\n",
    "                                          size=1)[0]\n",
    "                prob = np.random.rand()\n",
    "                # completion?\n",
    "                if prob <= self.comp_percent:\n",
    "                    yds = air_yds\n",
    "                    # fumble?\n",
    "                    if np.random.rand() <= self.fmb_rate:\n",
    "                        yds = air_yds\n",
    "                        turnover = True\n",
    "                # int?\n",
    "                elif prob >= (1 - self.int_rate):\n",
    "                    yds = air_yds\n",
    "                    turnover = True\n",
    "                # incomplete\n",
    "                else:\n",
    "                    yds = 0\n",
    "        # if action is not kick or punt\n",
    "        if action in [0, 1]:\n",
    "            self.yds_to_goal = max(self.yds_to_goal - yds, 0)\n",
    "            self.yds_to_first -= yds\n",
    "            # first down?\n",
    "            if self.yds_to_first <= 0:\n",
    "                self.down = self.init_down\n",
    "                self.yds_to_first = min(self.yds_to_goal, self.init_yds_to_first)\n",
    "            # turnover on downs?\n",
    "            elif self.down >= (self.init_down + 4):\n",
    "                turnover = True\n",
    "            # td?\n",
    "            if self.yds_to_goal == 0:\n",
    "                score = 7\n",
    "                self.reward = score - touchback_ep\n",
    "                self.done = True\n",
    "            if turnover == True:\n",
    "                score = 0\n",
    "                # should take touchback into account\n",
    "                self.reward = score - calc_ep(100 - self.yds_to_goal)\n",
    "                self.done = True\n",
    "            # trying a shaping reward here. just kind of winging this, probably needs refined\n",
    "            self.reward += (yds / 100)\n",
    "        \n",
    "        # not sure this is right but I think 5th down (expressed as 4) is breaking things turnover, kick on fourth down \n",
    "        if (self.down == (self.init_down + 4)):\n",
    "            self.down = self.init_down\n",
    "\n",
    "        self.state = {\n",
    "            \"yds_to_goal\": np.array([self.yds_to_goal], dtype=np.float32),\n",
    "            \"yds_to_first\": np.array([self.yds_to_first], dtype=np.float32),\n",
    "            \"down\": self.down  # Represents value 3 (0: 1st down, 1: 2nd down, 2: 3rd down, 3: 4th down)\n",
    "        }\n",
    "        \n",
    "        self.episode_reward += self.reward\n",
    "        \n",
    "        info = {}\n",
    "        info.update({\n",
    "            'prev_down': prev_down,\n",
    "            'prev_yds_to_first': prev_yds_to_first,\n",
    "            'prev_yds_to_goal': prev_yds_to_goal,\n",
    "            'yds': yds,\n",
    "            'turnover': turnover,\n",
    "            'score': score\n",
    "        })\n",
    "        \n",
    "        # https://gymnasium.farama.org/tutorials/gymnasium_basics/environment_creation/#sphx-glr-tutorials-gymnasium-basics-environment-creation-py\n",
    "        return self.state, self.reward, self.done, False, info\n",
    "\n",
    "    def reset(self, seed=None, yds_to_goal=None):\n",
    "\n",
    "        # https://gymnasium.farama.org/tutorials/gymnasium_basics/environment_creation/#sphx-glr-tutorials-gymnasium-basics-environment-creation-py\n",
    "        # We need the following line to seed self.np_random\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        self.down = self.init_down\n",
    "        self.yds_to_first = self.init_yds_to_first\n",
    "        if yds_to_goal is not None:\n",
    "            self.yds_to_goal = yds_to_goal\n",
    "        else:\n",
    "            self.yds_to_goal = self.init_yds_to_goal\n",
    "        \n",
    "        self.state = {\n",
    "            \"yds_to_goal\": self.yds_to_goal\n",
    "            , \"yds_to_first\": self.yds_to_first\n",
    "            , \"down\": self.down}\n",
    "        \n",
    "        self.reward = 0\n",
    "        self.episode_reward = 0\n",
    "        self.done = False\n",
    "        \n",
    "        # https://gymnasium.farama.org/tutorials/gymnasium_basics/environment_creation/#sphx-glr-tutorials-gymnasium-basics-environment-creation-py\n",
    "        info = {}\n",
    "        return self.state, info\n",
    "    \n",
    "\n",
    "    \n",
    "    def set_yds_to_goal(self, yds_to_goal):\n",
    "        self.yds_to_goal = yds_to_goal\n",
    "        self.state = {\n",
    "            \"yds_to_goal\": self.yds_to_goal\n",
    "            , \"yds_to_first\": self.yds_to_first\n",
    "            , \"down\": self.down}\n",
    "        \n",
    "        return self.state\n",
    "        \n",
    "    \n",
    "    def pretty_print(self, state, action, info):\n",
    "        down = state[\"down\"]\n",
    "        yds_to_first = state[\"yds_to_first\"][0]\n",
    "        yds_to_goal = state[\"yds_to_goal\"][0]\n",
    "        \n",
    "        yds = info[\"yds\"]\n",
    "        turnover = info[\"turnover\"]\n",
    "        score = info[\"score\"]\n",
    "        prev_down = info[\"prev_down\"]\n",
    "        prev_yds_to_first = info[\"prev_yds_to_first\"]\n",
    "        prev_yds_to_goal = info[\"prev_yds_to_goal\"]\n",
    "\n",
    "        if action == 0:\n",
    "            action = \"Run\"\n",
    "        elif action == 1:\n",
    "            action = \"Pass\"\n",
    "        elif action == 2:\n",
    "            action = \"Kick\"\n",
    "        elif action == 3:\n",
    "            action = \"Punt\"\n",
    "        \n",
    "        print(f\"Down: {prev_down}, Yards to First: {prev_yds_to_first:.1f}, Yards to Goal: {prev_yds_to_goal:.1f}, Action: {action}, Yards Gained: {yds:.1f}, Turnover: {turnover}\")\n",
    "        if turnover: print('Turnover')\n",
    "        if action == 'Kick':\n",
    "            if score == 3:\n",
    "                print('Made Field Goal')\n",
    "            else:\n",
    "                print('Missed Field Goal')\n",
    "        if score == 7: print('Touchdown')\n",
    "            \n",
    "        return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7db71304",
   "metadata": {},
   "source": [
    "Before we train the agents let's first try a custom policy on the environment. We'll use this as a benchmark to see how well the agents learn. Further, let's create two styles (chill & agro) so we can watch them play against each other. We'll want that functionality when we have the agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "084b3543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chill Custom policy mean reward: 2.71 +/- 4.13\n",
      "agro Custom policy mean reward: 2.64 +/- 4.09\n"
     ]
    }
   ],
   "source": [
    "from random import choices\n",
    "\n",
    "def custom_policy(state, style = 'chill'):\n",
    "    down = state['down']\n",
    "    yds_to_first = state['yds_to_first']\n",
    "    yds_to_goal = state['yds_to_goal']\n",
    "\n",
    "    if down == 0:\n",
    "        if style == 'chill':\n",
    "            # run first team\n",
    "            return choices([0, 1], weights=[70, 30], k=1)[0]\n",
    "        elif style == 'agro':\n",
    "            # pass first team\n",
    "            return choices([0, 1], weights=[30, 70], k=1)[0]\n",
    "        \n",
    "    if down == 1:\n",
    "        # heavy run first if ahead of the sticks\n",
    "        if yds_to_first <= (2*10/3):\n",
    "            return choices([0, 1], weights=[85, 15], k=1)[0]\n",
    "        # else pass first\n",
    "        else:\n",
    "            return choices([0, 1], weights=[30, 70], k=1)[0]\n",
    "        \n",
    "    if down == 2:\n",
    "        # passing down if well behind the sticks\n",
    "        if yds_to_first >= (2*10/3):\n",
    "            return 1\n",
    "        # heavy run first if ahead of the sticks\n",
    "        elif yds_to_first <= (10/3):\n",
    "            return choices([0, 1], weights=[85, 15], k=1)[0]\n",
    "        # else (>3.33 and <6.67) pass first\n",
    "        else:\n",
    "            return choices([0, 1], weights=[30, 70], k=1)[0]\n",
    "\n",
    "    # Kick on fourth down if yards to goal is less than 60 yards else same logic as third down\n",
    "    if down == 3:\n",
    "        # agro will always go for it ahead of the sticks\n",
    "        if (style == 'agro') & (yds_to_first <= (10/3)):\n",
    "            return choices([0, 1], weights=[85, 15], k=1)[0]\n",
    "        # kick\n",
    "        elif yds_to_goal < 60:\n",
    "            return 2\n",
    "        # punt\n",
    "        else:\n",
    "            return 3\n",
    "\n",
    "def custom_policy(state, style = 'chill'):\n",
    "    down = state['down']\n",
    "    yds_to_first = state['yds_to_first']\n",
    "    yds_to_goal = state['yds_to_goal']\n",
    "\n",
    "    if down == 0:\n",
    "        if style == 'chill':\n",
    "            # run first team\n",
    "            return choices([0, 1], weights=[70, 30], k=1)[0]\n",
    "        elif style == 'agro':\n",
    "            # pass first team\n",
    "            return choices([0, 1], weights=[30, 70], k=1)[0]\n",
    "        \n",
    "    if down == 1:\n",
    "        # heavy run first if ahead of the sticks\n",
    "        if yds_to_first <= (2*10/3):\n",
    "            return choices([0, 1], weights=[85, 15], k=1)[0]\n",
    "        # else pass first\n",
    "        else:\n",
    "            return choices([0, 1], weights=[30, 70], k=1)[0]\n",
    "        \n",
    "    if down == 2:\n",
    "        # passing down if well behind the sticks\n",
    "        if yds_to_first >= (2*10/3):\n",
    "            return 1\n",
    "        # heavy run first if ahead of the sticks\n",
    "        elif yds_to_first <= (10/3):\n",
    "            return choices([0, 1], weights=[85, 15], k=1)[0]\n",
    "        # else (>3.33 and <6.67) pass first\n",
    "        else:\n",
    "            return choices([0, 1], weights=[30, 70], k=1)[0]\n",
    "\n",
    "    # Kick on fourth down if yards to goal is less than 60 yards else same logic as third down\n",
    "    if down == 3:\n",
    "        # agro will always go for it ahead of the sticks\n",
    "        if (style == 'agro') & (yds_to_first <= (10/3)):\n",
    "            return choices([0, 1], weights=[85, 15], k=1)[0]\n",
    "        # kick\n",
    "        elif yds_to_goal < 60:\n",
    "            return 2\n",
    "        # punt\n",
    "        else:\n",
    "            return 3\n",
    "\n",
    "\n",
    "def evaluate_custom_policy(env, style='chill', n_episodes=1000, watch=False):\n",
    "    rewards = []\n",
    "    \n",
    "    for episode in range(n_episodes):\n",
    "        state, info = env.reset()\n",
    "        done = False\n",
    "        episode_reward = 0\n",
    "        step_count = 0\n",
    "\n",
    "        while not done:\n",
    "            action = custom_policy(state)\n",
    "            state, reward, done, placeholder, info = env.step(np.array([action]))\n",
    "            episode_reward += reward\n",
    "\n",
    "            if watch and episode == n_episodes - 1:\n",
    "                yds = info['yds']\n",
    "                prev_down = info['prev_down']\n",
    "                prev_yds_to_first = info['prev_yds_to_first']\n",
    "                prev_yds_to_goal = info['prev_yds_to_goal']\n",
    "                turnover = info['turnover']\n",
    "                print(f\"Step: {step_count}, Dwn: {prev_down}, to First: {round(float(prev_yds_to_first), 2)}, to Goal: {round(float(prev_yds_to_goal), 2)}, Action: {action}, Yds Gained: {round(float(yds), 2)}, Reward: {round(float(reward), 2)}, Tot Reward: {round(float(episode_reward), 2)}, TO: {turnover}\")\n",
    "\n",
    "            step_count += 1\n",
    "        \n",
    "        rewards.append(episode_reward)\n",
    "\n",
    "    mean_reward = np.mean(rewards)\n",
    "    std_reward = np.std(rewards)\n",
    "\n",
    "    return mean_reward, std_reward\n",
    "\n",
    "n_eval_episodes = 1_000\n",
    "styles = ['chill', 'agro']\n",
    "for style in styles:\n",
    "    env = NflEnv()\n",
    "    mean_reward_custom, std_reward_custom = evaluate_custom_policy(env, style, n_episodes=n_eval_episodes, watch=False)\n",
    "    print(f\"{style} Custom policy mean reward: {mean_reward_custom:.2f} +/- {std_reward_custom:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8532a0e7",
   "metadata": {},
   "source": [
    "Let's watch the two styles play a game against each other, first with text and then with images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9175e77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "def draw_field(player_with_ball, starting_yds_to_goal, yds, drive_yds, player_1_score, player_2_score, one_image='n'):\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.barh(0, 100, color='green', height=5)\n",
    "    plt.xlim(0, 100)\n",
    "    plt.ylim(-1, 1)\n",
    "    plt.xticks(range(0, 101, 10))\n",
    "    plt.yticks([])\n",
    "    plt.grid(axis='x')\n",
    "\n",
    "    if player_with_ball == 1:\n",
    "        starting_ball_position = (100 - starting_yds_to_goal)\n",
    "        ball_position = starting_ball_position + drive_yds\n",
    "    elif player_with_ball == 2:\n",
    "        starting_ball_position = starting_yds_to_goal\n",
    "        ball_position = starting_ball_position - drive_yds\n",
    "    \n",
    "    # Plot the ball\n",
    "    plt.plot(ball_position, 0, 'o', markersize=20, color='orange')\n",
    "\n",
    "    plt.text(ball_position, 0.1, f'Play gain: {yds} yards\\nTotal drive: {drive_yds} yards',\n",
    "             horizontalalignment='center', verticalalignment='bottom', color='white', fontsize=12, fontweight='bold')\n",
    "\n",
    "    if player_with_ball == 1:\n",
    "        plt.barh(0, drive_yds, left=starting_ball_position, color='red', height=0.1)\n",
    "    else:  # team 2\n",
    "        plt.barh(0, drive_yds, left=ball_position, color='blue', height=0.1)\n",
    "    \n",
    "    # Add a scoreboard in the top right corner\n",
    "    plt.text(98, 0.8, f'Team 1: {player_1_score}\\nTeam 2: {player_2_score}', \n",
    "             horizontalalignment='right', verticalalignment='top', \n",
    "             bbox=dict(boxstyle=\"square,pad=1\", fc=\"white\", ec=\"black\"), fontsize=14)\n",
    "    \n",
    "    if one_image == 'n':\n",
    "        plt.show()\n",
    "    else:\n",
    "        clear_output(wait=True)  # This will clear the output before showing the new plot\n",
    "        display(plt.gcf())  # This will display the current plot\n",
    "        plt.close()  # This will close the plot so it doesn't get shown again later\n",
    "        time.sleep(0.25)  # wait for quarter second between plays\n",
    "        \n",
    "\n",
    "\n",
    "def play_game(env, possessions=2, style_1='chill', style_2='agro', model_1=None, model_2=None, players = [1, 2], text_viz='y', image_viz='n', one_image='n'):\n",
    "    \n",
    "    starting_yds_to_goal = 80\n",
    "    player_1_score = 0\n",
    "    player_2_score = 0\n",
    "    \n",
    "    if model_1 is not None:\n",
    "        print('player 1 is an agent')\n",
    "    else:\n",
    "        print(f'player 1 is using {style_1} play style')\n",
    "    if model_2 is not None:\n",
    "        print('player 2 is an agent')\n",
    "    else:\n",
    "        print(f'player 2 is using {style_2} play style')\n",
    "    print()\n",
    "\n",
    "    for possessions in range(1, possessions+1):\n",
    "\n",
    "        for player in players:\n",
    "            \n",
    "            if text_viz == 'y':\n",
    "                if player == 1:\n",
    "                    print(f\"player 1 taking possession with {starting_yds_to_goal:.2f} yards to go\")\n",
    "                else:\n",
    "                    print(f\"player 2 taking possession with {starting_yds_to_goal:.2f} yards to go\")\n",
    "            \n",
    "            # state = env.reset(yds_to_goal = starting_yds_to_goal)\n",
    "            state, info = env.reset(yds_to_goal = starting_yds_to_goal)\n",
    "            \n",
    "            done = False\n",
    "            episode_reward = 0\n",
    "            \n",
    "            drive_yds = 0\n",
    "\n",
    "            while not done:\n",
    "                state_array = {'yds_to_goal': np.array([state['yds_to_goal']]), 'yds_to_first': np.array([state['yds_to_first']]), 'down': np.array([state['down']])}\n",
    "                if player == 1:\n",
    "                    if model_1 is not None:\n",
    "                        action, _states = model_1.predict(state_array)\n",
    "                    else:\n",
    "                        action = custom_policy(state, style=style_1)\n",
    "                elif player == 2:\n",
    "                    if model_2 is not None:\n",
    "                        action, _states = model_2.predict(state_array)\n",
    "                    else:\n",
    "                        action = custom_policy(state, style=style_2)\n",
    "                state, reward, done, placeholder, info = env.step(np.array([action]))\n",
    "                episode_reward += reward\n",
    "                \n",
    "                score = info[\"score\"]                \n",
    "                if player == 1:\n",
    "                    player_1_score += score\n",
    "                else:\n",
    "                    player_2_score += score\n",
    "                \n",
    "                if text_viz == 'y':\n",
    "                    env.pretty_print(state, action, info)\n",
    "                    \n",
    "                if image_viz == 'y':\n",
    "                    yds = info[\"yds\"]\n",
    "                    drive_yds += yds\n",
    "                    draw_field(player_with_ball=player, starting_yds_to_goal=round(starting_yds_to_goal,1), yds=round(yds,1), drive_yds=round(drive_yds,1), player_1_score=player_1_score, player_2_score=player_2_score, one_image=one_image)\n",
    "                                \n",
    "            # if not made fg or td, probably better way to implement. This doesn't include punt touchbacks.\n",
    "            if score < 3:\n",
    "                starting_yds_to_goal = 100 - state[\"yds_to_goal\"][0]\n",
    "            else:\n",
    "                starting_yds_to_goal = 80\n",
    "            \n",
    "            if text_viz == 'y':\n",
    "                print('Scoreboard:')\n",
    "                print(f\"player 1 - {player_1_score}\")\n",
    "                print(f\"player 2 - {player_2_score}\")\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "185f7165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player 1 is using chill play style\n",
      "player 2 is using agro play style\n",
      "\n",
      "player 1 taking possession with 80.00 yards to go\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 80.0, Action: Run, Yards Gained: -3.6, Turnover: False\n",
      "Down: 1, Yards to First: 13.6, Yards to Goal: 83.6, Action: Pass, Yards Gained: 32.7, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 50.9, Action: Pass, Yards Gained: 1.5, Turnover: False\n",
      "Down: 1, Yards to First: 8.5, Yards to Goal: 49.4, Action: Pass, Yards Gained: 12.4, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 37.0, Action: Pass, Yards Gained: 8.0, Turnover: False\n",
      "Down: 1, Yards to First: 2.0, Yards to Goal: 29.0, Action: Run, Yards Gained: 11.2, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 17.8, Action: Run, Yards Gained: 15.0, Turnover: False\n",
      "Down: 0, Yards to First: 2.8, Yards to Goal: 2.8, Action: Run, Yards Gained: -1.4, Turnover: False\n",
      "Down: 1, Yards to First: 4.2, Yards to Goal: 4.2, Action: Run, Yards Gained: -0.9, Turnover: False\n",
      "Down: 2, Yards to First: 5.1, Yards to Goal: 5.1, Action: Pass, Yards Gained: -4.9, Turnover: False\n",
      "Down: 3, Yards to First: 10.0, Yards to Goal: 10.0, Action: Kick, Yards Gained: 10.0, Turnover: False\n",
      "Made Field Goal\n",
      "Scoreboard:\n",
      "player 1 - 3\n",
      "player 2 - 0\n",
      "\n",
      "player 2 taking possession with 80.00 yards to go\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 80.0, Action: Pass, Yards Gained: 6.4, Turnover: False\n",
      "Down: 1, Yards to First: 3.6, Yards to Goal: 73.6, Action: Pass, Yards Gained: 19.2, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 54.4, Action: Run, Yards Gained: 5.3, Turnover: False\n",
      "Down: 1, Yards to First: 4.7, Yards to Goal: 49.1, Action: Run, Yards Gained: -1.6, Turnover: False\n",
      "Down: 2, Yards to First: 6.3, Yards to Goal: 50.7, Action: Run, Yards Gained: 6.2, Turnover: False\n",
      "Down: 3, Yards to First: 0.1, Yards to Goal: 44.5, Action: Run, Yards Gained: 0.1, Turnover: True\n",
      "Turnover\n",
      "Scoreboard:\n",
      "player 1 - 3\n",
      "player 2 - 0\n",
      "\n",
      "player 1 taking possession with 55.57 yards to go\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 55.6, Action: Run, Yards Gained: 1.2, Turnover: False\n",
      "Down: 1, Yards to First: 8.8, Yards to Goal: 54.4, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 2, Yards to First: 8.8, Yards to Goal: 54.4, Action: Pass, Yards Gained: 29.2, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 25.3, Action: Run, Yards Gained: 7.5, Turnover: False\n",
      "Down: 1, Yards to First: 2.5, Yards to Goal: 17.8, Action: Run, Yards Gained: 3.6, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 14.2, Action: Run, Yards Gained: 3.6, Turnover: False\n",
      "Down: 1, Yards to First: 6.4, Yards to Goal: 10.6, Action: Run, Yards Gained: 3.7, Turnover: False\n",
      "Down: 2, Yards to First: 2.7, Yards to Goal: 6.9, Action: Run, Yards Gained: -1.9, Turnover: False\n",
      "Down: 3, Yards to First: 4.6, Yards to Goal: 8.8, Action: Kick, Yards Gained: 8.8, Turnover: False\n",
      "Made Field Goal\n",
      "Scoreboard:\n",
      "player 1 - 6\n",
      "player 2 - 0\n",
      "\n",
      "player 2 taking possession with 80.00 yards to go\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 80.0, Action: Pass, Yards Gained: 8.4, Turnover: False\n",
      "Down: 1, Yards to First: 1.6, Yards to Goal: 71.6, Action: Run, Yards Gained: 1.3, Turnover: False\n",
      "Down: 2, Yards to First: 0.3, Yards to Goal: 70.3, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 3, Yards to First: 0.3, Yards to Goal: 70.3, Action: Run, Yards Gained: -1.8, Turnover: True\n",
      "Turnover\n",
      "Scoreboard:\n",
      "player 1 - 6\n",
      "player 2 - 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "play_game(env=NflEnv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdceb30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# play_game(env=NflEnv(), text_viz='n', image_viz='y')\n",
    "play_game(env=NflEnv(), text_viz='n', image_viz='y', one_image='y')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "313f7603",
   "metadata": {},
   "source": [
    "Now for the fun part, let's use RL to train agents. We'll use stable baselines3 to train and weights & biases to monitor and evaluate our training runs. First, let's import libraries and set hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0c2e4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgrantbell\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from stable_baselines3 import DQN, PPO, A2C\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "import wandb\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3916d263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training_job(model_type, use_wandb = 'y', timesteps=1_000_000, policy='MultiInputPolicy'\n",
    "                     ,exploration_final_eps=0.025, exploration_fraction=0.5\n",
    "                     , vec_envs='n', n_envs=4, sb3_model_verbose=0, wandb_verbose=2):\n",
    "    \n",
    "    # https://docs.wandb.ai/guides/integrations/stable-baselines-3\n",
    "    config = {\n",
    "    \"policy_type\": policy,\n",
    "    \"total_timesteps\": timesteps,\n",
    "    \"env_id\": \"NflEnv\",\n",
    "    }\n",
    "\n",
    "    if use_wandb == 'y':\n",
    "        run = wandb.init(\n",
    "            project=\"sb3_nfl_2\",\n",
    "            config=config,\n",
    "            sync_tensorboard=True\n",
    "        )\n",
    "\n",
    "    # when using multiple environments, the total number of steps taken in counts each step taken in each environment\n",
    "    # if using 4 environments and 400_000 TIMESTEPS, the agent will take a total of 100_000 steps in each environment.\n",
    "    if vec_envs == 'y':\n",
    "        # https://colab.research.google.com/github/araffin/rl-tutorial-jnrr19/blob/sb3/5_custom_gym_env.ipynb\n",
    "        # received 'ValueError: high is out of bounds for int32' without the seed\n",
    "        env = make_vec_env(env_id = NflEnv, n_envs=n_envs, seed=1)\n",
    "\n",
    "    elif vec_envs == 'n':\n",
    "        env = NflEnv()\n",
    "    \n",
    "    if use_wandb == 'y':\n",
    "        if model_type == 'DQN':\n",
    "            # default values for these parameters are exploration_final_eps=0.05 and exploration_fraction=0.1\n",
    "            # with the default values, the exploration rate will linearly decrease to 0.05 over the first 10% of the timesteps\n",
    "            model = DQN(config[\"policy_type\"], NflEnv(), verbose=sb3_model_verbose, tensorboard_log=f\"runs/{run.id}\", exploration_final_eps=exploration_final_eps\n",
    "                        , exploration_fraction = exploration_fraction)\n",
    "        elif model_type == 'PPO':\n",
    "            model = PPO(config[\"policy_type\"], NflEnv(), verbose=sb3_model_verbose, tensorboard_log=f\"runs/{run.id}\")\n",
    "        elif model_type == 'A2C':\n",
    "            model = A2C(config[\"policy_type\"], NflEnv(), verbose=sb3_model_verbose, tensorboard_log=f\"runs/{run.id}\")\n",
    "    else:\n",
    "        if model_type == 'DQN':\n",
    "            model = DQN(config[\"policy_type\"], NflEnv(), verbose=sb3_model_verbose, exploration_final_eps=exploration_final_eps\n",
    "                        , exploration_fraction = exploration_fraction)\n",
    "        elif model_type == 'PPO':\n",
    "            model = PPO(config[\"policy_type\"], NflEnv(), verbose=sb3_model_verbose)\n",
    "        elif model_type == 'A2C':\n",
    "            model = A2C(config[\"policy_type\"], NflEnv(), verbose=sb3_model_verbose)\n",
    "\n",
    "    mean_reward, std_reward = evaluate_policy(model=model, env=env, n_eval_episodes=n_eval_episodes)\n",
    "    print(f\"mean_reward before training:{mean_reward:.2f} +/- {std_reward:.2f}\")\n",
    "\n",
    "    if use_wandb == 'y':\n",
    "        model.learn(\n",
    "            total_timesteps=config[\"total_timesteps\"],\n",
    "            callback=WandbCallback(\n",
    "                model_save_path=f\"models/{run.id}\",\n",
    "                verbose=wandb_verbose,\n",
    "            ),\n",
    "        )\n",
    "        run.finish()\n",
    "    else:\n",
    "        model.learn(total_timesteps=config[\"total_timesteps\"])\n",
    "\n",
    "    mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=n_eval_episodes)\n",
    "    print(f\"mean_reward after training:{mean_reward:.2f} +/- {std_reward:.2f}\")\n",
    "\n",
    "    # parameters_saved = model.get_parameters()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5e74b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:jrcj95j9) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>rollout/ep_len_mean</td><td>▁▅▄▆▆▆▆▇▇▇▇▇▇▇▇▇█▇▆▇▆▆▅▆▅▅▄▄▄▄▄▄▄▄▄▄▅▅▆▆</td></tr><tr><td>rollout/ep_rew_mean</td><td>▁▇▅▇▇▆▇▇▇█▇▇███▇▇█▇▆▇▇▇▆▆▆▆▆▆▆▆▅▅▄▄▅▆▇▇█</td></tr><tr><td>rollout/exploration_rate</td><td>████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>time/fps</td><td>▁▂▃▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>1248</td></tr><tr><td>rollout/ep_len_mean</td><td>1.93</td></tr><tr><td>rollout/ep_rew_mean</td><td>-1.55767</td></tr><tr><td>rollout/exploration_rate</td><td>0.97574</td></tr><tr><td>time/fps</td><td>1409.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">balmy-rain-33</strong> at: <a href='https://wandb.ai/grantbell/sb3_nfl_2/runs/jrcj95j9' target=\"_blank\">https://wandb.ai/grantbell/sb3_nfl_2/runs/jrcj95j9</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230703_213308-jrcj95j9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:jrcj95j9). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\grant\\OneDrive\\Desktop\\nfl_jupyter\\wandb\\run-20230703_213332-g59ewbvq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/grantbell/sb3_nfl_2/runs/g59ewbvq' target=\"_blank\">summer-yogurt-34</a></strong> to <a href='https://wandb.ai/grantbell/sb3_nfl_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/grantbell/sb3_nfl_2' target=\"_blank\">https://wandb.ai/grantbell/sb3_nfl_2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/grantbell/sb3_nfl_2/runs/g59ewbvq' target=\"_blank\">https://wandb.ai/grantbell/sb3_nfl_2/runs/g59ewbvq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grant\\anaconda3\\envs\\rl\\Lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward before training:-0.02 +/- 2.41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅▆▆▆▇▇█</td></tr><tr><td>rollout/ep_len_mean</td><td>▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▆▆▆█▇█▇</td></tr><tr><td>rollout/ep_rew_mean</td><td>▂▂▂▂▂▂▂▁▂▂▁▂▂▂▂▂▂▁▁▂▂▁▃▃▃▃▃▃▃▃▃▃▄▄▄▄█▆▇▇</td></tr><tr><td>rollout/exploration_rate</td><td>██▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>time/fps</td><td>▇███████████████▇▇▇▇▇▇▇▆▆▅▅▄▄▄▃▃▃▃▂▂▂▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>▂▆▅▄▂▁▃▂▁▂▂▂▂▂▃▂▂▂▃▂▂▅▂▁▃▄▃█▆▅▂▄▃▄▃▅▆▄▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>99991</td></tr><tr><td>rollout/ep_len_mean</td><td>6.69</td></tr><tr><td>rollout/ep_rew_mean</td><td>2.25399</td></tr><tr><td>rollout/exploration_rate</td><td>0.025</td></tr><tr><td>time/fps</td><td>724.0</td></tr><tr><td>train/learning_rate</td><td>0.0001</td></tr><tr><td>train/loss</td><td>0.18514</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">summer-yogurt-34</strong> at: <a href='https://wandb.ai/grantbell/sb3_nfl_2/runs/g59ewbvq' target=\"_blank\">https://wandb.ai/grantbell/sb3_nfl_2/runs/g59ewbvq</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230703_213332-g59ewbvq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward after training:2.39 +/- 4.85\n"
     ]
    }
   ],
   "source": [
    "timesteps=100_000\n",
    "dqn_model = run_training_job('DQN',timesteps=timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5ebb199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\grant\\OneDrive\\Desktop\\nfl_jupyter\\wandb\\run-20230703_213621-5y9kf88m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/grantbell/sb3_nfl_2/runs/5y9kf88m' target=\"_blank\">lively-energy-35</a></strong> to <a href='https://wandb.ai/grantbell/sb3_nfl_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/grantbell/sb3_nfl_2' target=\"_blank\">https://wandb.ai/grantbell/sb3_nfl_2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/grantbell/sb3_nfl_2/runs/5y9kf88m' target=\"_blank\">https://wandb.ai/grantbell/sb3_nfl_2/runs/5y9kf88m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grant\\anaconda3\\envs\\rl\\Lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward before training:0.66 +/- 3.35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>rollout/ep_len_mean</td><td>▁▁▂▃▅▅▆▇▇▇███▇██▇██▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇█</td></tr><tr><td>rollout/ep_rew_mean</td><td>▁▂▂▄▄▄▅▇▆█▇▇▇▆▆▅▇▆▇▇▇▇▆█▇▇▇▆▆▆▇▇█▇▇█▆█▇█</td></tr><tr><td>time/fps</td><td>█▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/approx_kl</td><td>█▅▅▂▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/clip_fraction</td><td>█▃▆▄▄▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/clip_range</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/entropy_loss</td><td>▁▁▂▃▃▄▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇████████████████</td></tr><tr><td>train/explained_variance</td><td>▁▆▆▇▇█▇▅▇▆▆▇▇▆▆▆▅▆▇▆▆▆▇▆▇▇▇▆▇▇▅▇▆▆▆▆▅▇▇▆</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>▁▁▁▁▄▆▄▅▅▆▆▆▆▅█▅▅▇▆▆▆▅▆▅▅▅▇▅▆▅▅▆▇▇▆▄▅▆▆▅</td></tr><tr><td>train/policy_gradient_loss</td><td>▁▅▅▆▆▇▇█▇███████████████████████████████</td></tr><tr><td>train/value_loss</td><td>▁▁▁▂▄▆▆▇▇▇▇▇▇▇█▇▇█▇████▇█████▇▇█████▇██▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>100352</td></tr><tr><td>rollout/ep_len_mean</td><td>7.8</td></tr><tr><td>rollout/ep_rew_mean</td><td>3.33847</td></tr><tr><td>time/fps</td><td>554.0</td></tr><tr><td>train/approx_kl</td><td>7e-05</td></tr><tr><td>train/clip_fraction</td><td>0.00225</td></tr><tr><td>train/clip_range</td><td>0.2</td></tr><tr><td>train/entropy_loss</td><td>-0.04136</td></tr><tr><td>train/explained_variance</td><td>0.17916</td></tr><tr><td>train/learning_rate</td><td>0.0003</td></tr><tr><td>train/loss</td><td>7.32554</td></tr><tr><td>train/policy_gradient_loss</td><td>-0.00039</td></tr><tr><td>train/value_loss</td><td>14.90415</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lively-energy-35</strong> at: <a href='https://wandb.ai/grantbell/sb3_nfl_2/runs/5y9kf88m' target=\"_blank\">https://wandb.ai/grantbell/sb3_nfl_2/runs/5y9kf88m</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230703_213621-5y9kf88m\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward after training:2.48 +/- 5.45\n"
     ]
    }
   ],
   "source": [
    "ppo_model = run_training_job('PPO', timesteps=timesteps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b6075a9",
   "metadata": {},
   "source": [
    "Let's watch DQN and PPO play eachother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e00a1c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player 1 is an agent\n",
      "player 2 is an agent\n",
      "\n",
      "player 1 taking possession with 80.00 yards to go\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 80.0, Action: Pass, Yards Gained: 9.2, Turnover: False\n",
      "Down: 1, Yards to First: 0.8, Yards to Goal: 70.8, Action: Pass, Yards Gained: 5.8, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 65.0, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 1, Yards to First: 10.0, Yards to Goal: 65.0, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 2, Yards to First: 10.0, Yards to Goal: 65.0, Action: Pass, Yards Gained: 15.3, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 49.7, Action: Pass, Yards Gained: 2.7, Turnover: False\n",
      "Down: 1, Yards to First: 7.3, Yards to Goal: 46.9, Action: Pass, Yards Gained: 14.5, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 32.4, Action: Pass, Yards Gained: 2.3, Turnover: False\n",
      "Down: 1, Yards to First: 7.7, Yards to Goal: 30.1, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 2, Yards to First: 7.7, Yards to Goal: 30.1, Action: Pass, Yards Gained: 2.6, Turnover: False\n",
      "Down: 3, Yards to First: 5.0, Yards to Goal: 27.5, Action: Pass, Yards Gained: -3.8, Turnover: True\n",
      "Turnover\n",
      "Scoreboard:\n",
      "player 1 - 0\n",
      "player 2 - 0\n",
      "\n",
      "player 2 taking possession with 68.79 yards to go\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 68.8, Action: Pass, Yards Gained: 24.2, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 44.6, Action: Pass, Yards Gained: 7.7, Turnover: False\n",
      "Down: 1, Yards to First: 2.3, Yards to Goal: 36.9, Action: Pass, Yards Gained: -0.9, Turnover: False\n",
      "Down: 2, Yards to First: 3.3, Yards to Goal: 37.9, Action: Pass, Yards Gained: 16.7, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 21.2, Action: Pass, Yards Gained: 18.6, Turnover: False\n",
      "Down: 0, Yards to First: 2.5, Yards to Goal: 2.5, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 1, Yards to First: 2.5, Yards to Goal: 2.5, Action: Pass, Yards Gained: 5.4, Turnover: False\n",
      "Touchdown\n",
      "Scoreboard:\n",
      "player 1 - 0\n",
      "player 2 - 7\n",
      "\n",
      "player 1 taking possession with 80.00 yards to go\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 80.0, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 1, Yards to First: 10.0, Yards to Goal: 80.0, Action: Pass, Yards Gained: 11.7, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 68.3, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 1, Yards to First: 10.0, Yards to Goal: 68.3, Action: Pass, Yards Gained: 4.4, Turnover: False\n",
      "Down: 2, Yards to First: 5.6, Yards to Goal: 63.9, Action: Pass, Yards Gained: 21.1, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 42.7, Action: Pass, Yards Gained: 18.6, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 24.2, Action: Pass, Yards Gained: 12.0, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 12.2, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 1, Yards to First: 10.0, Yards to Goal: 12.2, Action: Pass, Yards Gained: 10.4, Turnover: False\n",
      "Down: 0, Yards to First: 1.7, Yards to Goal: 1.7, Action: Pass, Yards Gained: 2.2, Turnover: False\n",
      "Touchdown\n",
      "Scoreboard:\n",
      "player 1 - 7\n",
      "player 2 - 7\n",
      "\n",
      "player 2 taking possession with 80.00 yards to go\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 80.0, Action: Pass, Yards Gained: -5.2, Turnover: False\n",
      "Down: 1, Yards to First: 15.2, Yards to Goal: 85.2, Action: Pass, Yards Gained: 15.4, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 69.9, Action: Pass, Yards Gained: 1.6, Turnover: False\n",
      "Down: 1, Yards to First: 8.4, Yards to Goal: 68.3, Action: Pass, Yards Gained: 5.3, Turnover: False\n",
      "Down: 2, Yards to First: 3.0, Yards to Goal: 62.9, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 3, Yards to First: 3.0, Yards to Goal: 62.9, Action: Pass, Yards Gained: 3.9, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 59.0, Action: Pass, Yards Gained: 5.4, Turnover: False\n",
      "Down: 1, Yards to First: 4.6, Yards to Goal: 53.6, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 2, Yards to First: 4.6, Yards to Goal: 53.6, Action: Pass, Yards Gained: 22.6, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 30.9, Action: Pass, Yards Gained: 13.3, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 17.6, Action: Pass, Yards Gained: 7.5, Turnover: False\n",
      "Down: 1, Yards to First: 2.5, Yards to Goal: 10.2, Action: Pass, Yards Gained: 13.0, Turnover: False\n",
      "Touchdown\n",
      "Scoreboard:\n",
      "player 1 - 7\n",
      "player 2 - 14\n",
      "\n",
      "player 1 taking possession with 80.00 yards to go\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 80.0, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 1, Yards to First: 10.0, Yards to Goal: 80.0, Action: Pass, Yards Gained: 11.5, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 68.5, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 1, Yards to First: 10.0, Yards to Goal: 68.5, Action: Pass, Yards Gained: -4.3, Turnover: False\n",
      "Down: 2, Yards to First: 14.3, Yards to Goal: 72.8, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 3, Yards to First: 14.3, Yards to Goal: 72.8, Action: Pass, Yards Gained: 14.0, Turnover: True\n",
      "Turnover\n",
      "Scoreboard:\n",
      "player 1 - 7\n",
      "player 2 - 14\n",
      "\n",
      "player 2 taking possession with 41.14 yards to go\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 41.1, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 1, Yards to First: 10.0, Yards to Goal: 41.1, Action: Punt, Yards Gained: 40.1, Turnover: False\n",
      "Scoreboard:\n",
      "player 1 - 7\n",
      "player 2 - 14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "play_game(env=NflEnv(), model_1=ppo_model, model_2=dqn_model, possessions=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43cc3ccf",
   "metadata": {},
   "source": [
    "let's see if vectorized environments with more steps improve performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04021134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\grant\\OneDrive\\Desktop\\nfl_jupyter\\wandb\\run-20230703_214554-jrqtcwf1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/grantbell/sb3_nfl_2/runs/jrqtcwf1' target=\"_blank\">radiant-breeze-36</a></strong> to <a href='https://wandb.ai/grantbell/sb3_nfl_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/grantbell/sb3_nfl_2' target=\"_blank\">https://wandb.ai/grantbell/sb3_nfl_2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/grantbell/sb3_nfl_2/runs/jrqtcwf1' target=\"_blank\">https://wandb.ai/grantbell/sb3_nfl_2/runs/jrqtcwf1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward before training:0.62 +/- 3.48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>rollout/ep_len_mean</td><td>▁▅▆▇█▇█▇▇▇█▇▇▆▇█▇▇█▇▇▇▆██▇▇█▇▆█▇▇▇▇▆▇█▇▇</td></tr><tr><td>rollout/ep_rew_mean</td><td>▁▄▆▆▆▅▆▆▆▇█▇▆▆▆█▆▆▇▇▅▇▆▇▇▆▇▇▆▅▇▇▇▆▆▇▇▇▆▆</td></tr><tr><td>time/fps</td><td>█▁▂▃▃▃▃▃▃▄▄▃▃▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>train/approx_kl</td><td>█▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/clip_fraction</td><td>█▅▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁</td></tr><tr><td>train/clip_range</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/entropy_loss</td><td>▁▃▅▆▆▇▇▇▇▇▇▇████████████████████████████</td></tr><tr><td>train/explained_variance</td><td>▅█▅▆▃▃▅▄▆▃▅▄▂▅▅▃▆▆▄▄▃▂▅▆▁▄▄▃█▃▆▃▆▄▁▅▂▆▅▆</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>▁▂▆▅▅▆▇▇▆▅▆▅▆▆▆▅▆▆▅▇▅▆▆▆▆▆▅▆▅▇▆▇█▅▅▆▄▇▄▅</td></tr><tr><td>train/policy_gradient_loss</td><td>▁▆▇█████████████████████████████████████</td></tr><tr><td>train/value_loss</td><td>▁▃▇▇██▇█▇██▇▇███▇███▇█▇█▇▇███▇▇█████▇█▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>401408</td></tr><tr><td>rollout/ep_len_mean</td><td>7.27</td></tr><tr><td>rollout/ep_rew_mean</td><td>2.59181</td></tr><tr><td>time/fps</td><td>515.0</td></tr><tr><td>train/approx_kl</td><td>0.00021</td></tr><tr><td>train/clip_fraction</td><td>0.00342</td></tr><tr><td>train/clip_range</td><td>0.2</td></tr><tr><td>train/entropy_loss</td><td>-0.07553</td></tr><tr><td>train/explained_variance</td><td>0.18562</td></tr><tr><td>train/learning_rate</td><td>0.0003</td></tr><tr><td>train/loss</td><td>6.82318</td></tr><tr><td>train/policy_gradient_loss</td><td>-0.00012</td></tr><tr><td>train/value_loss</td><td>15.67249</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">radiant-breeze-36</strong> at: <a href='https://wandb.ai/grantbell/sb3_nfl_2/runs/jrqtcwf1' target=\"_blank\">https://wandb.ai/grantbell/sb3_nfl_2/runs/jrqtcwf1</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230703_214554-jrqtcwf1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward after training:2.86 +/- 5.72\n"
     ]
    }
   ],
   "source": [
    "n_envs = 4\n",
    "ppo_vec_model = run_training_job('PPO', timesteps=timesteps * n_envs, vec_envs='y',n_envs=n_envs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28238e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player 1 is an agent\n",
      "player 2 is an agent\n",
      "\n",
      "player 1 taking possession with 80.00 yards to go\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 80.0, Action: Pass, Yards Gained: 22.3, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 57.7, Action: Pass, Yards Gained: 5.9, Turnover: False\n",
      "Down: 1, Yards to First: 4.1, Yards to Goal: 51.9, Action: Pass, Yards Gained: 18.9, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 32.9, Action: Pass, Yards Gained: 22.4, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 10.5, Action: Pass, Yards Gained: 10.6, Turnover: False\n",
      "Touchdown\n",
      "Scoreboard:\n",
      "player 1 - 7\n",
      "player 2 - 0\n",
      "\n",
      "player 2 taking possession with 80.00 yards to go\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 80.0, Action: Pass, Yards Gained: 12.2, Turnover: True\n",
      "Turnover\n",
      "Scoreboard:\n",
      "player 1 - 7\n",
      "player 2 - 0\n",
      "\n",
      "player 1 taking possession with 32.15 yards to go\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 32.2, Action: Pass, Yards Gained: 6.9, Turnover: False\n",
      "Down: 1, Yards to First: 3.1, Yards to Goal: 25.2, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 2, Yards to First: 3.1, Yards to Goal: 25.2, Action: Run, Yards Gained: 1.2, Turnover: False\n",
      "Down: 3, Yards to First: 1.9, Yards to Goal: 24.0, Action: Pass, Yards Gained: 11.1, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 12.9, Action: Pass, Yards Gained: 2.1, Turnover: False\n",
      "Down: 1, Yards to First: 7.9, Yards to Goal: 10.8, Action: Pass, Yards Gained: -1.9, Turnover: False\n",
      "Down: 2, Yards to First: 9.8, Yards to Goal: 12.7, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 3, Yards to First: 9.8, Yards to Goal: 12.7, Action: Pass, Yards Gained: 6.7, Turnover: True\n",
      "Turnover\n",
      "Scoreboard:\n",
      "player 1 - 7\n",
      "player 2 - 0\n",
      "\n",
      "player 2 taking possession with 94.02 yards to go\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 94.0, Action: Pass, Yards Gained: 21.4, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 72.6, Action: Pass, Yards Gained: 34.2, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 38.4, Action: Pass, Yards Gained: -5.8, Turnover: False\n",
      "Down: 1, Yards to First: 15.8, Yards to Goal: 44.2, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 2, Yards to First: 15.8, Yards to Goal: 44.2, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 3, Yards to First: 15.8, Yards to Goal: 44.2, Action: Pass, Yards Gained: -4.8, Turnover: True\n",
      "Turnover\n",
      "Scoreboard:\n",
      "player 1 - 7\n",
      "player 2 - 0\n",
      "\n",
      "player 1 taking possession with 50.98 yards to go\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 51.0, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 1, Yards to First: 10.0, Yards to Goal: 51.0, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 2, Yards to First: 10.0, Yards to Goal: 51.0, Action: Pass, Yards Gained: 11.7, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 39.3, Action: Pass, Yards Gained: 14.1, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 25.2, Action: Pass, Yards Gained: 2.1, Turnover: False\n",
      "Down: 1, Yards to First: 7.9, Yards to Goal: 23.1, Action: Pass, Yards Gained: 8.0, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 15.0, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 1, Yards to First: 10.0, Yards to Goal: 15.0, Action: Pass, Yards Gained: 8.7, Turnover: False\n",
      "Down: 2, Yards to First: 1.3, Yards to Goal: 6.3, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 3, Yards to First: 1.3, Yards to Goal: 6.3, Action: Run, Yards Gained: 21.4, Turnover: False\n",
      "Touchdown\n",
      "Scoreboard:\n",
      "player 1 - 14\n",
      "player 2 - 0\n",
      "\n",
      "player 2 taking possession with 80.00 yards to go\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 80.0, Action: Pass, Yards Gained: 9.1, Turnover: False\n",
      "Down: 1, Yards to First: 0.9, Yards to Goal: 70.9, Action: Pass, Yards Gained: 18.7, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 52.2, Action: Pass, Yards Gained: 4.9, Turnover: False\n",
      "Down: 1, Yards to First: 5.1, Yards to Goal: 47.3, Action: Pass, Yards Gained: 10.3, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 36.9, Action: Pass, Yards Gained: 14.0, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 23.0, Action: Pass, Yards Gained: -4.2, Turnover: False\n",
      "Down: 1, Yards to First: 14.2, Yards to Goal: 27.2, Action: Pass, Yards Gained: 7.5, Turnover: False\n",
      "Down: 2, Yards to First: 6.7, Yards to Goal: 19.6, Action: Pass, Yards Gained: 12.7, Turnover: False\n",
      "Down: 0, Yards to First: 6.9, Yards to Goal: 6.9, Action: Run, Yards Gained: 0.6, Turnover: False\n",
      "Down: 1, Yards to First: 6.3, Yards to Goal: 6.3, Action: Pass, Yards Gained: 14.8, Turnover: False\n",
      "Touchdown\n",
      "Scoreboard:\n",
      "player 1 - 14\n",
      "player 2 - 7\n",
      "\n",
      "player 1 taking possession with 80.00 yards to go\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 80.0, Action: Pass, Yards Gained: 0.2, Turnover: False\n",
      "Down: 1, Yards to First: 9.8, Yards to Goal: 79.8, Action: Pass, Yards Gained: 7.0, Turnover: False\n",
      "Down: 2, Yards to First: 2.8, Yards to Goal: 72.8, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 3, Yards to First: 2.8, Yards to Goal: 72.8, Action: Pass, Yards Gained: 27.7, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 45.2, Action: Pass, Yards Gained: 1.6, Turnover: False\n",
      "Down: 1, Yards to First: 8.4, Yards to Goal: 43.6, Action: Pass, Yards Gained: 17.1, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 26.5, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 1, Yards to First: 10.0, Yards to Goal: 26.5, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 2, Yards to First: 10.0, Yards to Goal: 26.5, Action: Pass, Yards Gained: 6.6, Turnover: False\n",
      "Down: 3, Yards to First: 3.4, Yards to Goal: 19.9, Action: Pass, Yards Gained: 0.0, Turnover: True\n",
      "Turnover\n",
      "Scoreboard:\n",
      "player 1 - 14\n",
      "player 2 - 7\n",
      "\n",
      "player 2 taking possession with 80.10 yards to go\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 80.1, Action: Pass, Yards Gained: 11.4, Turnover: True\n",
      "Turnover\n",
      "Scoreboard:\n",
      "player 1 - 14\n",
      "player 2 - 7\n",
      "\n",
      "player 1 taking possession with 31.34 yards to go\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 31.3, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 1, Yards to First: 10.0, Yards to Goal: 31.3, Action: Pass, Yards Gained: -3.2, Turnover: False\n",
      "Down: 2, Yards to First: 13.2, Yards to Goal: 34.5, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 3, Yards to First: 13.2, Yards to Goal: 34.5, Action: Pass, Yards Gained: 0.0, Turnover: True\n",
      "Turnover\n",
      "Scoreboard:\n",
      "player 1 - 14\n",
      "player 2 - 7\n",
      "\n",
      "player 2 taking possession with 65.49 yards to go\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 65.5, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 1, Yards to First: 10.0, Yards to Goal: 65.5, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 2, Yards to First: 10.0, Yards to Goal: 65.5, Action: Pass, Yards Gained: 23.1, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 42.4, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 1, Yards to First: 10.0, Yards to Goal: 42.4, Action: Pass, Yards Gained: 27.2, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 15.2, Action: Pass, Yards Gained: -1.9, Turnover: False\n",
      "Down: 1, Yards to First: 11.9, Yards to Goal: 17.1, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 2, Yards to First: 11.9, Yards to Goal: 17.1, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 3, Yards to First: 11.9, Yards to Goal: 17.1, Action: Pass, Yards Gained: 5.4, Turnover: True\n",
      "Turnover\n",
      "Scoreboard:\n",
      "player 1 - 14\n",
      "player 2 - 7\n",
      "\n",
      "player 1 taking possession with 88.34 yards to go\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 88.3, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 1, Yards to First: 10.0, Yards to Goal: 88.3, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 2, Yards to First: 10.0, Yards to Goal: 88.3, Action: Pass, Yards Gained: -1.3, Turnover: False\n",
      "Down: 3, Yards to First: 11.3, Yards to Goal: 89.7, Action: Pass, Yards Gained: 20.5, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 69.2, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 1, Yards to First: 10.0, Yards to Goal: 69.2, Action: Pass, Yards Gained: -4.0, Turnover: False\n",
      "Down: 2, Yards to First: 14.0, Yards to Goal: 73.2, Action: Pass, Yards Gained: 9.9, Turnover: False\n",
      "Down: 3, Yards to First: 4.1, Yards to Goal: 63.3, Action: Pass, Yards Gained: 10.1, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 53.2, Action: Pass, Yards Gained: 0.1, Turnover: False\n",
      "Down: 1, Yards to First: 9.9, Yards to Goal: 53.1, Action: Pass, Yards Gained: 25.2, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 27.9, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 1, Yards to First: 10.0, Yards to Goal: 27.9, Action: Pass, Yards Gained: 11.3, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 16.6, Action: Pass, Yards Gained: 12.6, Turnover: False\n",
      "Down: 0, Yards to First: 4.0, Yards to Goal: 4.0, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 1, Yards to First: 4.0, Yards to Goal: 4.0, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 2, Yards to First: 4.0, Yards to Goal: 4.0, Action: Pass, Yards Gained: 9.2, Turnover: False\n",
      "Touchdown\n",
      "Scoreboard:\n",
      "player 1 - 21\n",
      "player 2 - 7\n",
      "\n",
      "player 2 taking possession with 80.00 yards to go\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 80.0, Action: Pass, Yards Gained: 1.9, Turnover: False\n",
      "Down: 1, Yards to First: 8.1, Yards to Goal: 78.1, Action: Pass, Yards Gained: 5.2, Turnover: False\n",
      "Down: 2, Yards to First: 2.9, Yards to Goal: 72.9, Action: Pass, Yards Gained: 26.3, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 46.5, Action: Pass, Yards Gained: 8.5, Turnover: False\n",
      "Down: 1, Yards to First: 1.5, Yards to Goal: 38.0, Action: Pass, Yards Gained: -3.7, Turnover: False\n",
      "Down: 2, Yards to First: 5.2, Yards to Goal: 41.7, Action: Pass, Yards Gained: 7.2, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 34.5, Action: Pass, Yards Gained: 4.3, Turnover: False\n",
      "Down: 1, Yards to First: 5.7, Yards to Goal: 30.2, Action: Pass, Yards Gained: 7.5, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 22.7, Action: Pass, Yards Gained: -3.1, Turnover: False\n",
      "Down: 1, Yards to First: 13.1, Yards to Goal: 25.8, Action: Pass, Yards Gained: -5.7, Turnover: False\n",
      "Down: 2, Yards to First: 18.8, Yards to Goal: 31.5, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 3, Yards to First: 18.8, Yards to Goal: 31.5, Action: Pass, Yards Gained: 35.2, Turnover: False\n",
      "Touchdown\n",
      "Scoreboard:\n",
      "player 1 - 21\n",
      "player 2 - 14\n",
      "\n",
      "player 1 taking possession with 80.00 yards to go\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 80.0, Action: Pass, Yards Gained: 23.9, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 56.1, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 1, Yards to First: 10.0, Yards to Goal: 56.1, Action: Pass, Yards Gained: 14.8, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 41.3, Action: Pass, Yards Gained: 3.9, Turnover: False\n",
      "Down: 1, Yards to First: 6.1, Yards to Goal: 37.5, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 2, Yards to First: 6.1, Yards to Goal: 37.5, Action: Pass, Yards Gained: 18.1, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 19.4, Action: Pass, Yards Gained: 0.8, Turnover: False\n",
      "Down: 1, Yards to First: 9.2, Yards to Goal: 18.6, Action: Pass, Yards Gained: -3.8, Turnover: False\n",
      "Down: 2, Yards to First: 13.0, Yards to Goal: 22.4, Action: Pass, Yards Gained: -2.9, Turnover: False\n",
      "Down: 3, Yards to First: 15.9, Yards to Goal: 25.3, Action: Pass, Yards Gained: 0.0, Turnover: True\n",
      "Turnover\n",
      "Scoreboard:\n",
      "player 1 - 21\n",
      "player 2 - 14\n",
      "\n",
      "player 2 taking possession with 74.71 yards to go\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 74.7, Action: Pass, Yards Gained: 5.1, Turnover: False\n",
      "Down: 1, Yards to First: 4.9, Yards to Goal: 69.7, Action: Pass, Yards Gained: 8.5, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 61.2, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 1, Yards to First: 10.0, Yards to Goal: 61.2, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 2, Yards to First: 10.0, Yards to Goal: 61.2, Action: Pass, Yards Gained: 24.1, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 37.0, Action: Pass, Yards Gained: 60.7, Turnover: False\n",
      "Touchdown\n",
      "Scoreboard:\n",
      "player 1 - 21\n",
      "player 2 - 21\n",
      "\n",
      "player 1 taking possession with 80.00 yards to go\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 80.0, Action: Pass, Yards Gained: 15.5, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 64.5, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 1, Yards to First: 10.0, Yards to Goal: 64.5, Action: Pass, Yards Gained: 26.4, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 38.1, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 1, Yards to First: 10.0, Yards to Goal: 38.1, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 2, Yards to First: 10.0, Yards to Goal: 38.1, Action: Pass, Yards Gained: -0.1, Turnover: False\n",
      "Down: 3, Yards to First: 10.1, Yards to Goal: 38.2, Action: Pass, Yards Gained: 0.0, Turnover: True\n",
      "Turnover\n",
      "Scoreboard:\n",
      "player 1 - 21\n",
      "player 2 - 21\n",
      "\n",
      "player 2 taking possession with 61.81 yards to go\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 61.8, Action: Pass, Yards Gained: 9.6, Turnover: False\n",
      "Down: 1, Yards to First: 0.4, Yards to Goal: 52.2, Action: Pass, Yards Gained: 6.4, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 45.8, Action: Pass, Yards Gained: 5.7, Turnover: False\n",
      "Down: 1, Yards to First: 4.3, Yards to Goal: 40.1, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 2, Yards to First: 4.3, Yards to Goal: 40.1, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 3, Yards to First: 4.3, Yards to Goal: 40.1, Action: Pass, Yards Gained: 22.0, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 18.1, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 1, Yards to First: 10.0, Yards to Goal: 18.1, Action: Pass, Yards Gained: 9.5, Turnover: False\n",
      "Down: 2, Yards to First: 0.5, Yards to Goal: 8.6, Action: Pass, Yards Gained: 10.5, Turnover: False\n",
      "Touchdown\n",
      "Scoreboard:\n",
      "player 1 - 21\n",
      "player 2 - 28\n",
      "\n",
      "player 1 taking possession with 80.00 yards to go\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 80.0, Action: Pass, Yards Gained: 2.7, Turnover: False\n",
      "Down: 1, Yards to First: 7.3, Yards to Goal: 77.3, Action: Pass, Yards Gained: 9.5, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 67.8, Action: Pass, Yards Gained: -6.5, Turnover: False\n",
      "Down: 1, Yards to First: 16.5, Yards to Goal: 74.3, Action: Pass, Yards Gained: 5.9, Turnover: False\n",
      "Down: 2, Yards to First: 10.6, Yards to Goal: 68.4, Action: Pass, Yards Gained: 5.1, Turnover: False\n",
      "Down: 3, Yards to First: 5.5, Yards to Goal: 63.3, Action: Pass, Yards Gained: 0.0, Turnover: True\n",
      "Turnover\n",
      "Scoreboard:\n",
      "player 1 - 21\n",
      "player 2 - 28\n",
      "\n",
      "player 2 taking possession with 36.67 yards to go\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 36.7, Action: Pass, Yards Gained: 7.4, Turnover: False\n",
      "Down: 1, Yards to First: 2.6, Yards to Goal: 29.3, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 2, Yards to First: 2.6, Yards to Goal: 29.3, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 3, Yards to First: 2.6, Yards to Goal: 29.3, Action: Pass, Yards Gained: 6.0, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 23.3, Action: Pass, Yards Gained: 5.1, Turnover: True\n",
      "Turnover\n",
      "Scoreboard:\n",
      "player 1 - 21\n",
      "player 2 - 28\n",
      "\n",
      "player 1 taking possession with 81.83 yards to go\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 81.8, Action: Pass, Yards Gained: 3.1, Turnover: False\n",
      "Down: 1, Yards to First: 6.9, Yards to Goal: 78.7, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 2, Yards to First: 6.9, Yards to Goal: 78.7, Action: Pass, Yards Gained: 11.3, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 67.4, Action: Pass, Yards Gained: 11.5, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 55.8, Action: Pass, Yards Gained: 0.5, Turnover: False\n",
      "Down: 1, Yards to First: 9.5, Yards to Goal: 55.3, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 2, Yards to First: 9.5, Yards to Goal: 55.3, Action: Pass, Yards Gained: 4.4, Turnover: True\n",
      "Turnover\n",
      "Scoreboard:\n",
      "player 1 - 21\n",
      "player 2 - 28\n",
      "\n",
      "player 2 taking possession with 49.04 yards to go\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 49.0, Action: Pass, Yards Gained: 35.0, Turnover: False\n",
      "Down: 0, Yards to First: 10.0, Yards to Goal: 14.0, Action: Pass, Yards Gained: 3.9, Turnover: False\n",
      "Down: 1, Yards to First: 6.1, Yards to Goal: 10.1, Action: Pass, Yards Gained: 2.8, Turnover: False\n",
      "Down: 2, Yards to First: 3.3, Yards to Goal: 7.4, Action: Pass, Yards Gained: 0.0, Turnover: False\n",
      "Down: 3, Yards to First: 3.3, Yards to Goal: 7.4, Action: Pass, Yards Gained: 0.8, Turnover: True\n",
      "Turnover\n",
      "Scoreboard:\n",
      "player 1 - 21\n",
      "player 2 - 28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "play_game(env=NflEnv(), model_1=ppo_model, model_2=ppo_vec_model, possessions=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
